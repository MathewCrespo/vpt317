[09/23 03:08:41][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 03:08:41][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 03:08:41][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/23 03:08:41][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 03:08:41][INFO] visual_prompt:  109: Training with config:
[09/23 03:08:41][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr2.5_wd0.001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 2.5,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 03:08:41][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 03:08:41][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 03:08:41][INFO] visual_prompt:   77: Number of images: 5394
[09/23 03:08:41][INFO] visual_prompt:   78: Number of classes: 200
[09/23 03:08:41][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 03:08:41][INFO] visual_prompt:   73: Loading validation data...
[09/23 03:08:41][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 03:08:41][INFO] visual_prompt:   77: Number of images: 600
[09/23 03:08:41][INFO] visual_prompt:   78: Number of classes: 200
[09/23 03:08:41][INFO] visual_prompt:   76: Loading test data...
[09/23 03:08:41][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 03:08:41][INFO] visual_prompt:   77: Number of images: 5794
[09/23 03:08:41][INFO] visual_prompt:   78: Number of classes: 200
[09/23 03:08:41][INFO] visual_prompt:  103: Constructing models...
[09/23 03:08:46][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 03:08:46][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 03:08:46][INFO] visual_prompt:   41: Device used for model: 0
[09/23 03:08:46][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 03:08:46][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 03:08:46][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 03:08:46][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/23 03:09:54][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.86e-02, avg batch time: 0.8020, average train loss: 5.3341average G loss: 7.0917, average realD loss: 11.8067, average fakeD loss: 0.5273, 
[09/23 03:09:57][INFO] visual_prompt:  435: Inference (val):avg data time: 8.28e-05, avg batch time: 0.1211, average loss: 5.3300
[09/23 03:09:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 03:10:11][INFO] visual_prompt:  435: Inference (test):avg data time: 1.03e-04, avg batch time: 0.1275, average loss: 5.3324
[09/23 03:10:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 2.49	
[09/23 03:10:11][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.005
[09/23 03:10:11][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.25
[09/23 03:11:19][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.88e-02, avg batch time: 0.7989, average train loss: 5.3580average G loss: 0.0000, average realD loss: 0.3741, average fakeD loss: 10.5066, 
[09/23 03:11:21][INFO] visual_prompt:  435: Inference (val):avg data time: 8.16e-05, avg batch time: 0.1209, average loss: 5.3229
[09/23 03:11:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 03:11:35][INFO] visual_prompt:  435: Inference (test):avg data time: 6.72e-05, avg batch time: 0.1281, average loss: 5.3228
[09/23 03:11:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.64	
[09/23 03:11:35][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.5
[09/23 03:12:43][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.89e-02, avg batch time: 0.7992, average train loss: 5.3840average G loss: 0.0000, average realD loss: 0.0700, average fakeD loss: 0.1673, 
[09/23 03:12:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.15e-05, avg batch time: 0.1219, average loss: 5.2856
[09/23 03:12:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.17	
[09/23 03:12:58][INFO] visual_prompt:  435: Inference (test):avg data time: 7.75e-05, avg batch time: 0.1281, average loss: 5.2828
[09/23 03:12:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.45	top5: 2.87	
[09/23 03:12:58][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.75
[09/23 03:14:06][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.75e-02, avg batch time: 0.7974, average train loss: 5.4026average G loss: 0.0133, average realD loss: 0.0648, average fakeD loss: 0.0486, 
[09/23 03:14:09][INFO] visual_prompt:  435: Inference (val):avg data time: 4.44e-05, avg batch time: 0.1208, average loss: 5.4190
[09/23 03:14:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 03:14:22][INFO] visual_prompt:  435: Inference (test):avg data time: 8.28e-05, avg batch time: 0.1276, average loss: 5.4172
[09/23 03:14:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.54	
[09/23 03:14:22][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 1.0
[09/23 03:15:30][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.95e-02, avg batch time: 0.8036, average train loss: 5.4284average G loss: 0.0004, average realD loss: 0.0206, average fakeD loss: 0.0257, 
[09/23 03:15:33][INFO] visual_prompt:  435: Inference (val):avg data time: 6.00e-05, avg batch time: 0.1208, average loss: 5.3789
[09/23 03:15:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 03:15:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1277, average loss: 5.3802
[09/23 03:15:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.55	
[09/23 03:15:47][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 1.25
[09/23 03:16:55][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.96e-02, avg batch time: 0.8027, average train loss: 4.1247average G loss: 0.0059, average realD loss: 0.0284, average fakeD loss: 0.0340, 
[09/23 03:16:57][INFO] visual_prompt:  435: Inference (val):avg data time: 7.17e-05, avg batch time: 0.1208, average loss: 1.1307
[09/23 03:16:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 92.83	
[09/23 03:17:11][INFO] visual_prompt:  435: Inference (test):avg data time: 8.01e-05, avg batch time: 0.1277, average loss: 1.1733
[09/23 03:17:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.61	top5: 92.82	
[09/23 03:17:11][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.683
[09/23 03:17:11][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 1.5
[09/23 03:18:19][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.83e-02, avg batch time: 0.8010, average train loss: 1.3674average G loss: 0.0103, average realD loss: 0.0337, average fakeD loss: 0.0373, 
[09/23 03:18:21][INFO] visual_prompt:  435: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1196, average loss: 1.3452
[09/23 03:18:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.50	top5: 90.00	
[09/23 03:18:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.30e-05, avg batch time: 0.1278, average loss: 1.3521
[09/23 03:18:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.98	top5: 90.97	
[09/23 03:18:35][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 1.75
[09/23 03:19:43][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.96e-02, avg batch time: 0.8024, average train loss: 1.4988average G loss: 0.0107, average realD loss: 0.0364, average fakeD loss: 0.0410, 
[09/23 03:19:46][INFO] visual_prompt:  435: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1205, average loss: 1.3626
[09/23 03:19:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.83	top5: 90.83	
[09/23 03:19:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.37e-05, avg batch time: 0.1272, average loss: 1.3603
[09/23 03:19:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.00	top5: 90.32	
[09/23 03:19:59][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 2.0
[09/23 03:21:08][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.94e-02, avg batch time: 0.8022, average train loss: 1.6171average G loss: 0.0111, average realD loss: 0.0338, average fakeD loss: 0.0376, 
[09/23 03:21:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.82e-05, avg batch time: 0.1200, average loss: 1.4536
[09/23 03:21:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.00	top5: 88.67	
[09/23 03:21:24][INFO] visual_prompt:  435: Inference (test):avg data time: 6.53e-05, avg batch time: 0.1271, average loss: 1.4726
[09/23 03:21:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.00	top5: 89.21	
[09/23 03:21:24][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 2.25
[09/23 03:22:32][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.94e-02, avg batch time: 0.8019, average train loss: 1.7767average G loss: 0.0142, average realD loss: 0.0437, average fakeD loss: 0.0494, 
[09/23 03:22:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.74e-05, avg batch time: 0.1200, average loss: 1.7314
[09/23 03:22:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.50	top5: 86.83	
[09/23 03:22:48][INFO] visual_prompt:  435: Inference (test):avg data time: 8.45e-05, avg batch time: 0.1273, average loss: 1.6747
[09/23 03:22:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.57	top5: 86.90	
[09/23 03:22:48][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 2.5
[09/23 03:23:57][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 2.00e-02, avg batch time: 0.8029, average train loss: 2.0088average G loss: 0.0148, average realD loss: 0.0455, average fakeD loss: 0.0510, 
[09/23 03:23:59][INFO] visual_prompt:  435: Inference (val):avg data time: 6.98e-05, avg batch time: 0.1199, average loss: 1.6959
[09/23 03:23:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.00	top5: 86.83	
[09/23 03:24:13][INFO] visual_prompt:  435: Inference (test):avg data time: 8.36e-05, avg batch time: 0.1274, average loss: 1.7152
[09/23 03:24:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.58	top5: 85.86	
[09/23 03:24:13][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/23 03:25:21][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.86e-02, avg batch time: 0.8013, average train loss: 2.0562average G loss: 0.0180, average realD loss: 0.0537, average fakeD loss: 0.0616, 
[09/23 03:25:23][INFO] visual_prompt:  435: Inference (val):avg data time: 7.25e-05, avg batch time: 0.1197, average loss: 3.8433
[09/23 03:25:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 20.00	top5: 39.33	
[09/23 03:25:37][INFO] visual_prompt:  435: Inference (test):avg data time: 7.64e-05, avg batch time: 0.1273, average loss: 3.8198
[09/23 03:25:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 21.76	top5: 42.44	
[09/23 03:25:37][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/23 03:26:45][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.75e-02, avg batch time: 0.7994, average train loss: 1.9005average G loss: 0.0120, average realD loss: 0.0465, average fakeD loss: 0.0557, 
[09/23 03:26:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1211, average loss: 1.7417
[09/23 03:26:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 59.67	top5: 85.50	
[09/23 03:27:01][INFO] visual_prompt:  435: Inference (test):avg data time: 7.83e-05, avg batch time: 0.1273, average loss: 1.7704
[09/23 03:27:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 59.98	top5: 86.24	
[09/23 03:27:01][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/23 03:28:09][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 2.01e-02, avg batch time: 0.8017, average train loss: 2.0216average G loss: 0.0149, average realD loss: 0.0502, average fakeD loss: 0.0628, 
[09/23 03:28:12][INFO] visual_prompt:  435: Inference (val):avg data time: 5.59e-05, avg batch time: 0.1209, average loss: 1.9617
[09/23 03:28:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 55.00	top5: 81.67	
[09/23 03:28:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1273, average loss: 1.9988
[09/23 03:28:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 55.54	top5: 82.69	
[09/23 03:28:25][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/23 03:29:33][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.75e-02, avg batch time: 0.7990, average train loss: 1.9998average G loss: 0.0146, average realD loss: 0.0461, average fakeD loss: 0.0556, 
[09/23 03:29:35][INFO] visual_prompt:  435: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1198, average loss: 1.7116
[09/23 03:29:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 57.00	top5: 86.17	
[09/23 03:29:49][INFO] visual_prompt:  435: Inference (test):avg data time: 7.97e-05, avg batch time: 0.1272, average loss: 1.6926
[09/23 03:29:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 59.54	top5: 87.28	
[09/23 03:29:49][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/23 03:30:57][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.77e-02, avg batch time: 0.7987, average train loss: 2.0350average G loss: 0.0159, average realD loss: 0.0599, average fakeD loss: 0.0658, 
[09/23 03:30:59][INFO] visual_prompt:  435: Inference (val):avg data time: 6.65e-05, avg batch time: 0.1202, average loss: 2.7115
[09/23 03:30:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 45.17	top5: 73.17	
[09/23 03:31:13][INFO] visual_prompt:  435: Inference (test):avg data time: 6.51e-05, avg batch time: 0.1274, average loss: 2.6916
[09/23 03:31:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 46.50	top5: 75.15	
[09/23 03:31:13][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/23 03:32:21][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.72e-02, avg batch time: 0.7984, average train loss: 2.0613average G loss: 0.0138, average realD loss: 0.0556, average fakeD loss: 0.0632, 
[09/23 03:32:23][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1198, average loss: 1.6963
[09/23 03:32:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.00	top5: 88.33	
[09/23 03:32:37][INFO] visual_prompt:  435: Inference (test):avg data time: 9.43e-05, avg batch time: 0.1272, average loss: 1.7288
[09/23 03:32:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.04	top5: 87.06	
[09/23 03:32:37][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/23 03:33:45][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.83e-02, avg batch time: 0.7998, average train loss: 1.9307average G loss: 0.0162, average realD loss: 0.0486, average fakeD loss: 0.0595, 
[09/23 03:33:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1198, average loss: 1.4409
[09/23 03:33:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.17	top5: 91.50	
[09/23 03:34:01][INFO] visual_prompt:  435: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1273, average loss: 1.4753
[09/23 03:34:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.39	top5: 90.80	
[09/23 03:34:01][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/23 03:35:09][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.79e-02, avg batch time: 0.7996, average train loss: 1.7735average G loss: 0.0139, average realD loss: 0.0483, average fakeD loss: 0.0491, 
[09/23 03:35:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1205, average loss: 1.7426
[09/23 03:35:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.50	top5: 87.00	
[09/23 03:35:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.62e-05, avg batch time: 0.1270, average loss: 1.7642
[09/23 03:35:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.36	top5: 85.50	
[09/23 03:35:25][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/23 03:36:33][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.85e-02, avg batch time: 0.8006, average train loss: 1.9067average G loss: 0.0162, average realD loss: 0.0466, average fakeD loss: 0.0574, 
[09/23 03:36:35][INFO] visual_prompt:  435: Inference (val):avg data time: 6.84e-05, avg batch time: 0.1199, average loss: 1.9792
[09/23 03:36:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 56.17	top5: 81.17	
[09/23 03:36:49][INFO] visual_prompt:  435: Inference (test):avg data time: 8.69e-05, avg batch time: 0.1274, average loss: 1.9454
[09/23 03:36:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 56.68	top5: 81.84	
[09/23 03:36:49][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/23 03:37:57][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.89e-02, avg batch time: 0.8014, average train loss: 1.9267average G loss: 0.0139, average realD loss: 0.0458, average fakeD loss: 0.0516, 
[09/23 03:37:59][INFO] visual_prompt:  435: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1209, average loss: 2.6521
[09/23 03:37:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 47.67	top5: 73.67	
[09/23 03:38:13][INFO] visual_prompt:  435: Inference (test):avg data time: 6.87e-05, avg batch time: 0.1271, average loss: 2.6499
[09/23 03:38:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 50.40	top5: 73.89	
[09/23 03:38:13][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/23 03:39:21][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.95e-02, avg batch time: 0.8019, average train loss: 1.8292average G loss: 0.0126, average realD loss: 0.0422, average fakeD loss: 0.0462, 
[09/23 03:39:24][INFO] visual_prompt:  435: Inference (val):avg data time: 5.52e-05, avg batch time: 0.1206, average loss: 1.7098
[09/23 03:39:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.17	top5: 86.33	
[09/23 03:39:37][INFO] visual_prompt:  435: Inference (test):avg data time: 7.59e-05, avg batch time: 0.1272, average loss: 1.7179
[09/23 03:39:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.65	top5: 86.64	
[09/23 03:39:38][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/23 03:40:46][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.80e-02, avg batch time: 0.8001, average train loss: 1.8862average G loss: 0.0160, average realD loss: 0.0555, average fakeD loss: 0.0644, 
[09/23 03:40:48][INFO] visual_prompt:  435: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1201, average loss: 1.6138
[09/23 03:40:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.00	top5: 86.83	
[09/23 03:41:02][INFO] visual_prompt:  435: Inference (test):avg data time: 6.85e-05, avg batch time: 0.1268, average loss: 1.6329
[09/23 03:41:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.63	top5: 87.97	
[09/23 03:41:02][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/23 03:42:10][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.77e-02, avg batch time: 0.8000, average train loss: 1.8650average G loss: 0.0140, average realD loss: 0.0435, average fakeD loss: 0.0512, 
[09/23 03:42:12][INFO] visual_prompt:  435: Inference (val):avg data time: 4.92e-05, avg batch time: 0.1207, average loss: 1.8281
[09/23 03:42:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 59.33	top5: 84.00	
[09/23 03:42:26][INFO] visual_prompt:  435: Inference (test):avg data time: 6.87e-05, avg batch time: 0.1270, average loss: 1.8751
[09/23 03:42:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 59.51	top5: 84.16	
[09/23 03:42:26][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/23 03:43:34][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.77e-02, avg batch time: 0.7998, average train loss: 1.8427average G loss: 0.0138, average realD loss: 0.0442, average fakeD loss: 0.0469, 
[09/23 03:43:36][INFO] visual_prompt:  435: Inference (val):avg data time: 8.94e-05, avg batch time: 0.1200, average loss: 1.4013
[09/23 03:43:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.33	top5: 92.00	
[09/23 03:43:50][INFO] visual_prompt:  435: Inference (test):avg data time: 6.81e-05, avg batch time: 0.1274, average loss: 1.3597
[09/23 03:43:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.48	top5: 91.03	
[09/23 03:43:50][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/23 03:44:58][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.94e-02, avg batch time: 0.8014, average train loss: 1.7293average G loss: 0.0130, average realD loss: 0.0430, average fakeD loss: 0.0495, 
[09/23 03:45:00][INFO] visual_prompt:  435: Inference (val):avg data time: 6.74e-05, avg batch time: 0.1199, average loss: 1.7315
[09/23 03:45:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.83	top5: 85.17	
[09/23 03:45:13][INFO] visual_prompt:  435: Inference (test):avg data time: 8.92e-05, avg batch time: 0.1279, average loss: 1.7102
[09/23 03:45:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.94	top5: 86.24	
[09/23 03:45:14][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/23 03:46:22][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.87e-02, avg batch time: 0.8003, average train loss: 1.8015average G loss: 0.0139, average realD loss: 0.0485, average fakeD loss: 0.0552, 
[09/23 03:46:24][INFO] visual_prompt:  435: Inference (val):avg data time: 7.93e-05, avg batch time: 0.1195, average loss: 1.6662
[09/23 03:46:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.50	top5: 86.50	
[09/23 03:46:38][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1269, average loss: 1.6591
[09/23 03:46:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.89	top5: 87.31	
[09/23 03:46:38][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/23 03:47:46][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.79e-02, avg batch time: 0.7994, average train loss: 1.6936average G loss: 0.0136, average realD loss: 0.0425, average fakeD loss: 0.0498, 
[09/23 03:47:48][INFO] visual_prompt:  435: Inference (val):avg data time: 1.17e-04, avg batch time: 0.1207, average loss: 1.7551
[09/23 03:47:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.33	top5: 87.50	
[09/23 03:48:02][INFO] visual_prompt:  435: Inference (test):avg data time: 7.36e-05, avg batch time: 0.1271, average loss: 1.6975
[09/23 03:48:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 62.79	top5: 87.83	
[09/23 03:48:02][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/23 03:49:10][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.86e-02, avg batch time: 0.8001, average train loss: 1.8432average G loss: 0.0146, average realD loss: 0.0454, average fakeD loss: 0.0509, 
[09/23 03:49:12][INFO] visual_prompt:  435: Inference (val):avg data time: 7.36e-05, avg batch time: 0.1200, average loss: 1.8420
[09/23 03:49:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.50	top5: 86.33	
[09/23 03:49:26][INFO] visual_prompt:  435: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1272, average loss: 1.7994
[09/23 03:49:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.15	top5: 87.16	
[09/23 03:49:26][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/23 03:50:34][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.87e-02, avg batch time: 0.8008, average train loss: 1.9016average G loss: 0.0134, average realD loss: 0.0564, average fakeD loss: 0.0617, 
[09/23 03:50:36][INFO] visual_prompt:  435: Inference (val):avg data time: 6.51e-05, avg batch time: 0.1208, average loss: 1.8231
[09/23 03:50:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 58.67	top5: 85.50	
[09/23 03:50:50][INFO] visual_prompt:  435: Inference (test):avg data time: 8.89e-05, avg batch time: 0.1274, average loss: 1.8296
[09/23 03:50:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 58.46	top5: 84.24	
[09/23 03:50:50][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/23 03:51:58][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.76e-02, avg batch time: 0.8000, average train loss: 1.7793average G loss: 0.0150, average realD loss: 0.0452, average fakeD loss: 0.0531, 
[09/23 03:52:00][INFO] visual_prompt:  435: Inference (val):avg data time: 6.67e-05, avg batch time: 0.1203, average loss: 1.7119
[09/23 03:52:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.00	top5: 86.00	
[09/23 03:52:14][INFO] visual_prompt:  435: Inference (test):avg data time: 8.77e-05, avg batch time: 0.1275, average loss: 1.6585
[09/23 03:52:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 62.94	top5: 85.83	
[09/23 03:52:14][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/23 03:53:22][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.83e-02, avg batch time: 0.8015, average train loss: 1.6656average G loss: 0.0125, average realD loss: 0.0374, average fakeD loss: 0.0407, 
[09/23 03:53:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.21e-05, avg batch time: 0.1202, average loss: 1.5372
[09/23 03:53:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.33	top5: 90.00	
[09/23 03:53:38][INFO] visual_prompt:  435: Inference (test):avg data time: 7.47e-05, avg batch time: 0.1274, average loss: 1.5235
[09/23 03:53:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.14	top5: 89.06	
[09/23 03:53:38][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/23 03:54:47][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.79e-02, avg batch time: 0.8009, average train loss: 1.6884average G loss: 0.0140, average realD loss: 0.0418, average fakeD loss: 0.0512, 
[09/23 03:54:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.00e-05, avg batch time: 0.1194, average loss: 1.4723
[09/23 03:54:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.00	top5: 89.17	
[09/23 03:55:02][INFO] visual_prompt:  435: Inference (test):avg data time: 8.53e-05, avg batch time: 0.1274, average loss: 1.4488
[09/23 03:55:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.64	top5: 89.28	
[09/23 03:55:03][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/23 03:56:11][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.74e-02, avg batch time: 0.8000, average train loss: 1.6875average G loss: 0.0145, average realD loss: 0.0400, average fakeD loss: 0.0432, 
[09/23 03:56:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1205, average loss: 1.3406
[09/23 03:56:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.67	top5: 91.83	
[09/23 03:56:26][INFO] visual_prompt:  435: Inference (test):avg data time: 9.19e-05, avg batch time: 0.1272, average loss: 1.3957
[09/23 03:56:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.15	top5: 90.75	
[09/23 03:56:27][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/23 03:57:35][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.75e-02, avg batch time: 0.7997, average train loss: 1.6647average G loss: 0.0124, average realD loss: 0.0366, average fakeD loss: 0.0446, 
[09/23 03:57:37][INFO] visual_prompt:  435: Inference (val):avg data time: 5.08e-05, avg batch time: 0.1196, average loss: 1.4040
[09/23 03:57:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.17	top5: 89.17	
[09/23 03:57:51][INFO] visual_prompt:  435: Inference (test):avg data time: 8.09e-05, avg batch time: 0.1268, average loss: 1.3859
[09/23 03:57:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.52	top5: 89.07	
[09/23 03:57:51][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/23 03:58:59][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.81e-02, avg batch time: 0.8004, average train loss: 1.9976average G loss: 0.0125, average realD loss: 0.0460, average fakeD loss: 0.0478, 
[09/23 03:59:01][INFO] visual_prompt:  435: Inference (val):avg data time: 7.52e-05, avg batch time: 0.1197, average loss: 1.5558
[09/23 03:59:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.83	top5: 90.00	
[09/23 03:59:15][INFO] visual_prompt:  435: Inference (test):avg data time: 9.42e-05, avg batch time: 0.1272, average loss: 1.5966
[09/23 03:59:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.98	top5: 88.49	
[09/23 03:59:15][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/23 04:00:24][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.97e-02, avg batch time: 0.8022, average train loss: 1.6347average G loss: 0.0111, average realD loss: 0.0356, average fakeD loss: 0.0456, 
[09/23 04:00:26][INFO] visual_prompt:  435: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1212, average loss: 1.7091
[09/23 04:00:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.67	top5: 87.00	
[09/23 04:00:40][INFO] visual_prompt:  435: Inference (test):avg data time: 7.93e-05, avg batch time: 0.1270, average loss: 1.6732
[09/23 04:00:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.60	top5: 87.97	
[09/23 04:00:40][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/23 04:01:48][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.89e-02, avg batch time: 0.8016, average train loss: 1.7768average G loss: 0.0129, average realD loss: 0.0484, average fakeD loss: 0.0540, 
[09/23 04:01:50][INFO] visual_prompt:  435: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1211, average loss: 1.4582
[09/23 04:01:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.33	top5: 90.50	
[09/23 04:02:04][INFO] visual_prompt:  435: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1271, average loss: 1.4293
[09/23 04:02:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.12	top5: 91.04	
[09/23 04:02:04][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/23 04:03:12][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 1.86e-02, avg batch time: 0.8011, average train loss: 1.5636average G loss: 0.0114, average realD loss: 0.0344, average fakeD loss: 0.0395, 
[09/23 04:03:14][INFO] visual_prompt:  435: Inference (val):avg data time: 7.06e-05, avg batch time: 0.1205, average loss: 1.3875
[09/23 04:03:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.67	top5: 91.67	
[09/23 04:03:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.77e-05, avg batch time: 0.1277, average loss: 1.3479
[09/23 04:03:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.36	top5: 92.49	
[09/23 04:03:28][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/23 04:04:36][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.95e-02, avg batch time: 0.8020, average train loss: 1.6295average G loss: 0.0127, average realD loss: 0.0351, average fakeD loss: 0.0433, 
[09/23 04:04:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.01e-05, avg batch time: 0.1200, average loss: 1.4286
[09/23 04:04:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.17	top5: 91.50	
[09/23 04:04:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.30e-05, avg batch time: 0.1272, average loss: 1.3751
[09/23 04:04:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.28	top5: 91.42	
[09/23 04:04:52][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 1.875
[09/23 04:06:00][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.78e-02, avg batch time: 0.8001, average train loss: 1.6121average G loss: 0.0110, average realD loss: 0.0348, average fakeD loss: 0.0388, 
[09/23 04:06:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.00e-05, avg batch time: 0.1202, average loss: 1.5407
[09/23 04:06:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.67	top5: 90.50	
[09/23 04:06:16][INFO] visual_prompt:  435: Inference (test):avg data time: 7.85e-05, avg batch time: 0.1271, average loss: 1.4546
[09/23 04:06:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.67	top5: 90.25	
[09/23 04:06:16][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/23 04:07:25][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 1.91e-02, avg batch time: 0.8010, average train loss: 1.5066average G loss: 0.0115, average realD loss: 0.0361, average fakeD loss: 0.0414, 
[09/23 04:07:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1197, average loss: 1.4307
[09/23 04:07:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.17	top5: 92.17	
[09/23 04:07:40][INFO] visual_prompt:  435: Inference (test):avg data time: 6.32e-05, avg batch time: 0.1278, average loss: 1.4568
[09/23 04:07:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.65	top5: 92.01	
[09/23 04:07:40][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/23 04:08:48][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.86e-02, avg batch time: 0.8002, average train loss: 1.5307average G loss: 0.0108, average realD loss: 0.0362, average fakeD loss: 0.0384, 
[09/23 04:08:51][INFO] visual_prompt:  435: Inference (val):avg data time: 5.33e-05, avg batch time: 0.1210, average loss: 1.4424
[09/23 04:08:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.83	top5: 91.50	
[09/23 04:09:04][INFO] visual_prompt:  435: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1272, average loss: 1.4394
[09/23 04:09:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.91	top5: 90.65	
[09/23 04:09:04][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/23 04:10:12][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 1.74e-02, avg batch time: 0.7995, average train loss: 1.4578average G loss: 0.0121, average realD loss: 0.0358, average fakeD loss: 0.0374, 
[09/23 04:10:15][INFO] visual_prompt:  435: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1199, average loss: 1.5842
[09/23 04:10:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.17	top5: 87.33	
[09/23 04:10:28][INFO] visual_prompt:  435: Inference (test):avg data time: 8.46e-05, avg batch time: 0.1271, average loss: 1.5436
[09/23 04:10:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.31	top5: 89.25	
[09/23 04:10:28][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/23 04:11:37][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.79e-02, avg batch time: 0.8003, average train loss: 1.5186average G loss: 0.0127, average realD loss: 0.0392, average fakeD loss: 0.0460, 
[09/23 04:11:39][INFO] visual_prompt:  435: Inference (val):avg data time: 5.60e-05, avg batch time: 0.1201, average loss: 1.3010
[09/23 04:11:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.67	top5: 90.00	
[09/23 04:11:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.44e-05, avg batch time: 0.1274, average loss: 1.3050
[09/23 04:11:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.42	top5: 90.89	
[09/23 04:11:53][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/23 04:13:01][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 1.71e-02, avg batch time: 0.8002, average train loss: 1.4073average G loss: 0.0111, average realD loss: 0.0321, average fakeD loss: 0.0352, 
[09/23 04:13:03][INFO] visual_prompt:  435: Inference (val):avg data time: 5.61e-05, avg batch time: 0.1197, average loss: 1.4034
[09/23 04:13:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.33	top5: 89.67	
[09/23 04:13:17][INFO] visual_prompt:  435: Inference (test):avg data time: 7.85e-05, avg batch time: 0.1273, average loss: 1.3712
[09/23 04:13:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.12	top5: 90.99	
[09/23 04:13:17][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/23 04:14:25][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 1.81e-02, avg batch time: 0.8017, average train loss: 1.3718average G loss: 0.0104, average realD loss: 0.0303, average fakeD loss: 0.0325, 
[09/23 04:14:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.37e-05, avg batch time: 0.1202, average loss: 1.2456
[09/23 04:14:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.00	top5: 91.67	
[09/23 04:14:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.80e-05, avg batch time: 0.1275, average loss: 1.2924
[09/23 04:14:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.07	top5: 91.23	
[09/23 04:14:41][INFO] visual_prompt:  357: Best epoch 47: best metric: 0.690
[09/23 04:14:41][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/23 04:15:49][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.97e-02, avg batch time: 0.8037, average train loss: 1.3691average G loss: 0.0099, average realD loss: 0.0303, average fakeD loss: 0.0344, 
[09/23 04:15:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.39e-05, avg batch time: 0.1201, average loss: 1.1754
[09/23 04:15:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.17	top5: 93.33	
[09/23 04:16:06][INFO] visual_prompt:  435: Inference (test):avg data time: 6.46e-05, avg batch time: 0.1272, average loss: 1.1682
[09/23 04:16:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.52	top5: 93.36	
[09/23 04:16:06][INFO] visual_prompt:  357: Best epoch 48: best metric: 0.712
[09/23 04:16:06][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/23 04:17:14][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.79e-02, avg batch time: 0.8021, average train loss: 1.3161average G loss: 0.0103, average realD loss: 0.0313, average fakeD loss: 0.0354, 
[09/23 04:17:16][INFO] visual_prompt:  435: Inference (val):avg data time: 7.57e-05, avg batch time: 0.1206, average loss: 1.1941
[09/23 04:17:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.50	top5: 93.00	
[09/23 04:17:30][INFO] visual_prompt:  435: Inference (test):avg data time: 7.54e-05, avg batch time: 0.1275, average loss: 1.2245
[09/23 04:17:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.87	top5: 93.46	
[09/23 04:17:30][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/23 04:18:38][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 1.85e-02, avg batch time: 0.8028, average train loss: 1.4462average G loss: 0.0109, average realD loss: 0.0368, average fakeD loss: 0.0426, 
[09/23 04:18:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.37e-05, avg batch time: 0.1205, average loss: 1.2124
[09/23 04:18:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.50	top5: 93.00	
[09/23 04:18:54][INFO] visual_prompt:  435: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1275, average loss: 1.2049
[09/23 04:18:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.88	top5: 93.30	
[09/23 04:18:54][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/23 04:20:03][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.84e-02, avg batch time: 0.8031, average train loss: 1.2449average G loss: 0.0088, average realD loss: 0.0303, average fakeD loss: 0.0305, 
[09/23 04:20:05][INFO] visual_prompt:  435: Inference (val):avg data time: 6.88e-05, avg batch time: 0.1205, average loss: 1.2372
[09/23 04:20:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.33	top5: 93.33	
[09/23 04:20:18][INFO] visual_prompt:  435: Inference (test):avg data time: 8.89e-05, avg batch time: 0.1280, average loss: 1.2774
[09/23 04:20:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.95	top5: 92.70	
[09/23 04:20:19][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/23 04:21:27][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.97e-02, avg batch time: 0.8049, average train loss: 1.2869average G loss: 0.0099, average realD loss: 0.0299, average fakeD loss: 0.0322, 
[09/23 04:21:29][INFO] visual_prompt:  435: Inference (val):avg data time: 7.29e-05, avg batch time: 0.1200, average loss: 1.2487
[09/23 04:21:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 92.83	
[09/23 04:21:43][INFO] visual_prompt:  435: Inference (test):avg data time: 7.58e-05, avg batch time: 0.1276, average loss: 1.2361
[09/23 04:21:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.57	top5: 92.99	
[09/23 04:21:43][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/23 04:22:51][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.75e-02, avg batch time: 0.8027, average train loss: 1.3430average G loss: 0.0107, average realD loss: 0.0358, average fakeD loss: 0.0425, 
[09/23 04:22:54][INFO] visual_prompt:  435: Inference (val):avg data time: 4.76e-05, avg batch time: 0.1209, average loss: 1.0934
[09/23 04:22:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.33	top5: 95.00	
[09/23 04:23:07][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1281, average loss: 1.0904
[09/23 04:23:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.06	top5: 95.62	
[09/23 04:23:07][INFO] visual_prompt:  357: Best epoch 53: best metric: 0.713
[09/23 04:23:07][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/23 04:24:16][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.98e-02, avg batch time: 0.8053, average train loss: 1.2677average G loss: 0.0088, average realD loss: 0.0303, average fakeD loss: 0.0300, 
[09/23 04:24:18][INFO] visual_prompt:  435: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1200, average loss: 1.1346
[09/23 04:24:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.50	top5: 93.83	
[09/23 04:24:32][INFO] visual_prompt:  435: Inference (test):avg data time: 6.99e-05, avg batch time: 0.1277, average loss: 1.1455
[09/23 04:24:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.23	top5: 94.18	
[09/23 04:24:32][INFO] visual_prompt:  357: Best epoch 54: best metric: 0.715
[09/23 04:24:32][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/23 04:25:41][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.91e-02, avg batch time: 0.8049, average train loss: 1.1920average G loss: 0.0097, average realD loss: 0.0305, average fakeD loss: 0.0319, 
[09/23 04:25:43][INFO] visual_prompt:  435: Inference (val):avg data time: 8.43e-05, avg batch time: 0.1205, average loss: 1.0766
[09/23 04:25:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.00	top5: 95.50	
[09/23 04:25:57][INFO] visual_prompt:  435: Inference (test):avg data time: 7.34e-05, avg batch time: 0.1274, average loss: 1.0746
[09/23 04:25:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.94	top5: 95.15	
[09/23 04:25:57][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 1.25
[09/23 04:27:06][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 1.91e-02, avg batch time: 0.8050, average train loss: 1.3653average G loss: 0.0083, average realD loss: 0.0302, average fakeD loss: 0.0338, 
[09/23 04:27:08][INFO] visual_prompt:  435: Inference (val):avg data time: 5.96e-05, avg batch time: 0.1213, average loss: 1.0867
[09/23 04:27:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.50	top5: 94.83	
[09/23 04:27:22][INFO] visual_prompt:  435: Inference (test):avg data time: 9.32e-05, avg batch time: 0.1279, average loss: 1.1077
[09/23 04:27:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.80	top5: 95.18	
[09/23 04:27:22][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/23 04:28:31][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.94e-02, avg batch time: 0.8058, average train loss: 1.1881average G loss: 0.0089, average realD loss: 0.0285, average fakeD loss: 0.0326, 
[09/23 04:28:33][INFO] visual_prompt:  435: Inference (val):avg data time: 5.62e-05, avg batch time: 0.1205, average loss: 1.1369
[09/23 04:28:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.50	top5: 93.17	
[09/23 04:28:47][INFO] visual_prompt:  435: Inference (test):avg data time: 1.17e-04, avg batch time: 0.1282, average loss: 1.1312
[09/23 04:28:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.78	top5: 93.51	
[09/23 04:28:47][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/23 04:29:55][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 2.01e-02, avg batch time: 0.8065, average train loss: 1.1133average G loss: 0.0081, average realD loss: 0.0280, average fakeD loss: 0.0348, 
[09/23 04:29:58][INFO] visual_prompt:  435: Inference (val):avg data time: 7.30e-05, avg batch time: 0.1208, average loss: 1.0235
[09/23 04:29:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.33	top5: 96.00	
[09/23 04:30:11][INFO] visual_prompt:  435: Inference (test):avg data time: 7.50e-05, avg batch time: 0.1279, average loss: 1.0010
[09/23 04:30:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.04	top5: 95.58	
[09/23 04:30:12][INFO] visual_prompt:  357: Best epoch 58: best metric: 0.723
[09/23 04:30:12][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/23 04:31:20][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.98e-02, avg batch time: 0.8059, average train loss: 1.0753average G loss: 0.0070, average realD loss: 0.0288, average fakeD loss: 0.0317, 
[09/23 04:31:23][INFO] visual_prompt:  435: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1202, average loss: 1.0495
[09/23 04:31:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.83	top5: 95.33	
[09/23 04:31:36][INFO] visual_prompt:  435: Inference (test):avg data time: 6.39e-05, avg batch time: 0.1280, average loss: 1.0249
[09/23 04:31:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.92	top5: 96.12	
[09/23 04:31:36][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/23 04:32:45][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 1.83e-02, avg batch time: 0.8040, average train loss: 1.0749average G loss: 0.0081, average realD loss: 0.0264, average fakeD loss: 0.0312, 
[09/23 04:32:47][INFO] visual_prompt:  435: Inference (val):avg data time: 8.42e-05, avg batch time: 0.1213, average loss: 1.0919
[09/23 04:32:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.17	top5: 94.00	
[09/23 04:33:01][INFO] visual_prompt:  435: Inference (test):avg data time: 8.61e-05, avg batch time: 0.1278, average loss: 1.0499
[09/23 04:33:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.65	top5: 94.43	
[09/23 04:33:01][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/23 04:34:09][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 2.03e-02, avg batch time: 0.8053, average train loss: 1.0682average G loss: 0.0077, average realD loss: 0.0268, average fakeD loss: 0.0300, 
[09/23 04:34:11][INFO] visual_prompt:  435: Inference (val):avg data time: 6.97e-05, avg batch time: 0.1195, average loss: 0.9941
[09/23 04:34:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.33	top5: 95.33	
[09/23 04:34:26][INFO] visual_prompt:  435: Inference (test):avg data time: 7.83e-05, avg batch time: 0.1275, average loss: 0.9773
[09/23 04:34:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.22	top5: 95.27	
[09/23 04:34:26][INFO] visual_prompt:  357: Best epoch 61: best metric: 0.753
[09/23 04:34:26][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/23 04:35:34][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.89e-02, avg batch time: 0.8035, average train loss: 1.0413average G loss: 0.0072, average realD loss: 0.0254, average fakeD loss: 0.0288, 
[09/23 04:35:36][INFO] visual_prompt:  435: Inference (val):avg data time: 7.17e-05, avg batch time: 0.1206, average loss: 0.9588
[09/23 04:35:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.67	top5: 97.00	
[09/23 04:35:50][INFO] visual_prompt:  435: Inference (test):avg data time: 9.07e-05, avg batch time: 0.1275, average loss: 0.9621
[09/23 04:35:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.44	top5: 96.44	
[09/23 04:35:50][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/23 04:36:59][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 2.17e-02, avg batch time: 0.8052, average train loss: 1.0149average G loss: 0.0071, average realD loss: 0.0258, average fakeD loss: 0.0278, 
[09/23 04:37:01][INFO] visual_prompt:  435: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1206, average loss: 0.9748
[09/23 04:37:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.83	top5: 96.33	
[09/23 04:37:15][INFO] visual_prompt:  435: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1270, average loss: 0.9837
[09/23 04:37:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.84	top5: 96.13	
[09/23 04:37:15][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/23 04:38:23][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.88e-02, avg batch time: 0.8015, average train loss: 1.0637average G loss: 0.0096, average realD loss: 0.0309, average fakeD loss: 0.0362, 
[09/23 04:38:26][INFO] visual_prompt:  435: Inference (val):avg data time: 7.10e-05, avg batch time: 0.1198, average loss: 0.9063
[09/23 04:38:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.00	top5: 97.33	
[09/23 04:38:40][INFO] visual_prompt:  435: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1270, average loss: 0.9060
[09/23 04:38:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.37	top5: 96.22	
[09/23 04:38:40][INFO] visual_prompt:  357: Best epoch 64: best metric: 0.760
[09/23 04:38:40][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/23 04:39:48][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.82e-02, avg batch time: 0.8003, average train loss: 1.0536average G loss: 0.0074, average realD loss: 0.0237, average fakeD loss: 0.0277, 
[09/23 04:39:50][INFO] visual_prompt:  435: Inference (val):avg data time: 5.90e-05, avg batch time: 0.1205, average loss: 1.0862
[09/23 04:39:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 96.50	
[09/23 04:40:04][INFO] visual_prompt:  435: Inference (test):avg data time: 1.04e-04, avg batch time: 0.1276, average loss: 1.0982
[09/23 04:40:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.52	top5: 95.86	
[09/23 04:40:04][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/23 04:41:12][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.76e-02, avg batch time: 0.7995, average train loss: 0.9967average G loss: 0.0072, average realD loss: 0.0302, average fakeD loss: 0.0306, 
[09/23 04:41:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.95e-05, avg batch time: 0.1198, average loss: 0.9892
[09/23 04:41:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.83	top5: 95.50	
[09/23 04:41:28][INFO] visual_prompt:  435: Inference (test):avg data time: 9.33e-05, avg batch time: 0.1270, average loss: 0.9463
[09/23 04:41:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.51	top5: 96.19	
[09/23 04:41:28][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/23 04:42:36][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.83e-02, avg batch time: 0.7997, average train loss: 0.9382average G loss: 0.0058, average realD loss: 0.0256, average fakeD loss: 0.0302, 
[09/23 04:42:39][INFO] visual_prompt:  435: Inference (val):avg data time: 9.73e-05, avg batch time: 0.1203, average loss: 0.9141
[09/23 04:42:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.17	top5: 96.33	
[09/23 04:42:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.52e-05, avg batch time: 0.1270, average loss: 0.9169
[09/23 04:42:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.60	top5: 96.60	
[09/23 04:42:52][INFO] visual_prompt:  357: Best epoch 67: best metric: 0.782
[09/23 04:42:52][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/23 04:44:00][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.95e-02, avg batch time: 0.8006, average train loss: 0.9085average G loss: 0.0063, average realD loss: 0.0270, average fakeD loss: 0.0269, 
[09/23 04:44:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.25e-05, avg batch time: 0.1206, average loss: 0.9500
[09/23 04:44:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.00	top5: 96.83	
[09/23 04:44:16][INFO] visual_prompt:  435: Inference (test):avg data time: 6.01e-05, avg batch time: 0.1270, average loss: 0.9413
[09/23 04:44:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.91	top5: 96.24	
[09/23 04:44:16][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/23 04:45:25][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 2.05e-02, avg batch time: 0.8019, average train loss: 0.8965average G loss: 0.0063, average realD loss: 0.0249, average fakeD loss: 0.0313, 
[09/23 04:45:27][INFO] visual_prompt:  435: Inference (val):avg data time: 5.84e-05, avg batch time: 0.1199, average loss: 0.8773
[09/23 04:45:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.17	top5: 97.83	
[09/23 04:45:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.80e-05, avg batch time: 0.1270, average loss: 0.8650
[09/23 04:45:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.67	top5: 97.29	
[09/23 04:45:41][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/23 04:46:49][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.86e-02, avg batch time: 0.8006, average train loss: 0.8704average G loss: 0.0062, average realD loss: 0.0251, average fakeD loss: 0.0274, 
[09/23 04:46:51][INFO] visual_prompt:  435: Inference (val):avg data time: 5.86e-05, avg batch time: 0.1199, average loss: 0.9067
[09/23 04:46:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 96.83	
[09/23 04:47:05][INFO] visual_prompt:  435: Inference (test):avg data time: 6.06e-05, avg batch time: 0.1277, average loss: 0.9044
[09/23 04:47:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.89	top5: 97.00	
[09/23 04:47:05][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/23 04:48:13][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 2.01e-02, avg batch time: 0.8030, average train loss: 0.8340average G loss: 0.0055, average realD loss: 0.0247, average fakeD loss: 0.0285, 
[09/23 04:48:16][INFO] visual_prompt:  435: Inference (val):avg data time: 5.74e-05, avg batch time: 0.1205, average loss: 0.8893
[09/23 04:48:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 97.00	
[09/23 04:48:29][INFO] visual_prompt:  435: Inference (test):avg data time: 8.67e-05, avg batch time: 0.1273, average loss: 0.8840
[09/23 04:48:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.24	top5: 97.17	
[09/23 04:48:29][INFO] visual_prompt:  357: Best epoch 71: best metric: 0.787
[09/23 04:48:29][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/23 04:49:38][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.81e-02, avg batch time: 0.8012, average train loss: 0.8154average G loss: 0.0053, average realD loss: 0.0253, average fakeD loss: 0.0270, 
[09/23 04:49:40][INFO] visual_prompt:  435: Inference (val):avg data time: 5.10e-05, avg batch time: 0.1202, average loss: 0.8685
[09/23 04:49:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.17	
[09/23 04:49:53][INFO] visual_prompt:  435: Inference (test):avg data time: 7.16e-05, avg batch time: 0.1279, average loss: 0.8632
[09/23 04:49:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.39	top5: 96.91	
[09/23 04:49:53][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/23 04:51:02][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 2.03e-02, avg batch time: 0.8040, average train loss: 0.8168average G loss: 0.0054, average realD loss: 0.0222, average fakeD loss: 0.0250, 
[09/23 04:51:04][INFO] visual_prompt:  435: Inference (val):avg data time: 5.12e-05, avg batch time: 0.1203, average loss: 0.8481
[09/23 04:51:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 97.00	
[09/23 04:51:18][INFO] visual_prompt:  435: Inference (test):avg data time: 6.84e-05, avg batch time: 0.1274, average loss: 0.8489
[09/23 04:51:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.87	top5: 97.57	
[09/23 04:51:18][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/23 04:52:26][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.96e-02, avg batch time: 0.8037, average train loss: 0.7968average G loss: 0.0051, average realD loss: 0.0253, average fakeD loss: 0.0292, 
[09/23 04:52:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1202, average loss: 0.8340
[09/23 04:52:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 97.67	
[09/23 04:52:42][INFO] visual_prompt:  435: Inference (test):avg data time: 6.09e-05, avg batch time: 0.1283, average loss: 0.8238
[09/23 04:52:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.08	top5: 97.38	
[09/23 04:52:42][INFO] visual_prompt:  357: Best epoch 74: best metric: 0.813
[09/23 04:52:42][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/23 04:53:51][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.89e-02, avg batch time: 0.8032, average train loss: 0.7820average G loss: 0.0054, average realD loss: 0.0244, average fakeD loss: 0.0290, 
[09/23 04:53:53][INFO] visual_prompt:  435: Inference (val):avg data time: 5.75e-05, avg batch time: 0.1201, average loss: 0.8016
[09/23 04:53:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 97.67	
[09/23 04:54:06][INFO] visual_prompt:  435: Inference (test):avg data time: 8.23e-05, avg batch time: 0.1281, average loss: 0.8225
[09/23 04:54:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.12	top5: 96.89	
[09/23 04:54:06][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/23 04:55:15][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.85e-02, avg batch time: 0.8032, average train loss: 0.7438average G loss: 0.0049, average realD loss: 0.0217, average fakeD loss: 0.0257, 
[09/23 04:55:17][INFO] visual_prompt:  435: Inference (val):avg data time: 6.06e-05, avg batch time: 0.1216, average loss: 0.7951
[09/23 04:55:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 98.17	
[09/23 04:55:30][INFO] visual_prompt:  435: Inference (test):avg data time: 6.65e-05, avg batch time: 0.1281, average loss: 0.7955
[09/23 04:55:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.20	top5: 97.41	
[09/23 04:55:30][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/23 04:56:39][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 1.82e-02, avg batch time: 0.8032, average train loss: 0.7310average G loss: 0.0051, average realD loss: 0.0225, average fakeD loss: 0.0250, 
[09/23 04:56:41][INFO] visual_prompt:  435: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1199, average loss: 0.7656
[09/23 04:56:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 98.00	
[09/23 04:56:55][INFO] visual_prompt:  435: Inference (test):avg data time: 7.54e-05, avg batch time: 0.1281, average loss: 0.7777
[09/23 04:56:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.22	top5: 97.93	
[09/23 04:56:55][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/23 04:58:03][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 2.04e-02, avg batch time: 0.8056, average train loss: 0.7222average G loss: 0.0044, average realD loss: 0.0234, average fakeD loss: 0.0252, 
[09/23 04:58:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.08e-05, avg batch time: 0.1201, average loss: 0.7316
[09/23 04:58:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.00	
[09/23 04:58:19][INFO] visual_prompt:  435: Inference (test):avg data time: 6.08e-05, avg batch time: 0.1282, average loss: 0.7470
[09/23 04:58:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.45	top5: 97.81	
[09/23 04:58:19][INFO] visual_prompt:  357: Best epoch 78: best metric: 0.840
[09/23 04:58:19][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/23 04:59:27][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.88e-02, avg batch time: 0.8043, average train loss: 0.7086average G loss: 0.0046, average realD loss: 0.0253, average fakeD loss: 0.0251, 
[09/23 04:59:30][INFO] visual_prompt:  435: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1209, average loss: 0.7337
[09/23 04:59:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.00	top5: 98.50	
[09/23 04:59:43][INFO] visual_prompt:  435: Inference (test):avg data time: 7.21e-05, avg batch time: 0.1281, average loss: 0.7340
[09/23 04:59:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.69	top5: 98.07	
[09/23 04:59:43][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/23 05:00:52][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 2.04e-02, avg batch time: 0.8059, average train loss: 0.7126average G loss: 0.0045, average realD loss: 0.0220, average fakeD loss: 0.0249, 
[09/23 05:00:54][INFO] visual_prompt:  435: Inference (val):avg data time: 7.41e-05, avg batch time: 0.1213, average loss: 0.7557
[09/23 05:00:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.83	
[09/23 05:01:08][INFO] visual_prompt:  435: Inference (test):avg data time: 6.75e-05, avg batch time: 0.1285, average loss: 0.7547
[09/23 05:01:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.90	top5: 97.96	
[09/23 05:01:08][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/23 05:02:16][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.87e-02, avg batch time: 0.8040, average train loss: 0.6800average G loss: 0.0043, average realD loss: 0.0216, average fakeD loss: 0.0227, 
[09/23 05:02:19][INFO] visual_prompt:  435: Inference (val):avg data time: 8.85e-05, avg batch time: 0.1203, average loss: 0.7512
[09/23 05:02:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 99.17	
[09/23 05:02:32][INFO] visual_prompt:  435: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1277, average loss: 0.7632
[09/23 05:02:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.03	top5: 97.69	
[09/23 05:02:32][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/23 05:03:41][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.91e-02, avg batch time: 0.8041, average train loss: 0.6745average G loss: 0.0044, average realD loss: 0.0233, average fakeD loss: 0.0235, 
[09/23 05:03:43][INFO] visual_prompt:  435: Inference (val):avg data time: 6.70e-05, avg batch time: 0.1209, average loss: 0.7189
[09/23 05:03:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.67	
[09/23 05:03:57][INFO] visual_prompt:  435: Inference (test):avg data time: 8.82e-05, avg batch time: 0.1272, average loss: 0.7280
[09/23 05:03:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.69	top5: 98.34	
[09/23 05:03:57][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/23 05:05:06][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.97e-02, avg batch time: 0.8038, average train loss: 0.6477average G loss: 0.0039, average realD loss: 0.0223, average fakeD loss: 0.0245, 
[09/23 05:05:08][INFO] visual_prompt:  435: Inference (val):avg data time: 9.10e-05, avg batch time: 0.1208, average loss: 0.7156
[09/23 05:05:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.33	
[09/23 05:05:22][INFO] visual_prompt:  435: Inference (test):avg data time: 7.24e-05, avg batch time: 0.1274, average loss: 0.7213
[09/23 05:05:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.24	top5: 98.07	
[09/23 05:05:22][INFO] visual_prompt:  357: Best epoch 83: best metric: 0.842
[09/23 05:05:22][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/23 05:06:30][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.87e-02, avg batch time: 0.8019, average train loss: 0.6418average G loss: 0.0039, average realD loss: 0.0226, average fakeD loss: 0.0248, 
[09/23 05:06:33][INFO] visual_prompt:  435: Inference (val):avg data time: 7.10e-05, avg batch time: 0.1200, average loss: 0.7276
[09/23 05:06:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.67	
[09/23 05:06:46][INFO] visual_prompt:  435: Inference (test):avg data time: 7.11e-05, avg batch time: 0.1275, average loss: 0.7172
[09/23 05:06:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.05	top5: 97.88	
[09/23 05:06:46][INFO] visual_prompt:  357: Best epoch 84: best metric: 0.847
[09/23 05:06:46][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/23 05:07:54][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.92e-02, avg batch time: 0.8021, average train loss: 0.6313average G loss: 0.0040, average realD loss: 0.0190, average fakeD loss: 0.0226, 
[09/23 05:07:57][INFO] visual_prompt:  435: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1195, average loss: 0.7182
[09/23 05:07:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.50	
[09/23 05:08:11][INFO] visual_prompt:  435: Inference (test):avg data time: 8.26e-05, avg batch time: 0.1270, average loss: 0.7264
[09/23 05:08:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.85	top5: 98.03	
[09/23 05:08:11][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/23 05:09:19][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.89e-02, avg batch time: 0.8006, average train loss: 0.6117average G loss: 0.0038, average realD loss: 0.0221, average fakeD loss: 0.0231, 
[09/23 05:09:21][INFO] visual_prompt:  435: Inference (val):avg data time: 5.27e-05, avg batch time: 0.1198, average loss: 0.6898
[09/23 05:09:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.67	
[09/23 05:09:35][INFO] visual_prompt:  435: Inference (test):avg data time: 6.19e-05, avg batch time: 0.1281, average loss: 0.7029
[09/23 05:09:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.38	top5: 98.14	
[09/23 05:09:35][INFO] visual_prompt:  357: Best epoch 86: best metric: 0.860
[09/23 05:09:35][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/23 05:10:43][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.75e-02, avg batch time: 0.7993, average train loss: 0.6071average G loss: 0.0035, average realD loss: 0.0212, average fakeD loss: 0.0230, 
[09/23 05:10:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.26e-05, avg batch time: 0.1200, average loss: 0.6869
[09/23 05:10:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.50	
[09/23 05:10:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1273, average loss: 0.6887
[09/23 05:10:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.30	top5: 98.17	
[09/23 05:10:59][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/23 05:12:07][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.77e-02, avg batch time: 0.7998, average train loss: 0.5885average G loss: 0.0035, average realD loss: 0.0222, average fakeD loss: 0.0234, 
[09/23 05:12:09][INFO] visual_prompt:  435: Inference (val):avg data time: 6.18e-05, avg batch time: 0.1208, average loss: 0.6887
[09/23 05:12:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.83	
[09/23 05:12:23][INFO] visual_prompt:  435: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1272, average loss: 0.6860
[09/23 05:12:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.12	top5: 98.14	
[09/23 05:12:23][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/23 05:13:31][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.76e-02, avg batch time: 0.8002, average train loss: 0.5840average G loss: 0.0035, average realD loss: 0.0222, average fakeD loss: 0.0232, 
[09/23 05:13:33][INFO] visual_prompt:  435: Inference (val):avg data time: 5.41e-05, avg batch time: 0.1212, average loss: 0.6999
[09/23 05:13:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.50	
[09/23 05:13:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.75e-05, avg batch time: 0.1275, average loss: 0.6872
[09/23 05:13:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.56	top5: 98.14	
[09/23 05:13:47][INFO] visual_prompt:  357: Best epoch 89: best metric: 0.872
[09/23 05:13:47][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/23 05:14:55][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.93e-02, avg batch time: 0.8025, average train loss: 0.5698average G loss: 0.0034, average realD loss: 0.0200, average fakeD loss: 0.0232, 
[09/23 05:14:57][INFO] visual_prompt:  435: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1216, average loss: 0.6804
[09/23 05:14:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.83	
[09/23 05:15:11][INFO] visual_prompt:  435: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1275, average loss: 0.6748
[09/23 05:15:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 98.19	
[09/23 05:15:11][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/23 05:16:19][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.75e-02, avg batch time: 0.8012, average train loss: 0.5526average G loss: 0.0031, average realD loss: 0.0195, average fakeD loss: 0.0249, 
[09/23 05:16:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.98e-05, avg batch time: 0.1211, average loss: 0.6780
[09/23 05:16:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 99.00	
[09/23 05:16:35][INFO] visual_prompt:  435: Inference (test):avg data time: 6.43e-05, avg batch time: 0.1278, average loss: 0.6735
[09/23 05:16:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.73	top5: 98.12	
[09/23 05:16:35][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/23 05:17:44][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.96e-02, avg batch time: 0.8035, average train loss: 0.5381average G loss: 0.0031, average realD loss: 0.0208, average fakeD loss: 0.0224, 
[09/23 05:17:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.49e-05, avg batch time: 0.1210, average loss: 0.6673
[09/23 05:17:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 99.00	
[09/23 05:17:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1279, average loss: 0.6680
[09/23 05:17:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.18	top5: 98.19	
[09/23 05:17:59][INFO] visual_prompt:  357: Best epoch 92: best metric: 0.877
[09/23 05:17:59][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/23 05:19:08][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.91e-02, avg batch time: 0.8035, average train loss: 0.5326average G loss: 0.0031, average realD loss: 0.0207, average fakeD loss: 0.0252, 
[09/23 05:19:10][INFO] visual_prompt:  435: Inference (val):avg data time: 5.79e-05, avg batch time: 0.1207, average loss: 0.6664
[09/23 05:19:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.83	
[09/23 05:19:23][INFO] visual_prompt:  435: Inference (test):avg data time: 8.02e-05, avg batch time: 0.1281, average loss: 0.6590
[09/23 05:19:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.57	top5: 98.10	
[09/23 05:19:23][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/23 05:20:32][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.83e-02, avg batch time: 0.8030, average train loss: 0.5119average G loss: 0.0027, average realD loss: 0.0201, average fakeD loss: 0.0226, 
[09/23 05:20:34][INFO] visual_prompt:  435: Inference (val):avg data time: 7.91e-05, avg batch time: 0.1207, average loss: 0.6583
[09/23 05:20:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.83	
[09/23 05:20:47][INFO] visual_prompt:  435: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1280, average loss: 0.6560
[09/23 05:20:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.44	top5: 98.15	
[09/23 05:20:48][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/23 05:21:56][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 1.75e-02, avg batch time: 0.8023, average train loss: 0.5130average G loss: 0.0030, average realD loss: 0.0194, average fakeD loss: 0.0231, 
[09/23 05:21:58][INFO] visual_prompt:  435: Inference (val):avg data time: 6.21e-05, avg batch time: 0.1203, average loss: 0.6439
[09/23 05:21:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.83	top5: 98.50	
[09/23 05:22:12][INFO] visual_prompt:  435: Inference (test):avg data time: 8.08e-05, avg batch time: 0.1281, average loss: 0.6512
[09/23 05:22:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.66	top5: 98.10	
[09/23 05:22:12][INFO] visual_prompt:  357: Best epoch 95: best metric: 0.878
[09/23 05:22:12][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/23 05:23:20][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.85e-02, avg batch time: 0.8033, average train loss: 0.4951average G loss: 0.0027, average realD loss: 0.0209, average fakeD loss: 0.0256, 
[09/23 05:23:22][INFO] visual_prompt:  435: Inference (val):avg data time: 5.99e-05, avg batch time: 0.1206, average loss: 0.6501
[09/23 05:23:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 88.33	top5: 98.83	
[09/23 05:23:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.40e-05, avg batch time: 0.1278, average loss: 0.6504
[09/23 05:23:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.44	top5: 98.05	
[09/23 05:23:36][INFO] visual_prompt:  357: Best epoch 96: best metric: 0.883
[09/23 05:23:36][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/23 05:24:45][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.94e-02, avg batch time: 0.8043, average train loss: 0.4884average G loss: 0.0026, average realD loss: 0.0214, average fakeD loss: 0.0233, 
[09/23 05:24:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.02e-05, avg batch time: 0.1205, average loss: 0.6475
[09/23 05:24:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.83	top5: 98.50	
[09/23 05:25:00][INFO] visual_prompt:  435: Inference (test):avg data time: 6.56e-05, avg batch time: 0.1285, average loss: 0.6481
[09/23 05:25:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.44	top5: 98.07	
[09/23 05:25:00][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/23 05:26:09][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 2.01e-02, avg batch time: 0.8054, average train loss: 0.4782average G loss: 0.0025, average realD loss: 0.0199, average fakeD loss: 0.0237, 
[09/23 05:26:11][INFO] visual_prompt:  435: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1204, average loss: 0.6460
[09/23 05:26:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.67	
[09/23 05:26:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1274, average loss: 0.6447
[09/23 05:26:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.45	top5: 98.03	
[09/23 05:26:26][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/23 05:27:34][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.88e-02, avg batch time: 0.8042, average train loss: 0.4687average G loss: 0.0024, average realD loss: 0.0198, average fakeD loss: 0.0239, 
[09/23 05:27:36][INFO] visual_prompt:  435: Inference (val):avg data time: 4.56e-05, avg batch time: 0.1214, average loss: 0.6363
[09/23 05:27:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.67	
[09/23 05:27:50][INFO] visual_prompt:  435: Inference (test):avg data time: 7.50e-05, avg batch time: 0.1280, average loss: 0.6407
[09/23 05:27:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.54	top5: 97.98	
[09/23 05:27:50][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/23 05:28:58][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.92e-02, avg batch time: 0.8048, average train loss: 0.4602average G loss: 0.0024, average realD loss: 0.0194, average fakeD loss: 0.0199, 
[09/23 05:29:01][INFO] visual_prompt:  435: Inference (val):avg data time: 5.05e-05, avg batch time: 0.1205, average loss: 0.6363
[09/23 05:29:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.83	top5: 98.83	
[09/23 05:29:14][INFO] visual_prompt:  435: Inference (test):avg data time: 7.89e-05, avg batch time: 0.1286, average loss: 0.6404
[09/23 05:29:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.56	top5: 98.00	
