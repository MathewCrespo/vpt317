[09/22 17:42:04][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/22 17:42:04][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/22 17:42:04][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/22 17:42:04][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/22 17:42:04][INFO] visual_prompt:  109: Training with config:
[09/22 17:42:04][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr6.25_wd0.001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 6.25,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/22 17:42:04][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/22 17:42:04][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/22 17:42:04][INFO] visual_prompt:   77: Number of images: 5394
[09/22 17:42:04][INFO] visual_prompt:   78: Number of classes: 200
[09/22 17:42:04][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/22 17:42:04][INFO] visual_prompt:   73: Loading validation data...
[09/22 17:42:04][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/22 17:42:04][INFO] visual_prompt:   77: Number of images: 600
[09/22 17:42:04][INFO] visual_prompt:   78: Number of classes: 200
[09/22 17:42:04][INFO] visual_prompt:   76: Loading test data...
[09/22 17:42:04][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/22 17:42:04][INFO] visual_prompt:   77: Number of images: 5794
[09/22 17:42:04][INFO] visual_prompt:   78: Number of classes: 200
[09/22 17:42:04][INFO] visual_prompt:  103: Constructing models...
[09/22 17:42:11][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/22 17:42:11][INFO] visual_prompt:   55: tuned percent:0.143
[09/22 17:42:12][INFO] visual_prompt:   41: Device used for model: 0
[09/22 17:42:12][INFO] visual_prompt:  106: Setting up Evalutator...
[09/22 17:42:12][INFO] visual_prompt:  108: Setting up Trainer...
[09/22 17:42:12][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/22 17:42:12][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/22 17:43:21][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.88e-02, avg batch time: 0.8112, average train loss: 5.3231average G loss: 2.6410, average realD loss: 7.7208, average fakeD loss: 2.1627, 
[09/22 17:43:23][INFO] visual_prompt:  435: Inference (val):avg data time: 7.09e-05, avg batch time: 0.1206, average loss: 5.3212
[09/22 17:43:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.17	top5: 2.83	
[09/22 17:43:37][INFO] visual_prompt:  435: Inference (test):avg data time: 9.95e-05, avg batch time: 0.1295, average loss: 5.3214
[09/22 17:43:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.43	top5: 2.49	
[09/22 17:43:37][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.002
[09/22 17:43:37][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.625
[09/22 17:44:46][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.84e-02, avg batch time: 0.8087, average train loss: 5.4258average G loss: 0.0000, average realD loss: 0.2931, average fakeD loss: 18.0989, 
[09/22 17:44:48][INFO] visual_prompt:  435: Inference (val):avg data time: 6.92e-05, avg batch time: 0.1218, average loss: 5.3288
[09/22 17:44:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.33	
[09/22 17:45:03][INFO] visual_prompt:  435: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1290, average loss: 5.3284
[09/22 17:45:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 3.16	
[09/22 17:45:03][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.005
[09/22 17:45:03][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 1.25
[09/22 17:46:12][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 2.20e-02, avg batch time: 0.8132, average train loss: 5.4808average G loss: 0.0416, average realD loss: 0.1339, average fakeD loss: 0.3077, 
[09/22 17:46:15][INFO] visual_prompt:  435: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1234, average loss: 5.3700
[09/22 17:46:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 17:46:29][INFO] visual_prompt:  435: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1290, average loss: 5.3721
[09/22 17:46:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.54	top5: 2.61	
[09/22 17:46:29][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 1.875
[09/22 17:47:39][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.95e-02, avg batch time: 0.8149, average train loss: 5.4428average G loss: 0.0006, average realD loss: 0.0155, average fakeD loss: 0.0292, 
[09/22 17:47:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.03e-05, avg batch time: 0.1212, average loss: 5.3927
[09/22 17:47:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 17:47:55][INFO] visual_prompt:  435: Inference (test):avg data time: 6.74e-05, avg batch time: 0.1298, average loss: 5.3993
[09/22 17:47:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.26	
[09/22 17:47:55][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 2.5
[09/22 17:49:05][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 2.30e-02, avg batch time: 0.8191, average train loss: 5.4805average G loss: 0.0031, average realD loss: 0.0277, average fakeD loss: 0.0289, 
[09/22 17:49:07][INFO] visual_prompt:  435: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1233, average loss: 5.4777
[09/22 17:49:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.83	
[09/22 17:49:21][INFO] visual_prompt:  435: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1291, average loss: 5.4867
[09/22 17:49:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 3.40	
[09/22 17:49:21][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 3.125
[09/22 17:50:31][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 2.16e-02, avg batch time: 0.8175, average train loss: 5.5992average G loss: 0.0030, average realD loss: 0.0268, average fakeD loss: 0.0352, 
[09/22 17:50:33][INFO] visual_prompt:  435: Inference (val):avg data time: 8.13e-05, avg batch time: 0.1216, average loss: 5.1657
[09/22 17:50:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.33	top5: 16.83	
[09/22 17:50:48][INFO] visual_prompt:  435: Inference (test):avg data time: 7.85e-05, avg batch time: 0.1287, average loss: 5.1547
[09/22 17:50:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.36	top5: 16.97	
[09/22 17:50:48][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.013
[09/22 17:50:48][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 3.75
[09/22 17:51:58][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 2.12e-02, avg batch time: 0.8163, average train loss: 3.3914average G loss: 0.0087, average realD loss: 0.0640, average fakeD loss: 0.0886, 
[09/22 17:52:00][INFO] visual_prompt:  435: Inference (val):avg data time: 5.29e-05, avg batch time: 0.1210, average loss: 2.4786
[09/22 17:52:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 48.50	top5: 74.67	
[09/22 17:52:15][INFO] visual_prompt:  435: Inference (test):avg data time: 9.19e-05, avg batch time: 0.1289, average loss: 2.4725
[09/22 17:52:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 49.97	top5: 74.99	
[09/22 17:52:15][INFO] visual_prompt:  357: Best epoch 7: best metric: 0.485
[09/22 17:52:15][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 4.375
[09/22 17:53:24][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 2.02e-02, avg batch time: 0.8129, average train loss: 3.6989average G loss: 0.0254, average realD loss: 0.1715, average fakeD loss: 0.2640, 
[09/22 17:53:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1211, average loss: 4.1053
[09/22 17:53:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 20.00	top5: 43.00	
[09/22 17:53:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.75e-05, avg batch time: 0.1295, average loss: 4.0600
[09/22 17:53:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 21.18	top5: 43.11	
[09/22 17:53:41][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 5.0
[09/22 17:54:50][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 2.05e-02, avg batch time: 0.8116, average train loss: 4.5900average G loss: 0.0316, average realD loss: 0.4962, average fakeD loss: 0.8749, 
[09/22 17:54:52][INFO] visual_prompt:  435: Inference (val):avg data time: 7.37e-05, avg batch time: 0.1212, average loss: 5.9066
[09/22 17:54:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 9.83	top5: 26.33	
[09/22 17:55:06][INFO] visual_prompt:  435: Inference (test):avg data time: 6.45e-05, avg batch time: 0.1289, average loss: 5.8572
[09/22 17:55:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 10.72	top5: 28.10	
[09/22 17:55:07][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 5.625
[09/22 17:56:16][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 2.05e-02, avg batch time: 0.8152, average train loss: 6.0276average G loss: 0.0059, average realD loss: 0.0457, average fakeD loss: 0.0687, 
[09/22 17:56:18][INFO] visual_prompt:  435: Inference (val):avg data time: 9.16e-05, avg batch time: 0.1212, average loss: 5.7247
[09/22 17:56:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.17	
[09/22 17:56:32][INFO] visual_prompt:  435: Inference (test):avg data time: 7.83e-05, avg batch time: 0.1292, average loss: 5.7219
[09/22 17:56:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.45	
[09/22 17:56:32][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 6.25
[09/22 17:57:42][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 2.21e-02, avg batch time: 0.8176, average train loss: 5.8939average G loss: 0.0027, average realD loss: 0.0405, average fakeD loss: 0.0532, 
[09/22 17:57:44][INFO] visual_prompt:  435: Inference (val):avg data time: 6.73e-05, avg batch time: 0.1208, average loss: 5.7538
[09/22 17:57:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 17:57:59][INFO] visual_prompt:  435: Inference (test):avg data time: 9.04e-05, avg batch time: 0.1289, average loss: 5.7556
[09/22 17:57:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/22 17:57:59][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 6.248096334434675
[09/22 17:59:08][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.83e-02, avg batch time: 0.8136, average train loss: 5.9149average G loss: 0.0030, average realD loss: 0.0400, average fakeD loss: 0.0456, 
[09/22 17:59:11][INFO] visual_prompt:  435: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1219, average loss: 6.1516
[09/22 17:59:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 17:59:25][INFO] visual_prompt:  435: Inference (test):avg data time: 6.78e-05, avg batch time: 0.1289, average loss: 6.1403
[09/22 17:59:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/22 17:59:25][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 6.2423876570619505
[09/22 18:00:34][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.87e-02, avg batch time: 0.8139, average train loss: 5.8976average G loss: 0.0031, average realD loss: 0.0344, average fakeD loss: 0.0352, 
[09/22 18:00:37][INFO] visual_prompt:  435: Inference (val):avg data time: 6.77e-05, avg batch time: 0.1218, average loss: 6.0739
[09/22 18:00:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:00:50][INFO] visual_prompt:  435: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1296, average loss: 6.0765
[09/22 18:00:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.19	
[09/22 18:00:51][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 6.232880923025854
[09/22 18:02:00][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 2.01e-02, avg batch time: 0.8154, average train loss: 6.5925average G loss: 0.0015, average realD loss: 0.0312, average fakeD loss: 0.0410, 
[09/22 18:02:02][INFO] visual_prompt:  435: Inference (val):avg data time: 6.07e-05, avg batch time: 0.1217, average loss: 6.5554
[09/22 18:02:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/22 18:02:16][INFO] visual_prompt:  435: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1296, average loss: 6.5480
[09/22 18:02:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.47	
[09/22 18:02:16][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 6.219587714817408
[09/22 18:03:25][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.82e-02, avg batch time: 0.8135, average train loss: 6.0652average G loss: 0.0028, average realD loss: 0.0404, average fakeD loss: 0.0404, 
[09/22 18:03:28][INFO] visual_prompt:  435: Inference (val):avg data time: 9.34e-05, avg batch time: 0.1218, average loss: 5.9668
[09/22 18:03:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/22 18:03:41][INFO] visual_prompt:  435: Inference (test):avg data time: 1.03e-04, avg batch time: 0.1294, average loss: 5.9662
[09/22 18:03:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.40	top5: 2.36	
[09/22 18:03:41][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 6.20252422816315
[09/22 18:04:51][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.81e-02, avg batch time: 0.8133, average train loss: 6.4515average G loss: 0.0022, average realD loss: 0.0322, average fakeD loss: 0.0359, 
[09/22 18:04:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.52e-05, avg batch time: 0.1208, average loss: 6.2830
[09/22 18:04:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:05:07][INFO] visual_prompt:  435: Inference (test):avg data time: 9.83e-05, avg batch time: 0.1293, average loss: 6.2969
[09/22 18:05:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.36	
[09/22 18:05:07][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 6.181711252293143
[09/22 18:06:16][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.96e-02, avg batch time: 0.8143, average train loss: 6.3198average G loss: 0.0026, average realD loss: 0.0363, average fakeD loss: 0.0436, 
[09/22 18:06:19][INFO] visual_prompt:  435: Inference (val):avg data time: 4.81e-05, avg batch time: 0.1215, average loss: 6.3609
[09/22 18:06:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:06:33][INFO] visual_prompt:  435: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1289, average loss: 6.3645
[09/22 18:06:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/22 18:06:33][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 6.157174144612489
[09/22 18:07:42][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.97e-02, avg batch time: 0.8146, average train loss: 6.1395average G loss: 0.0027, average realD loss: 0.0403, average fakeD loss: 0.0440, 
[09/22 18:07:45][INFO] visual_prompt:  435: Inference (val):avg data time: 9.06e-05, avg batch time: 0.1221, average loss: 6.2369
[09/22 18:07:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:07:59][INFO] visual_prompt:  435: Inference (test):avg data time: 6.49e-05, avg batch time: 0.1295, average loss: 6.2451
[09/22 18:07:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/22 18:07:59][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 6.1289427998072465
[09/22 18:09:08][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.89e-02, avg batch time: 0.8140, average train loss: 6.1596average G loss: 0.0026, average realD loss: 0.0428, average fakeD loss: 0.0434, 
[09/22 18:09:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.63e-05, avg batch time: 0.1219, average loss: 6.9619
[09/22 18:09:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.17	top5: 2.50	
[09/22 18:09:25][INFO] visual_prompt:  435: Inference (test):avg data time: 8.95e-05, avg batch time: 0.1288, average loss: 6.9978
[09/22 18:09:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 2.59	
[09/22 18:09:25][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 6.097051613422355
[09/22 18:10:34][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.95e-02, avg batch time: 0.8145, average train loss: 6.6997average G loss: 0.0022, average realD loss: 0.0380, average fakeD loss: 0.0436, 
[09/22 18:10:37][INFO] visual_prompt:  435: Inference (val):avg data time: 5.43e-05, avg batch time: 0.1210, average loss: 6.2491
[09/22 18:10:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/22 18:10:51][INFO] visual_prompt:  435: Inference (test):avg data time: 6.58e-05, avg batch time: 0.1289, average loss: 6.2610
[09/22 18:10:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.47	
[09/22 18:10:51][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 6.061539439955964
[09/22 18:12:00][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 2.01e-02, avg batch time: 0.8147, average train loss: 6.4163average G loss: 0.0020, average realD loss: 0.0420, average fakeD loss: 0.0490, 
[09/22 18:12:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.16e-05, avg batch time: 0.1212, average loss: 6.5826
[09/22 18:12:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/22 18:12:17][INFO] visual_prompt:  435: Inference (test):avg data time: 6.75e-05, avg batch time: 0.1290, average loss: 6.6086
[09/22 18:12:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.33	top5: 2.40	
[09/22 18:12:17][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 6.02244954552121
[09/22 18:13:26][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.84e-02, avg batch time: 0.8131, average train loss: 7.5517average G loss: 0.0015, average realD loss: 0.0338, average fakeD loss: 0.0443, 
[09/22 18:13:29][INFO] visual_prompt:  435: Inference (val):avg data time: 7.59e-05, avg batch time: 0.1220, average loss: 6.8301
[09/22 18:13:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:13:43][INFO] visual_prompt:  435: Inference (test):avg data time: 8.14e-05, avg batch time: 0.1292, average loss: 6.6294
[09/22 18:13:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/22 18:13:43][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 5.9798295551331275
[09/22 18:14:52][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.94e-02, avg batch time: 0.8141, average train loss: 6.6616average G loss: 0.0020, average realD loss: 0.0352, average fakeD loss: 0.0352, 
[09/22 18:14:55][INFO] visual_prompt:  435: Inference (val):avg data time: 6.01e-05, avg batch time: 0.1219, average loss: 6.0006
[09/22 18:14:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/22 18:15:09][INFO] visual_prompt:  435: Inference (test):avg data time: 5.80e-05, avg batch time: 0.1289, average loss: 5.8700
[09/22 18:15:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.54	top5: 2.47	
[09/22 18:15:09][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 5.933731394684897
[09/22 18:16:18][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.91e-02, avg batch time: 0.8136, average train loss: 6.9518average G loss: 0.0019, average realD loss: 0.0345, average fakeD loss: 0.0353, 
[09/22 18:16:21][INFO] visual_prompt:  435: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1219, average loss: 7.6047
[09/22 18:16:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:16:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1289, average loss: 7.5143
[09/22 18:16:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.52	
[09/22 18:16:35][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 5.884211227684147
[09/22 18:17:44][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.96e-02, avg batch time: 0.8143, average train loss: 7.0310average G loss: 0.0020, average realD loss: 0.0303, average fakeD loss: 0.0329, 
[09/22 18:17:47][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1211, average loss: 6.1062
[09/22 18:17:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/22 18:18:01][INFO] visual_prompt:  435: Inference (test):avg data time: 9.45e-05, avg batch time: 0.1287, average loss: 6.0721
[09/22 18:18:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.36	
[09/22 18:18:01][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 5.831329386826371
[09/22 18:19:10][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.92e-02, avg batch time: 0.8140, average train loss: 6.2537average G loss: 0.0028, average realD loss: 0.0307, average fakeD loss: 0.0328, 
[09/22 18:19:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.33e-05, avg batch time: 0.1230, average loss: 5.9800
[09/22 18:19:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:19:28][INFO] visual_prompt:  435: Inference (test):avg data time: 8.55e-05, avg batch time: 0.1286, average loss: 5.9716
[09/22 18:19:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/22 18:19:28][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 5.775150300488831
[09/22 18:20:37][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 2.00e-02, avg batch time: 0.8143, average train loss: 6.2309average G loss: 0.0010, average realD loss: 0.0255, average fakeD loss: 0.0322, 
[09/22 18:20:39][INFO] visual_prompt:  435: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1214, average loss: 5.7806
[09/22 18:20:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/22 18:20:54][INFO] visual_prompt:  435: Inference (test):avg data time: 8.08e-05, avg batch time: 0.1284, average loss: 5.7709
[09/22 18:20:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.62	
[09/22 18:20:54][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 5.715742414234505
[09/22 18:22:04][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.87e-02, avg batch time: 0.8135, average train loss: 5.7165average G loss: 0.0029, average realD loss: 0.0342, average fakeD loss: 0.0392, 
[09/22 18:22:06][INFO] visual_prompt:  435: Inference (val):avg data time: 7.02e-05, avg batch time: 0.1228, average loss: 5.7998
[09/22 18:22:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.67	
[09/22 18:22:20][INFO] visual_prompt:  435: Inference (test):avg data time: 8.63e-05, avg batch time: 0.1297, average loss: 5.7899
[09/22 18:22:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 2.66	
[09/22 18:22:20][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 5.653178107421711
[09/22 18:23:29][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.88e-02, avg batch time: 0.8137, average train loss: 5.8078average G loss: 0.0028, average realD loss: 0.0368, average fakeD loss: 0.0346, 
[09/22 18:23:31][INFO] visual_prompt:  435: Inference (val):avg data time: 7.45e-05, avg batch time: 0.1218, average loss: 5.7271
[09/22 18:23:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/22 18:23:46][INFO] visual_prompt:  435: Inference (test):avg data time: 1.14e-04, avg batch time: 0.1287, average loss: 5.7301
[09/22 18:23:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/22 18:23:46][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 5.587533605021005
[09/22 18:24:55][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.90e-02, avg batch time: 0.8139, average train loss: 5.6981average G loss: 0.0028, average realD loss: 0.0314, average fakeD loss: 0.0358, 
[09/22 18:24:58][INFO] visual_prompt:  435: Inference (val):avg data time: 6.42e-05, avg batch time: 0.1213, average loss: 5.8921
[09/22 18:24:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/22 18:25:12][INFO] visual_prompt:  435: Inference (test):avg data time: 1.31e-04, avg batch time: 0.1291, average loss: 5.9000
[09/22 18:25:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.61	
[09/22 18:25:12][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 5.518888884746806
[09/22 18:26:21][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.99e-02, avg batch time: 0.8141, average train loss: 5.9923average G loss: 0.0023, average realD loss: 0.0379, average fakeD loss: 0.0528, 
[09/22 18:26:23][INFO] visual_prompt:  435: Inference (val):avg data time: 6.56e-05, avg batch time: 0.1220, average loss: 5.6590
[09/22 18:26:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.83	
[09/22 18:26:38][INFO] visual_prompt:  435: Inference (test):avg data time: 8.51e-05, avg batch time: 0.1287, average loss: 5.6658
[09/22 18:26:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.38	top5: 2.88	
[09/22 18:26:38][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 5.447327579616857
[09/22 18:27:47][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.79e-02, avg batch time: 0.8127, average train loss: 6.2652average G loss: 0.0024, average realD loss: 0.0430, average fakeD loss: 0.0539, 
[09/22 18:27:49][INFO] visual_prompt:  435: Inference (val):avg data time: 5.68e-05, avg batch time: 0.1234, average loss: 6.1500
[09/22 18:27:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:28:04][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1289, average loss: 6.1583
[09/22 18:28:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.61	
[09/22 18:28:04][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 5.372936876058285
[09/22 18:29:13][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 2.05e-02, avg batch time: 0.8139, average train loss: 6.4266average G loss: 0.0011, average realD loss: 0.0463, average fakeD loss: 0.0630, 
[09/22 18:29:15][INFO] visual_prompt:  435: Inference (val):avg data time: 7.41e-05, avg batch time: 0.1214, average loss: 6.4571
[09/22 18:29:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:29:30][INFO] visual_prompt:  435: Inference (test):avg data time: 7.55e-05, avg batch time: 0.1286, average loss: 6.4674
[09/22 18:29:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.40	
[09/22 18:29:30][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 5.295807407684366
[09/22 18:30:39][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.85e-02, avg batch time: 0.8132, average train loss: 6.3314average G loss: 0.0030, average realD loss: 0.0294, average fakeD loss: 0.0383, 
[09/22 18:30:41][INFO] visual_prompt:  435: Inference (val):avg data time: 8.00e-05, avg batch time: 0.1217, average loss: 5.9826
[09/22 18:30:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/22 18:30:56][INFO] visual_prompt:  435: Inference (test):avg data time: 8.97e-05, avg batch time: 0.1285, average loss: 5.9852
[09/22 18:30:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.62	
[09/22 18:30:56][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 5.216033144871432
[09/22 18:32:05][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.92e-02, avg batch time: 0.8133, average train loss: 6.0505average G loss: 0.0032, average realD loss: 0.0359, average fakeD loss: 0.0389, 
[09/22 18:32:08][INFO] visual_prompt:  435: Inference (val):avg data time: 4.96e-05, avg batch time: 0.1207, average loss: 6.1978
[09/22 18:32:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:32:22][INFO] visual_prompt:  435: Inference (test):avg data time: 6.32e-05, avg batch time: 0.1285, average loss: 6.1897
[09/22 18:32:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/22 18:32:23][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 5.133711280270435
[09/22 18:33:32][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.83e-02, avg batch time: 0.8127, average train loss: 5.9567average G loss: 0.0022, average realD loss: 0.0275, average fakeD loss: 0.0347, 
[09/22 18:33:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.44e-05, avg batch time: 0.1210, average loss: 5.7017
[09/22 18:33:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:33:48][INFO] visual_prompt:  435: Inference (test):avg data time: 7.22e-05, avg batch time: 0.1293, average loss: 5.7068
[09/22 18:33:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.60	top5: 2.47	
[09/22 18:33:48][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 5.048942110392682
[09/22 18:34:57][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.96e-02, avg batch time: 0.8141, average train loss: 5.7272average G loss: 0.0031, average realD loss: 0.0360, average fakeD loss: 0.0349, 
[09/22 18:35:00][INFO] visual_prompt:  435: Inference (val):avg data time: 5.59e-05, avg batch time: 0.1216, average loss: 5.6189
[09/22 18:35:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/22 18:35:14][INFO] visual_prompt:  435: Inference (test):avg data time: 1.21e-04, avg batch time: 0.1288, average loss: 5.6214
[09/22 18:35:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.68	
[09/22 18:35:14][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 4.961828913413979
[09/22 18:36:24][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.78e-02, avg batch time: 0.8125, average train loss: 5.7112average G loss: 0.0031, average realD loss: 0.0270, average fakeD loss: 0.0341, 
[09/22 18:36:26][INFO] visual_prompt:  435: Inference (val):avg data time: 7.82e-05, avg batch time: 0.1222, average loss: 5.5438
[09/22 18:36:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/22 18:36:40][INFO] visual_prompt:  435: Inference (test):avg data time: 1.04e-04, avg batch time: 0.1289, average loss: 5.5389
[09/22 18:36:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.79	top5: 3.14	
[09/22 18:36:40][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 4.872477823346084
[09/22 18:37:50][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 2.03e-02, avg batch time: 0.8149, average train loss: 5.7191average G loss: 0.0029, average realD loss: 0.0335, average fakeD loss: 0.0351, 
[09/22 18:37:52][INFO] visual_prompt:  435: Inference (val):avg data time: 5.39e-05, avg batch time: 0.1220, average loss: 6.1695
[09/22 18:37:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/22 18:38:07][INFO] visual_prompt:  435: Inference (test):avg data time: 6.55e-05, avg batch time: 0.1287, average loss: 6.1632
[09/22 18:38:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.62	
[09/22 18:38:07][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 4.780997700728765
[09/22 18:39:16][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 2.17e-02, avg batch time: 0.8163, average train loss: 5.9403average G loss: 0.0026, average realD loss: 0.0321, average fakeD loss: 0.0355, 
[09/22 18:39:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1222, average loss: 5.7951
[09/22 18:39:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/22 18:39:32][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1293, average loss: 5.7977
[09/22 18:39:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.40	
[09/22 18:39:32][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 4.6875
[09/22 18:40:41][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.75e-02, avg batch time: 0.8103, average train loss: 5.9729average G loss: 0.0014, average realD loss: 0.1531, average fakeD loss: 0.1214, 
[09/22 18:40:44][INFO] visual_prompt:  435: Inference (val):avg data time: 7.55e-05, avg batch time: 0.1223, average loss: 5.7970
[09/22 18:40:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:40:58][INFO] visual_prompt:  435: Inference (test):avg data time: 1.07e-04, avg batch time: 0.1292, average loss: 5.7873
[09/22 18:40:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.54	
[09/22 18:40:58][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 4.592098633705908
[09/22 18:42:07][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 1.96e-02, avg batch time: 0.8142, average train loss: 5.7650average G loss: 0.0024, average realD loss: 0.0343, average fakeD loss: 0.0413, 
[09/22 18:42:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.56e-05, avg batch time: 0.1210, average loss: 5.8553
[09/22 18:42:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:42:24][INFO] visual_prompt:  435: Inference (test):avg data time: 1.27e-04, avg batch time: 0.1296, average loss: 5.8636
[09/22 18:42:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.40	
[09/22 18:42:24][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 4.494909833715867
[09/22 18:43:33][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 2.23e-02, avg batch time: 0.8169, average train loss: 5.8138average G loss: 0.0023, average realD loss: 0.0393, average fakeD loss: 0.0404, 
[09/22 18:43:36][INFO] visual_prompt:  435: Inference (val):avg data time: 4.92e-05, avg batch time: 0.1225, average loss: 5.8157
[09/22 18:43:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:43:50][INFO] visual_prompt:  435: Inference (test):avg data time: 6.90e-05, avg batch time: 0.1291, average loss: 5.8193
[09/22 18:43:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/22 18:43:50][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 4.396052009611876
[09/22 18:44:59][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 2.09e-02, avg batch time: 0.8157, average train loss: 5.6738average G loss: 0.0029, average realD loss: 0.0303, average fakeD loss: 0.0347, 
[09/22 18:45:02][INFO] visual_prompt:  435: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1212, average loss: 5.6666
[09/22 18:45:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:45:16][INFO] visual_prompt:  435: Inference (test):avg data time: 7.79e-05, avg batch time: 0.1292, average loss: 5.6635
[09/22 18:45:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.69	top5: 2.59	
[09/22 18:45:16][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 4.295645604424726
[09/22 18:46:25][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.86e-02, avg batch time: 0.8133, average train loss: 5.6763average G loss: 0.0031, average realD loss: 0.0336, average fakeD loss: 0.0333, 
[09/22 18:46:27][INFO] visual_prompt:  435: Inference (val):avg data time: 5.84e-05, avg batch time: 0.1210, average loss: 6.0549
[09/22 18:46:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:46:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.43e-05, avg batch time: 0.1293, average loss: 6.0556
[09/22 18:46:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.38	top5: 2.45	
[09/22 18:46:41][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 4.193812947892715
[09/22 18:47:51][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 2.01e-02, avg batch time: 0.8146, average train loss: 5.8018average G loss: 0.0030, average realD loss: 0.0270, average fakeD loss: 0.0307, 
[09/22 18:47:53][INFO] visual_prompt:  435: Inference (val):avg data time: 5.13e-05, avg batch time: 0.1216, average loss: 5.5252
[09/22 18:47:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/22 18:48:06][INFO] visual_prompt:  435: Inference (test):avg data time: 7.45e-05, avg batch time: 0.1297, average loss: 5.5218
[09/22 18:48:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.66	
[09/22 18:48:06][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 4.090678107421711
[09/22 18:49:15][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 1.82e-02, avg batch time: 0.8126, average train loss: 5.6744average G loss: 0.0025, average realD loss: 0.0259, average fakeD loss: 0.0300, 
[09/22 18:49:18][INFO] visual_prompt:  435: Inference (val):avg data time: 7.10e-05, avg batch time: 0.1227, average loss: 5.6969
[09/22 18:49:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:49:31][INFO] visual_prompt:  435: Inference (test):avg data time: 5.70e-05, avg batch time: 0.1298, average loss: 5.7053
[09/22 18:49:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.31	
[09/22 18:49:31][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 3.9863667369281224
[09/22 18:50:40][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.99e-02, avg batch time: 0.8144, average train loss: 5.6022average G loss: 0.0029, average realD loss: 0.0296, average fakeD loss: 0.0320, 
[09/22 18:50:43][INFO] visual_prompt:  435: Inference (val):avg data time: 5.31e-05, avg batch time: 0.1227, average loss: 5.4734
[09/22 18:50:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.50	
[09/22 18:50:57][INFO] visual_prompt:  435: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1294, average loss: 5.4723
[09/22 18:50:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.66	top5: 2.59	
[09/22 18:50:57][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 3.8810059237489614
[09/22 18:52:06][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.85e-02, avg batch time: 0.8126, average train loss: 5.7240average G loss: 0.0027, average realD loss: 0.0263, average fakeD loss: 0.0276, 
[09/22 18:52:08][INFO] visual_prompt:  435: Inference (val):avg data time: 5.76e-05, avg batch time: 0.1217, average loss: 5.5917
[09/22 18:52:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:52:22][INFO] visual_prompt:  435: Inference (test):avg data time: 5.81e-05, avg batch time: 0.1296, average loss: 5.5974
[09/22 18:52:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.42	
[09/22 18:52:22][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 3.7747240338054975
[09/22 18:53:31][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 1.92e-02, avg batch time: 0.8132, average train loss: 5.5935average G loss: 0.0031, average realD loss: 0.0228, average fakeD loss: 0.0280, 
[09/22 18:53:33][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1211, average loss: 5.6956
[09/22 18:53:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 2.50	
[09/22 18:53:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.20e-05, avg batch time: 0.1297, average loss: 5.7005
[09/22 18:53:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 2.38	
[09/22 18:53:47][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 3.667650555209158
[09/22 18:54:56][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.80e-02, avg batch time: 0.8123, average train loss: 5.5795average G loss: 0.0028, average realD loss: 0.0268, average fakeD loss: 0.0285, 
[09/22 18:54:58][INFO] visual_prompt:  435: Inference (val):avg data time: 8.59e-05, avg batch time: 0.1218, average loss: 5.6035
[09/22 18:54:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:55:12][INFO] visual_prompt:  435: Inference (test):avg data time: 5.88e-05, avg batch time: 0.1291, average loss: 5.5950
[09/22 18:55:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.36	
[09/22 18:55:12][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 3.5599159405002045
[09/22 18:56:22][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.85e-02, avg batch time: 0.8126, average train loss: 5.5781average G loss: 0.0029, average realD loss: 0.0280, average fakeD loss: 0.0273, 
[09/22 18:56:24][INFO] visual_prompt:  435: Inference (val):avg data time: 5.85e-05, avg batch time: 0.1225, average loss: 5.5067
[09/22 18:56:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.50	
[09/22 18:56:38][INFO] visual_prompt:  435: Inference (test):avg data time: 6.07e-05, avg batch time: 0.1289, average loss: 5.5046
[09/22 18:56:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.64	top5: 2.59	
[09/22 18:56:38][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 3.4516514477114173
[09/22 18:57:47][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.97e-02, avg batch time: 0.8137, average train loss: 5.5690average G loss: 0.0029, average realD loss: 0.0215, average fakeD loss: 0.0261, 
[09/22 18:57:50][INFO] visual_prompt:  435: Inference (val):avg data time: 7.87e-05, avg batch time: 0.1220, average loss: 5.4285
[09/22 18:57:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/22 18:58:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.94e-05, avg batch time: 0.1295, average loss: 5.4330
[09/22 18:58:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.61	
[09/22 18:58:04][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 3.342988980450391
[09/22 18:59:13][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.76e-02, avg batch time: 0.8115, average train loss: 5.5375average G loss: 0.0026, average realD loss: 0.0259, average fakeD loss: 0.0284, 
[09/22 18:59:15][INFO] visual_prompt:  435: Inference (val):avg data time: 7.46e-05, avg batch time: 0.1216, average loss: 5.5255
[09/22 18:59:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 18:59:29][INFO] visual_prompt:  435: Inference (test):avg data time: 7.30e-05, avg batch time: 0.1293, average loss: 5.5280
[09/22 18:59:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.61	
[09/22 18:59:29][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 3.234060927195316
[09/22 19:00:38][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.96e-02, avg batch time: 0.8133, average train loss: 5.5336average G loss: 0.0031, average realD loss: 0.0276, average fakeD loss: 0.0253, 
[09/22 19:00:41][INFO] visual_prompt:  435: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1209, average loss: 5.5038
[09/22 19:00:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/22 19:00:55][INFO] visual_prompt:  435: Inference (test):avg data time: 8.50e-05, avg batch time: 0.1293, average loss: 5.4991
[09/22 19:00:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/22 19:00:55][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 3.125
[09/22 19:02:04][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 1.88e-02, avg batch time: 0.8126, average train loss: 5.2232average G loss: 0.0040, average realD loss: 0.0486, average fakeD loss: 0.0511, 
[09/22 19:02:06][INFO] visual_prompt:  435: Inference (val):avg data time: 8.92e-05, avg batch time: 0.1217, average loss: 2.4191
[09/22 19:02:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 46.33	top5: 74.33	
[09/22 19:02:20][INFO] visual_prompt:  435: Inference (test):avg data time: 6.49e-05, avg batch time: 0.1296, average loss: 2.3522
[09/22 19:02:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 47.58	top5: 76.41	
[09/22 19:02:20][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 3.0159390728046853
[09/22 19:03:29][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.91e-02, avg batch time: 0.8117, average train loss: 2.5231average G loss: 0.0146, average realD loss: 0.0640, average fakeD loss: 0.0806, 
[09/22 19:03:31][INFO] visual_prompt:  435: Inference (val):avg data time: 5.90e-05, avg batch time: 0.1233, average loss: 2.5927
[09/22 19:03:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 43.17	top5: 71.67	
[09/22 19:03:45][INFO] visual_prompt:  435: Inference (test):avg data time: 1.34e-04, avg batch time: 0.1293, average loss: 2.6035
[09/22 19:03:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 44.37	top5: 72.40	
[09/22 19:03:45][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 2.9070110195496084
[09/22 19:04:54][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 1.73e-02, avg batch time: 0.8105, average train loss: 2.3925average G loss: 0.0152, average realD loss: 0.0626, average fakeD loss: 0.0721, 
[09/22 19:04:56][INFO] visual_prompt:  435: Inference (val):avg data time: 5.47e-05, avg batch time: 0.1213, average loss: 2.3626
[09/22 19:04:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 47.33	top5: 75.33	
[09/22 19:05:10][INFO] visual_prompt:  435: Inference (test):avg data time: 8.18e-05, avg batch time: 0.1289, average loss: 2.3108
[09/22 19:05:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 49.40	top5: 76.77	
[09/22 19:05:10][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 2.7983485522885836
[09/22 19:06:19][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.86e-02, avg batch time: 0.8117, average train loss: 2.1592average G loss: 0.0205, average realD loss: 0.0657, average fakeD loss: 0.0716, 
[09/22 19:06:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.39e-05, avg batch time: 0.1207, average loss: 1.6288
[09/22 19:06:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 59.83	top5: 88.33	
[09/22 19:06:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1290, average loss: 1.6029
[09/22 19:06:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.65	top5: 89.04	
[09/22 19:06:36][INFO] visual_prompt:  357: Best epoch 59: best metric: 0.598
[09/22 19:06:36][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 2.6900840594997963
[09/22 19:07:45][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 1.81e-02, avg batch time: 0.8116, average train loss: 2.3579average G loss: 0.0118, average realD loss: 0.0484, average fakeD loss: 0.0545, 
[09/22 19:07:47][INFO] visual_prompt:  435: Inference (val):avg data time: 6.51e-05, avg batch time: 0.1219, average loss: 1.8249
[09/22 19:07:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 55.67	top5: 86.00	
[09/22 19:08:01][INFO] visual_prompt:  435: Inference (test):avg data time: 6.99e-05, avg batch time: 0.1290, average loss: 1.7597
[09/22 19:08:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 58.13	top5: 86.61	
[09/22 19:08:01][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 2.5823494447908426
[09/22 19:09:10][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.95e-02, avg batch time: 0.8129, average train loss: 2.0375average G loss: 0.0176, average realD loss: 0.0712, average fakeD loss: 0.0748, 
[09/22 19:09:13][INFO] visual_prompt:  435: Inference (val):avg data time: 7.03e-05, avg batch time: 0.1230, average loss: 4.0633
[09/22 19:09:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 16.67	top5: 37.00	
[09/22 19:09:26][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1295, average loss: 4.0760
[09/22 19:09:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 17.57	top5: 38.61	
[09/22 19:09:26][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 2.4752759661945025
[09/22 19:10:35][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.97e-02, avg batch time: 0.8114, average train loss: 1.8948average G loss: 0.0156, average realD loss: 0.0683, average fakeD loss: 0.1359, 
[09/22 19:10:38][INFO] visual_prompt:  435: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1229, average loss: 1.8006
[09/22 19:10:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.83	top5: 87.83	
[09/22 19:10:52][INFO] visual_prompt:  435: Inference (test):avg data time: 9.48e-05, avg batch time: 0.1289, average loss: 1.7741
[09/22 19:10:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.44	top5: 88.70	
[09/22 19:10:52][INFO] visual_prompt:  357: Best epoch 62: best metric: 0.638
[09/22 19:10:52][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 2.3689940762510386
[09/22 19:12:01][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 1.91e-02, avg batch time: 0.8124, average train loss: 1.9508average G loss: 0.0155, average realD loss: 0.0522, average fakeD loss: 0.0578, 
[09/22 19:12:04][INFO] visual_prompt:  435: Inference (val):avg data time: 6.35e-05, avg batch time: 0.1211, average loss: 1.6865
[09/22 19:12:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.67	top5: 87.67	
[09/22 19:12:18][INFO] visual_prompt:  435: Inference (test):avg data time: 8.09e-05, avg batch time: 0.1290, average loss: 1.6237
[09/22 19:12:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 62.88	top5: 88.71	
[09/22 19:12:18][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 2.2636332630718776
[09/22 19:13:27][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.84e-02, avg batch time: 0.8117, average train loss: 1.7320average G loss: 0.0141, average realD loss: 0.0435, average fakeD loss: 0.0488, 
[09/22 19:13:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.01e-05, avg batch time: 0.1222, average loss: 1.7817
[09/22 19:13:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.50	top5: 84.83	
[09/22 19:13:43][INFO] visual_prompt:  435: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1292, average loss: 1.7842
[09/22 19:13:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.29	top5: 86.00	
[09/22 19:13:43][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 2.1593218925782898
[09/22 19:14:52][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.99e-02, avg batch time: 0.8131, average train loss: 1.7108average G loss: 0.0132, average realD loss: 0.0370, average fakeD loss: 0.0450, 
[09/22 19:14:54][INFO] visual_prompt:  435: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1214, average loss: 1.7261
[09/22 19:14:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.17	top5: 86.33	
[09/22 19:15:08][INFO] visual_prompt:  435: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1289, average loss: 1.7114
[09/22 19:15:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.72	top5: 87.21	
[09/22 19:15:08][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 2.0561870521072856
[09/22 19:16:17][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.83e-02, avg batch time: 0.8114, average train loss: 1.7145average G loss: 0.0114, average realD loss: 0.0426, average fakeD loss: 0.0449, 
[09/22 19:16:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.60e-05, avg batch time: 0.1206, average loss: 1.6186
[09/22 19:16:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.67	top5: 86.67	
[09/22 19:16:34][INFO] visual_prompt:  435: Inference (test):avg data time: 6.45e-05, avg batch time: 0.1293, average loss: 1.6000
[09/22 19:16:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.70	top5: 87.87	
[09/22 19:16:34][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 1.9543543955752747
[09/22 19:17:43][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.82e-02, avg batch time: 0.8112, average train loss: 1.6606average G loss: 0.0153, average realD loss: 0.0431, average fakeD loss: 0.0503, 
[09/22 19:17:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.26e-05, avg batch time: 0.1234, average loss: 1.7000
[09/22 19:17:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.33	top5: 89.17	
[09/22 19:17:59][INFO] visual_prompt:  435: Inference (test):avg data time: 8.15e-05, avg batch time: 0.1292, average loss: 1.7225
[09/22 19:17:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.14	top5: 89.75	
[09/22 19:17:59][INFO] visual_prompt:  357: Best epoch 67: best metric: 0.643
[09/22 19:17:59][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 1.8539479903881249
[09/22 19:19:08][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.94e-02, avg batch time: 0.8123, average train loss: 2.3630average G loss: 0.0114, average realD loss: 0.0382, average fakeD loss: 0.0421, 
[09/22 19:19:10][INFO] visual_prompt:  435: Inference (val):avg data time: 5.39e-05, avg batch time: 0.1224, average loss: 1.3642
[09/22 19:19:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.33	top5: 92.33	
[09/22 19:19:24][INFO] visual_prompt:  435: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1294, average loss: 1.3690
[09/22 19:19:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.73	top5: 91.75	
[09/22 19:19:24][INFO] visual_prompt:  357: Best epoch 68: best metric: 0.663
[09/22 19:19:24][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 1.7550901662841327
[09/22 19:20:33][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 1.88e-02, avg batch time: 0.8120, average train loss: 1.5028average G loss: 0.0117, average realD loss: 0.0380, average fakeD loss: 0.0421, 
[09/22 19:20:36][INFO] visual_prompt:  435: Inference (val):avg data time: 4.53e-05, avg batch time: 0.1208, average loss: 1.3333
[09/22 19:20:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.17	top5: 92.50	
[09/22 19:20:49][INFO] visual_prompt:  435: Inference (test):avg data time: 7.14e-05, avg batch time: 0.1291, average loss: 1.3216
[09/22 19:20:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.47	top5: 92.20	
[09/22 19:20:49][INFO] visual_prompt:  357: Best epoch 69: best metric: 0.672
[09/22 19:20:49][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 1.657901366294092
[09/22 19:21:58][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.83e-02, avg batch time: 0.8116, average train loss: 1.4220average G loss: 0.0110, average realD loss: 0.0311, average fakeD loss: 0.0328, 
[09/22 19:22:01][INFO] visual_prompt:  435: Inference (val):avg data time: 6.74e-05, avg batch time: 0.1210, average loss: 1.3734
[09/22 19:22:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.50	top5: 93.00	
[09/22 19:22:14][INFO] visual_prompt:  435: Inference (test):avg data time: 7.93e-05, avg batch time: 0.1298, average loss: 1.3348
[09/22 19:22:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.92	top5: 93.03	
[09/22 19:22:14][INFO] visual_prompt:  357: Best epoch 70: best metric: 0.675
[09/22 19:22:14][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 1.5625000000000007
[09/22 19:23:23][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 1.87e-02, avg batch time: 0.8121, average train loss: 1.3620average G loss: 0.0099, average realD loss: 0.0312, average fakeD loss: 0.0328, 
[09/22 19:23:26][INFO] visual_prompt:  435: Inference (val):avg data time: 5.98e-05, avg batch time: 0.1206, average loss: 1.2957
[09/22 19:23:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.67	top5: 92.17	
[09/22 19:23:39][INFO] visual_prompt:  435: Inference (test):avg data time: 7.02e-05, avg batch time: 0.1291, average loss: 1.2974
[09/22 19:23:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.14	top5: 91.72	
[09/22 19:23:39][INFO] visual_prompt:  357: Best epoch 71: best metric: 0.687
[09/22 19:23:39][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 1.469002299271235
[09/22 19:24:48][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.93e-02, avg batch time: 0.8126, average train loss: 1.2925average G loss: 0.0096, average realD loss: 0.0317, average fakeD loss: 0.0330, 
[09/22 19:24:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.29e-05, avg batch time: 0.1206, average loss: 1.1425
[09/22 19:24:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.67	top5: 95.67	
[09/22 19:25:04][INFO] visual_prompt:  435: Inference (test):avg data time: 8.41e-05, avg batch time: 0.1293, average loss: 1.1546
[09/22 19:25:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.75	top5: 93.92	
[09/22 19:25:04][INFO] visual_prompt:  357: Best epoch 72: best metric: 0.697
[09/22 19:25:04][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 1.3775221766539165
[09/22 19:26:13][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 1.86e-02, avg batch time: 0.8117, average train loss: 1.2847average G loss: 0.0089, average realD loss: 0.0299, average fakeD loss: 0.0320, 
[09/22 19:26:16][INFO] visual_prompt:  435: Inference (val):avg data time: 5.70e-05, avg batch time: 0.1220, average loss: 1.1419
[09/22 19:26:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.00	top5: 94.83	
[09/22 19:26:30][INFO] visual_prompt:  435: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1289, average loss: 1.1353
[09/22 19:26:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.08	top5: 94.46	
[09/22 19:26:30][INFO] visual_prompt:  357: Best epoch 73: best metric: 0.720
[09/22 19:26:30][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 1.2881710865860219
[09/22 19:27:39][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.82e-02, avg batch time: 0.8112, average train loss: 1.2408average G loss: 0.0092, average realD loss: 0.0308, average fakeD loss: 0.0354, 
[09/22 19:27:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.84e-05, avg batch time: 0.1218, average loss: 1.1507
[09/22 19:27:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.83	top5: 93.17	
[09/22 19:27:55][INFO] visual_prompt:  435: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1295, average loss: 1.1772
[09/22 19:27:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.64	top5: 92.98	
[09/22 19:27:55][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 1.2010578896073179
[09/22 19:29:04][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.97e-02, avg batch time: 0.8129, average train loss: 1.2029average G loss: 0.0084, average realD loss: 0.0277, average fakeD loss: 0.0353, 
[09/22 19:29:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.38e-05, avg batch time: 0.1211, average loss: 1.0806
[09/22 19:29:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.83	top5: 94.17	
[09/22 19:29:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.05e-05, avg batch time: 0.1295, average loss: 1.1122
[09/22 19:29:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.04	top5: 93.86	
[09/22 19:29:20][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 1.1162887197295646
[09/22 19:30:29][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.82e-02, avg batch time: 0.8111, average train loss: 1.0952average G loss: 0.0070, average realD loss: 0.0281, average fakeD loss: 0.0310, 
[09/22 19:30:31][INFO] visual_prompt:  435: Inference (val):avg data time: 5.44e-05, avg batch time: 0.1217, average loss: 0.9942
[09/22 19:30:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.83	top5: 96.17	
[09/22 19:30:45][INFO] visual_prompt:  435: Inference (test):avg data time: 7.37e-05, avg batch time: 0.1292, average loss: 1.0049
[09/22 19:30:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.09	top5: 95.12	
[09/22 19:30:45][INFO] visual_prompt:  357: Best epoch 76: best metric: 0.748
[09/22 19:30:45][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 1.033966855128569
[09/22 19:31:54][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 1.84e-02, avg batch time: 0.8113, average train loss: 1.0870average G loss: 0.0072, average realD loss: 0.0268, average fakeD loss: 0.0320, 
[09/22 19:31:56][INFO] visual_prompt:  435: Inference (val):avg data time: 5.88e-05, avg batch time: 0.1235, average loss: 1.0137
[09/22 19:31:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.83	top5: 95.00	
[09/22 19:32:10][INFO] visual_prompt:  435: Inference (test):avg data time: 6.48e-05, avg batch time: 0.1296, average loss: 1.0184
[09/22 19:32:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.66	top5: 95.34	
[09/22 19:32:10][INFO] visual_prompt:  357: Best epoch 77: best metric: 0.758
[09/22 19:32:10][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.9541925923156332
[09/22 19:33:19][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 2.06e-02, avg batch time: 0.8135, average train loss: 1.0237average G loss: 0.0063, average realD loss: 0.0257, average fakeD loss: 0.0322, 
[09/22 19:33:21][INFO] visual_prompt:  435: Inference (val):avg data time: 5.84e-05, avg batch time: 0.1224, average loss: 1.0016
[09/22 19:33:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.50	top5: 96.00	
[09/22 19:33:35][INFO] visual_prompt:  435: Inference (test):avg data time: 9.12e-05, avg batch time: 0.1294, average loss: 1.0037
[09/22 19:33:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.68	top5: 95.43	
[09/22 19:33:35][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.8770631239417157
[09/22 19:34:44][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.97e-02, avg batch time: 0.8128, average train loss: 1.0038average G loss: 0.0073, average realD loss: 0.0261, average fakeD loss: 0.0278, 
[09/22 19:34:47][INFO] visual_prompt:  435: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1232, average loss: 1.0523
[09/22 19:34:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 95.50	
[09/22 19:35:01][INFO] visual_prompt:  435: Inference (test):avg data time: 6.84e-05, avg batch time: 0.1288, average loss: 1.0411
[09/22 19:35:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.01	top5: 96.17	
[09/22 19:35:01][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.8026724203831427
[09/22 19:36:10][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 2.07e-02, avg batch time: 0.8136, average train loss: 0.9289average G loss: 0.0058, average realD loss: 0.0247, average fakeD loss: 0.0304, 
[09/22 19:36:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.51e-05, avg batch time: 0.1222, average loss: 0.9092
[09/22 19:36:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 96.83	
[09/22 19:36:26][INFO] visual_prompt:  435: Inference (test):avg data time: 6.38e-05, avg batch time: 0.1290, average loss: 0.9125
[09/22 19:36:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.84	top5: 96.76	
[09/22 19:36:26][INFO] visual_prompt:  357: Best epoch 80: best metric: 0.777
[09/22 19:36:26][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.731111115253194
[09/22 19:37:35][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.91e-02, avg batch time: 0.8121, average train loss: 0.8810average G loss: 0.0060, average realD loss: 0.0247, average fakeD loss: 0.0268, 
[09/22 19:37:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.83e-05, avg batch time: 0.1222, average loss: 0.9155
[09/22 19:37:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.50	top5: 97.67	
[09/22 19:37:52][INFO] visual_prompt:  435: Inference (test):avg data time: 8.66e-05, avg batch time: 0.1288, average loss: 0.9316
[09/22 19:37:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.65	top5: 97.01	
[09/22 19:37:52][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.6624663949789941
[09/22 19:39:01][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.88e-02, avg batch time: 0.8118, average train loss: 0.8682average G loss: 0.0058, average realD loss: 0.0234, average fakeD loss: 0.0266, 
[09/22 19:39:03][INFO] visual_prompt:  435: Inference (val):avg data time: 8.13e-05, avg batch time: 0.1227, average loss: 0.8462
[09/22 19:39:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 96.83	
[09/22 19:39:16][INFO] visual_prompt:  435: Inference (test):avg data time: 7.67e-05, avg batch time: 0.1299, average loss: 0.8628
[09/22 19:39:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.62	top5: 96.89	
[09/22 19:39:17][INFO] visual_prompt:  357: Best epoch 82: best metric: 0.802
[09/22 19:39:17][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.5968218925782895
[09/22 19:40:26][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.95e-02, avg batch time: 0.8126, average train loss: 0.8205average G loss: 0.0053, average realD loss: 0.0238, average fakeD loss: 0.0287, 
[09/22 19:40:28][INFO] visual_prompt:  435: Inference (val):avg data time: 9.19e-05, avg batch time: 0.1221, average loss: 0.8160
[09/22 19:40:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 98.33	
[09/22 19:40:41][INFO] visual_prompt:  435: Inference (test):avg data time: 9.13e-05, avg batch time: 0.1296, average loss: 0.8234
[09/22 19:40:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.39	top5: 97.24	
[09/22 19:40:42][INFO] visual_prompt:  357: Best epoch 83: best metric: 0.817
[09/22 19:40:42][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.534257585765495
[09/22 19:41:51][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.99e-02, avg batch time: 0.8131, average train loss: 0.7894average G loss: 0.0051, average realD loss: 0.0273, average fakeD loss: 0.0264, 
[09/22 19:41:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1208, average loss: 0.8389
[09/22 19:41:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 97.67	
[09/22 19:42:07][INFO] visual_prompt:  435: Inference (test):avg data time: 1.06e-04, avg batch time: 0.1295, average loss: 0.8456
[09/22 19:42:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.39	top5: 97.03	
[09/22 19:42:07][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.4748496995111689
[09/22 19:43:16][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.80e-02, avg batch time: 0.8110, average train loss: 0.7862average G loss: 0.0050, average realD loss: 0.0231, average fakeD loss: 0.0276, 
[09/22 19:43:18][INFO] visual_prompt:  435: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1213, average loss: 0.8986
[09/22 19:43:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 98.17	
[09/22 19:43:32][INFO] visual_prompt:  435: Inference (test):avg data time: 9.98e-05, avg batch time: 0.1288, average loss: 0.9029
[09/22 19:43:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.19	top5: 97.62	
[09/22 19:43:32][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.418670613173629
[09/22 19:44:41][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.88e-02, avg batch time: 0.8119, average train loss: 0.7520average G loss: 0.0049, average realD loss: 0.0221, average fakeD loss: 0.0260, 
[09/22 19:44:44][INFO] visual_prompt:  435: Inference (val):avg data time: 3.94e-05, avg batch time: 0.1213, average loss: 0.7516
[09/22 19:44:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.83	
[09/22 19:44:57][INFO] visual_prompt:  435: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1291, average loss: 0.7692
[09/22 19:44:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.72	top5: 97.69	
[09/22 19:44:57][INFO] visual_prompt:  357: Best epoch 86: best metric: 0.853
[09/22 19:44:57][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.36578877231585316
[09/22 19:46:07][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.95e-02, avg batch time: 0.8123, average train loss: 0.7193average G loss: 0.0047, average realD loss: 0.0223, average fakeD loss: 0.0224, 
[09/22 19:46:09][INFO] visual_prompt:  435: Inference (val):avg data time: 6.44e-05, avg batch time: 0.1219, average loss: 0.7792
[09/22 19:46:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 98.17	
[09/22 19:46:23][INFO] visual_prompt:  435: Inference (test):avg data time: 8.45e-05, avg batch time: 0.1289, average loss: 0.7746
[09/22 19:46:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.46	top5: 97.88	
[09/22 19:46:23][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.3162686053151037
[09/22 19:47:32][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 2.00e-02, avg batch time: 0.8129, average train loss: 0.6916average G loss: 0.0043, average realD loss: 0.0256, average fakeD loss: 0.0259, 
[09/22 19:47:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.96e-05, avg batch time: 0.1211, average loss: 0.7636
[09/22 19:47:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 98.17	
[09/22 19:47:48][INFO] visual_prompt:  435: Inference (test):avg data time: 9.52e-05, avg batch time: 0.1292, average loss: 0.7698
[09/22 19:47:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.48	top5: 97.77	
[09/22 19:47:48][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.2701704448668719
[09/22 19:48:57][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.74e-02, avg batch time: 0.8103, average train loss: 0.6738average G loss: 0.0042, average realD loss: 0.0233, average fakeD loss: 0.0275, 
[09/22 19:48:59][INFO] visual_prompt:  435: Inference (val):avg data time: 8.20e-05, avg batch time: 0.1227, average loss: 0.7043
[09/22 19:48:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.50	
[09/22 19:49:13][INFO] visual_prompt:  435: Inference (test):avg data time: 1.00e-04, avg batch time: 0.1298, average loss: 0.7265
[09/22 19:49:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.24	top5: 98.05	
[09/22 19:49:13][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.22755045447878963
[09/22 19:50:22][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 2.09e-02, avg batch time: 0.8136, average train loss: 0.6460average G loss: 0.0041, average realD loss: 0.0211, average fakeD loss: 0.0261, 
[09/22 19:50:24][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1218, average loss: 0.7139
[09/22 19:50:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.83	
[09/22 19:50:38][INFO] visual_prompt:  435: Inference (test):avg data time: 9.45e-05, avg batch time: 0.1295, average loss: 0.7252
[09/22 19:50:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.09	top5: 98.07	
[09/22 19:50:38][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.1884605600440365
[09/22 19:51:47][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.88e-02, avg batch time: 0.8121, average train loss: 0.6351average G loss: 0.0038, average realD loss: 0.0214, average fakeD loss: 0.0246, 
[09/22 19:51:49][INFO] visual_prompt:  435: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1215, average loss: 0.6896
[09/22 19:51:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.50	
[09/22 19:52:03][INFO] visual_prompt:  435: Inference (test):avg data time: 5.84e-05, avg batch time: 0.1289, average loss: 0.7081
[09/22 19:52:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.02	top5: 98.15	
[09/22 19:52:03][INFO] visual_prompt:  357: Best epoch 91: best metric: 0.862
[09/22 19:52:03][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.1529483865776452
[09/22 19:53:12][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 2.11e-02, avg batch time: 0.8143, average train loss: 0.6121average G loss: 0.0041, average realD loss: 0.0231, average fakeD loss: 0.0240, 
[09/22 19:53:15][INFO] visual_prompt:  435: Inference (val):avg data time: 6.22e-05, avg batch time: 0.1222, average loss: 0.7121
[09/22 19:53:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.17	
[09/22 19:53:28][INFO] visual_prompt:  435: Inference (test):avg data time: 9.19e-05, avg batch time: 0.1290, average loss: 0.7031
[09/22 19:53:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.86	top5: 98.00	
[09/22 19:53:28][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.12105720019275346
[09/22 19:54:38][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.81e-02, avg batch time: 0.8111, average train loss: 0.5910average G loss: 0.0034, average realD loss: 0.0218, average fakeD loss: 0.0248, 
[09/22 19:54:40][INFO] visual_prompt:  435: Inference (val):avg data time: 5.45e-05, avg batch time: 0.1219, average loss: 0.7017
[09/22 19:54:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.67	
[09/22 19:54:54][INFO] visual_prompt:  435: Inference (test):avg data time: 5.77e-05, avg batch time: 0.1292, average loss: 0.6919
[09/22 19:54:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.54	top5: 98.17	
[09/22 19:54:54][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.09282585538751102
[09/22 19:56:03][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.95e-02, avg batch time: 0.8125, average train loss: 0.5836average G loss: 0.0036, average realD loss: 0.0207, average fakeD loss: 0.0235, 
[09/22 19:56:05][INFO] visual_prompt:  435: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1225, average loss: 0.6569
[09/22 19:56:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.67	
[09/22 19:56:19][INFO] visual_prompt:  435: Inference (test):avg data time: 6.61e-05, avg batch time: 0.1289, average loss: 0.6698
[09/22 19:56:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.93	top5: 98.19	
[09/22 19:56:19][INFO] visual_prompt:  357: Best epoch 94: best metric: 0.872
[09/22 19:56:19][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.06828874770685722
[09/22 19:57:28][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 1.98e-02, avg batch time: 0.8127, average train loss: 0.5570average G loss: 0.0030, average realD loss: 0.0200, average fakeD loss: 0.0242, 
[09/22 19:57:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.07e-05, avg batch time: 0.1224, average loss: 0.6693
[09/22 19:57:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 88.00	top5: 98.83	
[09/22 19:57:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.38e-05, avg batch time: 0.1296, average loss: 0.6755
[09/22 19:57:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.31	top5: 98.07	
[09/22 19:57:44][INFO] visual_prompt:  357: Best epoch 95: best metric: 0.880
[09/22 19:57:44][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.047475771836849937
[09/22 19:58:53][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 2.01e-02, avg batch time: 0.8129, average train loss: 0.5377average G loss: 0.0032, average realD loss: 0.0187, average fakeD loss: 0.0221, 
[09/22 19:58:56][INFO] visual_prompt:  435: Inference (val):avg data time: 5.27e-05, avg batch time: 0.1215, average loss: 0.6606
[09/22 19:58:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.67	
[09/22 19:59:09][INFO] visual_prompt:  435: Inference (test):avg data time: 6.82e-05, avg batch time: 0.1289, average loss: 0.6610
[09/22 19:59:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.54	top5: 98.10	
[09/22 19:59:09][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.03041228518259262
[09/22 20:00:18][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.84e-02, avg batch time: 0.8111, average train loss: 0.5155average G loss: 0.0028, average realD loss: 0.0222, average fakeD loss: 0.0247, 
[09/22 20:00:21][INFO] visual_prompt:  435: Inference (val):avg data time: 8.03e-05, avg batch time: 0.1218, average loss: 0.6446
[09/22 20:00:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 88.17	top5: 98.83	
[09/22 20:00:34][INFO] visual_prompt:  435: Inference (test):avg data time: 6.55e-05, avg batch time: 0.1292, average loss: 0.6529
[09/22 20:00:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.83	top5: 98.15	
[09/22 20:00:34][INFO] visual_prompt:  357: Best epoch 97: best metric: 0.882
[09/22 20:00:34][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.01711907697414597
[09/22 20:01:43][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 1.89e-02, avg batch time: 0.8119, average train loss: 0.5009average G loss: 0.0027, average realD loss: 0.0181, average fakeD loss: 0.0235, 
[09/22 20:01:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.18e-05, avg batch time: 0.1215, average loss: 0.6415
[09/22 20:01:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 88.83	top5: 98.83	
[09/22 20:01:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1293, average loss: 0.6477
[09/22 20:01:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.13	top5: 98.14	
[09/22 20:01:59][INFO] visual_prompt:  357: Best epoch 98: best metric: 0.888
[09/22 20:01:59][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.007612342938049382
[09/22 20:03:08][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.80e-02, avg batch time: 0.8108, average train loss: 0.4904average G loss: 0.0026, average realD loss: 0.0179, average fakeD loss: 0.0215, 
[09/22 20:03:11][INFO] visual_prompt:  435: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1224, average loss: 0.6357
[09/22 20:03:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 88.83	top5: 98.83	
[09/22 20:03:25][INFO] visual_prompt:  435: Inference (test):avg data time: 6.71e-05, avg batch time: 0.1285, average loss: 0.6455
[09/22 20:03:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.28	top5: 98.07	
[09/22 20:03:25][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 0.0019036655653257434
[09/22 20:04:34][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.89e-02, avg batch time: 0.8115, average train loss: 0.4902average G loss: 0.0029, average realD loss: 0.0204, average fakeD loss: 0.0261, 
[09/22 20:04:36][INFO] visual_prompt:  435: Inference (val):avg data time: 5.03e-05, avg batch time: 0.1226, average loss: 0.6387
[09/22 20:04:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 89.33	top5: 98.83	
[09/22 20:04:50][INFO] visual_prompt:  435: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1294, average loss: 0.6445
[09/22 20:04:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.25	top5: 98.07	
[09/22 20:04:50][INFO] visual_prompt:  357: Best epoch 100: best metric: 0.893
