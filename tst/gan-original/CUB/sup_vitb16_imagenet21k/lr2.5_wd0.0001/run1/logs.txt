[09/23 05:29:18][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 05:29:18][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 05:29:18][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/23 05:29:18][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 05:29:18][INFO] visual_prompt:  109: Training with config:
[09/23 05:29:18][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr2.5_wd0.0001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 2.5,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 05:29:18][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 05:29:18][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 05:29:18][INFO] visual_prompt:   77: Number of images: 5394
[09/23 05:29:18][INFO] visual_prompt:   78: Number of classes: 200
[09/23 05:29:18][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 05:29:18][INFO] visual_prompt:   73: Loading validation data...
[09/23 05:29:18][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 05:29:18][INFO] visual_prompt:   77: Number of images: 600
[09/23 05:29:18][INFO] visual_prompt:   78: Number of classes: 200
[09/23 05:29:18][INFO] visual_prompt:   76: Loading test data...
[09/23 05:29:18][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 05:29:18][INFO] visual_prompt:   77: Number of images: 5794
[09/23 05:29:18][INFO] visual_prompt:   78: Number of classes: 200
[09/23 05:29:18][INFO] visual_prompt:  103: Constructing models...
[09/23 05:29:23][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 05:29:23][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 05:29:23][INFO] visual_prompt:   41: Device used for model: 0
[09/23 05:29:23][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 05:29:23][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 05:29:23][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 05:29:23][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/23 05:30:32][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.96e-02, avg batch time: 0.8037, average train loss: 5.3242average G loss: 6.1612, average realD loss: 11.7971, average fakeD loss: 0.6480, 
[09/23 05:30:34][INFO] visual_prompt:  435: Inference (val):avg data time: 7.62e-05, avg batch time: 0.1204, average loss: 5.3263
[09/23 05:30:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.00	top5: 1.33	
[09/23 05:30:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.96e-05, avg batch time: 0.1279, average loss: 5.3241
[09/23 05:30:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.17	top5: 1.90	
[09/23 05:30:48][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.25
[09/23 05:31:56][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.79e-02, avg batch time: 0.7984, average train loss: 5.3568average G loss: 0.0000, average realD loss: 0.4066, average fakeD loss: 18.4892, 
[09/23 05:31:58][INFO] visual_prompt:  435: Inference (val):avg data time: 6.35e-05, avg batch time: 0.1215, average loss: 5.3212
[09/23 05:31:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 05:32:12][INFO] visual_prompt:  435: Inference (test):avg data time: 7.14e-05, avg batch time: 0.1284, average loss: 5.3225
[09/23 05:32:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.54	top5: 2.42	
[09/23 05:32:12][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.005
[09/23 05:32:12][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.5
[09/23 05:33:20][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.99e-02, avg batch time: 0.8007, average train loss: 5.3787average G loss: 0.0000, average realD loss: 0.1190, average fakeD loss: 0.2360, 
[09/23 05:33:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1203, average loss: 5.3547
[09/23 05:33:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.17	
[09/23 05:33:36][INFO] visual_prompt:  435: Inference (test):avg data time: 6.66e-05, avg batch time: 0.1283, average loss: 5.3548
[09/23 05:33:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.60	top5: 3.00	
[09/23 05:33:36][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.75
[09/23 05:34:44][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.86e-02, avg batch time: 0.7998, average train loss: 5.3384average G loss: 0.0000, average realD loss: 0.0681, average fakeD loss: 0.0595, 
[09/23 05:34:46][INFO] visual_prompt:  435: Inference (val):avg data time: 6.63e-05, avg batch time: 0.1208, average loss: 5.0055
[09/23 05:34:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.83	top5: 8.17	
[09/23 05:35:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.22e-05, avg batch time: 0.1284, average loss: 5.0050
[09/23 05:35:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.95	top5: 8.25	
[09/23 05:35:00][INFO] visual_prompt:  357: Best epoch 4: best metric: 0.018
[09/23 05:35:00][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 1.0
[09/23 05:36:08][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.76e-02, avg batch time: 0.7990, average train loss: 2.6913average G loss: 0.0135, average realD loss: 0.0646, average fakeD loss: 0.1009, 
[09/23 05:36:10][INFO] visual_prompt:  435: Inference (val):avg data time: 8.04e-05, avg batch time: 0.1214, average loss: 0.9508
[09/23 05:36:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.50	top5: 94.17	
[09/23 05:36:23][INFO] visual_prompt:  435: Inference (test):avg data time: 7.34e-05, avg batch time: 0.1283, average loss: 0.9303
[09/23 05:36:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.68	top5: 95.50	
[09/23 05:36:23][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.735
[09/23 05:36:23][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 1.25
[09/23 05:37:31][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.93e-02, avg batch time: 0.8008, average train loss: 0.8995average G loss: 0.0031, average realD loss: 0.0334, average fakeD loss: 0.0626, 
[09/23 05:37:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.50e-05, avg batch time: 0.1201, average loss: 0.8021
[09/23 05:37:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 96.33	
[09/23 05:37:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1284, average loss: 0.7938
[09/23 05:37:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.51	top5: 95.98	
[09/23 05:37:48][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.777
[09/23 05:37:48][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 1.5
[09/23 05:38:56][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.79e-02, avg batch time: 0.7997, average train loss: 0.6981average G loss: 0.0022, average realD loss: 0.0256, average fakeD loss: 0.0754, 
[09/23 05:38:58][INFO] visual_prompt:  435: Inference (val):avg data time: 8.66e-05, avg batch time: 0.1202, average loss: 0.9570
[09/23 05:38:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.50	top5: 95.17	
[09/23 05:39:12][INFO] visual_prompt:  435: Inference (test):avg data time: 6.68e-05, avg batch time: 0.1277, average loss: 0.9515
[09/23 05:39:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.80	top5: 94.74	
[09/23 05:39:12][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 1.75
[09/23 05:40:20][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 2.00e-02, avg batch time: 0.8016, average train loss: 0.6102average G loss: 0.0014, average realD loss: 0.0105, average fakeD loss: 0.0214, 
[09/23 05:40:23][INFO] visual_prompt:  435: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1215, average loss: 0.9383
[09/23 05:40:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 95.00	
[09/23 05:40:36][INFO] visual_prompt:  435: Inference (test):avg data time: 6.35e-05, avg batch time: 0.1279, average loss: 0.8548
[09/23 05:40:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.79	top5: 95.46	
[09/23 05:40:36][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 2.0
[09/23 05:41:44][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.99e-02, avg batch time: 0.8017, average train loss: 0.5731average G loss: 0.0012, average realD loss: 0.0152, average fakeD loss: 0.0136, 
[09/23 05:41:47][INFO] visual_prompt:  435: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1217, average loss: 0.8584
[09/23 05:41:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.33	top5: 95.33	
[09/23 05:42:01][INFO] visual_prompt:  435: Inference (test):avg data time: 9.37e-05, avg batch time: 0.1278, average loss: 0.8866
[09/23 05:42:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.27	top5: 95.08	
[09/23 05:42:01][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 2.25
[09/23 05:43:09][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.81e-02, avg batch time: 0.8004, average train loss: 0.6847average G loss: 0.0012, average realD loss: 0.0082, average fakeD loss: 0.0152, 
[09/23 05:43:11][INFO] visual_prompt:  435: Inference (val):avg data time: 6.86e-05, avg batch time: 0.1197, average loss: 0.8726
[09/23 05:43:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 94.50	
[09/23 05:43:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.97e-05, avg batch time: 0.1278, average loss: 0.9093
[09/23 05:43:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.77	top5: 94.86	
[09/23 05:43:25][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 2.5
[09/23 05:44:33][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.78e-02, avg batch time: 0.7998, average train loss: 0.6492average G loss: 0.0013, average realD loss: 0.0096, average fakeD loss: 0.0154, 
[09/23 05:44:35][INFO] visual_prompt:  435: Inference (val):avg data time: 9.15e-05, avg batch time: 0.1206, average loss: 0.9999
[09/23 05:44:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.17	top5: 93.67	
[09/23 05:44:49][INFO] visual_prompt:  435: Inference (test):avg data time: 8.00e-05, avg batch time: 0.1274, average loss: 1.0174
[09/23 05:44:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.13	top5: 94.67	
[09/23 05:44:49][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/23 05:45:57][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 2.03e-02, avg batch time: 0.8024, average train loss: 0.7100average G loss: 0.0011, average realD loss: 0.0084, average fakeD loss: 0.0146, 
[09/23 05:46:00][INFO] visual_prompt:  435: Inference (val):avg data time: 8.48e-05, avg batch time: 0.1201, average loss: 1.0459
[09/23 05:46:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.00	top5: 94.17	
[09/23 05:46:14][INFO] visual_prompt:  435: Inference (test):avg data time: 6.89e-05, avg batch time: 0.1271, average loss: 1.0104
[09/23 05:46:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.20	top5: 94.63	
[09/23 05:46:14][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/23 05:47:22][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.88e-02, avg batch time: 0.8008, average train loss: 0.6234average G loss: 0.0012, average realD loss: 0.0090, average fakeD loss: 0.0133, 
[09/23 05:47:24][INFO] visual_prompt:  435: Inference (val):avg data time: 7.33e-05, avg batch time: 0.1199, average loss: 0.9539
[09/23 05:47:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.83	top5: 94.50	
[09/23 05:47:38][INFO] visual_prompt:  435: Inference (test):avg data time: 6.52e-05, avg batch time: 0.1279, average loss: 1.0118
[09/23 05:47:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.72	top5: 93.96	
[09/23 05:47:38][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/23 05:48:46][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.90e-02, avg batch time: 0.8005, average train loss: 0.5977average G loss: 0.0013, average realD loss: 0.0076, average fakeD loss: 0.0108, 
[09/23 05:48:49][INFO] visual_prompt:  435: Inference (val):avg data time: 1.11e-04, avg batch time: 0.1194, average loss: 1.0633
[09/23 05:48:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.33	top5: 95.33	
[09/23 05:49:02][INFO] visual_prompt:  435: Inference (test):avg data time: 6.82e-05, avg batch time: 0.1273, average loss: 1.0555
[09/23 05:49:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.84	top5: 94.29	
[09/23 05:49:02][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/23 05:50:11][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.91e-02, avg batch time: 0.8002, average train loss: 0.5331average G loss: 0.0017, average realD loss: 0.0095, average fakeD loss: 0.0107, 
[09/23 05:50:13][INFO] visual_prompt:  435: Inference (val):avg data time: 6.83e-05, avg batch time: 0.1210, average loss: 1.0363
[09/23 05:50:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 92.33	
[09/23 05:50:27][INFO] visual_prompt:  435: Inference (test):avg data time: 7.89e-05, avg batch time: 0.1270, average loss: 1.0261
[09/23 05:50:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.03	top5: 93.55	
[09/23 05:50:27][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/23 05:51:35][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.82e-02, avg batch time: 0.7994, average train loss: 0.4997average G loss: 0.0019, average realD loss: 0.0105, average fakeD loss: 0.0097, 
[09/23 05:51:37][INFO] visual_prompt:  435: Inference (val):avg data time: 8.80e-05, avg batch time: 0.1206, average loss: 0.8832
[09/23 05:51:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 95.83	
[09/23 05:51:51][INFO] visual_prompt:  435: Inference (test):avg data time: 5.75e-05, avg batch time: 0.1273, average loss: 0.9098
[09/23 05:51:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.72	top5: 95.58	
[09/23 05:51:51][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/23 05:52:59][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 2.04e-02, avg batch time: 0.8016, average train loss: 0.5502average G loss: 0.0018, average realD loss: 0.0097, average fakeD loss: 0.0094, 
[09/23 05:53:01][INFO] visual_prompt:  435: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1206, average loss: 1.1444
[09/23 05:53:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.67	top5: 92.67	
[09/23 05:53:15][INFO] visual_prompt:  435: Inference (test):avg data time: 9.89e-05, avg batch time: 0.1273, average loss: 1.0639
[09/23 05:53:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.82	top5: 93.87	
[09/23 05:53:15][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/23 05:54:23][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.89e-02, avg batch time: 0.7998, average train loss: 0.4832average G loss: 0.0020, average realD loss: 0.0118, average fakeD loss: 0.0152, 
[09/23 05:54:25][INFO] visual_prompt:  435: Inference (val):avg data time: 5.93e-05, avg batch time: 0.1195, average loss: 0.9675
[09/23 05:54:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 93.83	
[09/23 05:54:39][INFO] visual_prompt:  435: Inference (test):avg data time: 8.24e-05, avg batch time: 0.1271, average loss: 0.9411
[09/23 05:54:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.19	top5: 94.32	
[09/23 05:54:39][INFO] visual_prompt:  357: Best epoch 18: best metric: 0.797
[09/23 05:54:39][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/23 05:55:47][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.81e-02, avg batch time: 0.7989, average train loss: 0.5039average G loss: 0.0021, average realD loss: 0.0091, average fakeD loss: 0.0095, 
[09/23 05:55:50][INFO] visual_prompt:  435: Inference (val):avg data time: 6.07e-05, avg batch time: 0.1197, average loss: 0.9397
[09/23 05:55:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 95.67	
[09/23 05:56:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1271, average loss: 0.8958
[09/23 05:56:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.48	top5: 95.01	
[09/23 05:56:03][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/23 05:57:11][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 2.07e-02, avg batch time: 0.8012, average train loss: 0.5086average G loss: 0.0018, average realD loss: 0.0105, average fakeD loss: 0.0118, 
[09/23 05:57:14][INFO] visual_prompt:  435: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1196, average loss: 0.9721
[09/23 05:57:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.17	top5: 94.50	
[09/23 05:57:28][INFO] visual_prompt:  435: Inference (test):avg data time: 9.02e-05, avg batch time: 0.1271, average loss: 0.9351
[09/23 05:57:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.75	top5: 95.10	
[09/23 05:57:28][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/23 05:58:36][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.84e-02, avg batch time: 0.7998, average train loss: 0.4626average G loss: 0.0017, average realD loss: 0.0101, average fakeD loss: 0.0134, 
[09/23 05:58:38][INFO] visual_prompt:  435: Inference (val):avg data time: 5.39e-05, avg batch time: 0.1207, average loss: 0.9723
[09/23 05:58:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.17	top5: 94.33	
[09/23 05:58:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.65e-05, avg batch time: 0.1271, average loss: 0.9175
[09/23 05:58:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.25	top5: 95.10	
[09/23 05:58:52][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/23 06:00:01][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 2.04e-02, avg batch time: 0.8020, average train loss: 0.4707average G loss: 0.0023, average realD loss: 0.0097, average fakeD loss: 0.0128, 
[09/23 06:00:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.46e-05, avg batch time: 0.1197, average loss: 0.8247
[09/23 06:00:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 95.67	
[09/23 06:00:17][INFO] visual_prompt:  435: Inference (test):avg data time: 8.10e-05, avg batch time: 0.1269, average loss: 0.8152
[09/23 06:00:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.32	top5: 95.56	
[09/23 06:00:17][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/23 06:01:26][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.86e-02, avg batch time: 0.8006, average train loss: 0.5170average G loss: 0.0026, average realD loss: 0.0111, average fakeD loss: 0.0133, 
[09/23 06:01:28][INFO] visual_prompt:  435: Inference (val):avg data time: 1.07e-04, avg batch time: 0.1205, average loss: 0.9701
[09/23 06:01:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 95.00	
[09/23 06:01:42][INFO] visual_prompt:  435: Inference (test):avg data time: 8.45e-05, avg batch time: 0.1275, average loss: 0.9208
[09/23 06:01:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.70	top5: 94.65	
[09/23 06:01:42][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/23 06:02:50][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.87e-02, avg batch time: 0.8010, average train loss: 0.5191average G loss: 0.0021, average realD loss: 0.0093, average fakeD loss: 0.0112, 
[09/23 06:02:52][INFO] visual_prompt:  435: Inference (val):avg data time: 7.93e-05, avg batch time: 0.1209, average loss: 0.8696
[09/23 06:02:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 93.50	
[09/23 06:03:06][INFO] visual_prompt:  435: Inference (test):avg data time: 8.72e-05, avg batch time: 0.1276, average loss: 0.8437
[09/23 06:03:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.31	top5: 95.41	
[09/23 06:03:06][INFO] visual_prompt:  357: Best epoch 24: best metric: 0.805
[09/23 06:03:06][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/23 06:04:14][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 2.09e-02, avg batch time: 0.8037, average train loss: 0.4340average G loss: 0.0015, average realD loss: 0.0077, average fakeD loss: 0.0111, 
[09/23 06:04:17][INFO] visual_prompt:  435: Inference (val):avg data time: 6.01e-05, avg batch time: 0.1214, average loss: 0.9373
[09/23 06:04:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.17	top5: 94.00	
[09/23 06:04:30][INFO] visual_prompt:  435: Inference (test):avg data time: 8.75e-05, avg batch time: 0.1271, average loss: 0.8935
[09/23 06:04:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.84	top5: 94.44	
[09/23 06:04:30][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/23 06:05:39][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.86e-02, avg batch time: 0.8014, average train loss: 0.4773average G loss: 0.0024, average realD loss: 0.0116, average fakeD loss: 0.0131, 
[09/23 06:05:41][INFO] visual_prompt:  435: Inference (val):avg data time: 1.12e-04, avg batch time: 0.1212, average loss: 0.9529
[09/23 06:05:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 94.00	
[09/23 06:05:55][INFO] visual_prompt:  435: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1276, average loss: 0.9303
[09/23 06:05:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.51	top5: 95.15	
[09/23 06:05:55][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/23 06:07:03][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.90e-02, avg batch time: 0.8021, average train loss: 0.4635average G loss: 0.0026, average realD loss: 0.0107, average fakeD loss: 0.0135, 
[09/23 06:07:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1200, average loss: 0.8534
[09/23 06:07:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 95.00	
[09/23 06:07:19][INFO] visual_prompt:  435: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1275, average loss: 0.9215
[09/23 06:07:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.89	top5: 94.58	
[09/23 06:07:20][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/23 06:08:28][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.82e-02, avg batch time: 0.8019, average train loss: 0.4341average G loss: 0.0022, average realD loss: 0.0100, average fakeD loss: 0.0107, 
[09/23 06:08:30][INFO] visual_prompt:  435: Inference (val):avg data time: 5.47e-05, avg batch time: 0.1202, average loss: 0.9295
[09/23 06:08:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.17	top5: 94.50	
[09/23 06:08:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.09e-05, avg batch time: 0.1282, average loss: 0.8839
[09/23 06:08:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.12	top5: 95.15	
[09/23 06:08:44][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/23 06:09:52][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.87e-02, avg batch time: 0.8028, average train loss: 0.4427average G loss: 0.0020, average realD loss: 0.0116, average fakeD loss: 0.0107, 
[09/23 06:09:55][INFO] visual_prompt:  435: Inference (val):avg data time: 9.37e-05, avg batch time: 0.1200, average loss: 0.8773
[09/23 06:09:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 95.17	
[09/23 06:10:08][INFO] visual_prompt:  435: Inference (test):avg data time: 8.45e-05, avg batch time: 0.1276, average loss: 0.8895
[09/23 06:10:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.91	top5: 95.31	
[09/23 06:10:08][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/23 06:11:17][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.97e-02, avg batch time: 0.8039, average train loss: 0.3959average G loss: 0.0020, average realD loss: 0.0097, average fakeD loss: 0.0103, 
[09/23 06:11:19][INFO] visual_prompt:  435: Inference (val):avg data time: 7.52e-05, avg batch time: 0.1204, average loss: 0.7441
[09/23 06:11:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 95.50	
[09/23 06:11:33][INFO] visual_prompt:  435: Inference (test):avg data time: 9.13e-05, avg batch time: 0.1283, average loss: 0.7990
[09/23 06:11:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.74	top5: 95.48	
[09/23 06:11:33][INFO] visual_prompt:  357: Best epoch 30: best metric: 0.813
[09/23 06:11:33][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/23 06:12:41][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.94e-02, avg batch time: 0.8033, average train loss: 0.3719average G loss: 0.0017, average realD loss: 0.0083, average fakeD loss: 0.0111, 
[09/23 06:12:44][INFO] visual_prompt:  435: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1197, average loss: 0.8294
[09/23 06:12:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 95.50	
[09/23 06:12:57][INFO] visual_prompt:  435: Inference (test):avg data time: 8.97e-05, avg batch time: 0.1279, average loss: 0.7789
[09/23 06:12:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.33	top5: 95.53	
[09/23 06:12:57][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/23 06:14:06][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.88e-02, avg batch time: 0.8031, average train loss: 0.4172average G loss: 0.0027, average realD loss: 0.0099, average fakeD loss: 0.0146, 
[09/23 06:14:08][INFO] visual_prompt:  435: Inference (val):avg data time: 7.87e-05, avg batch time: 0.1204, average loss: 0.8079
[09/23 06:14:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 95.67	
[09/23 06:14:21][INFO] visual_prompt:  435: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1289, average loss: 0.8255
[09/23 06:14:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.32	top5: 95.62	
[09/23 06:14:21][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/23 06:15:30][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.91e-02, avg batch time: 0.8037, average train loss: 0.4132average G loss: 0.0020, average realD loss: 0.0090, average fakeD loss: 0.0102, 
[09/23 06:15:32][INFO] visual_prompt:  435: Inference (val):avg data time: 7.28e-05, avg batch time: 0.1210, average loss: 0.6917
[09/23 06:15:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.17	
[09/23 06:15:46][INFO] visual_prompt:  435: Inference (test):avg data time: 6.94e-05, avg batch time: 0.1273, average loss: 0.7160
[09/23 06:15:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.77	top5: 96.46	
[09/23 06:15:46][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/23 06:16:54][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.80e-02, avg batch time: 0.8026, average train loss: 0.4061average G loss: 0.0023, average realD loss: 0.0080, average fakeD loss: 0.0110, 
[09/23 06:16:57][INFO] visual_prompt:  435: Inference (val):avg data time: 5.04e-05, avg batch time: 0.1212, average loss: 0.8857
[09/23 06:16:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 95.33	
[09/23 06:17:10][INFO] visual_prompt:  435: Inference (test):avg data time: 5.74e-05, avg batch time: 0.1276, average loss: 0.8875
[09/23 06:17:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.34	top5: 95.05	
[09/23 06:17:10][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/23 06:18:19][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.86e-02, avg batch time: 0.8031, average train loss: 0.3545average G loss: 0.0024, average realD loss: 0.0122, average fakeD loss: 0.0115, 
[09/23 06:18:21][INFO] visual_prompt:  435: Inference (val):avg data time: 7.36e-05, avg batch time: 0.1206, average loss: 0.7884
[09/23 06:18:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.17	top5: 95.17	
[09/23 06:18:35][INFO] visual_prompt:  435: Inference (test):avg data time: 6.19e-05, avg batch time: 0.1279, average loss: 0.7869
[09/23 06:18:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.10	top5: 95.79	
[09/23 06:18:35][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/23 06:19:44][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.87e-02, avg batch time: 0.8039, average train loss: 0.3716average G loss: 0.0021, average realD loss: 0.0082, average fakeD loss: 0.0118, 
[09/23 06:19:46][INFO] visual_prompt:  435: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1207, average loss: 0.7655
[09/23 06:19:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 95.67	
[09/23 06:19:59][INFO] visual_prompt:  435: Inference (test):avg data time: 8.85e-05, avg batch time: 0.1281, average loss: 0.7935
[09/23 06:19:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.77	top5: 95.72	
[09/23 06:19:59][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/23 06:21:08][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.90e-02, avg batch time: 0.8041, average train loss: 0.3734average G loss: 0.0014, average realD loss: 0.0084, average fakeD loss: 0.0112, 
[09/23 06:21:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.84e-05, avg batch time: 0.1200, average loss: 0.9872
[09/23 06:21:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 94.83	
[09/23 06:21:24][INFO] visual_prompt:  435: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1279, average loss: 0.9032
[09/23 06:21:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.43	top5: 95.22	
[09/23 06:21:24][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/23 06:22:33][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.96e-02, avg batch time: 0.8048, average train loss: 0.3410average G loss: 0.0019, average realD loss: 0.0086, average fakeD loss: 0.0117, 
[09/23 06:22:35][INFO] visual_prompt:  435: Inference (val):avg data time: 6.07e-05, avg batch time: 0.1200, average loss: 0.7901
[09/23 06:22:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 96.50	
[09/23 06:22:49][INFO] visual_prompt:  435: Inference (test):avg data time: 1.08e-04, avg batch time: 0.1282, average loss: 0.8362
[09/23 06:22:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.46	top5: 95.39	
[09/23 06:22:49][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/23 06:23:57][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 1.97e-02, avg batch time: 0.8047, average train loss: 0.3334average G loss: 0.0018, average realD loss: 0.0095, average fakeD loss: 0.0134, 
[09/23 06:24:00][INFO] visual_prompt:  435: Inference (val):avg data time: 4.85e-05, avg batch time: 0.1205, average loss: 0.9286
[09/23 06:24:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 95.67	
[09/23 06:24:14][INFO] visual_prompt:  435: Inference (test):avg data time: 1.17e-04, avg batch time: 0.1280, average loss: 0.8867
[09/23 06:24:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.41	top5: 95.91	
[09/23 06:24:14][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/23 06:25:22][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.96e-02, avg batch time: 0.8040, average train loss: 0.3386average G loss: 0.0019, average realD loss: 0.0085, average fakeD loss: 0.0103, 
[09/23 06:25:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1204, average loss: 0.8072
[09/23 06:25:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 96.50	
[09/23 06:25:38][INFO] visual_prompt:  435: Inference (test):avg data time: 8.46e-05, avg batch time: 0.1285, average loss: 0.8525
[09/23 06:25:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.98	top5: 95.86	
[09/23 06:25:38][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 1.875
[09/23 06:26:46][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.81e-02, avg batch time: 0.8022, average train loss: 0.3286average G loss: 0.0019, average realD loss: 0.0096, average fakeD loss: 0.0107, 
[09/23 06:26:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.23e-05, avg batch time: 0.1199, average loss: 0.7197
[09/23 06:26:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 96.50	
[09/23 06:27:02][INFO] visual_prompt:  435: Inference (test):avg data time: 9.51e-05, avg batch time: 0.1277, average loss: 0.7180
[09/23 06:27:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.00	top5: 96.69	
[09/23 06:27:02][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/23 06:28:11][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 2.03e-02, avg batch time: 0.8044, average train loss: 0.3090average G loss: 0.0022, average realD loss: 0.0095, average fakeD loss: 0.0106, 
[09/23 06:28:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.76e-05, avg batch time: 0.1196, average loss: 0.7934
[09/23 06:28:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.50	top5: 96.00	
[09/23 06:28:27][INFO] visual_prompt:  435: Inference (test):avg data time: 7.82e-05, avg batch time: 0.1277, average loss: 0.7493
[09/23 06:28:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.65	top5: 96.34	
[09/23 06:28:27][INFO] visual_prompt:  357: Best epoch 42: best metric: 0.815
[09/23 06:28:27][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/23 06:29:36][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.95e-02, avg batch time: 0.8027, average train loss: 0.2764average G loss: 0.0015, average realD loss: 0.0078, average fakeD loss: 0.0106, 
[09/23 06:29:38][INFO] visual_prompt:  435: Inference (val):avg data time: 5.21e-05, avg batch time: 0.1212, average loss: 0.6989
[09/23 06:29:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.00	top5: 97.17	
[09/23 06:29:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1271, average loss: 0.7101
[09/23 06:29:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.27	top5: 96.41	
[09/23 06:29:52][INFO] visual_prompt:  357: Best epoch 43: best metric: 0.830
[09/23 06:29:52][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/23 06:31:01][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 2.22e-02, avg batch time: 0.8047, average train loss: 0.2741average G loss: 0.0016, average realD loss: 0.0078, average fakeD loss: 0.0087, 
[09/23 06:31:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.33e-05, avg batch time: 0.1200, average loss: 0.7011
[09/23 06:31:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 97.50	
[09/23 06:31:17][INFO] visual_prompt:  435: Inference (test):avg data time: 5.87e-05, avg batch time: 0.1274, average loss: 0.7107
[09/23 06:31:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.77	top5: 96.77	
[09/23 06:31:17][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/23 06:32:25][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.92e-02, avg batch time: 0.8014, average train loss: 0.2730average G loss: 0.0015, average realD loss: 0.0069, average fakeD loss: 0.0076, 
[09/23 06:32:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1207, average loss: 0.6719
[09/23 06:32:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 96.67	
[09/23 06:32:41][INFO] visual_prompt:  435: Inference (test):avg data time: 8.74e-05, avg batch time: 0.1275, average loss: 0.6794
[09/23 06:32:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.02	top5: 96.74	
[09/23 06:32:41][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/23 06:33:49][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 1.94e-02, avg batch time: 0.8012, average train loss: 0.2766average G loss: 0.0014, average realD loss: 0.0076, average fakeD loss: 0.0101, 
[09/23 06:33:52][INFO] visual_prompt:  435: Inference (val):avg data time: 8.48e-05, avg batch time: 0.1195, average loss: 0.7349
[09/23 06:33:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 95.00	
[09/23 06:34:05][INFO] visual_prompt:  435: Inference (test):avg data time: 9.51e-05, avg batch time: 0.1276, average loss: 0.6802
[09/23 06:34:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.74	top5: 96.50	
[09/23 06:34:05][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/23 06:35:13][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 1.90e-02, avg batch time: 0.8001, average train loss: 0.2591average G loss: 0.0015, average realD loss: 0.0094, average fakeD loss: 0.0099, 
[09/23 06:35:16][INFO] visual_prompt:  435: Inference (val):avg data time: 6.88e-05, avg batch time: 0.1204, average loss: 0.7742
[09/23 06:35:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.00	
[09/23 06:35:29][INFO] visual_prompt:  435: Inference (test):avg data time: 7.34e-05, avg batch time: 0.1271, average loss: 0.7752
[09/23 06:35:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.86	top5: 96.19	
[09/23 06:35:29][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/23 06:36:38][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.89e-02, avg batch time: 0.8007, average train loss: 0.2642average G loss: 0.0017, average realD loss: 0.0080, average fakeD loss: 0.0092, 
[09/23 06:36:40][INFO] visual_prompt:  435: Inference (val):avg data time: 6.98e-05, avg batch time: 0.1204, average loss: 0.6324
[09/23 06:36:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 97.00	
[09/23 06:36:54][INFO] visual_prompt:  435: Inference (test):avg data time: 1.03e-04, avg batch time: 0.1273, average loss: 0.6539
[09/23 06:36:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.12	top5: 97.07	
[09/23 06:36:54][INFO] visual_prompt:  357: Best epoch 48: best metric: 0.835
[09/23 06:36:54][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/23 06:38:02][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.94e-02, avg batch time: 0.8016, average train loss: 0.2382average G loss: 0.0019, average realD loss: 0.0095, average fakeD loss: 0.0117, 
[09/23 06:38:04][INFO] visual_prompt:  435: Inference (val):avg data time: 5.21e-05, avg batch time: 0.1201, average loss: 0.6475
[09/23 06:38:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 97.33	
[09/23 06:38:19][INFO] visual_prompt:  435: Inference (test):avg data time: 7.03e-05, avg batch time: 0.1272, average loss: 0.6618
[09/23 06:38:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.03	top5: 96.65	
[09/23 06:38:19][INFO] visual_prompt:  357: Best epoch 49: best metric: 0.840
[09/23 06:38:19][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/23 06:39:27][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 1.87e-02, avg batch time: 0.8013, average train loss: 0.2545average G loss: 0.0014, average realD loss: 0.0073, average fakeD loss: 0.0087, 
[09/23 06:39:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.44e-05, avg batch time: 0.1207, average loss: 0.6716
[09/23 06:39:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.67	
[09/23 06:39:43][INFO] visual_prompt:  435: Inference (test):avg data time: 9.66e-05, avg batch time: 0.1274, average loss: 0.6707
[09/23 06:39:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.24	top5: 97.10	
[09/23 06:39:44][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/23 06:40:52][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 2.05e-02, avg batch time: 0.8037, average train loss: 0.2202average G loss: 0.0011, average realD loss: 0.0084, average fakeD loss: 0.0100, 
[09/23 06:40:54][INFO] visual_prompt:  435: Inference (val):avg data time: 5.77e-05, avg batch time: 0.1203, average loss: 0.6259
[09/23 06:40:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.17	
[09/23 06:41:08][INFO] visual_prompt:  435: Inference (test):avg data time: 8.76e-05, avg batch time: 0.1274, average loss: 0.6388
[09/23 06:41:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.90	top5: 97.00	
[09/23 06:41:08][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/23 06:42:17][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 2.05e-02, avg batch time: 0.8042, average train loss: 0.2041average G loss: 0.0013, average realD loss: 0.0076, average fakeD loss: 0.0111, 
[09/23 06:42:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.72e-05, avg batch time: 0.1213, average loss: 0.7160
[09/23 06:42:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 96.33	
[09/23 06:42:33][INFO] visual_prompt:  435: Inference (test):avg data time: 7.26e-05, avg batch time: 0.1280, average loss: 0.6804
[09/23 06:42:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.19	top5: 97.07	
[09/23 06:42:33][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/23 06:43:41][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.75e-02, avg batch time: 0.8012, average train loss: 0.2112average G loss: 0.0015, average realD loss: 0.0073, average fakeD loss: 0.0085, 
[09/23 06:43:43][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1199, average loss: 0.6695
[09/23 06:43:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 97.00	
[09/23 06:43:57][INFO] visual_prompt:  435: Inference (test):avg data time: 8.15e-05, avg batch time: 0.1274, average loss: 0.6543
[09/23 06:43:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.57	top5: 96.86	
[09/23 06:43:57][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/23 06:45:06][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.85e-02, avg batch time: 0.8026, average train loss: 0.2332average G loss: 0.0013, average realD loss: 0.0077, average fakeD loss: 0.0091, 
[09/23 06:45:08][INFO] visual_prompt:  435: Inference (val):avg data time: 5.76e-05, avg batch time: 0.1203, average loss: 0.6941
[09/23 06:45:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 96.50	
[09/23 06:45:22][INFO] visual_prompt:  435: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1277, average loss: 0.6813
[09/23 06:45:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.72	top5: 96.74	
[09/23 06:45:22][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/23 06:46:30][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.99e-02, avg batch time: 0.8038, average train loss: 0.2006average G loss: 0.0015, average realD loss: 0.0072, average fakeD loss: 0.0079, 
[09/23 06:46:33][INFO] visual_prompt:  435: Inference (val):avg data time: 7.97e-05, avg batch time: 0.1213, average loss: 0.6658
[09/23 06:46:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 97.67	
[09/23 06:46:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1277, average loss: 0.6623
[09/23 06:46:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.34	top5: 96.72	
[09/23 06:46:47][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 1.25
[09/23 06:47:55][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 2.06e-02, avg batch time: 0.8048, average train loss: 0.2086average G loss: 0.0013, average realD loss: 0.0063, average fakeD loss: 0.0077, 
[09/23 06:47:58][INFO] visual_prompt:  435: Inference (val):avg data time: 7.59e-05, avg batch time: 0.1219, average loss: 0.5975
[09/23 06:47:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.50	
[09/23 06:48:11][INFO] visual_prompt:  435: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1280, average loss: 0.5755
[09/23 06:48:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.23	top5: 97.88	
[09/23 06:48:11][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/23 06:49:20][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 2.04e-02, avg batch time: 0.8049, average train loss: 0.1995average G loss: 0.0011, average realD loss: 0.0065, average fakeD loss: 0.0093, 
[09/23 06:49:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1205, average loss: 0.5919
[09/23 06:49:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 98.50	
[09/23 06:49:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1279, average loss: 0.6038
[09/23 06:49:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.67	top5: 97.26	
[09/23 06:49:36][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/23 06:50:45][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 2.02e-02, avg batch time: 0.8049, average train loss: 0.1808average G loss: 0.0011, average realD loss: 0.0064, average fakeD loss: 0.0083, 
[09/23 06:50:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.88e-05, avg batch time: 0.1210, average loss: 0.5680
[09/23 06:50:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.83	
[09/23 06:51:01][INFO] visual_prompt:  435: Inference (test):avg data time: 8.34e-05, avg batch time: 0.1279, average loss: 0.5813
[09/23 06:51:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.74	top5: 97.39	
[09/23 06:51:01][INFO] visual_prompt:  357: Best epoch 58: best metric: 0.847
[09/23 06:51:01][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/23 06:52:09][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.98e-02, avg batch time: 0.8044, average train loss: 0.1610average G loss: 0.0011, average realD loss: 0.0073, average fakeD loss: 0.0092, 
[09/23 06:52:12][INFO] visual_prompt:  435: Inference (val):avg data time: 8.63e-05, avg batch time: 0.1198, average loss: 0.6019
[09/23 06:52:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 97.50	
[09/23 06:52:25][INFO] visual_prompt:  435: Inference (test):avg data time: 6.20e-05, avg batch time: 0.1287, average loss: 0.5937
[09/23 06:52:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.97	top5: 97.15	
[09/23 06:52:25][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/23 06:53:34][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 2.01e-02, avg batch time: 0.8048, average train loss: 0.1683average G loss: 0.0016, average realD loss: 0.0076, average fakeD loss: 0.0102, 
[09/23 06:53:36][INFO] visual_prompt:  435: Inference (val):avg data time: 6.40e-05, avg batch time: 0.1204, average loss: 0.5774
[09/23 06:53:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 97.83	
[09/23 06:53:50][INFO] visual_prompt:  435: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1281, average loss: 0.5723
[09/23 06:53:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.55	top5: 97.53	
[09/23 06:53:50][INFO] visual_prompt:  357: Best epoch 60: best metric: 0.852
[09/23 06:53:50][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/23 06:54:58][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.86e-02, avg batch time: 0.8037, average train loss: 0.1742average G loss: 0.0012, average realD loss: 0.0074, average fakeD loss: 0.0091, 
[09/23 06:55:01][INFO] visual_prompt:  435: Inference (val):avg data time: 6.26e-05, avg batch time: 0.1198, average loss: 0.5994
[09/23 06:55:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.67	
[09/23 06:55:15][INFO] visual_prompt:  435: Inference (test):avg data time: 6.43e-05, avg batch time: 0.1280, average loss: 0.6068
[09/23 06:55:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.05	top5: 97.41	
[09/23 06:55:15][INFO] visual_prompt:  357: Best epoch 61: best metric: 0.857
[09/23 06:55:15][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/23 06:56:23][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 2.23e-02, avg batch time: 0.8073, average train loss: 0.1759average G loss: 0.0011, average realD loss: 0.0065, average fakeD loss: 0.0088, 
[09/23 06:56:26][INFO] visual_prompt:  435: Inference (val):avg data time: 6.18e-05, avg batch time: 0.1202, average loss: 0.5799
[09/23 06:56:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.83	
[09/23 06:56:40][INFO] visual_prompt:  435: Inference (test):avg data time: 6.40e-05, avg batch time: 0.1275, average loss: 0.5892
[09/23 06:56:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.64	top5: 97.34	
[09/23 06:56:40][INFO] visual_prompt:  357: Best epoch 62: best metric: 0.862
[09/23 06:56:40][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/23 06:57:48][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 1.89e-02, avg batch time: 0.8042, average train loss: 0.1554average G loss: 0.0010, average realD loss: 0.0064, average fakeD loss: 0.0069, 
[09/23 06:57:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1216, average loss: 0.5582
[09/23 06:57:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.00	
[09/23 06:58:04][INFO] visual_prompt:  435: Inference (test):avg data time: 8.51e-05, avg batch time: 0.1286, average loss: 0.5716
[09/23 06:58:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.64	top5: 97.38	
[09/23 06:58:04][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/23 06:59:13][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.99e-02, avg batch time: 0.8056, average train loss: 0.1496average G loss: 0.0010, average realD loss: 0.0071, average fakeD loss: 0.0090, 
[09/23 06:59:15][INFO] visual_prompt:  435: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1210, average loss: 0.5799
[09/23 06:59:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 97.83	
[09/23 06:59:29][INFO] visual_prompt:  435: Inference (test):avg data time: 6.61e-05, avg batch time: 0.1277, average loss: 0.5605
[09/23 06:59:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.71	top5: 97.46	
[09/23 06:59:29][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/23 07:00:38][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 2.04e-02, avg batch time: 0.8058, average train loss: 0.1471average G loss: 0.0011, average realD loss: 0.0077, average fakeD loss: 0.0093, 
[09/23 07:00:40][INFO] visual_prompt:  435: Inference (val):avg data time: 6.76e-05, avg batch time: 0.1209, average loss: 0.5307
[09/23 07:00:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/23 07:00:54][INFO] visual_prompt:  435: Inference (test):avg data time: 6.83e-05, avg batch time: 0.1280, average loss: 0.5386
[09/23 07:00:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.61	top5: 97.51	
[09/23 07:00:54][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/23 07:02:02][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.80e-02, avg batch time: 0.8031, average train loss: 0.1472average G loss: 0.0011, average realD loss: 0.0065, average fakeD loss: 0.0079, 
[09/23 07:02:05][INFO] visual_prompt:  435: Inference (val):avg data time: 5.69e-05, avg batch time: 0.1207, average loss: 0.5283
[09/23 07:02:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.17	
[09/23 07:02:18][INFO] visual_prompt:  435: Inference (test):avg data time: 7.50e-05, avg batch time: 0.1281, average loss: 0.5459
[09/23 07:02:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.05	top5: 97.55	
[09/23 07:02:18][INFO] visual_prompt:  357: Best epoch 66: best metric: 0.867
[09/23 07:02:18][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/23 07:03:27][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.76e-02, avg batch time: 0.8022, average train loss: 0.1384average G loss: 0.0009, average realD loss: 0.0056, average fakeD loss: 0.0074, 
[09/23 07:03:29][INFO] visual_prompt:  435: Inference (val):avg data time: 5.94e-05, avg batch time: 0.1209, average loss: 0.5345
[09/23 07:03:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.17	
[09/23 07:03:43][INFO] visual_prompt:  435: Inference (test):avg data time: 8.76e-05, avg batch time: 0.1277, average loss: 0.5454
[09/23 07:03:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.62	
[09/23 07:03:43][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/23 07:04:51][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.91e-02, avg batch time: 0.8032, average train loss: 0.1351average G loss: 0.0010, average realD loss: 0.0066, average fakeD loss: 0.0066, 
[09/23 07:04:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1200, average loss: 0.5342
[09/23 07:04:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.17	
[09/23 07:05:07][INFO] visual_prompt:  435: Inference (test):avg data time: 6.37e-05, avg batch time: 0.1279, average loss: 0.5272
[09/23 07:05:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.65	
[09/23 07:05:07][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/23 07:06:15][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 2.05e-02, avg batch time: 0.8040, average train loss: 0.1441average G loss: 0.0010, average realD loss: 0.0049, average fakeD loss: 0.0091, 
[09/23 07:06:18][INFO] visual_prompt:  435: Inference (val):avg data time: 5.51e-05, avg batch time: 0.1214, average loss: 0.5193
[09/23 07:06:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.67	
[09/23 07:06:31][INFO] visual_prompt:  435: Inference (test):avg data time: 8.02e-05, avg batch time: 0.1277, average loss: 0.5277
[09/23 07:06:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.55	
[09/23 07:06:31][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/23 07:07:40][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.87e-02, avg batch time: 0.8015, average train loss: 0.1340average G loss: 0.0009, average realD loss: 0.0067, average fakeD loss: 0.0093, 
[09/23 07:07:42][INFO] visual_prompt:  435: Inference (val):avg data time: 4.63e-05, avg batch time: 0.1217, average loss: 0.5136
[09/23 07:07:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.50	
[09/23 07:07:56][INFO] visual_prompt:  435: Inference (test):avg data time: 6.83e-05, avg batch time: 0.1275, average loss: 0.5131
[09/23 07:07:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.97	top5: 97.91	
[09/23 07:07:56][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/23 07:09:04][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 1.83e-02, avg batch time: 0.8008, average train loss: 0.1304average G loss: 0.0009, average realD loss: 0.0062, average fakeD loss: 0.0070, 
[09/23 07:09:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1204, average loss: 0.5088
[09/23 07:09:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.50	
[09/23 07:09:20][INFO] visual_prompt:  435: Inference (test):avg data time: 8.76e-05, avg batch time: 0.1277, average loss: 0.5167
[09/23 07:09:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.97	top5: 97.79	
[09/23 07:09:20][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/23 07:10:28][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 2.05e-02, avg batch time: 0.8023, average train loss: 0.1248average G loss: 0.0009, average realD loss: 0.0063, average fakeD loss: 0.0086, 
[09/23 07:10:31][INFO] visual_prompt:  435: Inference (val):avg data time: 8.42e-05, avg batch time: 0.1195, average loss: 0.5055
[09/23 07:10:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.67	
[09/23 07:10:46][INFO] visual_prompt:  435: Inference (test):avg data time: 8.14e-05, avg batch time: 0.1265, average loss: 0.5180
[09/23 07:10:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.69	
[09/23 07:10:46][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/23 07:11:54][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 2.16e-02, avg batch time: 0.8029, average train loss: 0.1222average G loss: 0.0009, average realD loss: 0.0059, average fakeD loss: 0.0064, 
[09/23 07:11:57][INFO] visual_prompt:  435: Inference (val):avg data time: 8.21e-05, avg batch time: 0.1195, average loss: 0.5314
[09/23 07:11:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.50	
[09/23 07:12:12][INFO] visual_prompt:  435: Inference (test):avg data time: 9.11e-05, avg batch time: 0.1267, average loss: 0.5337
[09/23 07:12:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.38	top5: 97.69	
[09/23 07:12:12][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/23 07:13:20][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 2.01e-02, avg batch time: 0.8014, average train loss: 0.1171average G loss: 0.0008, average realD loss: 0.0063, average fakeD loss: 0.0082, 
[09/23 07:13:22][INFO] visual_prompt:  435: Inference (val):avg data time: 7.70e-05, avg batch time: 0.1198, average loss: 0.5167
[09/23 07:13:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 97.83	
[09/23 07:13:36][INFO] visual_prompt:  435: Inference (test):avg data time: 1.07e-04, avg batch time: 0.1270, average loss: 0.5219
[09/23 07:13:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.33	top5: 97.69	
[09/23 07:13:37][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/23 07:14:45][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 2.09e-02, avg batch time: 0.8023, average train loss: 0.1198average G loss: 0.0007, average realD loss: 0.0056, average fakeD loss: 0.0063, 
[09/23 07:14:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.98e-05, avg batch time: 0.1191, average loss: 0.4909
[09/23 07:14:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.67	
[09/23 07:15:02][INFO] visual_prompt:  435: Inference (test):avg data time: 8.65e-05, avg batch time: 0.1268, average loss: 0.5030
[09/23 07:15:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.12	top5: 97.91	
[09/23 07:15:02][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/23 07:16:10][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.96e-02, avg batch time: 0.8008, average train loss: 0.1148average G loss: 0.0007, average realD loss: 0.0075, average fakeD loss: 0.0080, 
[09/23 07:16:13][INFO] visual_prompt:  435: Inference (val):avg data time: 8.06e-05, avg batch time: 0.1193, average loss: 0.5037
[09/23 07:16:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.50	
[09/23 07:16:28][INFO] visual_prompt:  435: Inference (test):avg data time: 9.38e-05, avg batch time: 0.1266, average loss: 0.5076
[09/23 07:16:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.76	top5: 97.84	
[09/23 07:16:28][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/23 07:17:36][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 2.08e-02, avg batch time: 0.8023, average train loss: 0.1148average G loss: 0.0007, average realD loss: 0.0058, average fakeD loss: 0.0064, 
[09/23 07:17:38][INFO] visual_prompt:  435: Inference (val):avg data time: 7.81e-05, avg batch time: 0.1194, average loss: 0.5098
[09/23 07:17:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.67	
[09/23 07:17:53][INFO] visual_prompt:  435: Inference (test):avg data time: 9.68e-05, avg batch time: 0.1261, average loss: 0.5138
[09/23 07:17:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.50	top5: 97.83	
[09/23 07:17:53][INFO] visual_prompt:  357: Best epoch 77: best metric: 0.870
[09/23 07:17:53][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/23 07:19:02][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 2.05e-02, avg batch time: 0.8017, average train loss: 0.1172average G loss: 0.0007, average realD loss: 0.0060, average fakeD loss: 0.0071, 
[09/23 07:19:04][INFO] visual_prompt:  435: Inference (val):avg data time: 1.02e-04, avg batch time: 0.1205, average loss: 0.5166
[09/23 07:19:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.67	
[09/23 07:19:17][INFO] visual_prompt:  435: Inference (test):avg data time: 6.51e-05, avg batch time: 0.1275, average loss: 0.5220
[09/23 07:19:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.23	top5: 97.67	
[09/23 07:19:17][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/23 07:20:26][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.88e-02, avg batch time: 0.8003, average train loss: 0.1082average G loss: 0.0007, average realD loss: 0.0058, average fakeD loss: 0.0091, 
[09/23 07:20:28][INFO] visual_prompt:  435: Inference (val):avg data time: 6.03e-05, avg batch time: 0.1212, average loss: 0.4994
[09/23 07:20:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 99.17	
[09/23 07:20:42][INFO] visual_prompt:  435: Inference (test):avg data time: 1.05e-04, avg batch time: 0.1271, average loss: 0.5051
[09/23 07:20:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.26	top5: 97.91	
[09/23 07:20:42][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/23 07:21:50][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 1.92e-02, avg batch time: 0.8010, average train loss: 0.1123average G loss: 0.0007, average realD loss: 0.0063, average fakeD loss: 0.0099, 
[09/23 07:21:52][INFO] visual_prompt:  435: Inference (val):avg data time: 5.79e-05, avg batch time: 0.1200, average loss: 0.4992
[09/23 07:21:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.50	
[09/23 07:22:06][INFO] visual_prompt:  435: Inference (test):avg data time: 7.36e-05, avg batch time: 0.1277, average loss: 0.5091
[09/23 07:22:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.23	top5: 97.93	
[09/23 07:22:06][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/23 07:23:14][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.94e-02, avg batch time: 0.8017, average train loss: 0.1065average G loss: 0.0006, average realD loss: 0.0059, average fakeD loss: 0.0064, 
[09/23 07:23:17][INFO] visual_prompt:  435: Inference (val):avg data time: 6.38e-05, avg batch time: 0.1191, average loss: 0.4905
[09/23 07:23:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 99.00	
[09/23 07:23:30][INFO] visual_prompt:  435: Inference (test):avg data time: 7.64e-05, avg batch time: 0.1277, average loss: 0.4936
[09/23 07:23:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.69	top5: 97.86	
[09/23 07:23:30][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/23 07:24:38][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.84e-02, avg batch time: 0.8013, average train loss: 0.1014average G loss: 0.0006, average realD loss: 0.0058, average fakeD loss: 0.0086, 
[09/23 07:24:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.18e-05, avg batch time: 0.1199, average loss: 0.5036
[09/23 07:24:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.50	
[09/23 07:24:55][INFO] visual_prompt:  435: Inference (test):avg data time: 1.20e-04, avg batch time: 0.1274, average loss: 0.5121
[09/23 07:24:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.68	top5: 97.86	
[09/23 07:24:55][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/23 07:26:03][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 2.04e-02, avg batch time: 0.8033, average train loss: 0.1033average G loss: 0.0008, average realD loss: 0.0053, average fakeD loss: 0.0086, 
[09/23 07:26:05][INFO] visual_prompt:  435: Inference (val):avg data time: 6.59e-05, avg batch time: 0.1200, average loss: 0.4981
[09/23 07:26:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 99.00	
[09/23 07:26:19][INFO] visual_prompt:  435: Inference (test):avg data time: 9.18e-05, avg batch time: 0.1278, average loss: 0.4993
[09/23 07:26:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.69	top5: 98.02	
[09/23 07:26:19][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/23 07:27:27][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.92e-02, avg batch time: 0.8026, average train loss: 0.0999average G loss: 0.0005, average realD loss: 0.0066, average fakeD loss: 0.0082, 
[09/23 07:27:30][INFO] visual_prompt:  435: Inference (val):avg data time: 7.04e-05, avg batch time: 0.1203, average loss: 0.4770
[09/23 07:27:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.83	
[09/23 07:27:43][INFO] visual_prompt:  435: Inference (test):avg data time: 5.94e-05, avg batch time: 0.1279, average loss: 0.4935
[09/23 07:27:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.59	top5: 97.93	
[09/23 07:27:43][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/23 07:28:52][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.99e-02, avg batch time: 0.8036, average train loss: 0.0951average G loss: 0.0006, average realD loss: 0.0053, average fakeD loss: 0.0055, 
[09/23 07:28:54][INFO] visual_prompt:  435: Inference (val):avg data time: 4.74e-05, avg batch time: 0.1214, average loss: 0.4767
[09/23 07:28:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.67	
[09/23 07:29:08][INFO] visual_prompt:  435: Inference (test):avg data time: 9.71e-05, avg batch time: 0.1274, average loss: 0.4898
[09/23 07:29:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.02	top5: 97.95	
[09/23 07:29:08][INFO] visual_prompt:  357: Best epoch 85: best metric: 0.873
[09/23 07:29:08][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/23 07:30:17][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.96e-02, avg batch time: 0.8033, average train loss: 0.0970average G loss: 0.0005, average realD loss: 0.0046, average fakeD loss: 0.0077, 
[09/23 07:30:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.77e-05, avg batch time: 0.1208, average loss: 0.4977
[09/23 07:30:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.83	
[09/23 07:30:33][INFO] visual_prompt:  435: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1273, average loss: 0.4963
[09/23 07:30:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.07	top5: 98.03	
[09/23 07:30:33][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/23 07:31:41][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.96e-02, avg batch time: 0.8039, average train loss: 0.0914average G loss: 0.0005, average realD loss: 0.0053, average fakeD loss: 0.0060, 
[09/23 07:31:44][INFO] visual_prompt:  435: Inference (val):avg data time: 7.24e-05, avg batch time: 0.1212, average loss: 0.4849
[09/23 07:31:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 99.17	
[09/23 07:31:58][INFO] visual_prompt:  435: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1274, average loss: 0.4956
[09/23 07:31:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.94	top5: 97.98	
[09/23 07:31:58][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/23 07:33:06][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.91e-02, avg batch time: 0.8033, average train loss: 0.0920average G loss: 0.0006, average realD loss: 0.0056, average fakeD loss: 0.0078, 
[09/23 07:33:08][INFO] visual_prompt:  435: Inference (val):avg data time: 6.22e-05, avg batch time: 0.1201, average loss: 0.4864
[09/23 07:33:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.83	
[09/23 07:33:22][INFO] visual_prompt:  435: Inference (test):avg data time: 6.90e-05, avg batch time: 0.1280, average loss: 0.4937
[09/23 07:33:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.80	top5: 97.95	
[09/23 07:33:22][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/23 07:34:30][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.95e-02, avg batch time: 0.8042, average train loss: 0.0897average G loss: 0.0005, average realD loss: 0.0051, average fakeD loss: 0.0062, 
[09/23 07:34:33][INFO] visual_prompt:  435: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1198, average loss: 0.4820
[09/23 07:34:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.67	
[09/23 07:34:46][INFO] visual_prompt:  435: Inference (test):avg data time: 8.14e-05, avg batch time: 0.1280, average loss: 0.4903
[09/23 07:34:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.75	top5: 97.95	
[09/23 07:34:47][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/23 07:35:55][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.85e-02, avg batch time: 0.8031, average train loss: 0.0819average G loss: 0.0005, average realD loss: 0.0056, average fakeD loss: 0.0091, 
[09/23 07:35:57][INFO] visual_prompt:  435: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1199, average loss: 0.4779
[09/23 07:35:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.67	
[09/23 07:36:11][INFO] visual_prompt:  435: Inference (test):avg data time: 6.37e-05, avg batch time: 0.1280, average loss: 0.4871
[09/23 07:36:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.07	top5: 97.93	
[09/23 07:36:11][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/23 07:37:19][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.84e-02, avg batch time: 0.8030, average train loss: 0.0820average G loss: 0.0005, average realD loss: 0.0067, average fakeD loss: 0.0044, 
[09/23 07:37:21][INFO] visual_prompt:  435: Inference (val):avg data time: 5.68e-05, avg batch time: 0.1199, average loss: 0.4698
[09/23 07:37:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.83	
[09/23 07:37:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.14e-05, avg batch time: 0.1280, average loss: 0.4830
[09/23 07:37:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.83	top5: 97.89	
[09/23 07:37:35][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/23 07:38:44][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 2.01e-02, avg batch time: 0.8053, average train loss: 0.0820average G loss: 0.0005, average realD loss: 0.0045, average fakeD loss: 0.0085, 
[09/23 07:38:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.49e-05, avg batch time: 0.1206, average loss: 0.4878
[09/23 07:38:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.83	
[09/23 07:38:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.34e-05, avg batch time: 0.1286, average loss: 0.4899
[09/23 07:38:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.97	top5: 97.88	
[09/23 07:38:59][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/23 07:40:08][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 2.09e-02, avg batch time: 0.8061, average train loss: 0.0824average G loss: 0.0005, average realD loss: 0.0051, average fakeD loss: 0.0071, 
[09/23 07:40:10][INFO] visual_prompt:  435: Inference (val):avg data time: 4.90e-05, avg batch time: 0.1215, average loss: 0.4818
[09/23 07:40:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.83	
[09/23 07:40:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.43e-05, avg batch time: 0.1283, average loss: 0.4879
[09/23 07:40:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.13	top5: 97.91	
[09/23 07:40:24][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/23 07:41:32][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.75e-02, avg batch time: 0.8028, average train loss: 0.0786average G loss: 0.0006, average realD loss: 0.0059, average fakeD loss: 0.0081, 
[09/23 07:41:35][INFO] visual_prompt:  435: Inference (val):avg data time: 7.15e-05, avg batch time: 0.1202, average loss: 0.4791
[09/23 07:41:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.67	
[09/23 07:41:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.01e-05, avg batch time: 0.1284, average loss: 0.4877
[09/23 07:41:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.09	top5: 97.89	
[09/23 07:41:48][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/23 07:42:57][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 1.86e-02, avg batch time: 0.8038, average train loss: 0.0794average G loss: 0.0005, average realD loss: 0.0058, average fakeD loss: 0.0081, 
[09/23 07:42:59][INFO] visual_prompt:  435: Inference (val):avg data time: 6.84e-05, avg batch time: 0.1214, average loss: 0.4805
[09/23 07:42:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.67	
[09/23 07:43:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1275, average loss: 0.4876
[09/23 07:43:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.11	top5: 97.89	
[09/23 07:43:13][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/23 07:44:21][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.94e-02, avg batch time: 0.8048, average train loss: 0.0849average G loss: 0.0004, average realD loss: 0.0051, average fakeD loss: 0.0073, 
[09/23 07:44:24][INFO] visual_prompt:  435: Inference (val):avg data time: 7.63e-05, avg batch time: 0.1202, average loss: 0.4810
[09/23 07:44:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.67	
[09/23 07:44:37][INFO] visual_prompt:  435: Inference (test):avg data time: 9.90e-05, avg batch time: 0.1278, average loss: 0.4881
[09/23 07:44:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.18	top5: 97.86	
[09/23 07:44:37][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/23 07:45:46][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.86e-02, avg batch time: 0.8042, average train loss: 0.0760average G loss: 0.0005, average realD loss: 0.0057, average fakeD loss: 0.0042, 
[09/23 07:45:48][INFO] visual_prompt:  435: Inference (val):avg data time: 7.33e-05, avg batch time: 0.1215, average loss: 0.4782
[09/23 07:45:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.83	
[09/23 07:46:02][INFO] visual_prompt:  435: Inference (test):avg data time: 8.25e-05, avg batch time: 0.1278, average loss: 0.4855
[09/23 07:46:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.11	top5: 97.96	
[09/23 07:46:02][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/23 07:47:11][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 1.93e-02, avg batch time: 0.8048, average train loss: 0.0770average G loss: 0.0005, average realD loss: 0.0050, average fakeD loss: 0.0077, 
[09/23 07:47:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.44e-05, avg batch time: 0.1210, average loss: 0.4800
[09/23 07:47:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.83	
[09/23 07:47:27][INFO] visual_prompt:  435: Inference (test):avg data time: 7.22e-05, avg batch time: 0.1277, average loss: 0.4863
[09/23 07:47:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.06	top5: 97.93	
[09/23 07:47:27][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/23 07:48:36][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.98e-02, avg batch time: 0.8050, average train loss: 0.0769average G loss: 0.0005, average realD loss: 0.0048, average fakeD loss: 0.0084, 
[09/23 07:48:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1211, average loss: 0.4796
[09/23 07:48:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.83	
[09/23 07:48:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1278, average loss: 0.4864
[09/23 07:48:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.97	top5: 97.93	
[09/23 07:48:52][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/23 07:50:00][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.90e-02, avg batch time: 0.8037, average train loss: 0.0758average G loss: 0.0004, average realD loss: 0.0058, average fakeD loss: 0.0096, 
[09/23 07:50:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.37e-05, avg batch time: 0.1209, average loss: 0.4796
[09/23 07:50:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.83	
[09/23 07:50:17][INFO] visual_prompt:  435: Inference (test):avg data time: 1.06e-04, avg batch time: 0.1275, average loss: 0.4864
[09/23 07:50:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.02	top5: 97.91	
