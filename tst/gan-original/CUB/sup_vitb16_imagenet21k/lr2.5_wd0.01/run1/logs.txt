[09/23 00:47:27][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 00:47:27][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 00:47:27][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/23 00:47:27][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 00:47:27][INFO] visual_prompt:  109: Training with config:
[09/23 00:47:27][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr2.5_wd0.01/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 2.5,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.01,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 00:47:27][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 00:47:27][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 00:47:27][INFO] visual_prompt:   77: Number of images: 5394
[09/23 00:47:27][INFO] visual_prompt:   78: Number of classes: 200
[09/23 00:47:27][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 00:47:27][INFO] visual_prompt:   73: Loading validation data...
[09/23 00:47:27][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 00:47:27][INFO] visual_prompt:   77: Number of images: 600
[09/23 00:47:27][INFO] visual_prompt:   78: Number of classes: 200
[09/23 00:47:27][INFO] visual_prompt:   76: Loading test data...
[09/23 00:47:27][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 00:47:27][INFO] visual_prompt:   77: Number of images: 5794
[09/23 00:47:27][INFO] visual_prompt:   78: Number of classes: 200
[09/23 00:47:27][INFO] visual_prompt:  103: Constructing models...
[09/23 00:47:32][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 00:47:32][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 00:47:32][INFO] visual_prompt:   41: Device used for model: 0
[09/23 00:47:32][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 00:47:32][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 00:47:32][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 00:47:32][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/23 00:48:40][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.77e-02, avg batch time: 0.8042, average train loss: 5.3311average G loss: 8.7635, average realD loss: 13.2310, average fakeD loss: 1.6842, 
[09/23 00:48:43][INFO] visual_prompt:  435: Inference (val):avg data time: 4.80e-05, avg batch time: 0.1210, average loss: 5.3305
[09/23 00:48:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.67	
[09/23 00:48:56][INFO] visual_prompt:  435: Inference (test):avg data time: 9.05e-05, avg batch time: 0.1283, average loss: 5.3298
[09/23 00:48:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.36	top5: 2.45	
[09/23 00:48:56][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.007
[09/23 00:48:56][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.25
[09/23 00:50:05][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 2.17e-02, avg batch time: 0.8046, average train loss: 5.3373average G loss: 0.0066, average realD loss: 0.2872, average fakeD loss: 2.6785, 
[09/23 00:50:07][INFO] visual_prompt:  435: Inference (val):avg data time: 5.69e-05, avg batch time: 0.1223, average loss: 5.3111
[09/23 00:50:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 00:50:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1282, average loss: 5.3111
[09/23 00:50:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.57	
[09/23 00:50:20][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.5
[09/23 00:51:29][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.91e-02, avg batch time: 0.8067, average train loss: 5.3463average G loss: 0.0048, average realD loss: 0.0652, average fakeD loss: 0.0781, 
[09/23 00:51:32][INFO] visual_prompt:  435: Inference (val):avg data time: 5.26e-05, avg batch time: 0.1199, average loss: 5.3179
[09/23 00:51:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/23 00:51:45][INFO] visual_prompt:  435: Inference (test):avg data time: 7.86e-05, avg batch time: 0.1283, average loss: 5.3187
[09/23 00:51:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.88	
[09/23 00:51:45][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.75
[09/23 00:52:54][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.87e-02, avg batch time: 0.8062, average train loss: 5.3625average G loss: 0.0076, average realD loss: 0.0664, average fakeD loss: 0.0708, 
[09/23 00:52:56][INFO] visual_prompt:  435: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1201, average loss: 5.3491
[09/23 00:52:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 00:53:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.59e-05, avg batch time: 0.1282, average loss: 5.3472
[09/23 00:53:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 00:53:10][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 1.0
[09/23 00:54:19][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.92e-02, avg batch time: 0.8064, average train loss: 5.3851average G loss: 0.0080, average realD loss: 0.0708, average fakeD loss: 0.0718, 
[09/23 00:54:21][INFO] visual_prompt:  435: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1206, average loss: 5.4065
[09/23 00:54:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 00:54:35][INFO] visual_prompt:  435: Inference (test):avg data time: 6.02e-05, avg batch time: 0.1288, average loss: 5.4044
[09/23 00:54:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.54	
[09/23 00:54:35][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 1.25
[09/23 00:55:43][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 2.02e-02, avg batch time: 0.8074, average train loss: 5.4004average G loss: 0.0097, average realD loss: 0.0730, average fakeD loss: 0.0768, 
[09/23 00:55:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.16e-05, avg batch time: 0.1215, average loss: 5.3609
[09/23 00:55:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 00:56:00][INFO] visual_prompt:  435: Inference (test):avg data time: 6.89e-05, avg batch time: 0.1280, average loss: 5.3637
[09/23 00:56:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.30	
[09/23 00:56:00][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 1.5
[09/23 00:57:08][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.93e-02, avg batch time: 0.8062, average train loss: 5.4133average G loss: 0.0085, average realD loss: 0.0739, average fakeD loss: 0.0827, 
[09/23 00:57:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.15e-05, avg batch time: 0.1207, average loss: 5.4028
[09/23 00:57:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 00:57:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.02e-05, avg batch time: 0.1292, average loss: 5.4045
[09/23 00:57:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 00:57:24][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 1.75
[09/23 00:58:33][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 2.07e-02, avg batch time: 0.8078, average train loss: 5.4336average G loss: 0.0089, average realD loss: 0.0713, average fakeD loss: 0.0812, 
[09/23 00:58:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.56e-05, avg batch time: 0.1213, average loss: 5.4078
[09/23 00:58:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 00:58:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.59e-05, avg batch time: 0.1287, average loss: 5.4154
[09/23 00:58:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.30	
[09/23 00:58:48][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 2.0
[09/23 00:59:57][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.88e-02, avg batch time: 0.8064, average train loss: 5.4540average G loss: 0.0087, average realD loss: 0.0778, average fakeD loss: 0.0869, 
[09/23 00:59:59][INFO] visual_prompt:  435: Inference (val):avg data time: 7.20e-05, avg batch time: 0.1210, average loss: 5.3789
[09/23 00:59:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:00:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.03e-05, avg batch time: 0.1281, average loss: 5.3788
[09/23 01:00:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.45	
[09/23 01:00:13][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 2.25
[09/23 01:01:22][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.92e-02, avg batch time: 0.8062, average train loss: 5.4474average G loss: 0.0066, average realD loss: 0.0984, average fakeD loss: 0.1036, 
[09/23 01:01:24][INFO] visual_prompt:  435: Inference (val):avg data time: 5.83e-05, avg batch time: 0.1207, average loss: 5.4560
[09/23 01:01:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 01:01:38][INFO] visual_prompt:  435: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1286, average loss: 5.4650
[09/23 01:01:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 2.47	
[09/23 01:01:38][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 2.5
[09/23 01:02:47][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.96e-02, avg batch time: 0.8070, average train loss: 5.4735average G loss: 0.0087, average realD loss: 0.0863, average fakeD loss: 0.0958, 
[09/23 01:02:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.06e-05, avg batch time: 0.1219, average loss: 5.4432
[09/23 01:02:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:03:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.33e-05, avg batch time: 0.1278, average loss: 5.4422
[09/23 01:03:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 01:03:03][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/23 01:04:11][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.85e-02, avg batch time: 0.8059, average train loss: 5.4955average G loss: 0.0068, average realD loss: 0.0872, average fakeD loss: 0.1056, 
[09/23 01:04:14][INFO] visual_prompt:  435: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1206, average loss: 5.3914
[09/23 01:04:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:04:27][INFO] visual_prompt:  435: Inference (test):avg data time: 8.80e-05, avg batch time: 0.1279, average loss: 5.3917
[09/23 01:04:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 01:04:27][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/23 01:05:36][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.85e-02, avg batch time: 0.8060, average train loss: 5.4693average G loss: 0.0070, average realD loss: 0.0998, average fakeD loss: 0.1114, 
[09/23 01:05:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.42e-05, avg batch time: 0.1203, average loss: 5.3813
[09/23 01:05:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:05:52][INFO] visual_prompt:  435: Inference (test):avg data time: 8.30e-05, avg batch time: 0.1280, average loss: 5.3809
[09/23 01:05:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/23 01:05:53][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/23 01:07:01][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.82e-02, avg batch time: 0.8053, average train loss: 5.4651average G loss: 0.0071, average realD loss: 0.1090, average fakeD loss: 0.1242, 
[09/23 01:07:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.43e-05, avg batch time: 0.1205, average loss: 5.4272
[09/23 01:07:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 01:07:17][INFO] visual_prompt:  435: Inference (test):avg data time: 6.74e-05, avg batch time: 0.1284, average loss: 5.4205
[09/23 01:07:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.73	
[09/23 01:07:17][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/23 01:08:26][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.92e-02, avg batch time: 0.8066, average train loss: 5.4901average G loss: 0.0060, average realD loss: 0.1106, average fakeD loss: 0.1254, 
[09/23 01:08:28][INFO] visual_prompt:  435: Inference (val):avg data time: 5.85e-05, avg batch time: 0.1213, average loss: 5.3946
[09/23 01:08:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 01:08:42][INFO] visual_prompt:  435: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1277, average loss: 5.3935
[09/23 01:08:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.28	top5: 2.62	
[09/23 01:08:42][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/23 01:09:51][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 2.00e-02, avg batch time: 0.8074, average train loss: 5.4768average G loss: 0.0081, average realD loss: 0.0838, average fakeD loss: 0.0945, 
[09/23 01:09:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1208, average loss: 5.8235
[09/23 01:09:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:10:07][INFO] visual_prompt:  435: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1287, average loss: 5.8230
[09/23 01:10:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.50	
[09/23 01:10:07][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/23 01:11:15][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.94e-02, avg batch time: 0.8067, average train loss: 5.5025average G loss: 0.0094, average realD loss: 0.0805, average fakeD loss: 0.0929, 
[09/23 01:11:18][INFO] visual_prompt:  435: Inference (val):avg data time: 8.51e-05, avg batch time: 0.1206, average loss: 5.6269
[09/23 01:11:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 01:11:31][INFO] visual_prompt:  435: Inference (test):avg data time: 6.95e-05, avg batch time: 0.1284, average loss: 5.6322
[09/23 01:11:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.74	
[09/23 01:11:31][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/23 01:12:40][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.87e-02, avg batch time: 0.8054, average train loss: 5.4956average G loss: 0.0082, average realD loss: 0.1448, average fakeD loss: 0.1650, 
[09/23 01:12:42][INFO] visual_prompt:  435: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1217, average loss: 5.4269
[09/23 01:12:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 01:12:55][INFO] visual_prompt:  435: Inference (test):avg data time: 6.77e-05, avg batch time: 0.1283, average loss: 5.4245
[09/23 01:12:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.45	top5: 2.55	
[09/23 01:12:55][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/23 01:14:04][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.99e-02, avg batch time: 0.8073, average train loss: 5.4756average G loss: 0.0081, average realD loss: 0.0764, average fakeD loss: 0.0915, 
[09/23 01:14:06][INFO] visual_prompt:  435: Inference (val):avg data time: 4.75e-05, avg batch time: 0.1222, average loss: 5.4857
[09/23 01:14:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 2.50	
[09/23 01:14:20][INFO] visual_prompt:  435: Inference (test):avg data time: 5.67e-05, avg batch time: 0.1286, average loss: 5.4854
[09/23 01:14:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.60	top5: 2.59	
[09/23 01:14:20][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/23 01:15:28][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.77e-02, avg batch time: 0.8053, average train loss: 5.4676average G loss: 0.0082, average realD loss: 0.0834, average fakeD loss: 0.0916, 
[09/23 01:15:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1207, average loss: 5.3603
[09/23 01:15:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 01:15:44][INFO] visual_prompt:  435: Inference (test):avg data time: 8.23e-05, avg batch time: 0.1285, average loss: 5.3577
[09/23 01:15:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.42	
[09/23 01:15:44][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/23 01:16:53][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.80e-02, avg batch time: 0.8055, average train loss: 5.4563average G loss: 0.0087, average realD loss: 0.0762, average fakeD loss: 0.0889, 
[09/23 01:16:55][INFO] visual_prompt:  435: Inference (val):avg data time: 5.17e-05, avg batch time: 0.1218, average loss: 5.4889
[09/23 01:16:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:17:08][INFO] visual_prompt:  435: Inference (test):avg data time: 6.29e-05, avg batch time: 0.1287, average loss: 5.4807
[09/23 01:17:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 01:17:08][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/23 01:18:17][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.78e-02, avg batch time: 0.8054, average train loss: 5.4668average G loss: 0.0085, average realD loss: 0.0819, average fakeD loss: 0.0921, 
[09/23 01:18:19][INFO] visual_prompt:  435: Inference (val):avg data time: 7.95e-05, avg batch time: 0.1210, average loss: 5.4282
[09/23 01:18:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 01:18:33][INFO] visual_prompt:  435: Inference (test):avg data time: 6.90e-05, avg batch time: 0.1286, average loss: 5.4308
[09/23 01:18:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 01:18:33][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/23 01:19:42][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.93e-02, avg batch time: 0.8069, average train loss: 5.4704average G loss: 0.0065, average realD loss: 0.1117, average fakeD loss: 0.1316, 
[09/23 01:19:44][INFO] visual_prompt:  435: Inference (val):avg data time: 5.62e-05, avg batch time: 0.1221, average loss: 5.5695
[09/23 01:19:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:19:58][INFO] visual_prompt:  435: Inference (test):avg data time: 8.29e-05, avg batch time: 0.1284, average loss: 5.5704
[09/23 01:19:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/23 01:19:58][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/23 01:21:06][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.90e-02, avg batch time: 0.8068, average train loss: 5.4727average G loss: 0.0024, average realD loss: 0.3743, average fakeD loss: 0.3404, 
[09/23 01:21:09][INFO] visual_prompt:  435: Inference (val):avg data time: 5.69e-05, avg batch time: 0.1217, average loss: 5.4677
[09/23 01:21:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:21:23][INFO] visual_prompt:  435: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1281, average loss: 5.4627
[09/23 01:21:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 01:21:23][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/23 01:22:32][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.95e-02, avg batch time: 0.8073, average train loss: 5.4617average G loss: 0.0074, average realD loss: 0.2907, average fakeD loss: 0.2685, 
[09/23 01:22:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1216, average loss: 5.4552
[09/23 01:22:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:22:48][INFO] visual_prompt:  435: Inference (test):avg data time: 7.23e-05, avg batch time: 0.1282, average loss: 5.4606
[09/23 01:22:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.47	
[09/23 01:22:48][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/23 01:23:57][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.83e-02, avg batch time: 0.8061, average train loss: 5.4780average G loss: 0.0131, average realD loss: 0.1154, average fakeD loss: 0.1494, 
[09/23 01:23:59][INFO] visual_prompt:  435: Inference (val):avg data time: 5.83e-05, avg batch time: 0.1212, average loss: 5.4116
[09/23 01:23:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:24:13][INFO] visual_prompt:  435: Inference (test):avg data time: 8.41e-05, avg batch time: 0.1283, average loss: 5.4153
[09/23 01:24:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/23 01:24:13][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/23 01:25:21][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.85e-02, avg batch time: 0.8063, average train loss: 5.4655average G loss: 0.1153, average realD loss: 0.3983, average fakeD loss: 0.2878, 
[09/23 01:25:24][INFO] visual_prompt:  435: Inference (val):avg data time: 4.99e-05, avg batch time: 0.1220, average loss: 5.4208
[09/23 01:25:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:25:37][INFO] visual_prompt:  435: Inference (test):avg data time: 7.38e-05, avg batch time: 0.1288, average loss: 5.4195
[09/23 01:25:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.62	
[09/23 01:25:37][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/23 01:26:46][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 2.04e-02, avg batch time: 0.8089, average train loss: 5.4605average G loss: 0.0082, average realD loss: 0.0872, average fakeD loss: 0.1089, 
[09/23 01:26:48][INFO] visual_prompt:  435: Inference (val):avg data time: 5.04e-05, avg batch time: 0.1212, average loss: 5.4235
[09/23 01:26:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:27:02][INFO] visual_prompt:  435: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1289, average loss: 5.4236
[09/23 01:27:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.49	
[09/23 01:27:02][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/23 01:28:11][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.87e-02, avg batch time: 0.8074, average train loss: 5.4712average G loss: 0.0109, average realD loss: 0.0734, average fakeD loss: 0.0826, 
[09/23 01:28:13][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1218, average loss: 5.3885
[09/23 01:28:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:28:27][INFO] visual_prompt:  435: Inference (test):avg data time: 6.12e-05, avg batch time: 0.1284, average loss: 5.3845
[09/23 01:28:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 01:28:27][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/23 01:29:36][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.95e-02, avg batch time: 0.8084, average train loss: 5.4473average G loss: 0.0089, average realD loss: 0.1056, average fakeD loss: 0.0960, 
[09/23 01:29:38][INFO] visual_prompt:  435: Inference (val):avg data time: 7.15e-05, avg batch time: 0.1209, average loss: 5.3842
[09/23 01:29:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:29:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1287, average loss: 5.3833
[09/23 01:29:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/23 01:29:52][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/23 01:31:00][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.91e-02, avg batch time: 0.8065, average train loss: 5.4624average G loss: 0.1206, average realD loss: 0.4383, average fakeD loss: 0.2665, 
[09/23 01:31:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.07e-05, avg batch time: 0.1215, average loss: 5.4657
[09/23 01:31:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:31:16][INFO] visual_prompt:  435: Inference (test):avg data time: 7.74e-05, avg batch time: 0.1285, average loss: 5.4612
[09/23 01:31:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.54	top5: 2.61	
[09/23 01:31:16][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/23 01:32:25][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.79e-02, avg batch time: 0.8052, average train loss: 5.4654average G loss: 0.0111, average realD loss: 0.3926, average fakeD loss: 0.3976, 
[09/23 01:32:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1233, average loss: 5.4255
[09/23 01:32:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:32:41][INFO] visual_prompt:  435: Inference (test):avg data time: 5.33e-05, avg batch time: 0.1287, average loss: 5.4244
[09/23 01:32:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.47	top5: 2.54	
[09/23 01:32:41][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/23 01:33:49][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.97e-02, avg batch time: 0.8086, average train loss: 5.4617average G loss: 0.0066, average realD loss: 0.0839, average fakeD loss: 0.0969, 
[09/23 01:33:52][INFO] visual_prompt:  435: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1217, average loss: 5.4143
[09/23 01:33:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.17	
[09/23 01:34:05][INFO] visual_prompt:  435: Inference (test):avg data time: 8.27e-05, avg batch time: 0.1283, average loss: 5.4424
[09/23 01:34:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.74	top5: 2.30	
[09/23 01:34:06][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/23 01:35:14][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.85e-02, avg batch time: 0.8074, average train loss: 5.4675average G loss: 0.0059, average realD loss: 0.0935, average fakeD loss: 0.0985, 
[09/23 01:35:17][INFO] visual_prompt:  435: Inference (val):avg data time: 7.00e-05, avg batch time: 0.1220, average loss: 5.3632
[09/23 01:35:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:35:30][INFO] visual_prompt:  435: Inference (test):avg data time: 9.07e-05, avg batch time: 0.1281, average loss: 5.3631
[09/23 01:35:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 01:35:31][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/23 01:36:39][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.96e-02, avg batch time: 0.8085, average train loss: 5.4357average G loss: 0.0094, average realD loss: 0.0802, average fakeD loss: 0.0889, 
[09/23 01:36:42][INFO] visual_prompt:  435: Inference (val):avg data time: 7.14e-05, avg batch time: 0.1215, average loss: 5.3902
[09/23 01:36:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:36:55][INFO] visual_prompt:  435: Inference (test):avg data time: 7.93e-05, avg batch time: 0.1290, average loss: 5.3878
[09/23 01:36:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.47	
[09/23 01:36:55][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/23 01:38:04][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 2.08e-02, avg batch time: 0.8089, average train loss: 5.4545average G loss: 0.0059, average realD loss: 0.1778, average fakeD loss: 0.2186, 
[09/23 01:38:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.77e-05, avg batch time: 0.1210, average loss: 5.4636
[09/23 01:38:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/23 01:38:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.02e-05, avg batch time: 0.1291, average loss: 5.4599
[09/23 01:38:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.68	
[09/23 01:38:20][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/23 01:39:29][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 2.00e-02, avg batch time: 0.8090, average train loss: 5.4680average G loss: 0.0063, average realD loss: 0.1053, average fakeD loss: 0.1199, 
[09/23 01:39:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1217, average loss: 5.4030
[09/23 01:39:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 3.00	
[09/23 01:39:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1285, average loss: 5.4060
[09/23 01:39:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.40	top5: 2.16	
[09/23 01:39:45][INFO] visual_prompt:  357: Best epoch 37: best metric: 0.008
[09/23 01:39:45][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/23 01:40:53][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.82e-02, avg batch time: 0.8075, average train loss: 5.4440average G loss: 0.0088, average realD loss: 0.0738, average fakeD loss: 0.0827, 
[09/23 01:40:56][INFO] visual_prompt:  435: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1203, average loss: 5.4076
[09/23 01:40:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:41:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.22e-05, avg batch time: 0.1283, average loss: 5.4073
[09/23 01:41:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.45	top5: 2.52	
[09/23 01:41:10][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/23 01:42:19][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 1.96e-02, avg batch time: 0.8083, average train loss: 5.4666average G loss: 0.0073, average realD loss: 0.1059, average fakeD loss: 0.1204, 
[09/23 01:42:21][INFO] visual_prompt:  435: Inference (val):avg data time: 6.53e-05, avg batch time: 0.1210, average loss: 5.3734
[09/23 01:42:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 2.00	
[09/23 01:42:34][INFO] visual_prompt:  435: Inference (test):avg data time: 6.30e-05, avg batch time: 0.1286, average loss: 5.3715
[09/23 01:42:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.54	top5: 2.50	
[09/23 01:42:34][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/23 01:43:43][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.90e-02, avg batch time: 0.8054, average train loss: 5.4412average G loss: 0.0072, average realD loss: 0.7696, average fakeD loss: 0.5950, 
[09/23 01:43:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.32e-05, avg batch time: 0.1212, average loss: 5.3873
[09/23 01:43:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 01:43:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1283, average loss: 5.3862
[09/23 01:43:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.47	
[09/23 01:43:59][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 1.875
[09/23 01:45:08][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.98e-02, avg batch time: 0.8070, average train loss: 5.4504average G loss: 0.0142, average realD loss: 0.5178, average fakeD loss: 0.4574, 
[09/23 01:45:10][INFO] visual_prompt:  435: Inference (val):avg data time: 8.57e-05, avg batch time: 0.1215, average loss: 5.4571
[09/23 01:45:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:45:24][INFO] visual_prompt:  435: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1283, average loss: 5.4617
[09/23 01:45:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.64	
[09/23 01:45:24][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/23 01:46:33][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 1.92e-02, avg batch time: 0.8078, average train loss: 5.4448average G loss: 0.0069, average realD loss: 0.0936, average fakeD loss: 0.1068, 
[09/23 01:46:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1214, average loss: 5.3972
[09/23 01:46:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:46:49][INFO] visual_prompt:  435: Inference (test):avg data time: 5.31e-05, avg batch time: 0.1287, average loss: 5.3977
[09/23 01:46:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.36	
[09/23 01:46:49][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/23 01:47:58][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.93e-02, avg batch time: 0.8082, average train loss: 5.4298average G loss: 0.0078, average realD loss: 0.0845, average fakeD loss: 0.0953, 
[09/23 01:48:00][INFO] visual_prompt:  435: Inference (val):avg data time: 4.89e-05, avg batch time: 0.1207, average loss: 5.3955
[09/23 01:48:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:48:14][INFO] visual_prompt:  435: Inference (test):avg data time: 5.68e-05, avg batch time: 0.1285, average loss: 5.3923
[09/23 01:48:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.45	
[09/23 01:48:14][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/23 01:49:22][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 1.89e-02, avg batch time: 0.8079, average train loss: 5.4243average G loss: 0.0081, average realD loss: 0.0806, average fakeD loss: 0.0865, 
[09/23 01:49:25][INFO] visual_prompt:  435: Inference (val):avg data time: 5.37e-05, avg batch time: 0.1224, average loss: 5.3657
[09/23 01:49:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:49:38][INFO] visual_prompt:  435: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1285, average loss: 5.3729
[09/23 01:49:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.31	top5: 2.38	
[09/23 01:49:38][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/23 01:50:47][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.85e-02, avg batch time: 0.8068, average train loss: 5.4356average G loss: 0.0085, average realD loss: 0.0758, average fakeD loss: 0.0818, 
[09/23 01:50:49][INFO] visual_prompt:  435: Inference (val):avg data time: 7.81e-05, avg batch time: 0.1215, average loss: 5.4167
[09/23 01:50:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:51:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1281, average loss: 5.4125
[09/23 01:51:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.55	
[09/23 01:51:03][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/23 01:52:12][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 1.96e-02, avg batch time: 0.8068, average train loss: 5.4279average G loss: 0.0064, average realD loss: 0.0867, average fakeD loss: 0.0958, 
[09/23 01:52:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.99e-05, avg batch time: 0.1207, average loss: 5.3774
[09/23 01:52:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:52:27][INFO] visual_prompt:  435: Inference (test):avg data time: 8.71e-05, avg batch time: 0.1283, average loss: 5.3751
[09/23 01:52:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 01:52:28][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/23 01:53:36][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 2.01e-02, avg batch time: 0.8058, average train loss: 5.4237average G loss: 0.0037, average realD loss: 0.1241, average fakeD loss: 0.1362, 
[09/23 01:53:38][INFO] visual_prompt:  435: Inference (val):avg data time: 5.75e-05, avg batch time: 0.1205, average loss: 5.4890
[09/23 01:53:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 01:53:52][INFO] visual_prompt:  435: Inference (test):avg data time: 9.03e-05, avg batch time: 0.1280, average loss: 5.4885
[09/23 01:53:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.61	
[09/23 01:53:52][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/23 01:55:01][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.96e-02, avg batch time: 0.8057, average train loss: 5.4222average G loss: 0.0085, average realD loss: 0.0798, average fakeD loss: 0.0890, 
[09/23 01:55:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.06e-05, avg batch time: 0.1210, average loss: 5.3828
[09/23 01:55:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:55:17][INFO] visual_prompt:  435: Inference (test):avg data time: 8.46e-05, avg batch time: 0.1286, average loss: 5.3837
[09/23 01:55:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.26	top5: 2.28	
[09/23 01:55:17][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/23 01:56:25][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.87e-02, avg batch time: 0.8050, average train loss: 5.4219average G loss: 0.0092, average realD loss: 0.0799, average fakeD loss: 0.0865, 
[09/23 01:56:28][INFO] visual_prompt:  435: Inference (val):avg data time: 8.63e-05, avg batch time: 0.1207, average loss: 5.3603
[09/23 01:56:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:56:41][INFO] visual_prompt:  435: Inference (test):avg data time: 8.65e-05, avg batch time: 0.1284, average loss: 5.3580
[09/23 01:56:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.57	
[09/23 01:56:41][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/23 01:57:50][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 2.03e-02, avg batch time: 0.8069, average train loss: 5.4115average G loss: 0.0105, average realD loss: 0.0723, average fakeD loss: 0.0822, 
[09/23 01:57:52][INFO] visual_prompt:  435: Inference (val):avg data time: 5.91e-05, avg batch time: 0.1210, average loss: 5.3771
[09/23 01:57:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:58:05][INFO] visual_prompt:  435: Inference (test):avg data time: 8.66e-05, avg batch time: 0.1285, average loss: 5.3742
[09/23 01:58:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.55	
[09/23 01:58:05][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/23 01:59:14][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.82e-02, avg batch time: 0.8043, average train loss: 5.4068average G loss: 0.0089, average realD loss: 0.0729, average fakeD loss: 0.0786, 
[09/23 01:59:16][INFO] visual_prompt:  435: Inference (val):avg data time: 7.14e-05, avg batch time: 0.1202, average loss: 5.3988
[09/23 01:59:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 01:59:30][INFO] visual_prompt:  435: Inference (test):avg data time: 7.82e-05, avg batch time: 0.1277, average loss: 5.3977
[09/23 01:59:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.57	
[09/23 01:59:30][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/23 02:00:38][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.80e-02, avg batch time: 0.8040, average train loss: 5.4094average G loss: 0.0079, average realD loss: 0.0790, average fakeD loss: 0.0879, 
[09/23 02:00:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.14e-05, avg batch time: 0.1209, average loss: 5.3809
[09/23 02:00:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:00:54][INFO] visual_prompt:  435: Inference (test):avg data time: 7.02e-05, avg batch time: 0.1280, average loss: 5.3783
[09/23 02:00:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.61	
[09/23 02:00:55][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/23 02:02:03][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.92e-02, avg batch time: 0.8050, average train loss: 5.4297average G loss: 0.0073, average realD loss: 0.0762, average fakeD loss: 0.0874, 
[09/23 02:02:05][INFO] visual_prompt:  435: Inference (val):avg data time: 5.58e-05, avg batch time: 0.1204, average loss: 5.3597
[09/23 02:02:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:02:19][INFO] visual_prompt:  435: Inference (test):avg data time: 7.37e-05, avg batch time: 0.1278, average loss: 5.3557
[09/23 02:02:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 02:02:19][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/23 02:03:28][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.86e-02, avg batch time: 0.8042, average train loss: 5.3989average G loss: 0.0063, average realD loss: 0.0843, average fakeD loss: 0.0878, 
[09/23 02:03:30][INFO] visual_prompt:  435: Inference (val):avg data time: 6.19e-05, avg batch time: 0.1212, average loss: 5.3427
[09/23 02:03:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:03:43][INFO] visual_prompt:  435: Inference (test):avg data time: 8.45e-05, avg batch time: 0.1281, average loss: 5.3457
[09/23 02:03:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.07	
[09/23 02:03:43][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/23 02:04:52][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.85e-02, avg batch time: 0.8037, average train loss: 5.4130average G loss: 0.0083, average realD loss: 0.0715, average fakeD loss: 0.0790, 
[09/23 02:04:54][INFO] visual_prompt:  435: Inference (val):avg data time: 5.41e-05, avg batch time: 0.1213, average loss: 5.3803
[09/23 02:04:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:05:07][INFO] visual_prompt:  435: Inference (test):avg data time: 6.73e-05, avg batch time: 0.1281, average loss: 5.3815
[09/23 02:05:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 02:05:07][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 1.25
[09/23 02:06:16][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 1.79e-02, avg batch time: 0.8024, average train loss: 5.3980average G loss: 0.0081, average realD loss: 0.1140, average fakeD loss: 0.1221, 
[09/23 02:06:18][INFO] visual_prompt:  435: Inference (val):avg data time: 6.09e-05, avg batch time: 0.1200, average loss: 5.3451
[09/23 02:06:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:06:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1282, average loss: 5.3477
[09/23 02:06:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.35	top5: 2.36	
[09/23 02:06:31][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/23 02:07:40][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.87e-02, avg batch time: 0.8031, average train loss: 5.3941average G loss: 0.0074, average realD loss: 0.0738, average fakeD loss: 0.0808, 
[09/23 02:07:42][INFO] visual_prompt:  435: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1210, average loss: 5.3534
[09/23 02:07:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:07:56][INFO] visual_prompt:  435: Inference (test):avg data time: 6.35e-05, avg batch time: 0.1279, average loss: 5.3519
[09/23 02:07:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 2.55	
[09/23 02:07:56][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/23 02:09:04][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 1.85e-02, avg batch time: 0.8032, average train loss: 5.3943average G loss: 0.0081, average realD loss: 0.0694, average fakeD loss: 0.0774, 
[09/23 02:09:06][INFO] visual_prompt:  435: Inference (val):avg data time: 7.36e-05, avg batch time: 0.1201, average loss: 5.3658
[09/23 02:09:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:09:20][INFO] visual_prompt:  435: Inference (test):avg data time: 6.99e-05, avg batch time: 0.1281, average loss: 5.3675
[09/23 02:09:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.57	top5: 2.52	
[09/23 02:09:20][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/23 02:10:28][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.88e-02, avg batch time: 0.8036, average train loss: 5.3868average G loss: 0.0080, average realD loss: 0.0715, average fakeD loss: 0.0778, 
[09/23 02:10:31][INFO] visual_prompt:  435: Inference (val):avg data time: 4.94e-05, avg batch time: 0.1202, average loss: 5.3908
[09/23 02:10:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 02:10:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.77e-05, avg batch time: 0.1278, average loss: 5.3892
[09/23 02:10:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 02:10:44][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/23 02:11:53][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 2.03e-02, avg batch time: 0.8050, average train loss: 5.3889average G loss: 0.0090, average realD loss: 0.0718, average fakeD loss: 0.0783, 
[09/23 02:11:55][INFO] visual_prompt:  435: Inference (val):avg data time: 4.97e-05, avg batch time: 0.1215, average loss: 5.3434
[09/23 02:11:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.00	top5: 2.50	
[09/23 02:12:08][INFO] visual_prompt:  435: Inference (test):avg data time: 6.65e-05, avg batch time: 0.1279, average loss: 5.3447
[09/23 02:12:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.43	top5: 2.42	
[09/23 02:12:09][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/23 02:13:17][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.88e-02, avg batch time: 0.8035, average train loss: 5.3903average G loss: 0.0086, average realD loss: 0.0700, average fakeD loss: 0.0764, 
[09/23 02:13:19][INFO] visual_prompt:  435: Inference (val):avg data time: 6.57e-05, avg batch time: 0.1207, average loss: 5.3583
[09/23 02:13:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:13:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.05e-05, avg batch time: 0.1272, average loss: 5.3601
[09/23 02:13:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 02:13:33][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/23 02:14:42][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.82e-02, avg batch time: 0.8027, average train loss: 5.3781average G loss: 0.0073, average realD loss: 0.0682, average fakeD loss: 0.0759, 
[09/23 02:14:44][INFO] visual_prompt:  435: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1198, average loss: 5.3650
[09/23 02:14:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 02:14:58][INFO] visual_prompt:  435: Inference (test):avg data time: 9.25e-05, avg batch time: 0.1276, average loss: 5.3639
[09/23 02:14:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/23 02:14:58][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/23 02:16:07][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 1.89e-02, avg batch time: 0.8033, average train loss: 5.3884average G loss: 0.0078, average realD loss: 0.0692, average fakeD loss: 0.0745, 
[09/23 02:16:09][INFO] visual_prompt:  435: Inference (val):avg data time: 7.40e-05, avg batch time: 0.1200, average loss: 5.3479
[09/23 02:16:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:16:23][INFO] visual_prompt:  435: Inference (test):avg data time: 6.88e-05, avg batch time: 0.1277, average loss: 5.3484
[09/23 02:16:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.24	
[09/23 02:16:23][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/23 02:17:31][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.81e-02, avg batch time: 0.8029, average train loss: 5.3841average G loss: 0.0080, average realD loss: 0.0698, average fakeD loss: 0.0776, 
[09/23 02:17:33][INFO] visual_prompt:  435: Inference (val):avg data time: 5.17e-05, avg batch time: 0.1212, average loss: 5.3297
[09/23 02:17:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:17:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.75e-05, avg batch time: 0.1278, average loss: 5.3308
[09/23 02:17:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 02:17:47][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/23 02:18:56][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 2.01e-02, avg batch time: 0.8047, average train loss: 5.3699average G loss: 0.0074, average realD loss: 0.0698, average fakeD loss: 0.0755, 
[09/23 02:18:58][INFO] visual_prompt:  435: Inference (val):avg data time: 5.49e-05, avg batch time: 0.1213, average loss: 5.3453
[09/23 02:18:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:19:11][INFO] visual_prompt:  435: Inference (test):avg data time: 7.75e-05, avg batch time: 0.1278, average loss: 5.3483
[09/23 02:19:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.47	
[09/23 02:19:12][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/23 02:20:20][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.93e-02, avg batch time: 0.8039, average train loss: 5.3756average G loss: 0.0075, average realD loss: 0.0676, average fakeD loss: 0.0731, 
[09/23 02:20:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.97e-05, avg batch time: 0.1202, average loss: 5.3561
[09/23 02:20:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:20:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.60e-05, avg batch time: 0.1277, average loss: 5.3565
[09/23 02:20:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 02:20:36][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/23 02:21:44][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.91e-02, avg batch time: 0.8038, average train loss: 5.3695average G loss: 0.0081, average realD loss: 0.0661, average fakeD loss: 0.0752, 
[09/23 02:21:47][INFO] visual_prompt:  435: Inference (val):avg data time: 8.16e-05, avg batch time: 0.1210, average loss: 5.3323
[09/23 02:21:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:22:00][INFO] visual_prompt:  435: Inference (test):avg data time: 8.83e-05, avg batch time: 0.1282, average loss: 5.3313
[09/23 02:22:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 02:22:00][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/23 02:23:09][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.83e-02, avg batch time: 0.8034, average train loss: 5.3617average G loss: 0.0081, average realD loss: 0.0683, average fakeD loss: 0.0747, 
[09/23 02:23:11][INFO] visual_prompt:  435: Inference (val):avg data time: 7.45e-05, avg batch time: 0.1208, average loss: 5.3074
[09/23 02:23:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:23:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.06e-05, avg batch time: 0.1277, average loss: 5.3089
[09/23 02:23:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.24	top5: 2.14	
[09/23 02:23:25][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/23 02:24:33][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 2.01e-02, avg batch time: 0.8050, average train loss: 5.3602average G loss: 0.0069, average realD loss: 0.0683, average fakeD loss: 0.0748, 
[09/23 02:24:36][INFO] visual_prompt:  435: Inference (val):avg data time: 6.16e-05, avg batch time: 0.1210, average loss: 5.3216
[09/23 02:24:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:24:49][INFO] visual_prompt:  435: Inference (test):avg data time: 8.71e-05, avg batch time: 0.1283, average loss: 5.3210
[09/23 02:24:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 02:24:49][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/23 02:25:57][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.85e-02, avg batch time: 0.8038, average train loss: 5.3615average G loss: 0.0066, average realD loss: 0.0703, average fakeD loss: 0.0750, 
[09/23 02:26:00][INFO] visual_prompt:  435: Inference (val):avg data time: 7.57e-05, avg batch time: 0.1198, average loss: 5.3344
[09/23 02:26:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:26:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.57e-05, avg batch time: 0.1284, average loss: 5.3366
[09/23 02:26:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.16	
[09/23 02:26:13][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/23 02:27:22][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 1.81e-02, avg batch time: 0.8037, average train loss: 5.3592average G loss: 0.0083, average realD loss: 0.0702, average fakeD loss: 0.0753, 
[09/23 02:27:24][INFO] visual_prompt:  435: Inference (val):avg data time: 4.57e-05, avg batch time: 0.1212, average loss: 5.3231
[09/23 02:27:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 02:27:37][INFO] visual_prompt:  435: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1279, average loss: 5.3197
[09/23 02:27:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.66	
[09/23 02:27:37][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/23 02:28:46][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.76e-02, avg batch time: 0.8029, average train loss: 5.3544average G loss: 0.0060, average realD loss: 0.0708, average fakeD loss: 0.0764, 
[09/23 02:28:48][INFO] visual_prompt:  435: Inference (val):avg data time: 5.43e-05, avg batch time: 0.1204, average loss: 5.3249
[09/23 02:28:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:29:02][INFO] visual_prompt:  435: Inference (test):avg data time: 6.41e-05, avg batch time: 0.1279, average loss: 5.3255
[09/23 02:29:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.62	
[09/23 02:29:02][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/23 02:30:10][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 2.00e-02, avg batch time: 0.8049, average train loss: 5.3489average G loss: 0.0054, average realD loss: 0.0657, average fakeD loss: 0.0730, 
[09/23 02:30:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.70e-05, avg batch time: 0.1198, average loss: 5.3069
[09/23 02:30:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:30:27][INFO] visual_prompt:  435: Inference (test):avg data time: 9.56e-05, avg batch time: 0.1272, average loss: 5.3062
[09/23 02:30:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.76	top5: 2.42	
[09/23 02:30:27][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/23 02:31:35][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.84e-02, avg batch time: 0.8027, average train loss: 5.3507average G loss: 0.0060, average realD loss: 0.0693, average fakeD loss: 0.0745, 
[09/23 02:31:38][INFO] visual_prompt:  435: Inference (val):avg data time: 8.69e-05, avg batch time: 0.1208, average loss: 5.3283
[09/23 02:31:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:31:52][INFO] visual_prompt:  435: Inference (test):avg data time: 9.46e-05, avg batch time: 0.1272, average loss: 5.3265
[09/23 02:31:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.45	
[09/23 02:31:52][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/23 02:33:00][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.82e-02, avg batch time: 0.8021, average train loss: 5.3464average G loss: 0.0052, average realD loss: 0.0682, average fakeD loss: 0.0693, 
[09/23 02:33:03][INFO] visual_prompt:  435: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1212, average loss: 5.3306
[09/23 02:33:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:33:17][INFO] visual_prompt:  435: Inference (test):avg data time: 8.65e-05, avg batch time: 0.1272, average loss: 5.3291
[09/23 02:33:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.40	
[09/23 02:33:17][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/23 02:34:25][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 2.04e-02, avg batch time: 0.8042, average train loss: 5.3466average G loss: 0.0060, average realD loss: 0.0692, average fakeD loss: 0.0718, 
[09/23 02:34:28][INFO] visual_prompt:  435: Inference (val):avg data time: 6.25e-05, avg batch time: 0.1207, average loss: 5.3200
[09/23 02:34:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:34:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1274, average loss: 5.3217
[09/23 02:34:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.55	
[09/23 02:34:41][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/23 02:35:50][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 2.05e-02, avg batch time: 0.8043, average train loss: 5.3393average G loss: 0.0048, average realD loss: 0.0681, average fakeD loss: 0.0749, 
[09/23 02:35:52][INFO] visual_prompt:  435: Inference (val):avg data time: 6.15e-05, avg batch time: 0.1208, average loss: 5.3085
[09/23 02:35:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.00	top5: 2.50	
[09/23 02:36:06][INFO] visual_prompt:  435: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1275, average loss: 5.3088
[09/23 02:36:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.88	top5: 2.47	
[09/23 02:36:06][INFO] visual_prompt:  357: Best epoch 77: best metric: 0.010
[09/23 02:36:06][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/23 02:37:14][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 1.89e-02, avg batch time: 0.8022, average train loss: 5.3387average G loss: 0.0071, average realD loss: 0.0710, average fakeD loss: 0.0706, 
[09/23 02:37:17][INFO] visual_prompt:  435: Inference (val):avg data time: 7.03e-05, avg batch time: 0.1210, average loss: 5.3241
[09/23 02:37:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/23 02:37:30][INFO] visual_prompt:  435: Inference (test):avg data time: 7.74e-05, avg batch time: 0.1275, average loss: 5.3260
[09/23 02:37:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.24	top5: 2.47	
[09/23 02:37:31][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/23 02:38:39][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.95e-02, avg batch time: 0.8031, average train loss: 5.3378average G loss: 0.0049, average realD loss: 0.0643, average fakeD loss: 0.0715, 
[09/23 02:38:41][INFO] visual_prompt:  435: Inference (val):avg data time: 7.58e-05, avg batch time: 0.1199, average loss: 5.3152
[09/23 02:38:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:38:55][INFO] visual_prompt:  435: Inference (test):avg data time: 8.09e-05, avg batch time: 0.1272, average loss: 5.3176
[09/23 02:38:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.31	
[09/23 02:38:55][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/23 02:40:03][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 1.86e-02, avg batch time: 0.8021, average train loss: 5.3412average G loss: 0.0036, average realD loss: 0.0645, average fakeD loss: 0.0696, 
[09/23 02:40:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.97e-05, avg batch time: 0.1196, average loss: 5.3153
[09/23 02:40:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:40:19][INFO] visual_prompt:  435: Inference (test):avg data time: 7.75e-05, avg batch time: 0.1275, average loss: 5.3180
[09/23 02:40:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.19	top5: 2.33	
[09/23 02:40:20][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/23 02:41:28][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 2.00e-02, avg batch time: 0.8032, average train loss: 5.3335average G loss: 0.0045, average realD loss: 0.0672, average fakeD loss: 0.0715, 
[09/23 02:41:30][INFO] visual_prompt:  435: Inference (val):avg data time: 5.72e-05, avg batch time: 0.1209, average loss: 5.3105
[09/23 02:41:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:41:44][INFO] visual_prompt:  435: Inference (test):avg data time: 8.84e-05, avg batch time: 0.1278, average loss: 5.3108
[09/23 02:41:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 02:41:44][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/23 02:42:52][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.82e-02, avg batch time: 0.8012, average train loss: 5.3289average G loss: 0.0042, average realD loss: 0.0662, average fakeD loss: 0.0714, 
[09/23 02:42:55][INFO] visual_prompt:  435: Inference (val):avg data time: 4.69e-05, avg batch time: 0.1207, average loss: 5.3126
[09/23 02:42:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:43:08][INFO] visual_prompt:  435: Inference (test):avg data time: 5.70e-05, avg batch time: 0.1278, average loss: 5.3095
[09/23 02:43:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 02:43:08][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/23 02:44:16][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 2.03e-02, avg batch time: 0.8032, average train loss: 5.3309average G loss: 0.0044, average realD loss: 0.0651, average fakeD loss: 0.0685, 
[09/23 02:44:19][INFO] visual_prompt:  435: Inference (val):avg data time: 6.20e-05, avg batch time: 0.1205, average loss: 5.3112
[09/23 02:44:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/23 02:44:32][INFO] visual_prompt:  435: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1282, average loss: 5.3112
[09/23 02:44:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.76	
[09/23 02:44:32][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/23 02:45:40][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.84e-02, avg batch time: 0.8016, average train loss: 5.3276average G loss: 0.0032, average realD loss: 0.0648, average fakeD loss: 0.0714, 
[09/23 02:45:43][INFO] visual_prompt:  435: Inference (val):avg data time: 5.83e-05, avg batch time: 0.1195, average loss: 5.3005
[09/23 02:45:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 02:45:56][INFO] visual_prompt:  435: Inference (test):avg data time: 5.99e-05, avg batch time: 0.1275, average loss: 5.3003
[09/23 02:45:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.54	
[09/23 02:45:56][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/23 02:47:05][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 2.03e-02, avg batch time: 0.8033, average train loss: 5.3012average G loss: 0.0036, average realD loss: 0.0694, average fakeD loss: 0.0728, 
[09/23 02:47:07][INFO] visual_prompt:  435: Inference (val):avg data time: 5.40e-05, avg batch time: 0.1206, average loss: 4.9804
[09/23 02:47:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 4.83	top5: 15.33	
[09/23 02:47:21][INFO] visual_prompt:  435: Inference (test):avg data time: 7.78e-05, avg batch time: 0.1271, average loss: 4.9828
[09/23 02:47:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 4.59	top5: 15.00	
[09/23 02:47:21][INFO] visual_prompt:  357: Best epoch 85: best metric: 0.048
[09/23 02:47:21][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/23 02:48:29][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.96e-02, avg batch time: 0.8023, average train loss: 3.5423average G loss: 0.0152, average realD loss: 0.0728, average fakeD loss: 0.0762, 
[09/23 02:48:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1202, average loss: 2.5424
[09/23 02:48:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 59.33	top5: 90.67	
[09/23 02:48:45][INFO] visual_prompt:  435: Inference (test):avg data time: 8.92e-05, avg batch time: 0.1276, average loss: 2.5337
[09/23 02:48:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.30	top5: 89.52	
[09/23 02:48:45][INFO] visual_prompt:  357: Best epoch 86: best metric: 0.593
[09/23 02:48:45][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/23 02:49:53][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.82e-02, avg batch time: 0.8008, average train loss: 2.5049average G loss: 0.0168, average realD loss: 0.0724, average fakeD loss: 0.0792, 
[09/23 02:49:56][INFO] visual_prompt:  435: Inference (val):avg data time: 7.50e-05, avg batch time: 0.1201, average loss: 2.3378
[09/23 02:49:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.17	top5: 92.17	
[09/23 02:50:10][INFO] visual_prompt:  435: Inference (test):avg data time: 8.50e-05, avg batch time: 0.1268, average loss: 2.3456
[09/23 02:50:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.10	top5: 92.80	
[09/23 02:50:10][INFO] visual_prompt:  357: Best epoch 87: best metric: 0.632
[09/23 02:50:10][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/23 02:51:18][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 2.00e-02, avg batch time: 0.8021, average train loss: 2.4236average G loss: 0.0169, average realD loss: 0.0736, average fakeD loss: 0.0788, 
[09/23 02:51:20][INFO] visual_prompt:  435: Inference (val):avg data time: 5.03e-05, avg batch time: 0.1200, average loss: 2.2859
[09/23 02:51:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.50	top5: 95.83	
[09/23 02:51:34][INFO] visual_prompt:  435: Inference (test):avg data time: 8.48e-05, avg batch time: 0.1276, average loss: 2.2827
[09/23 02:51:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.60	top5: 95.39	
[09/23 02:51:34][INFO] visual_prompt:  357: Best epoch 88: best metric: 0.655
[09/23 02:51:34][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/23 02:52:42][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.92e-02, avg batch time: 0.8011, average train loss: 2.4172average G loss: 0.0153, average realD loss: 0.0719, average fakeD loss: 0.0759, 
[09/23 02:52:44][INFO] visual_prompt:  435: Inference (val):avg data time: 4.80e-05, avg batch time: 0.1209, average loss: 2.2242
[09/23 02:52:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 96.17	
[09/23 02:52:58][INFO] visual_prompt:  435: Inference (test):avg data time: 6.49e-05, avg batch time: 0.1279, average loss: 2.2275
[09/23 02:52:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.04	top5: 95.20	
[09/23 02:52:58][INFO] visual_prompt:  357: Best epoch 89: best metric: 0.683
[09/23 02:52:58][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/23 02:54:06][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.73e-02, avg batch time: 0.7989, average train loss: 2.3297average G loss: 0.0156, average realD loss: 0.0711, average fakeD loss: 0.0770, 
[09/23 02:54:08][INFO] visual_prompt:  435: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1200, average loss: 2.2022
[09/23 02:54:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.67	top5: 96.67	
[09/23 02:54:22][INFO] visual_prompt:  435: Inference (test):avg data time: 7.38e-05, avg batch time: 0.1270, average loss: 2.2038
[09/23 02:54:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.87	top5: 95.91	
[09/23 02:54:22][INFO] visual_prompt:  357: Best epoch 90: best metric: 0.717
[09/23 02:54:22][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/23 02:55:30][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.90e-02, avg batch time: 0.8009, average train loss: 2.2932average G loss: 0.0154, average realD loss: 0.0721, average fakeD loss: 0.0779, 
[09/23 02:55:32][INFO] visual_prompt:  435: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1203, average loss: 2.2054
[09/23 02:55:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.50	top5: 95.67	
[09/23 02:55:46][INFO] visual_prompt:  435: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1273, average loss: 2.2043
[09/23 02:55:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.76	top5: 96.12	
[09/23 02:55:46][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/23 02:56:54][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.99e-02, avg batch time: 0.8025, average train loss: 2.2444average G loss: 0.0149, average realD loss: 0.0728, average fakeD loss: 0.0784, 
[09/23 02:56:57][INFO] visual_prompt:  435: Inference (val):avg data time: 6.29e-05, avg batch time: 0.1196, average loss: 2.1390
[09/23 02:56:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.33	top5: 97.50	
[09/23 02:57:10][INFO] visual_prompt:  435: Inference (test):avg data time: 8.21e-05, avg batch time: 0.1276, average loss: 2.1340
[09/23 02:57:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.96	top5: 96.89	
[09/23 02:57:11][INFO] visual_prompt:  357: Best epoch 92: best metric: 0.743
[09/23 02:57:11][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/23 02:58:19][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.88e-02, avg batch time: 0.8021, average train loss: 2.1915average G loss: 0.0139, average realD loss: 0.0688, average fakeD loss: 0.0761, 
[09/23 02:58:21][INFO] visual_prompt:  435: Inference (val):avg data time: 7.25e-05, avg batch time: 0.1200, average loss: 2.1217
[09/23 02:58:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.50	top5: 96.50	
[09/23 02:58:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1273, average loss: 2.1219
[09/23 02:58:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.68	top5: 96.96	
[09/23 02:58:35][INFO] visual_prompt:  357: Best epoch 93: best metric: 0.755
[09/23 02:58:35][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/23 02:59:43][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.82e-02, avg batch time: 0.8022, average train loss: 2.1543average G loss: 0.0135, average realD loss: 0.0704, average fakeD loss: 0.0732, 
[09/23 02:59:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.11e-05, avg batch time: 0.1200, average loss: 2.1083
[09/23 02:59:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.33	top5: 97.67	
[09/23 02:59:59][INFO] visual_prompt:  435: Inference (test):avg data time: 6.17e-05, avg batch time: 0.1284, average loss: 2.1079
[09/23 02:59:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.85	top5: 97.57	
[09/23 02:59:59][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/23 03:01:08][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 2.05e-02, avg batch time: 0.8051, average train loss: 2.1229average G loss: 0.0131, average realD loss: 0.0703, average fakeD loss: 0.0770, 
[09/23 03:01:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1196, average loss: 2.0808
[09/23 03:01:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.17	top5: 96.83	
[09/23 03:01:24][INFO] visual_prompt:  435: Inference (test):avg data time: 1.06e-04, avg batch time: 0.1275, average loss: 2.0664
[09/23 03:01:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.39	top5: 97.53	
[09/23 03:01:24][INFO] visual_prompt:  357: Best epoch 95: best metric: 0.772
[09/23 03:01:24][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/23 03:02:32][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.85e-02, avg batch time: 0.8036, average train loss: 2.0762average G loss: 0.0125, average realD loss: 0.0706, average fakeD loss: 0.0746, 
[09/23 03:02:35][INFO] visual_prompt:  435: Inference (val):avg data time: 8.22e-05, avg batch time: 0.1196, average loss: 2.0473
[09/23 03:02:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 97.67	
[09/23 03:02:49][INFO] visual_prompt:  435: Inference (test):avg data time: 6.97e-05, avg batch time: 0.1281, average loss: 2.0372
[09/23 03:02:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.72	top5: 97.79	
[09/23 03:02:49][INFO] visual_prompt:  357: Best epoch 96: best metric: 0.807
[09/23 03:02:49][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/23 03:03:57][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.84e-02, avg batch time: 0.8038, average train loss: 2.0444average G loss: 0.0120, average realD loss: 0.0677, average fakeD loss: 0.0757, 
[09/23 03:03:59][INFO] visual_prompt:  435: Inference (val):avg data time: 8.18e-05, avg batch time: 0.1203, average loss: 2.0096
[09/23 03:03:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.83	
[09/23 03:04:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.99e-05, avg batch time: 0.1279, average loss: 2.0151
[09/23 03:04:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.55	top5: 98.02	
[09/23 03:04:13][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/23 03:05:22][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 1.89e-02, avg batch time: 0.8048, average train loss: 2.0070average G loss: 0.0113, average realD loss: 0.0667, average fakeD loss: 0.0736, 
[09/23 03:05:24][INFO] visual_prompt:  435: Inference (val):avg data time: 7.68e-05, avg batch time: 0.1205, average loss: 2.0084
[09/23 03:05:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 97.00	
[09/23 03:05:38][INFO] visual_prompt:  435: Inference (test):avg data time: 8.10e-05, avg batch time: 0.1275, average loss: 1.9961
[09/23 03:05:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.98	top5: 97.79	
[09/23 03:05:38][INFO] visual_prompt:  357: Best epoch 98: best metric: 0.808
[09/23 03:05:38][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/23 03:06:47][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 2.00e-02, avg batch time: 0.8063, average train loss: 1.9770average G loss: 0.0107, average realD loss: 0.0687, average fakeD loss: 0.0757, 
[09/23 03:06:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.22e-05, avg batch time: 0.1201, average loss: 1.9773
[09/23 03:06:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 97.50	
[09/23 03:07:03][INFO] visual_prompt:  435: Inference (test):avg data time: 8.36e-05, avg batch time: 0.1283, average loss: 1.9730
[09/23 03:07:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.72	top5: 97.96	
[09/23 03:07:03][INFO] visual_prompt:  357: Best epoch 99: best metric: 0.827
[09/23 03:07:03][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/23 03:08:12][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.82e-02, avg batch time: 0.8044, average train loss: 1.9587average G loss: 0.0102, average realD loss: 0.0662, average fakeD loss: 0.0765, 
[09/23 03:08:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.77e-05, avg batch time: 0.1207, average loss: 1.9664
[09/23 03:08:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.33	
[09/23 03:08:27][INFO] visual_prompt:  435: Inference (test):avg data time: 7.89e-05, avg batch time: 0.1289, average loss: 1.9621
[09/23 03:08:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.93	top5: 97.98	
[09/23 03:08:27][INFO] visual_prompt:  357: Best epoch 100: best metric: 0.828
