[09/23 19:37:55][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 19:37:55][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 19:37:55][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/23 19:37:55][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 19:37:55][INFO] visual_prompt:  109: Training with config:
[09/23 19:37:55][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr0.0625_wd0.01/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 0.0625,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.01,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 19:37:55][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 19:37:55][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 19:37:56][INFO] visual_prompt:   77: Number of images: 5394
[09/23 19:37:56][INFO] visual_prompt:   78: Number of classes: 200
[09/23 19:37:56][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 19:37:56][INFO] visual_prompt:   73: Loading validation data...
[09/23 19:37:56][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 19:37:56][INFO] visual_prompt:   77: Number of images: 600
[09/23 19:37:56][INFO] visual_prompt:   78: Number of classes: 200
[09/23 19:37:56][INFO] visual_prompt:   76: Loading test data...
[09/23 19:37:56][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 19:37:56][INFO] visual_prompt:   77: Number of images: 5794
[09/23 19:37:56][INFO] visual_prompt:   78: Number of classes: 200
[09/23 19:37:56][INFO] visual_prompt:  103: Constructing models...
[09/23 19:38:06][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 19:38:06][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 19:38:07][INFO] visual_prompt:   41: Device used for model: 0
[09/23 19:38:07][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 19:38:07][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 19:38:07][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 19:38:07][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/23 19:39:15][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.92e-02, avg batch time: 0.7998, average train loss: 5.3354average G loss: 2.5600, average realD loss: 7.3098, average fakeD loss: 1.6561, 
[09/23 19:39:17][INFO] visual_prompt:  435: Inference (val):avg data time: 5.26e-05, avg batch time: 0.1206, average loss: 5.3305
[09/23 19:39:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.17	top5: 3.33	
[09/23 19:39:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.70e-05, avg batch time: 0.1269, average loss: 5.3318
[09/23 19:39:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.45	
[09/23 19:39:31][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.002
[09/23 19:39:31][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.00625
[09/23 19:40:39][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.72e-02, avg batch time: 0.7960, average train loss: 5.3206average G loss: 0.0278, average realD loss: 2.9963, average fakeD loss: 1.5804, 
[09/23 19:40:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.41e-05, avg batch time: 0.1205, average loss: 5.3098
[09/23 19:40:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 19:40:55][INFO] visual_prompt:  435: Inference (test):avg data time: 8.98e-05, avg batch time: 0.1272, average loss: 5.3115
[09/23 19:40:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.72	top5: 2.62	
[09/23 19:40:55][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.005
[09/23 19:40:55][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.0125
[09/23 19:42:03][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.74e-02, avg batch time: 0.7965, average train loss: 5.3095average G loss: 0.0000, average realD loss: 1.2754, average fakeD loss: 0.7779, 
[09/23 19:42:05][INFO] visual_prompt:  435: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1214, average loss: 5.2988
[09/23 19:42:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.00	
[09/23 19:42:19][INFO] visual_prompt:  435: Inference (test):avg data time: 8.08e-05, avg batch time: 0.1276, average loss: 5.2999
[09/23 19:42:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.60	top5: 2.38	
[09/23 19:42:19][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.01875
[09/23 19:43:27][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.75e-02, avg batch time: 0.7970, average train loss: 5.3023average G loss: 0.0000, average realD loss: 0.4705, average fakeD loss: 0.3882, 
[09/23 19:43:29][INFO] visual_prompt:  435: Inference (val):avg data time: 5.29e-05, avg batch time: 0.1206, average loss: 5.2907
[09/23 19:43:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.50	
[09/23 19:43:43][INFO] visual_prompt:  435: Inference (test):avg data time: 7.45e-05, avg batch time: 0.1279, average loss: 5.2915
[09/23 19:43:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.76	top5: 3.78	
[09/23 19:43:43][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 0.025
[09/23 19:44:51][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.83e-02, avg batch time: 0.7985, average train loss: 5.2738average G loss: 0.0000, average realD loss: 0.1784, average fakeD loss: 0.1722, 
[09/23 19:44:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.90e-05, avg batch time: 0.1205, average loss: 5.1518
[09/23 19:44:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 2.50	top5: 9.00	
[09/23 19:45:07][INFO] visual_prompt:  435: Inference (test):avg data time: 9.42e-05, avg batch time: 0.1272, average loss: 5.1524
[09/23 19:45:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.90	top5: 7.44	
[09/23 19:45:07][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.025
[09/23 19:45:07][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 0.03125
[09/23 19:46:15][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 2.04e-02, avg batch time: 0.8030, average train loss: 4.9178average G loss: 0.0004, average realD loss: 0.1162, average fakeD loss: 0.0997, 
[09/23 19:46:17][INFO] visual_prompt:  435: Inference (val):avg data time: 6.49e-05, avg batch time: 0.1203, average loss: 4.5190
[09/23 19:46:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 10.50	top5: 33.83	
[09/23 19:46:31][INFO] visual_prompt:  435: Inference (test):avg data time: 8.23e-05, avg batch time: 0.1279, average loss: 4.5190
[09/23 19:46:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 9.82	top5: 31.79	
[09/23 19:46:31][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.105
[09/23 19:46:31][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 0.0375
[09/23 19:47:39][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.76e-02, avg batch time: 0.8019, average train loss: 4.1589average G loss: 0.0020, average realD loss: 0.0806, average fakeD loss: 0.0743, 
[09/23 19:47:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1206, average loss: 3.6214
[09/23 19:47:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 46.83	top5: 83.00	
[09/23 19:47:55][INFO] visual_prompt:  435: Inference (test):avg data time: 7.59e-05, avg batch time: 0.1280, average loss: 3.6188
[09/23 19:47:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 48.22	top5: 82.21	
[09/23 19:47:55][INFO] visual_prompt:  357: Best epoch 7: best metric: 0.468
[09/23 19:47:55][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 0.04375
[09/23 19:49:03][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.75e-02, avg batch time: 0.8017, average train loss: 3.3225average G loss: 0.0058, average realD loss: 0.0740, average fakeD loss: 0.0685, 
[09/23 19:49:05][INFO] visual_prompt:  435: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1201, average loss: 2.8888
[09/23 19:49:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.83	top5: 92.67	
[09/23 19:49:19][INFO] visual_prompt:  435: Inference (test):avg data time: 8.13e-05, avg batch time: 0.1274, average loss: 2.8901
[09/23 19:49:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.91	top5: 92.79	
[09/23 19:49:19][INFO] visual_prompt:  357: Best epoch 8: best metric: 0.638
[09/23 19:49:19][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 0.05
[09/23 19:50:27][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.84e-02, avg batch time: 0.8027, average train loss: 2.7594average G loss: 0.0103, average realD loss: 0.0720, average fakeD loss: 0.0661, 
[09/23 19:50:30][INFO] visual_prompt:  435: Inference (val):avg data time: 7.35e-05, avg batch time: 0.1202, average loss: 2.5046
[09/23 19:50:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.00	top5: 93.67	
[09/23 19:50:44][INFO] visual_prompt:  435: Inference (test):avg data time: 1.00e-04, avg batch time: 0.1271, average loss: 2.5068
[09/23 19:50:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.45	top5: 94.63	
[09/23 19:50:44][INFO] visual_prompt:  357: Best epoch 9: best metric: 0.650
[09/23 19:50:44][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 0.05625
[09/23 19:51:52][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.92e-02, avg batch time: 0.8033, average train loss: 2.4962average G loss: 0.0149, average realD loss: 0.0761, average fakeD loss: 0.0731, 
[09/23 19:51:55][INFO] visual_prompt:  435: Inference (val):avg data time: 4.73e-05, avg batch time: 0.1212, average loss: 2.3469
[09/23 19:51:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.67	top5: 92.83	
[09/23 19:52:08][INFO] visual_prompt:  435: Inference (test):avg data time: 9.08e-05, avg batch time: 0.1277, average loss: 2.3366
[09/23 19:52:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.97	top5: 94.22	
[09/23 19:52:09][INFO] visual_prompt:  357: Best epoch 10: best metric: 0.707
[09/23 19:52:09][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 0.0625
[09/23 19:53:17][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.91e-02, avg batch time: 0.8032, average train loss: 2.3990average G loss: 0.0170, average realD loss: 0.0789, average fakeD loss: 0.0787, 
[09/23 19:53:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.96e-05, avg batch time: 0.1220, average loss: 2.2588
[09/23 19:53:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.33	top5: 95.50	
[09/23 19:53:32][INFO] visual_prompt:  435: Inference (test):avg data time: 6.46e-05, avg batch time: 0.1281, average loss: 2.2461
[09/23 19:53:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.73	top5: 95.08	
[09/23 19:53:33][INFO] visual_prompt:  357: Best epoch 11: best metric: 0.743
[09/23 19:53:33][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 0.062480963344346746
[09/23 19:54:41][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 2.05e-02, avg batch time: 0.8049, average train loss: 2.3157average G loss: 0.0157, average realD loss: 0.0767, average fakeD loss: 0.0745, 
[09/23 19:54:43][INFO] visual_prompt:  435: Inference (val):avg data time: 5.60e-05, avg batch time: 0.1202, average loss: 2.2403
[09/23 19:54:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.33	top5: 96.17	
[09/23 19:54:57][INFO] visual_prompt:  435: Inference (test):avg data time: 7.78e-05, avg batch time: 0.1276, average loss: 2.2324
[09/23 19:54:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.97	top5: 96.31	
[09/23 19:54:57][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 0.062423876570619506
[09/23 19:56:05][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.89e-02, avg batch time: 0.8028, average train loss: 2.2940average G loss: 0.0151, average realD loss: 0.0725, average fakeD loss: 0.0719, 
[09/23 19:56:08][INFO] visual_prompt:  435: Inference (val):avg data time: 5.85e-05, avg batch time: 0.1212, average loss: 2.1590
[09/23 19:56:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.17	top5: 96.50	
[09/23 19:56:21][INFO] visual_prompt:  435: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1277, average loss: 2.1627
[09/23 19:56:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.71	top5: 96.69	
[09/23 19:56:21][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 0.06232880923025854
[09/23 19:57:30][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.86e-02, avg batch time: 0.8027, average train loss: 2.2608average G loss: 0.0148, average realD loss: 0.0705, average fakeD loss: 0.0750, 
[09/23 19:57:32][INFO] visual_prompt:  435: Inference (val):avg data time: 5.45e-05, avg batch time: 0.1202, average loss: 2.1654
[09/23 19:57:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.50	top5: 95.83	
[09/23 19:57:45][INFO] visual_prompt:  435: Inference (test):avg data time: 8.80e-05, avg batch time: 0.1276, average loss: 2.1534
[09/23 19:57:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.70	top5: 95.94	
[09/23 19:57:46][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 0.062195877148174074
[09/23 19:58:54][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.70e-02, avg batch time: 0.8012, average train loss: 2.2604average G loss: 0.0145, average realD loss: 0.0718, average fakeD loss: 0.0742, 
[09/23 19:58:56][INFO] visual_prompt:  435: Inference (val):avg data time: 6.57e-05, avg batch time: 0.1202, average loss: 2.1794
[09/23 19:58:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.83	top5: 95.67	
[09/23 19:59:10][INFO] visual_prompt:  435: Inference (test):avg data time: 8.36e-05, avg batch time: 0.1273, average loss: 2.1622
[09/23 19:59:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.06	top5: 96.44	
[09/23 19:59:10][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 0.062025242281631504
[09/23 20:00:18][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.98e-02, avg batch time: 0.8042, average train loss: 2.2455average G loss: 0.0143, average realD loss: 0.0711, average fakeD loss: 0.0768, 
[09/23 20:00:20][INFO] visual_prompt:  435: Inference (val):avg data time: 7.00e-05, avg batch time: 0.1203, average loss: 2.1319
[09/23 20:00:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.33	top5: 95.50	
[09/23 20:00:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.47e-05, avg batch time: 0.1275, average loss: 2.1217
[09/23 20:00:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.97	top5: 96.36	
[09/23 20:00:34][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 0.06181711252293143
[09/23 20:01:42][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.81e-02, avg batch time: 0.8026, average train loss: 2.2266average G loss: 0.0141, average realD loss: 0.0709, average fakeD loss: 0.0760, 
[09/23 20:01:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.20e-05, avg batch time: 0.1204, average loss: 2.1237
[09/23 20:01:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.17	top5: 96.67	
[09/23 20:01:58][INFO] visual_prompt:  435: Inference (test):avg data time: 8.86e-05, avg batch time: 0.1277, average loss: 2.1244
[09/23 20:01:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.13	top5: 96.31	
[09/23 20:01:58][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 0.061571741446124886
[09/23 20:03:07][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.85e-02, avg batch time: 0.8027, average train loss: 2.2214average G loss: 0.0143, average realD loss: 0.0679, average fakeD loss: 0.0746, 
[09/23 20:03:09][INFO] visual_prompt:  435: Inference (val):avg data time: 6.54e-05, avg batch time: 0.1212, average loss: 2.1261
[09/23 20:03:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.50	top5: 97.00	
[09/23 20:03:22][INFO] visual_prompt:  435: Inference (test):avg data time: 8.13e-05, avg batch time: 0.1278, average loss: 2.1139
[09/23 20:03:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.80	top5: 96.72	
[09/23 20:03:22][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 0.061289427998072465
[09/23 20:04:31][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.93e-02, avg batch time: 0.8035, average train loss: 2.2002average G loss: 0.0143, average realD loss: 0.0735, average fakeD loss: 0.0746, 
[09/23 20:04:33][INFO] visual_prompt:  435: Inference (val):avg data time: 6.11e-05, avg batch time: 0.1199, average loss: 2.1359
[09/23 20:04:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.83	top5: 95.17	
[09/23 20:04:47][INFO] visual_prompt:  435: Inference (test):avg data time: 6.82e-05, avg batch time: 0.1275, average loss: 2.1263
[09/23 20:04:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.30	top5: 96.05	
[09/23 20:04:47][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 0.06097051613422355
[09/23 20:05:55][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.80e-02, avg batch time: 0.8023, average train loss: 2.2173average G loss: 0.0140, average realD loss: 0.0695, average fakeD loss: 0.0775, 
[09/23 20:05:57][INFO] visual_prompt:  435: Inference (val):avg data time: 5.91e-05, avg batch time: 0.1206, average loss: 2.1305
[09/23 20:05:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.17	top5: 96.83	
[09/23 20:06:11][INFO] visual_prompt:  435: Inference (test):avg data time: 8.81e-05, avg batch time: 0.1282, average loss: 2.1297
[09/23 20:06:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.44	top5: 96.19	
[09/23 20:06:11][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 0.06061539439955964
[09/23 20:07:19][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.79e-02, avg batch time: 0.8023, average train loss: 2.2054average G loss: 0.0145, average realD loss: 0.0707, average fakeD loss: 0.0760, 
[09/23 20:07:21][INFO] visual_prompt:  435: Inference (val):avg data time: 7.86e-05, avg batch time: 0.1209, average loss: 2.1425
[09/23 20:07:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.17	top5: 96.33	
[09/23 20:07:35][INFO] visual_prompt:  435: Inference (test):avg data time: 9.11e-05, avg batch time: 0.1278, average loss: 2.1427
[09/23 20:07:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.80	top5: 95.69	
[09/23 20:07:35][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 0.06022449545521211
[09/23 20:08:43][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.82e-02, avg batch time: 0.8025, average train loss: 2.2053average G loss: 0.0140, average realD loss: 0.0699, average fakeD loss: 0.0762, 
[09/23 20:08:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.33e-05, avg batch time: 0.1211, average loss: 2.1263
[09/23 20:08:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.50	top5: 96.00	
[09/23 20:08:59][INFO] visual_prompt:  435: Inference (test):avg data time: 5.73e-05, avg batch time: 0.1279, average loss: 2.1186
[09/23 20:08:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.11	top5: 96.62	
[09/23 20:08:59][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 0.059798295551331274
[09/23 20:10:07][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.86e-02, avg batch time: 0.8029, average train loss: 2.2018average G loss: 0.0146, average realD loss: 0.0699, average fakeD loss: 0.0737, 
[09/23 20:10:10][INFO] visual_prompt:  435: Inference (val):avg data time: 7.88e-05, avg batch time: 0.1202, average loss: 2.1369
[09/23 20:10:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.50	top5: 96.17	
[09/23 20:10:23][INFO] visual_prompt:  435: Inference (test):avg data time: 6.49e-05, avg batch time: 0.1280, average loss: 2.1390
[09/23 20:10:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.06	top5: 96.19	
[09/23 20:10:23][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 0.05933731394684897
[09/23 20:11:31][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.84e-02, avg batch time: 0.8028, average train loss: 2.1923average G loss: 0.0137, average realD loss: 0.0688, average fakeD loss: 0.0741, 
[09/23 20:11:34][INFO] visual_prompt:  435: Inference (val):avg data time: 7.23e-05, avg batch time: 0.1208, average loss: 2.1267
[09/23 20:11:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.33	top5: 96.83	
[09/23 20:11:47][INFO] visual_prompt:  435: Inference (test):avg data time: 9.07e-05, avg batch time: 0.1275, average loss: 2.1322
[09/23 20:11:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.75	top5: 96.10	
[09/23 20:11:47][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 0.05884211227684147
[09/23 20:12:56][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.79e-02, avg batch time: 0.8021, average train loss: 2.1865average G loss: 0.0140, average realD loss: 0.0713, average fakeD loss: 0.0789, 
[09/23 20:12:58][INFO] visual_prompt:  435: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1205, average loss: 2.1169
[09/23 20:12:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.50	top5: 97.17	
[09/23 20:13:12][INFO] visual_prompt:  435: Inference (test):avg data time: 7.23e-05, avg batch time: 0.1276, average loss: 2.1116
[09/23 20:13:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.02	top5: 97.05	
[09/23 20:13:12][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 0.05831329386826371
[09/23 20:14:20][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.91e-02, avg batch time: 0.8030, average train loss: 2.1824average G loss: 0.0142, average realD loss: 0.0689, average fakeD loss: 0.0732, 
[09/23 20:14:22][INFO] visual_prompt:  435: Inference (val):avg data time: 8.27e-05, avg batch time: 0.1197, average loss: 2.1295
[09/23 20:14:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.00	top5: 97.17	
[09/23 20:14:36][INFO] visual_prompt:  435: Inference (test):avg data time: 6.96e-05, avg batch time: 0.1275, average loss: 2.1243
[09/23 20:14:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.61	top5: 96.91	
[09/23 20:14:36][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 0.05775150300488831
[09/23 20:15:44][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.89e-02, avg batch time: 0.8027, average train loss: 2.1789average G loss: 0.0137, average realD loss: 0.0692, average fakeD loss: 0.0764, 
[09/23 20:15:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.98e-05, avg batch time: 0.1198, average loss: 2.1034
[09/23 20:15:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.67	top5: 96.17	
[09/23 20:16:00][INFO] visual_prompt:  435: Inference (test):avg data time: 9.14e-05, avg batch time: 0.1275, average loss: 2.0926
[09/23 20:16:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.37	top5: 96.24	
[09/23 20:16:00][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 0.05715742414234505
[09/23 20:17:09][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.80e-02, avg batch time: 0.8017, average train loss: 2.1929average G loss: 0.0139, average realD loss: 0.0707, average fakeD loss: 0.0753, 
[09/23 20:17:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.81e-05, avg batch time: 0.1210, average loss: 2.1205
[09/23 20:17:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.33	top5: 96.33	
[09/23 20:17:24][INFO] visual_prompt:  435: Inference (test):avg data time: 6.76e-05, avg batch time: 0.1279, average loss: 2.1095
[09/23 20:17:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.16	top5: 96.51	
[09/23 20:17:24][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 0.05653178107421711
[09/23 20:18:33][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.74e-02, avg batch time: 0.8012, average train loss: 2.1942average G loss: 0.0139, average realD loss: 0.0670, average fakeD loss: 0.0747, 
[09/23 20:18:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.21e-05, avg batch time: 0.1201, average loss: 2.1150
[09/23 20:18:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.33	top5: 96.67	
[09/23 20:18:49][INFO] visual_prompt:  435: Inference (test):avg data time: 8.27e-05, avg batch time: 0.1275, average loss: 2.1055
[09/23 20:18:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.64	top5: 96.74	
[09/23 20:18:49][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 0.055875336050210056
[09/23 20:19:57][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.86e-02, avg batch time: 0.8023, average train loss: 2.1841average G loss: 0.0140, average realD loss: 0.0687, average fakeD loss: 0.0703, 
[09/23 20:19:59][INFO] visual_prompt:  435: Inference (val):avg data time: 7.74e-05, avg batch time: 0.1206, average loss: 2.0965
[09/23 20:19:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.67	top5: 95.83	
[09/23 20:20:13][INFO] visual_prompt:  435: Inference (test):avg data time: 8.36e-05, avg batch time: 0.1273, average loss: 2.0936
[09/23 20:20:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.89	top5: 96.25	
[09/23 20:20:13][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 0.05518888884746806
[09/23 20:21:21][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.80e-02, avg batch time: 0.8020, average train loss: 2.1882average G loss: 0.0142, average realD loss: 0.0700, average fakeD loss: 0.0738, 
[09/23 20:21:24][INFO] visual_prompt:  435: Inference (val):avg data time: 7.09e-05, avg batch time: 0.1205, average loss: 2.1604
[09/23 20:21:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.83	top5: 96.33	
[09/23 20:21:38][INFO] visual_prompt:  435: Inference (test):avg data time: 7.61e-05, avg batch time: 0.1270, average loss: 2.1440
[09/23 20:21:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.92	top5: 96.57	
[09/23 20:21:38][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 0.05447327579616857
[09/23 20:22:46][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.78e-02, avg batch time: 0.8017, average train loss: 2.1820average G loss: 0.0138, average realD loss: 0.0688, average fakeD loss: 0.0748, 
[09/23 20:22:48][INFO] visual_prompt:  435: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1206, average loss: 2.1264
[09/23 20:22:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.17	top5: 96.50	
[09/23 20:23:02][INFO] visual_prompt:  435: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1273, average loss: 2.1149
[09/23 20:23:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.61	top5: 96.74	
[09/23 20:23:03][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 0.053729368760582846
[09/23 20:24:11][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.70e-02, avg batch time: 0.8009, average train loss: 2.1872average G loss: 0.0140, average realD loss: 0.0691, average fakeD loss: 0.0748, 
[09/23 20:24:13][INFO] visual_prompt:  435: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1204, average loss: 2.0953
[09/23 20:24:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.50	top5: 96.17	
[09/23 20:24:27][INFO] visual_prompt:  435: Inference (test):avg data time: 8.71e-05, avg batch time: 0.1274, average loss: 2.1012
[09/23 20:24:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.02	top5: 96.44	
[09/23 20:24:27][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 0.052958074076843664
[09/23 20:25:36][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 2.13e-02, avg batch time: 0.8054, average train loss: 2.1709average G loss: 0.0139, average realD loss: 0.0722, average fakeD loss: 0.0763, 
[09/23 20:25:38][INFO] visual_prompt:  435: Inference (val):avg data time: 7.10e-05, avg batch time: 0.1202, average loss: 2.1303
[09/23 20:25:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.17	top5: 96.33	
[09/23 20:25:51][INFO] visual_prompt:  435: Inference (test):avg data time: 5.90e-05, avg batch time: 0.1280, average loss: 2.1255
[09/23 20:25:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.77	top5: 96.19	
[09/23 20:25:51][INFO] visual_prompt:  357: Best epoch 34: best metric: 0.752
[09/23 20:25:51][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 0.05216033144871432
[09/23 20:27:00][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.95e-02, avg batch time: 0.8034, average train loss: 2.1818average G loss: 0.0144, average realD loss: 0.0707, average fakeD loss: 0.0758, 
[09/23 20:27:02][INFO] visual_prompt:  435: Inference (val):avg data time: 5.74e-05, avg batch time: 0.1201, average loss: 2.1039
[09/23 20:27:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.17	top5: 97.17	
[09/23 20:27:15][INFO] visual_prompt:  435: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1277, average loss: 2.0980
[09/23 20:27:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.40	top5: 96.82	
[09/23 20:27:15][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 0.05133711280270435
[09/23 20:28:24][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.91e-02, avg batch time: 0.8033, average train loss: 2.1718average G loss: 0.0142, average realD loss: 0.0694, average fakeD loss: 0.0743, 
[09/23 20:28:26][INFO] visual_prompt:  435: Inference (val):avg data time: 4.97e-05, avg batch time: 0.1210, average loss: 2.1517
[09/23 20:28:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.50	top5: 96.00	
[09/23 20:28:40][INFO] visual_prompt:  435: Inference (test):avg data time: 9.71e-05, avg batch time: 0.1273, average loss: 2.1505
[09/23 20:28:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.28	top5: 95.60	
[09/23 20:28:40][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 0.05048942110392682
[09/23 20:29:48][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.74e-02, avg batch time: 0.8013, average train loss: 2.1794average G loss: 0.0140, average realD loss: 0.0688, average fakeD loss: 0.0752, 
[09/23 20:29:50][INFO] visual_prompt:  435: Inference (val):avg data time: 6.26e-05, avg batch time: 0.1211, average loss: 2.1125
[09/23 20:29:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.67	top5: 95.67	
[09/23 20:30:04][INFO] visual_prompt:  435: Inference (test):avg data time: 7.33e-05, avg batch time: 0.1278, average loss: 2.1128
[09/23 20:30:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.59	top5: 96.13	
[09/23 20:30:04][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 0.049618289134139786
[09/23 20:31:12][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.76e-02, avg batch time: 0.8015, average train loss: 2.1769average G loss: 0.0138, average realD loss: 0.0683, average fakeD loss: 0.0732, 
[09/23 20:31:14][INFO] visual_prompt:  435: Inference (val):avg data time: 6.20e-05, avg batch time: 0.1206, average loss: 2.0870
[09/23 20:31:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.67	top5: 96.50	
[09/23 20:31:28][INFO] visual_prompt:  435: Inference (test):avg data time: 7.90e-05, avg batch time: 0.1276, average loss: 2.0990
[09/23 20:31:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.97	top5: 96.60	
[09/23 20:31:28][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 0.04872477823346084
[09/23 20:32:36][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 1.76e-02, avg batch time: 0.8016, average train loss: 2.1663average G loss: 0.0138, average realD loss: 0.0708, average fakeD loss: 0.0746, 
[09/23 20:32:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.47e-05, avg batch time: 0.1205, average loss: 2.0918
[09/23 20:32:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.17	top5: 97.33	
[09/23 20:32:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.86e-05, avg batch time: 0.1276, average loss: 2.0783
[09/23 20:32:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.01	top5: 97.05	
[09/23 20:32:52][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 0.04780997700728765
[09/23 20:34:00][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.96e-02, avg batch time: 0.8036, average train loss: 2.1606average G loss: 0.0135, average realD loss: 0.0687, average fakeD loss: 0.0775, 
[09/23 20:34:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.21e-05, avg batch time: 0.1201, average loss: 2.0770
[09/23 20:34:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.83	top5: 96.67	
[09/23 20:34:16][INFO] visual_prompt:  435: Inference (test):avg data time: 8.57e-05, avg batch time: 0.1280, average loss: 2.0788
[09/23 20:34:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.49	top5: 97.19	
[09/23 20:34:16][INFO] visual_prompt:  357: Best epoch 40: best metric: 0.758
[09/23 20:34:16][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 0.046875
[09/23 20:35:25][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.80e-02, avg batch time: 0.8018, average train loss: 2.1644average G loss: 0.0137, average realD loss: 0.0713, average fakeD loss: 0.0770, 
[09/23 20:35:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.40e-05, avg batch time: 0.1199, average loss: 2.0931
[09/23 20:35:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 96.33	
[09/23 20:35:40][INFO] visual_prompt:  435: Inference (test):avg data time: 7.11e-05, avg batch time: 0.1275, average loss: 2.0799
[09/23 20:35:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.56	top5: 96.67	
[09/23 20:35:41][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 0.045920986337059086
[09/23 20:36:49][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 1.93e-02, avg batch time: 0.8032, average train loss: 2.1437average G loss: 0.0138, average realD loss: 0.0698, average fakeD loss: 0.0768, 
[09/23 20:36:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.25e-05, avg batch time: 0.1206, average loss: 2.1021
[09/23 20:36:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.00	top5: 97.50	
[09/23 20:37:05][INFO] visual_prompt:  435: Inference (test):avg data time: 7.58e-05, avg batch time: 0.1275, average loss: 2.1079
[09/23 20:37:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.46	top5: 96.69	
[09/23 20:37:05][INFO] visual_prompt:  357: Best epoch 42: best metric: 0.760
[09/23 20:37:05][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 0.04494909833715867
[09/23 20:38:13][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.75e-02, avg batch time: 0.8014, average train loss: 2.1558average G loss: 0.0140, average realD loss: 0.0711, average fakeD loss: 0.0758, 
[09/23 20:38:15][INFO] visual_prompt:  435: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1203, average loss: 2.0655
[09/23 20:38:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.50	top5: 98.00	
[09/23 20:38:29][INFO] visual_prompt:  435: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1274, average loss: 2.0717
[09/23 20:38:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.68	top5: 97.10	
[09/23 20:38:29][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 0.04396052009611876
[09/23 20:39:37][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 1.89e-02, avg batch time: 0.8024, average train loss: 2.1375average G loss: 0.0134, average realD loss: 0.0684, average fakeD loss: 0.0745, 
[09/23 20:39:40][INFO] visual_prompt:  435: Inference (val):avg data time: 5.65e-05, avg batch time: 0.1208, average loss: 2.0625
[09/23 20:39:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.33	top5: 97.50	
[09/23 20:39:54][INFO] visual_prompt:  435: Inference (test):avg data time: 9.60e-05, avg batch time: 0.1273, average loss: 2.0588
[09/23 20:39:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.54	top5: 97.12	
[09/23 20:39:54][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 0.042956456044247256
[09/23 20:41:02][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.90e-02, avg batch time: 0.8027, average train loss: 2.1388average G loss: 0.0135, average realD loss: 0.0707, average fakeD loss: 0.0728, 
[09/23 20:41:04][INFO] visual_prompt:  435: Inference (val):avg data time: 7.61e-05, avg batch time: 0.1199, average loss: 2.0868
[09/23 20:41:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.67	top5: 96.33	
[09/23 20:41:18][INFO] visual_prompt:  435: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1272, average loss: 2.0749
[09/23 20:41:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.70	top5: 96.95	
[09/23 20:41:18][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 0.04193812947892715
[09/23 20:42:26][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 1.77e-02, avg batch time: 0.8011, average train loss: 2.1357average G loss: 0.0136, average realD loss: 0.0698, average fakeD loss: 0.0755, 
[09/23 20:42:29][INFO] visual_prompt:  435: Inference (val):avg data time: 7.20e-05, avg batch time: 0.1200, average loss: 2.0699
[09/23 20:42:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.67	top5: 96.83	
[09/23 20:42:42][INFO] visual_prompt:  435: Inference (test):avg data time: 7.95e-05, avg batch time: 0.1274, average loss: 2.0635
[09/23 20:42:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.75	top5: 97.03	
[09/23 20:42:42][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 0.04090678107421711
[09/23 20:43:51][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 1.81e-02, avg batch time: 0.8014, average train loss: 2.1360average G loss: 0.0138, average realD loss: 0.0691, average fakeD loss: 0.0763, 
[09/23 20:43:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.55e-05, avg batch time: 0.1199, average loss: 2.0419
[09/23 20:43:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.33	top5: 97.50	
[09/23 20:44:06][INFO] visual_prompt:  435: Inference (test):avg data time: 8.19e-05, avg batch time: 0.1274, average loss: 2.0430
[09/23 20:44:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.87	top5: 97.32	
[09/23 20:44:06][INFO] visual_prompt:  357: Best epoch 47: best metric: 0.773
[09/23 20:44:06][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 0.03986366736928122
[09/23 20:45:15][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.85e-02, avg batch time: 0.8019, average train loss: 2.1274average G loss: 0.0133, average realD loss: 0.0695, average fakeD loss: 0.0755, 
[09/23 20:45:17][INFO] visual_prompt:  435: Inference (val):avg data time: 4.97e-05, avg batch time: 0.1199, average loss: 2.0626
[09/23 20:45:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 97.50	
[09/23 20:45:31][INFO] visual_prompt:  435: Inference (test):avg data time: 8.33e-05, avg batch time: 0.1271, average loss: 2.0579
[09/23 20:45:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.80	top5: 97.39	
[09/23 20:45:31][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 0.03881005923748961
[09/23 20:46:39][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.87e-02, avg batch time: 0.8020, average train loss: 2.1230average G loss: 0.0134, average realD loss: 0.0687, average fakeD loss: 0.0754, 
[09/23 20:46:42][INFO] visual_prompt:  435: Inference (val):avg data time: 8.38e-05, avg batch time: 0.1200, average loss: 2.0557
[09/23 20:46:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.00	top5: 97.00	
[09/23 20:46:55][INFO] visual_prompt:  435: Inference (test):avg data time: 7.79e-05, avg batch time: 0.1272, average loss: 2.0549
[09/23 20:46:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.70	top5: 97.24	
[09/23 20:46:55][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 0.037747240338054974
[09/23 20:48:04][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 1.92e-02, avg batch time: 0.8026, average train loss: 2.1163average G loss: 0.0132, average realD loss: 0.0712, average fakeD loss: 0.0751, 
[09/23 20:48:06][INFO] visual_prompt:  435: Inference (val):avg data time: 5.33e-05, avg batch time: 0.1204, average loss: 2.0694
[09/23 20:48:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.50	top5: 97.50	
[09/23 20:48:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.38e-05, avg batch time: 0.1270, average loss: 2.0594
[09/23 20:48:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.32	top5: 97.36	
[09/23 20:48:20][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 0.03667650555209158
[09/23 20:49:28][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.83e-02, avg batch time: 0.8016, average train loss: 2.1147average G loss: 0.0133, average realD loss: 0.0682, average fakeD loss: 0.0758, 
[09/23 20:49:31][INFO] visual_prompt:  435: Inference (val):avg data time: 8.17e-05, avg batch time: 0.1199, average loss: 2.0593
[09/23 20:49:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.67	top5: 96.33	
[09/23 20:49:44][INFO] visual_prompt:  435: Inference (test):avg data time: 8.30e-05, avg batch time: 0.1277, average loss: 2.0455
[09/23 20:49:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.30	top5: 96.50	
[09/23 20:49:44][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 0.035599159405002044
[09/23 20:50:53][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.76e-02, avg batch time: 0.8010, average train loss: 2.1069average G loss: 0.0129, average realD loss: 0.0687, average fakeD loss: 0.0731, 
[09/23 20:50:55][INFO] visual_prompt:  435: Inference (val):avg data time: 7.41e-05, avg batch time: 0.1205, average loss: 2.0583
[09/23 20:50:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.50	top5: 97.17	
[09/23 20:51:08][INFO] visual_prompt:  435: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1275, average loss: 2.0413
[09/23 20:51:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.72	top5: 96.76	
[09/23 20:51:08][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 0.03451651447711417
[09/23 20:52:17][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.90e-02, avg batch time: 0.8023, average train loss: 2.0970average G loss: 0.0128, average realD loss: 0.0708, average fakeD loss: 0.0754, 
[09/23 20:52:19][INFO] visual_prompt:  435: Inference (val):avg data time: 4.74e-05, avg batch time: 0.1202, average loss: 2.0348
[09/23 20:52:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.67	top5: 97.83	
[09/23 20:52:33][INFO] visual_prompt:  435: Inference (test):avg data time: 6.79e-05, avg batch time: 0.1273, average loss: 2.0307
[09/23 20:52:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.13	top5: 97.22	
[09/23 20:52:33][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 0.03342988980450391
[09/23 20:53:41][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.88e-02, avg batch time: 0.8020, average train loss: 2.1105average G loss: 0.0136, average realD loss: 0.0724, average fakeD loss: 0.0759, 
[09/23 20:53:43][INFO] visual_prompt:  435: Inference (val):avg data time: 8.21e-05, avg batch time: 0.1200, average loss: 2.0582
[09/23 20:53:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 97.67	
[09/23 20:53:57][INFO] visual_prompt:  435: Inference (test):avg data time: 8.73e-05, avg batch time: 0.1272, average loss: 2.0479
[09/23 20:53:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.48	top5: 97.53	
[09/23 20:53:57][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 0.03234060927195316
[09/23 20:55:05][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.86e-02, avg batch time: 0.8020, average train loss: 2.0882average G loss: 0.0129, average realD loss: 0.0688, average fakeD loss: 0.0744, 
[09/23 20:55:08][INFO] visual_prompt:  435: Inference (val):avg data time: 7.37e-05, avg batch time: 0.1196, average loss: 2.0400
[09/23 20:55:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 97.33	
[09/23 20:55:21][INFO] visual_prompt:  435: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1273, average loss: 2.0267
[09/23 20:55:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.53	top5: 96.95	
[09/23 20:55:21][INFO] visual_prompt:  357: Best epoch 55: best metric: 0.787
[09/23 20:55:21][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 0.03125
[09/23 20:56:30][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 1.80e-02, avg batch time: 0.8015, average train loss: 2.0805average G loss: 0.0126, average realD loss: 0.0705, average fakeD loss: 0.0764, 
[09/23 20:56:32][INFO] visual_prompt:  435: Inference (val):avg data time: 8.18e-05, avg batch time: 0.1198, average loss: 2.0359
[09/23 20:56:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.50	
[09/23 20:56:46][INFO] visual_prompt:  435: Inference (test):avg data time: 9.04e-05, avg batch time: 0.1270, average loss: 2.0266
[09/23 20:56:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.05	top5: 97.38	
[09/23 20:56:46][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 0.030159390728046853
[09/23 20:57:54][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.89e-02, avg batch time: 0.8025, average train loss: 2.0754average G loss: 0.0130, average realD loss: 0.0706, average fakeD loss: 0.0745, 
[09/23 20:57:57][INFO] visual_prompt:  435: Inference (val):avg data time: 5.88e-05, avg batch time: 0.1200, average loss: 2.0523
[09/23 20:57:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 97.67	
[09/23 20:58:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1273, average loss: 2.0456
[09/23 20:58:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.67	top5: 96.82	
[09/23 20:58:11][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 0.029070110195496084
[09/23 20:59:19][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 1.79e-02, avg batch time: 0.8014, average train loss: 2.0715average G loss: 0.0131, average realD loss: 0.0677, average fakeD loss: 0.0725, 
[09/23 20:59:21][INFO] visual_prompt:  435: Inference (val):avg data time: 6.35e-05, avg batch time: 0.1206, average loss: 2.0122
[09/23 20:59:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 97.50	
[09/23 20:59:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1275, average loss: 2.0034
[09/23 20:59:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.98	top5: 97.83	
[09/23 20:59:35][INFO] visual_prompt:  357: Best epoch 58: best metric: 0.793
[09/23 20:59:35][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 0.027983485522885834
[09/23 21:00:43][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.77e-02, avg batch time: 0.8011, average train loss: 2.0688average G loss: 0.0129, average realD loss: 0.0699, average fakeD loss: 0.0749, 
[09/23 21:00:45][INFO] visual_prompt:  435: Inference (val):avg data time: 8.76e-05, avg batch time: 0.1213, average loss: 2.0171
[09/23 21:00:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 97.33	
[09/23 21:00:58][INFO] visual_prompt:  435: Inference (test):avg data time: 5.95e-05, avg batch time: 0.1279, average loss: 2.0127
[09/23 21:00:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.56	top5: 97.31	
[09/23 21:00:58][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 0.026900840594997963
[09/23 21:02:07][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 2.02e-02, avg batch time: 0.8036, average train loss: 2.0677average G loss: 0.0129, average realD loss: 0.0690, average fakeD loss: 0.0767, 
[09/23 21:02:09][INFO] visual_prompt:  435: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1201, average loss: 2.0210
[09/23 21:02:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.50	top5: 97.17	
[09/23 21:02:23][INFO] visual_prompt:  435: Inference (test):avg data time: 8.33e-05, avg batch time: 0.1272, average loss: 2.0137
[09/23 21:02:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.61	top5: 96.93	
[09/23 21:02:23][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 0.025823494447908428
[09/23 21:03:31][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.79e-02, avg batch time: 0.8014, average train loss: 2.0573average G loss: 0.0126, average realD loss: 0.0703, average fakeD loss: 0.0748, 
[09/23 21:03:33][INFO] visual_prompt:  435: Inference (val):avg data time: 6.01e-05, avg batch time: 0.1204, average loss: 2.0050
[09/23 21:03:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 97.17	
[09/23 21:03:47][INFO] visual_prompt:  435: Inference (test):avg data time: 6.81e-05, avg batch time: 0.1274, average loss: 2.0014
[09/23 21:03:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.36	top5: 97.46	
[09/23 21:03:47][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 0.024752759661945026
[09/23 21:04:55][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.74e-02, avg batch time: 0.8010, average train loss: 2.0564average G loss: 0.0126, average realD loss: 0.0684, average fakeD loss: 0.0751, 
[09/23 21:04:57][INFO] visual_prompt:  435: Inference (val):avg data time: 6.65e-05, avg batch time: 0.1200, average loss: 2.0137
[09/23 21:04:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 97.50	
[09/23 21:05:11][INFO] visual_prompt:  435: Inference (test):avg data time: 8.01e-05, avg batch time: 0.1272, average loss: 2.0067
[09/23 21:05:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.94	top5: 97.34	
[09/23 21:05:11][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 0.023689940762510388
[09/23 21:06:20][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 1.87e-02, avg batch time: 0.8022, average train loss: 2.0515average G loss: 0.0127, average realD loss: 0.0670, average fakeD loss: 0.0732, 
[09/23 21:06:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1202, average loss: 2.0076
[09/23 21:06:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 98.00	
[09/23 21:06:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1277, average loss: 2.0036
[09/23 21:06:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.36	top5: 97.39	
[09/23 21:06:35][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 0.022636332630718778
[09/23 21:07:44][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.89e-02, avg batch time: 0.8027, average train loss: 2.0413average G loss: 0.0121, average realD loss: 0.0684, average fakeD loss: 0.0732, 
[09/23 21:07:46][INFO] visual_prompt:  435: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1201, average loss: 1.9843
[09/23 21:07:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 97.50	
[09/23 21:08:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1276, average loss: 1.9899
[09/23 21:08:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.58	top5: 96.69	
[09/23 21:08:00][INFO] visual_prompt:  357: Best epoch 64: best metric: 0.800
[09/23 21:08:00][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 0.021593218925782896
[09/23 21:09:08][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.78e-02, avg batch time: 0.8015, average train loss: 2.0778average G loss: 0.0135, average realD loss: 0.0685, average fakeD loss: 0.0759, 
[09/23 21:09:10][INFO] visual_prompt:  435: Inference (val):avg data time: 5.80e-05, avg batch time: 0.1211, average loss: 2.1498
[09/23 21:09:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 96.83	
[09/23 21:09:23][INFO] visual_prompt:  435: Inference (test):avg data time: 6.06e-05, avg batch time: 0.1278, average loss: 2.1471
[09/23 21:09:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.86	top5: 96.67	
[09/23 21:09:24][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 0.020561870521072854
[09/23 21:10:32][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.69e-02, avg batch time: 0.8006, average train loss: 2.1331average G loss: 0.0139, average realD loss: 0.0667, average fakeD loss: 0.0770, 
[09/23 21:10:34][INFO] visual_prompt:  435: Inference (val):avg data time: 7.35e-05, avg batch time: 0.1205, average loss: 2.0410
[09/23 21:10:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.17	top5: 97.50	
[09/23 21:10:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.37e-05, avg batch time: 0.1282, average loss: 2.0443
[09/23 21:10:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.10	top5: 97.19	
[09/23 21:10:47][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 0.019543543955752748
[09/23 21:11:55][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.95e-02, avg batch time: 0.8030, average train loss: 2.0665average G loss: 0.0128, average realD loss: 0.0699, average fakeD loss: 0.0720, 
[09/23 21:11:58][INFO] visual_prompt:  435: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1204, average loss: 2.0365
[09/23 21:11:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 96.33	
[09/23 21:12:11][INFO] visual_prompt:  435: Inference (test):avg data time: 6.80e-05, avg batch time: 0.1277, average loss: 2.0294
[09/23 21:12:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.29	top5: 97.55	
[09/23 21:12:11][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 0.01853947990388125
[09/23 21:13:20][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.83e-02, avg batch time: 0.8020, average train loss: 2.0449average G loss: 0.0125, average realD loss: 0.0657, average fakeD loss: 0.0736, 
[09/23 21:13:22][INFO] visual_prompt:  435: Inference (val):avg data time: 7.80e-05, avg batch time: 0.1208, average loss: 2.0218
[09/23 21:13:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 97.17	
[09/23 21:13:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1273, average loss: 2.0113
[09/23 21:13:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.46	top5: 97.36	
[09/23 21:13:36][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 0.017550901662841328
[09/23 21:14:44][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 1.88e-02, avg batch time: 0.8024, average train loss: 2.0402average G loss: 0.0126, average realD loss: 0.0701, average fakeD loss: 0.0746, 
[09/23 21:14:46][INFO] visual_prompt:  435: Inference (val):avg data time: 6.38e-05, avg batch time: 0.1203, average loss: 1.9954
[09/23 21:14:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 97.50	
[09/23 21:15:00][INFO] visual_prompt:  435: Inference (test):avg data time: 8.47e-05, avg batch time: 0.1273, average loss: 1.9932
[09/23 21:15:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.88	top5: 97.58	
[09/23 21:15:00][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 0.01657901366294092
[09/23 21:16:08][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.88e-02, avg batch time: 0.8024, average train loss: 2.0294average G loss: 0.0121, average realD loss: 0.0710, average fakeD loss: 0.0760, 
[09/23 21:16:10][INFO] visual_prompt:  435: Inference (val):avg data time: 7.57e-05, avg batch time: 0.1200, average loss: 2.0170
[09/23 21:16:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 96.67	
[09/23 21:16:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.67e-05, avg batch time: 0.1279, average loss: 2.0130
[09/23 21:16:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.36	top5: 96.95	
[09/23 21:16:24][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 0.015625000000000007
[09/23 21:17:32][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 1.74e-02, avg batch time: 0.8011, average train loss: 2.0269average G loss: 0.0124, average realD loss: 0.0676, average fakeD loss: 0.0760, 
[09/23 21:17:34][INFO] visual_prompt:  435: Inference (val):avg data time: 8.18e-05, avg batch time: 0.1208, average loss: 2.0006
[09/23 21:17:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 97.67	
[09/23 21:17:48][INFO] visual_prompt:  435: Inference (test):avg data time: 7.30e-05, avg batch time: 0.1281, average loss: 1.9881
[09/23 21:17:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.29	top5: 97.58	
[09/23 21:17:48][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 0.01469002299271235
[09/23 21:18:56][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.88e-02, avg batch time: 0.8025, average train loss: 2.0047average G loss: 0.0123, average realD loss: 0.0705, average fakeD loss: 0.0740, 
[09/23 21:18:58][INFO] visual_prompt:  435: Inference (val):avg data time: 5.88e-05, avg batch time: 0.1201, average loss: 1.9746
[09/23 21:18:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 97.33	
[09/23 21:19:12][INFO] visual_prompt:  435: Inference (test):avg data time: 8.07e-05, avg batch time: 0.1273, average loss: 1.9694
[09/23 21:19:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.39	top5: 97.36	
[09/23 21:19:12][INFO] visual_prompt:  357: Best epoch 72: best metric: 0.802
[09/23 21:19:12][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 0.013775221766539166
[09/23 21:20:20][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 1.83e-02, avg batch time: 0.8021, average train loss: 2.0041average G loss: 0.0120, average realD loss: 0.0685, average fakeD loss: 0.0754, 
[09/23 21:20:23][INFO] visual_prompt:  435: Inference (val):avg data time: 7.33e-05, avg batch time: 0.1206, average loss: 1.9961
[09/23 21:20:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.50	
[09/23 21:20:37][INFO] visual_prompt:  435: Inference (test):avg data time: 8.96e-05, avg batch time: 0.1273, average loss: 1.9844
[09/23 21:20:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.70	top5: 97.46	
[09/23 21:20:37][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 0.012881710865860218
[09/23 21:21:45][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.89e-02, avg batch time: 0.8027, average train loss: 1.9853average G loss: 0.0120, average realD loss: 0.0663, average fakeD loss: 0.0714, 
[09/23 21:21:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.30e-05, avg batch time: 0.1205, average loss: 1.9854
[09/23 21:21:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 97.83	
[09/23 21:22:01][INFO] visual_prompt:  435: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1272, average loss: 1.9745
[09/23 21:22:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.65	top5: 97.45	
[09/23 21:22:01][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 0.012010578896073178
[09/23 21:23:09][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.72e-02, avg batch time: 0.8007, average train loss: 1.9852average G loss: 0.0117, average realD loss: 0.0668, average fakeD loss: 0.0739, 
[09/23 21:23:12][INFO] visual_prompt:  435: Inference (val):avg data time: 6.16e-05, avg batch time: 0.1209, average loss: 1.9570
[09/23 21:23:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.67	
[09/23 21:23:26][INFO] visual_prompt:  435: Inference (test):avg data time: 8.17e-05, avg batch time: 0.1270, average loss: 1.9589
[09/23 21:23:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.13	top5: 97.36	
[09/23 21:23:26][INFO] visual_prompt:  357: Best epoch 75: best metric: 0.812
[09/23 21:23:26][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 0.011162887197295645
[09/23 21:24:34][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.83e-02, avg batch time: 0.8019, average train loss: 1.9713average G loss: 0.0117, average realD loss: 0.0695, average fakeD loss: 0.0736, 
[09/23 21:24:36][INFO] visual_prompt:  435: Inference (val):avg data time: 6.33e-05, avg batch time: 0.1203, average loss: 1.9377
[09/23 21:24:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 97.67	
[09/23 21:24:50][INFO] visual_prompt:  435: Inference (test):avg data time: 5.60e-05, avg batch time: 0.1274, average loss: 1.9378
[09/23 21:24:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.05	top5: 97.70	
[09/23 21:24:50][INFO] visual_prompt:  357: Best epoch 76: best metric: 0.823
[09/23 21:24:50][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 0.01033966855128569
[09/23 21:25:58][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 2.00e-02, avg batch time: 0.8034, average train loss: 1.9656average G loss: 0.0117, average realD loss: 0.0678, average fakeD loss: 0.0752, 
[09/23 21:26:01][INFO] visual_prompt:  435: Inference (val):avg data time: 1.03e-04, avg batch time: 0.1201, average loss: 1.9635
[09/23 21:26:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 97.83	
[09/23 21:26:14][INFO] visual_prompt:  435: Inference (test):avg data time: 1.03e-04, avg batch time: 0.1281, average loss: 1.9509
[09/23 21:26:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.38	top5: 97.38	
[09/23 21:26:14][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.009541925923156332
[09/23 21:27:22][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 1.83e-02, avg batch time: 0.8021, average train loss: 1.9483average G loss: 0.0114, average realD loss: 0.0682, average fakeD loss: 0.0754, 
[09/23 21:27:25][INFO] visual_prompt:  435: Inference (val):avg data time: 7.02e-05, avg batch time: 0.1199, average loss: 1.9342
[09/23 21:27:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 97.83	
[09/23 21:27:39][INFO] visual_prompt:  435: Inference (test):avg data time: 8.17e-05, avg batch time: 0.1270, average loss: 1.9237
[09/23 21:27:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.41	top5: 97.79	
[09/23 21:27:39][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.008770631239417157
[09/23 21:28:47][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.95e-02, avg batch time: 0.8033, average train loss: 1.9432average G loss: 0.0117, average realD loss: 0.0691, average fakeD loss: 0.0720, 
[09/23 21:28:50][INFO] visual_prompt:  435: Inference (val):avg data time: 5.41e-05, avg batch time: 0.1207, average loss: 1.9414
[09/23 21:28:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 97.17	
[09/23 21:29:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.72e-05, avg batch time: 0.1277, average loss: 1.9394
[09/23 21:29:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.67	top5: 97.43	
[09/23 21:29:03][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.008026724203831426
[09/23 21:30:11][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 1.83e-02, avg batch time: 0.8023, average train loss: 1.9376average G loss: 0.0115, average realD loss: 0.0665, average fakeD loss: 0.0738, 
[09/23 21:30:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.58e-05, avg batch time: 0.1202, average loss: 1.9282
[09/23 21:30:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 98.00	
[09/23 21:30:27][INFO] visual_prompt:  435: Inference (test):avg data time: 8.99e-05, avg batch time: 0.1278, average loss: 1.9218
[09/23 21:30:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.36	top5: 97.67	
[09/23 21:30:27][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.0073111111525319405
[09/23 21:31:36][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.74e-02, avg batch time: 0.8011, average train loss: 1.9323average G loss: 0.0113, average realD loss: 0.0683, average fakeD loss: 0.0739, 
[09/23 21:31:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1204, average loss: 1.9186
[09/23 21:31:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.83	
[09/23 21:31:51][INFO] visual_prompt:  435: Inference (test):avg data time: 7.39e-05, avg batch time: 0.1275, average loss: 1.9147
[09/23 21:31:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.45	top5: 98.03	
[09/23 21:31:51][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.0066246639497899405
[09/23 21:33:00][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.81e-02, avg batch time: 0.8016, average train loss: 1.9207average G loss: 0.0112, average realD loss: 0.0642, average fakeD loss: 0.0733, 
[09/23 21:33:02][INFO] visual_prompt:  435: Inference (val):avg data time: 7.57e-05, avg batch time: 0.1195, average loss: 1.9258
[09/23 21:33:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.67	
[09/23 21:33:16][INFO] visual_prompt:  435: Inference (test):avg data time: 6.81e-05, avg batch time: 0.1275, average loss: 1.9238
[09/23 21:33:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.64	top5: 97.50	
[09/23 21:33:16][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.005968218925782896
[09/23 21:34:24][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.76e-02, avg batch time: 0.8012, average train loss: 1.9127average G loss: 0.0111, average realD loss: 0.0681, average fakeD loss: 0.0735, 
[09/23 21:34:26][INFO] visual_prompt:  435: Inference (val):avg data time: 6.94e-05, avg batch time: 0.1208, average loss: 1.9268
[09/23 21:34:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 97.50	
[09/23 21:34:40][INFO] visual_prompt:  435: Inference (test):avg data time: 6.71e-05, avg batch time: 0.1271, average loss: 1.9183
[09/23 21:34:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.29	top5: 97.64	
[09/23 21:34:40][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.005342575857654949
[09/23 21:35:48][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.93e-02, avg batch time: 0.8029, average train loss: 1.9029average G loss: 0.0113, average realD loss: 0.0676, average fakeD loss: 0.0729, 
[09/23 21:35:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1202, average loss: 1.8970
[09/23 21:35:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.50	top5: 97.50	
[09/23 21:36:04][INFO] visual_prompt:  435: Inference (test):avg data time: 8.86e-05, avg batch time: 0.1271, average loss: 1.8948
[09/23 21:36:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.36	top5: 97.70	
[09/23 21:36:05][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.004748496995111689
[09/23 21:37:13][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.82e-02, avg batch time: 0.8014, average train loss: 1.8923average G loss: 0.0111, average realD loss: 0.0639, average fakeD loss: 0.0751, 
[09/23 21:37:15][INFO] visual_prompt:  435: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1204, average loss: 1.9026
[09/23 21:37:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.83	
[09/23 21:37:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.88e-05, avg batch time: 0.1276, average loss: 1.9014
[09/23 21:37:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.62	top5: 97.79	
[09/23 21:37:28][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.00418670613173629
[09/23 21:38:37][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.84e-02, avg batch time: 0.8018, average train loss: 1.8820average G loss: 0.0109, average realD loss: 0.0707, average fakeD loss: 0.0709, 
[09/23 21:38:39][INFO] visual_prompt:  435: Inference (val):avg data time: 6.57e-05, avg batch time: 0.1198, average loss: 1.8879
[09/23 21:38:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.83	
[09/23 21:38:52][INFO] visual_prompt:  435: Inference (test):avg data time: 8.18e-05, avg batch time: 0.1274, average loss: 1.8901
[09/23 21:38:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.83	top5: 97.83	
[09/23 21:38:52][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.0036578877231585316
[09/23 21:40:01][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.98e-02, avg batch time: 0.8031, average train loss: 1.8789average G loss: 0.0107, average realD loss: 0.0665, average fakeD loss: 0.0748, 
[09/23 21:40:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.85e-05, avg batch time: 0.1202, average loss: 1.8949
[09/23 21:40:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.50	
[09/23 21:40:17][INFO] visual_prompt:  435: Inference (test):avg data time: 9.19e-05, avg batch time: 0.1271, average loss: 1.8843
[09/23 21:40:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.41	top5: 97.79	
[09/23 21:40:17][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.003162686053151037
[09/23 21:41:25][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.75e-02, avg batch time: 0.8011, average train loss: 1.8727average G loss: 0.0107, average realD loss: 0.0716, average fakeD loss: 0.0721, 
[09/23 21:41:27][INFO] visual_prompt:  435: Inference (val):avg data time: 5.35e-05, avg batch time: 0.1200, average loss: 1.8864
[09/23 21:41:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.67	
[09/23 21:41:41][INFO] visual_prompt:  435: Inference (test):avg data time: 8.57e-05, avg batch time: 0.1274, average loss: 1.8827
[09/23 21:41:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.74	top5: 97.77	
[09/23 21:41:41][INFO] visual_prompt:  357: Best epoch 88: best metric: 0.825
[09/23 21:41:41][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.0027017044486687194
[09/23 21:42:50][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 2.04e-02, avg batch time: 0.8039, average train loss: 1.8663average G loss: 0.0107, average realD loss: 0.0670, average fakeD loss: 0.0746, 
[09/23 21:42:52][INFO] visual_prompt:  435: Inference (val):avg data time: 7.68e-05, avg batch time: 0.1201, average loss: 1.8830
[09/23 21:42:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 97.83	
[09/23 21:43:06][INFO] visual_prompt:  435: Inference (test):avg data time: 1.00e-04, avg batch time: 0.1270, average loss: 1.8749
[09/23 21:43:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.64	top5: 97.86	
[09/23 21:43:06][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.0022755045447878965
[09/23 21:44:14][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.81e-02, avg batch time: 0.8017, average train loss: 1.8595average G loss: 0.0105, average realD loss: 0.0681, average fakeD loss: 0.0723, 
[09/23 21:44:16][INFO] visual_prompt:  435: Inference (val):avg data time: 8.95e-05, avg batch time: 0.1198, average loss: 1.8903
[09/23 21:44:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 97.17	
[09/23 21:44:30][INFO] visual_prompt:  435: Inference (test):avg data time: 8.47e-05, avg batch time: 0.1272, average loss: 1.8781
[09/23 21:44:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.38	top5: 97.77	
[09/23 21:44:30][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.001884605600440365
[09/23 21:45:38][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.79e-02, avg batch time: 0.8014, average train loss: 1.8459average G loss: 0.0102, average realD loss: 0.0685, average fakeD loss: 0.0738, 
[09/23 21:45:41][INFO] visual_prompt:  435: Inference (val):avg data time: 5.81e-05, avg batch time: 0.1199, average loss: 1.8795
[09/23 21:45:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 98.00	
[09/23 21:45:54][INFO] visual_prompt:  435: Inference (test):avg data time: 7.58e-05, avg batch time: 0.1277, average loss: 1.8699
[09/23 21:45:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.19	top5: 97.84	
[09/23 21:45:54][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.0015294838657764522
[09/23 21:47:03][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.87e-02, avg batch time: 0.8022, average train loss: 1.8349average G loss: 0.0103, average realD loss: 0.0656, average fakeD loss: 0.0712, 
[09/23 21:47:05][INFO] visual_prompt:  435: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1201, average loss: 1.8686
[09/23 21:47:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 97.50	
[09/23 21:47:18][INFO] visual_prompt:  435: Inference (test):avg data time: 6.67e-05, avg batch time: 0.1275, average loss: 1.8606
[09/23 21:47:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.77	top5: 97.81	
[09/23 21:47:18][INFO] visual_prompt:  357: Best epoch 92: best metric: 0.827
[09/23 21:47:18][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.0012105720019275346
[09/23 21:48:27][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.76e-02, avg batch time: 0.8010, average train loss: 1.8240average G loss: 0.0104, average realD loss: 0.0698, average fakeD loss: 0.0730, 
[09/23 21:48:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.90e-05, avg batch time: 0.1205, average loss: 1.8650
[09/23 21:48:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 97.33	
[09/23 21:48:43][INFO] visual_prompt:  435: Inference (test):avg data time: 6.85e-05, avg batch time: 0.1274, average loss: 1.8586
[09/23 21:48:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.43	top5: 97.74	
[09/23 21:48:43][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.0009282585538751102
[09/23 21:49:51][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 2.00e-02, avg batch time: 0.8035, average train loss: 1.8243average G loss: 0.0101, average realD loss: 0.0642, average fakeD loss: 0.0724, 
[09/23 21:49:53][INFO] visual_prompt:  435: Inference (val):avg data time: 5.24e-05, avg batch time: 0.1198, average loss: 1.8598
[09/23 21:49:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.83	
[09/23 21:50:07][INFO] visual_prompt:  435: Inference (test):avg data time: 9.53e-05, avg batch time: 0.1272, average loss: 1.8540
[09/23 21:50:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.84	top5: 97.81	
[09/23 21:50:07][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.0006828874770685722
[09/23 21:51:15][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 1.96e-02, avg batch time: 0.8028, average train loss: 1.8168average G loss: 0.0102, average realD loss: 0.0671, average fakeD loss: 0.0738, 
[09/23 21:51:18][INFO] visual_prompt:  435: Inference (val):avg data time: 4.69e-05, avg batch time: 0.1210, average loss: 1.8558
[09/23 21:51:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 97.67	
[09/23 21:51:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.99e-05, avg batch time: 0.1276, average loss: 1.8500
[09/23 21:51:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.88	top5: 97.83	
[09/23 21:51:31][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.00047475771836849937
[09/23 21:52:40][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.96e-02, avg batch time: 0.8029, average train loss: 1.8096average G loss: 0.0100, average realD loss: 0.0657, average fakeD loss: 0.0748, 
[09/23 21:52:42][INFO] visual_prompt:  435: Inference (val):avg data time: 5.68e-05, avg batch time: 0.1198, average loss: 1.8572
[09/23 21:52:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.17	
[09/23 21:52:55][INFO] visual_prompt:  435: Inference (test):avg data time: 8.23e-05, avg batch time: 0.1276, average loss: 1.8487
[09/23 21:52:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.90	top5: 97.88	
[09/23 21:52:55][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.0003041228518259262
[09/23 21:54:04][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.92e-02, avg batch time: 0.8029, average train loss: 1.8058average G loss: 0.0101, average realD loss: 0.0688, average fakeD loss: 0.0737, 
[09/23 21:54:06][INFO] visual_prompt:  435: Inference (val):avg data time: 5.84e-05, avg batch time: 0.1205, average loss: 1.8516
[09/23 21:54:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 97.67	
[09/23 21:54:20][INFO] visual_prompt:  435: Inference (test):avg data time: 6.78e-05, avg batch time: 0.1270, average loss: 1.8455
[09/23 21:54:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.79	top5: 97.93	
[09/23 21:54:20][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.0001711907697414597
[09/23 21:55:28][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 2.03e-02, avg batch time: 0.8038, average train loss: 1.8061average G loss: 0.0098, average realD loss: 0.0639, average fakeD loss: 0.0755, 
[09/23 21:55:30][INFO] visual_prompt:  435: Inference (val):avg data time: 5.14e-05, avg batch time: 0.1212, average loss: 1.8525
[09/23 21:55:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 97.50	
[09/23 21:55:44][INFO] visual_prompt:  435: Inference (test):avg data time: 6.76e-05, avg batch time: 0.1271, average loss: 1.8452
[09/23 21:55:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.77	top5: 97.95	
[09/23 21:55:45][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 7.612342938049382e-05
[09/23 21:56:53][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.80e-02, avg batch time: 0.8013, average train loss: 1.8004average G loss: 0.0098, average realD loss: 0.0706, average fakeD loss: 0.0751, 
[09/23 21:56:55][INFO] visual_prompt:  435: Inference (val):avg data time: 6.35e-05, avg batch time: 0.1213, average loss: 1.8500
[09/23 21:56:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.33	
[09/23 21:57:08][INFO] visual_prompt:  435: Inference (test):avg data time: 7.40e-05, avg batch time: 0.1278, average loss: 1.8437
[09/23 21:57:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.88	top5: 97.96	
[09/23 21:57:08][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 1.9036655653257434e-05
[09/23 21:58:17][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.82e-02, avg batch time: 0.8017, average train loss: 1.8022average G loss: 0.0097, average realD loss: 0.0667, average fakeD loss: 0.0738, 
[09/23 21:58:19][INFO] visual_prompt:  435: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1198, average loss: 1.8498
[09/23 21:58:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.33	
[09/23 21:58:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.96e-05, avg batch time: 0.1270, average loss: 1.8436
[09/23 21:58:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.84	top5: 97.98	
