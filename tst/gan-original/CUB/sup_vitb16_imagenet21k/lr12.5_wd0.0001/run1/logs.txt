[09/22 10:35:24][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/22 10:35:24][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/22 10:35:24][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/22 10:35:24][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/22 10:35:24][INFO] visual_prompt:  109: Training with config:
[09/22 10:35:24][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr12.5_wd0.0001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 12.5,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/22 10:35:24][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/22 10:35:24][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/22 10:35:24][INFO] visual_prompt:   77: Number of images: 5394
[09/22 10:35:24][INFO] visual_prompt:   78: Number of classes: 200
[09/22 10:35:24][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/22 10:35:24][INFO] visual_prompt:   73: Loading validation data...
[09/22 10:35:24][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/22 10:35:24][INFO] visual_prompt:   77: Number of images: 600
[09/22 10:35:24][INFO] visual_prompt:   78: Number of classes: 200
[09/22 10:35:24][INFO] visual_prompt:   76: Loading test data...
[09/22 10:35:24][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/22 10:35:24][INFO] visual_prompt:   77: Number of images: 5794
[09/22 10:35:24][INFO] visual_prompt:   78: Number of classes: 200
[09/22 10:35:24][INFO] visual_prompt:  103: Constructing models...
[09/22 10:35:29][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/22 10:35:29][INFO] visual_prompt:   55: tuned percent:0.143
[09/22 10:35:30][INFO] visual_prompt:   41: Device used for model: 0
[09/22 10:35:30][INFO] visual_prompt:  106: Setting up Evalutator...
[09/22 10:35:30][INFO] visual_prompt:  108: Setting up Trainer...
[09/22 10:35:30][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/22 10:35:30][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/22 10:36:39][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.93e-02, avg batch time: 0.8116, average train loss: 5.3263average G loss: 3.9875, average realD loss: 10.9925, average fakeD loss: 0.4690, 
[09/22 10:36:41][INFO] visual_prompt:  435: Inference (val):avg data time: 7.73e-05, avg batch time: 0.1224, average loss: 5.3303
[09/22 10:36:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.17	top5: 2.17	
[09/22 10:36:55][INFO] visual_prompt:  435: Inference (test):avg data time: 6.03e-05, avg batch time: 0.1292, average loss: 5.3287
[09/22 10:36:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.40	top5: 2.74	
[09/22 10:36:55][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.002
[09/22 10:36:55][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 1.25
[09/22 10:38:04][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.81e-02, avg batch time: 0.8075, average train loss: 5.5914average G loss: 0.0000, average realD loss: 0.1195, average fakeD loss: 98.7749, 
[09/22 10:38:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.54e-05, avg batch time: 0.1227, average loss: 5.5044
[09/22 10:38:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.50	
[09/22 10:38:19][INFO] visual_prompt:  435: Inference (test):avg data time: 9.01e-05, avg batch time: 0.1297, average loss: 5.5044
[09/22 10:38:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.92	
[09/22 10:38:19][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.005
[09/22 10:38:19][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 2.5
[09/22 10:39:28][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.89e-02, avg batch time: 0.8089, average train loss: 5.8011average G loss: 0.0085, average realD loss: 0.0094, average fakeD loss: 100.0000, 
[09/22 10:39:31][INFO] visual_prompt:  435: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1224, average loss: 5.6926
[09/22 10:39:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/22 10:39:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.45e-05, avg batch time: 0.1299, average loss: 5.6838
[09/22 10:39:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.69	top5: 2.68	
[09/22 10:39:44][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 3.75
[09/22 10:40:53][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.92e-02, avg batch time: 0.8090, average train loss: 5.4888average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:40:56][INFO] visual_prompt:  435: Inference (val):avg data time: 6.23e-05, avg batch time: 0.1222, average loss: 3.8226
[09/22 10:40:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 25.83	top5: 54.33	
[09/22 10:41:09][INFO] visual_prompt:  435: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1292, average loss: 3.7780
[09/22 10:41:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 27.08	top5: 54.69	
[09/22 10:41:10][INFO] visual_prompt:  357: Best epoch 4: best metric: 0.258
[09/22 10:41:10][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 5.0
[09/22 10:42:18][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.97e-02, avg batch time: 0.8096, average train loss: 2.3045average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:42:21][INFO] visual_prompt:  435: Inference (val):avg data time: 8.18e-05, avg batch time: 0.1220, average loss: 1.5290
[09/22 10:42:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.67	top5: 90.00	
[09/22 10:42:34][INFO] visual_prompt:  435: Inference (test):avg data time: 8.31e-05, avg batch time: 0.1298, average loss: 1.4591
[09/22 10:42:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.36	top5: 90.54	
[09/22 10:42:35][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.677
[09/22 10:42:35][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 6.25
[09/22 10:43:43][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.99e-02, avg batch time: 0.8100, average train loss: 1.7496average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:43:46][INFO] visual_prompt:  435: Inference (val):avg data time: 6.46e-05, avg batch time: 0.1230, average loss: 1.4834
[09/22 10:43:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.83	top5: 89.17	
[09/22 10:43:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.05e-05, avg batch time: 0.1298, average loss: 1.4679
[09/22 10:43:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.02	top5: 89.85	
[09/22 10:43:59][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.688
[09/22 10:43:59][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 7.5
[09/22 10:45:08][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 2.10e-02, avg batch time: 0.8107, average train loss: 1.7072average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:45:11][INFO] visual_prompt:  435: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1224, average loss: 1.7995
[09/22 10:45:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.17	top5: 89.83	
[09/22 10:45:24][INFO] visual_prompt:  435: Inference (test):avg data time: 9.98e-05, avg batch time: 0.1296, average loss: 1.7596
[09/22 10:45:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.09	top5: 89.47	
[09/22 10:45:25][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 8.75
[09/22 10:46:33][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.85e-02, avg batch time: 0.8083, average train loss: 2.0746average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:46:36][INFO] visual_prompt:  435: Inference (val):avg data time: 1.08e-04, avg batch time: 0.1216, average loss: 2.0747
[09/22 10:46:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.17	top5: 87.17	
[09/22 10:46:49][INFO] visual_prompt:  435: Inference (test):avg data time: 6.58e-05, avg batch time: 0.1294, average loss: 2.0739
[09/22 10:46:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.22	top5: 86.61	
[09/22 10:46:50][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 10.0
[09/22 10:47:58][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.89e-02, avg batch time: 0.8086, average train loss: 4.1581average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:48:01][INFO] visual_prompt:  435: Inference (val):avg data time: 5.67e-05, avg batch time: 0.1219, average loss: 3.8508
[09/22 10:48:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 55.33	top5: 75.67	
[09/22 10:48:14][INFO] visual_prompt:  435: Inference (test):avg data time: 6.59e-05, avg batch time: 0.1301, average loss: 3.7609
[09/22 10:48:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 55.75	top5: 78.01	
[09/22 10:48:14][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 11.25
[09/22 10:49:23][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.85e-02, avg batch time: 0.8084, average train loss: 13.2820average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:49:25][INFO] visual_prompt:  435: Inference (val):avg data time: 5.71e-05, avg batch time: 0.1220, average loss: 7.0169
[09/22 10:49:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 36.00	top5: 61.50	
[09/22 10:49:39][INFO] visual_prompt:  435: Inference (test):avg data time: 7.44e-05, avg batch time: 0.1294, average loss: 7.0588
[09/22 10:49:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 35.93	top5: 59.99	
[09/22 10:49:39][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 12.5
[09/22 10:50:48][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.89e-02, avg batch time: 0.8088, average train loss: 4.5753average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:50:50][INFO] visual_prompt:  435: Inference (val):avg data time: 5.99e-05, avg batch time: 0.1221, average loss: 4.8945
[09/22 10:50:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 29.17	top5: 49.50	
[09/22 10:51:04][INFO] visual_prompt:  435: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1297, average loss: 4.8454
[09/22 10:51:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 27.15	top5: 49.90	
[09/22 10:51:04][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 12.49619266886935
[09/22 10:52:13][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.88e-02, avg batch time: 0.8086, average train loss: 8.7993average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:52:15][INFO] visual_prompt:  435: Inference (val):avg data time: 5.92e-05, avg batch time: 0.1224, average loss: 3.5188
[09/22 10:52:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 46.50	top5: 70.50	
[09/22 10:52:29][INFO] visual_prompt:  435: Inference (test):avg data time: 6.76e-05, avg batch time: 0.1300, average loss: 3.4760
[09/22 10:52:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 48.55	top5: 71.85	
[09/22 10:52:29][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 12.484775314123901
[09/22 10:53:38][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 2.22e-02, avg batch time: 0.8123, average train loss: 3.3738average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:53:40][INFO] visual_prompt:  435: Inference (val):avg data time: 5.16e-05, avg batch time: 0.1230, average loss: 3.0432
[09/22 10:53:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 51.83	top5: 73.00	
[09/22 10:53:54][INFO] visual_prompt:  435: Inference (test):avg data time: 6.81e-05, avg batch time: 0.1294, average loss: 3.0104
[09/22 10:53:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 52.93	top5: 72.92	
[09/22 10:53:54][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 12.465761846051707
[09/22 10:55:03][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.84e-02, avg batch time: 0.8085, average train loss: 6.1186average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:55:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.14e-05, avg batch time: 0.1213, average loss: 3.8144
[09/22 10:55:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 48.67	top5: 76.17	
[09/22 10:55:19][INFO] visual_prompt:  435: Inference (test):avg data time: 6.75e-05, avg batch time: 0.1298, average loss: 3.8289
[09/22 10:55:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 49.29	top5: 75.87	
[09/22 10:55:19][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 12.439175429634815
[09/22 10:56:28][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.96e-02, avg batch time: 0.8098, average train loss: 3.3390average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:56:31][INFO] visual_prompt:  435: Inference (val):avg data time: 5.96e-05, avg batch time: 0.1231, average loss: 3.7515
[09/22 10:56:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 54.00	top5: 81.00	
[09/22 10:56:44][INFO] visual_prompt:  435: Inference (test):avg data time: 8.19e-05, avg batch time: 0.1299, average loss: 3.6965
[09/22 10:56:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 53.54	top5: 79.93	
[09/22 10:56:44][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 12.4050484563263
[09/22 10:57:53][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.78e-02, avg batch time: 0.8074, average train loss: 2.9687average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:57:56][INFO] visual_prompt:  435: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1228, average loss: 3.0811
[09/22 10:57:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 50.50	top5: 76.67	
[09/22 10:58:09][INFO] visual_prompt:  435: Inference (test):avg data time: 6.04e-05, avg batch time: 0.1298, average loss: 3.0810
[09/22 10:58:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 52.52	top5: 76.53	
[09/22 10:58:09][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 12.363422504586286
[09/22 10:59:18][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 2.03e-02, avg batch time: 0.8101, average train loss: 4.5436average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 10:59:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.77e-05, avg batch time: 0.1223, average loss: 8.9038
[09/22 10:59:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 22.83	top5: 51.67	
[09/22 10:59:34][INFO] visual_prompt:  435: Inference (test):avg data time: 6.06e-05, avg batch time: 0.1300, average loss: 8.7845
[09/22 10:59:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 24.44	top5: 51.73	
[09/22 10:59:34][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 12.314348289224977
[09/22 11:00:43][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.89e-02, avg batch time: 0.8087, average train loss: 9.3817average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:00:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.35e-05, avg batch time: 0.1233, average loss: 3.7979
[09/22 11:00:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 48.33	top5: 72.83	
[09/22 11:00:58][INFO] visual_prompt:  435: Inference (test):avg data time: 6.66e-05, avg batch time: 0.1299, average loss: 3.6671
[09/22 11:00:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 50.05	top5: 72.73	
[09/22 11:00:59][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 12.257885599614493
[09/22 11:02:07][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.92e-02, avg batch time: 0.8092, average train loss: 4.9792average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:02:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.03e-05, avg batch time: 0.1225, average loss: 12.4214
[09/22 11:02:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 20.00	top5: 33.83	
[09/22 11:02:23][INFO] visual_prompt:  435: Inference (test):avg data time: 7.57e-05, avg batch time: 0.1300, average loss: 12.5806
[09/22 11:02:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 19.23	top5: 32.62	
[09/22 11:02:23][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 12.19410322684471
[09/22 11:03:32][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.96e-02, avg batch time: 0.8094, average train loss: 6.4037average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:03:34][INFO] visual_prompt:  435: Inference (val):avg data time: 5.41e-05, avg batch time: 0.1221, average loss: 2.9762
[09/22 11:03:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 52.33	top5: 74.33	
[09/22 11:03:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.01e-05, avg batch time: 0.1300, average loss: 2.9628
[09/22 11:03:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 53.14	top5: 75.34	
[09/22 11:03:48][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 12.123078879911928
[09/22 11:04:57][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.98e-02, avg batch time: 0.8094, average train loss: 3.0846average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:04:59][INFO] visual_prompt:  435: Inference (val):avg data time: 4.81e-05, avg batch time: 0.1231, average loss: 4.2311
[09/22 11:04:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 58.17	top5: 80.67	
[09/22 11:05:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.51e-05, avg batch time: 0.1297, average loss: 4.1932
[09/22 11:05:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 57.39	top5: 82.52	
[09/22 11:05:13][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 12.04489909104242
[09/22 11:06:22][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 2.04e-02, avg batch time: 0.8105, average train loss: 3.3641average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:06:24][INFO] visual_prompt:  435: Inference (val):avg data time: 6.67e-05, avg batch time: 0.1224, average loss: 2.6102
[09/22 11:06:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 57.33	top5: 78.17	
[09/22 11:06:38][INFO] visual_prompt:  435: Inference (test):avg data time: 6.84e-05, avg batch time: 0.1300, average loss: 2.6289
[09/22 11:06:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 58.41	top5: 79.08	
[09/22 11:06:38][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 11.959659110266255
[09/22 11:07:47][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.97e-02, avg batch time: 0.8100, average train loss: 5.5184average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:07:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.23e-05, avg batch time: 0.1219, average loss: 3.2361
[09/22 11:07:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 52.00	top5: 70.50	
[09/22 11:08:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.16e-05, avg batch time: 0.1294, average loss: 3.2686
[09/22 11:08:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 53.02	top5: 70.75	
[09/22 11:08:03][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 11.867462789369794
[09/22 11:09:12][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.94e-02, avg batch time: 0.8093, average train loss: 2.8609average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:09:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1223, average loss: 2.7536
[09/22 11:09:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.67	top5: 85.83	
[09/22 11:09:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.24e-05, avg batch time: 0.1293, average loss: 2.7986
[09/22 11:09:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.18	top5: 85.11	
[09/22 11:09:29][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 11.768422455368293
[09/22 11:10:37][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.91e-02, avg batch time: 0.8089, average train loss: 2.7113average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:10:40][INFO] visual_prompt:  435: Inference (val):avg data time: 8.72e-05, avg batch time: 0.1222, average loss: 3.7280
[09/22 11:10:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 42.00	top5: 64.83	
[09/22 11:10:53][INFO] visual_prompt:  435: Inference (test):avg data time: 7.98e-05, avg batch time: 0.1298, average loss: 3.5310
[09/22 11:10:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 42.49	top5: 65.22	
[09/22 11:10:53][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 11.662658773652742
[09/22 11:12:02][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.86e-02, avg batch time: 0.8087, average train loss: 3.7580average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:12:05][INFO] visual_prompt:  435: Inference (val):avg data time: 7.85e-05, avg batch time: 0.1214, average loss: 5.2126
[09/22 11:12:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 23.33	top5: 44.17	
[09/22 11:12:18][INFO] visual_prompt:  435: Inference (test):avg data time: 9.82e-05, avg batch time: 0.1297, average loss: 5.1915
[09/22 11:12:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 23.87	top5: 44.08	
[09/22 11:12:18][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 11.550300600977662
[09/22 11:13:27][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 2.01e-02, avg batch time: 0.8100, average train loss: 2.8095average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:13:30][INFO] visual_prompt:  435: Inference (val):avg data time: 4.92e-05, avg batch time: 0.1235, average loss: 2.4893
[09/22 11:13:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.17	top5: 83.50	
[09/22 11:13:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.99e-05, avg batch time: 0.1293, average loss: 2.3718
[09/22 11:13:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 62.55	top5: 83.34	
[09/22 11:13:44][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 11.43148482846901
[09/22 11:14:53][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.88e-02, avg batch time: 0.8089, average train loss: 2.9093average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:14:55][INFO] visual_prompt:  435: Inference (val):avg data time: 4.31e-05, avg batch time: 0.1220, average loss: 3.0834
[09/22 11:14:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 49.33	top5: 69.33	
[09/22 11:15:09][INFO] visual_prompt:  435: Inference (test):avg data time: 6.47e-05, avg batch time: 0.1292, average loss: 3.0693
[09/22 11:15:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 50.00	top5: 69.57	
[09/22 11:15:09][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 11.306356214843422
[09/22 11:16:18][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.93e-02, avg batch time: 0.8092, average train loss: 3.1485average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:16:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.83e-05, avg batch time: 0.1226, average loss: 2.6969
[09/22 11:16:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 57.83	top5: 80.33	
[09/22 11:16:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1300, average loss: 2.6592
[09/22 11:16:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 59.70	top5: 79.53	
[09/22 11:16:34][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 11.17506721004201
[09/22 11:17:43][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 2.11e-02, avg batch time: 0.8111, average train loss: 6.4851average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:17:45][INFO] visual_prompt:  435: Inference (val):avg data time: 7.01e-05, avg batch time: 0.1219, average loss: 15.6525
[09/22 11:17:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 4.00	
[09/22 11:17:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.11e-05, avg batch time: 0.1290, average loss: 15.7519
[09/22 11:17:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 3.99	
[09/22 11:17:59][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 11.037777769493612
[09/22 11:19:08][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.79e-02, avg batch time: 0.8078, average train loss: 9.0522average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:19:10][INFO] visual_prompt:  435: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1216, average loss: 3.3218
[09/22 11:19:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 52.00	top5: 79.00	
[09/22 11:19:24][INFO] visual_prompt:  435: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1301, average loss: 3.2636
[09/22 11:19:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 51.76	top5: 77.99	
[09/22 11:19:24][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 10.894655159233714
[09/22 11:20:33][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.91e-02, avg batch time: 0.8091, average train loss: 2.7497average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:20:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1227, average loss: 1.9509
[09/22 11:20:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.50	top5: 84.67	
[09/22 11:20:49][INFO] visual_prompt:  435: Inference (test):avg data time: 7.99e-05, avg batch time: 0.1295, average loss: 2.0753
[09/22 11:20:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.20	top5: 83.50	
[09/22 11:20:49][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 10.74587375211657
[09/22 11:21:58][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 2.04e-02, avg batch time: 0.8104, average train loss: 3.0984average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:22:00][INFO] visual_prompt:  435: Inference (val):avg data time: 5.18e-05, avg batch time: 0.1223, average loss: 3.5613
[09/22 11:22:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 55.67	top5: 77.00	
[09/22 11:22:14][INFO] visual_prompt:  435: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1298, average loss: 3.5724
[09/22 11:22:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 55.44	top5: 75.91	
[09/22 11:22:14][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 10.591614815368732
[09/22 11:23:23][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.94e-02, avg batch time: 0.8092, average train loss: 2.9645average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:23:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.88e-05, avg batch time: 0.1233, average loss: 3.1972
[09/22 11:23:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 56.83	top5: 82.00	
[09/22 11:23:39][INFO] visual_prompt:  435: Inference (test):avg data time: 6.14e-05, avg batch time: 0.1292, average loss: 3.1591
[09/22 11:23:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 57.34	top5: 82.67	
[09/22 11:23:39][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 10.432066289742863
[09/22 11:24:48][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 2.03e-02, avg batch time: 0.8102, average train loss: 4.0985average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:24:50][INFO] visual_prompt:  435: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1218, average loss: 3.8805
[09/22 11:24:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 51.83	top5: 70.50	
[09/22 11:25:04][INFO] visual_prompt:  435: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1303, average loss: 3.9530
[09/22 11:25:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 49.84	top5: 70.26	
[09/22 11:25:04][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 10.26742256054087
[09/22 11:26:12][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.76e-02, avg batch time: 0.8074, average train loss: 2.6241average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:26:15][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1231, average loss: 2.2817
[09/22 11:26:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.33	top5: 86.00	
[09/22 11:26:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.33e-05, avg batch time: 0.1296, average loss: 2.2037
[09/22 11:26:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.39	top5: 86.26	
[09/22 11:26:28][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 10.097884220785364
[09/22 11:27:37][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.82e-02, avg batch time: 0.8081, average train loss: 3.8575average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:27:40][INFO] visual_prompt:  435: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1228, average loss: 2.1677
[09/22 11:27:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.00	top5: 81.50	
[09/22 11:27:53][INFO] visual_prompt:  435: Inference (test):avg data time: 6.72e-05, avg batch time: 0.1303, average loss: 2.1521
[09/22 11:27:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.06	top5: 80.50	
[09/22 11:27:53][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 9.923657826827958
[09/22 11:29:02][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.79e-02, avg batch time: 0.8075, average train loss: 2.4856average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:29:04][INFO] visual_prompt:  435: Inference (val):avg data time: 6.44e-05, avg batch time: 0.1226, average loss: 2.4062
[09/22 11:29:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 58.50	top5: 77.00	
[09/22 11:29:18][INFO] visual_prompt:  435: Inference (test):avg data time: 6.49e-05, avg batch time: 0.1297, average loss: 2.4019
[09/22 11:29:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 59.77	top5: 78.37	
[09/22 11:29:18][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 9.744955646692167
[09/22 11:30:27][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 1.83e-02, avg batch time: 0.8079, average train loss: 3.1280average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:30:29][INFO] visual_prompt:  435: Inference (val):avg data time: 5.69e-05, avg batch time: 0.1214, average loss: 3.7482
[09/22 11:30:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 59.00	top5: 83.67	
[09/22 11:30:43][INFO] visual_prompt:  435: Inference (test):avg data time: 7.77e-05, avg batch time: 0.1293, average loss: 3.5656
[09/22 11:30:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.60	top5: 83.78	
[09/22 11:30:43][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 9.56199540145753
[09/22 11:31:52][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.86e-02, avg batch time: 0.8085, average train loss: 3.6727average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:31:54][INFO] visual_prompt:  435: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1229, average loss: 3.3397
[09/22 11:31:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 60.83	top5: 82.00	
[09/22 11:32:08][INFO] visual_prompt:  435: Inference (test):avg data time: 6.11e-05, avg batch time: 0.1297, average loss: 3.2492
[09/22 11:32:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.22	top5: 83.34	
[09/22 11:32:08][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 9.375
[09/22 11:33:17][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.85e-02, avg batch time: 0.8084, average train loss: 4.5507average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:33:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.62e-05, avg batch time: 0.1220, average loss: 8.5601
[09/22 11:33:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 15.67	top5: 33.00	
[09/22 11:33:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.88e-05, avg batch time: 0.1293, average loss: 8.6569
[09/22 11:33:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 17.69	top5: 32.40	
[09/22 11:33:33][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 9.184197267411816
[09/22 11:34:42][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 2.01e-02, avg batch time: 0.8101, average train loss: 7.7856average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:34:44][INFO] visual_prompt:  435: Inference (val):avg data time: 7.90e-05, avg batch time: 0.1215, average loss: 8.4418
[09/22 11:34:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 20.83	top5: 38.17	
[09/22 11:34:58][INFO] visual_prompt:  435: Inference (test):avg data time: 6.56e-05, avg batch time: 0.1299, average loss: 8.5071
[09/22 11:34:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 20.81	top5: 38.18	
[09/22 11:34:58][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 8.989819667431734
[09/22 11:36:07][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.99e-02, avg batch time: 0.8096, average train loss: 3.7479average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:36:09][INFO] visual_prompt:  435: Inference (val):avg data time: 5.45e-05, avg batch time: 0.1214, average loss: 2.2656
[09/22 11:36:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 58.67	top5: 83.67	
[09/22 11:36:23][INFO] visual_prompt:  435: Inference (test):avg data time: 6.92e-05, avg batch time: 0.1299, average loss: 2.2613
[09/22 11:36:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.17	top5: 83.47	
[09/22 11:36:23][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 8.792104019223752
[09/22 11:37:32][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 2.04e-02, avg batch time: 0.8099, average train loss: 2.1348average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:37:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.05e-05, avg batch time: 0.1222, average loss: 2.0588
[09/22 11:37:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 58.67	top5: 85.83	
[09/22 11:37:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.35e-05, avg batch time: 0.1297, average loss: 2.0709
[09/22 11:37:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.79	top5: 85.88	
[09/22 11:37:48][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 8.591291208849452
[09/22 11:38:57][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.86e-02, avg batch time: 0.8082, average train loss: 2.0538average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:38:59][INFO] visual_prompt:  435: Inference (val):avg data time: 6.55e-05, avg batch time: 0.1230, average loss: 1.9452
[09/22 11:38:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 87.83	
[09/22 11:39:12][INFO] visual_prompt:  435: Inference (test):avg data time: 5.88e-05, avg batch time: 0.1300, average loss: 1.8420
[09/22 11:39:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.86	top5: 88.57	
[09/22 11:39:13][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 8.38762589578543
[09/22 11:40:22][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 2.05e-02, avg batch time: 0.8102, average train loss: 1.8911average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:40:24][INFO] visual_prompt:  435: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1226, average loss: 1.9600
[09/22 11:40:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.67	top5: 86.00	
[09/22 11:40:38][INFO] visual_prompt:  435: Inference (test):avg data time: 6.65e-05, avg batch time: 0.1297, average loss: 1.8484
[09/22 11:40:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.91	top5: 86.90	
[09/22 11:40:38][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 8.181356214843422
[09/22 11:41:47][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 1.86e-02, avg batch time: 0.8082, average train loss: 2.0264average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:41:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.73e-05, avg batch time: 0.1229, average loss: 2.0334
[09/22 11:41:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.33	top5: 89.83	
[09/22 11:42:03][INFO] visual_prompt:  435: Inference (test):avg data time: 9.43e-05, avg batch time: 0.1294, average loss: 2.0758
[09/22 11:42:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.81	top5: 89.33	
[09/22 11:42:03][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 7.972733473856245
[09/22 11:43:12][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.96e-02, avg batch time: 0.8094, average train loss: 1.9221average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:43:14][INFO] visual_prompt:  435: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1223, average loss: 1.6875
[09/22 11:43:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.50	top5: 88.00	
[09/22 11:43:28][INFO] visual_prompt:  435: Inference (test):avg data time: 8.39e-05, avg batch time: 0.1301, average loss: 1.7287
[09/22 11:43:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.81	top5: 88.09	
[09/22 11:43:28][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 7.762011847497923
[09/22 11:44:37][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.95e-02, avg batch time: 0.8094, average train loss: 1.8598average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:44:39][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1219, average loss: 1.5653
[09/22 11:44:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.50	top5: 87.83	
[09/22 11:44:53][INFO] visual_prompt:  435: Inference (test):avg data time: 7.65e-05, avg batch time: 0.1295, average loss: 1.5306
[09/22 11:44:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.11	top5: 88.80	
[09/22 11:44:53][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 7.549448067610995
[09/22 11:46:02][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 2.09e-02, avg batch time: 0.8109, average train loss: 1.8135average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:46:04][INFO] visual_prompt:  435: Inference (val):avg data time: 5.94e-05, avg batch time: 0.1230, average loss: 1.5707
[09/22 11:46:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.83	top5: 86.67	
[09/22 11:46:19][INFO] visual_prompt:  435: Inference (test):avg data time: 7.43e-05, avg batch time: 0.1290, average loss: 1.5355
[09/22 11:46:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.36	top5: 87.12	
[09/22 11:46:19][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 7.335301110418316
[09/22 11:47:28][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.99e-02, avg batch time: 0.8099, average train loss: 2.7234average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:47:30][INFO] visual_prompt:  435: Inference (val):avg data time: 7.44e-05, avg batch time: 0.1215, average loss: 4.4428
[09/22 11:47:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 23.67	top5: 48.50	
[09/22 11:47:43][INFO] visual_prompt:  435: Inference (test):avg data time: 5.70e-05, avg batch time: 0.1306, average loss: 4.3772
[09/22 11:47:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 25.11	top5: 49.28	
[09/22 11:47:43][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 7.119831881000409
[09/22 11:48:52][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.89e-02, avg batch time: 0.8090, average train loss: 2.9141average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:48:54][INFO] visual_prompt:  435: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1219, average loss: 3.1102
[09/22 11:48:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 61.83	top5: 85.00	
[09/22 11:49:08][INFO] visual_prompt:  435: Inference (test):avg data time: 6.83e-05, avg batch time: 0.1300, average loss: 2.9612
[09/22 11:49:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.60	top5: 85.17	
[09/22 11:49:08][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 6.903302895422835
[09/22 11:50:17][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.86e-02, avg batch time: 0.8088, average train loss: 3.9249average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:50:19][INFO] visual_prompt:  435: Inference (val):avg data time: 7.14e-05, avg batch time: 0.1216, average loss: 2.2629
[09/22 11:50:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.67	top5: 89.83	
[09/22 11:50:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.06e-05, avg batch time: 0.1299, average loss: 2.2683
[09/22 11:50:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.92	top5: 89.80	
[09/22 11:50:33][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 6.685977960900782
[09/22 11:51:42][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.92e-02, avg batch time: 0.8094, average train loss: 2.3539average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:51:44][INFO] visual_prompt:  435: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1228, average loss: 2.3328
[09/22 11:51:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.00	top5: 87.50	
[09/22 11:51:58][INFO] visual_prompt:  435: Inference (test):avg data time: 8.60e-05, avg batch time: 0.1294, average loss: 2.2681
[09/22 11:51:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.17	top5: 88.00	
[09/22 11:51:58][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 6.468121854390632
[09/22 11:53:07][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.88e-02, avg batch time: 0.8089, average train loss: 2.4558average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:53:10][INFO] visual_prompt:  435: Inference (val):avg data time: 5.49e-05, avg batch time: 0.1231, average loss: 3.0549
[09/22 11:53:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.00	top5: 84.83	
[09/22 11:53:23][INFO] visual_prompt:  435: Inference (test):avg data time: 5.77e-05, avg batch time: 0.1300, average loss: 2.8812
[09/22 11:53:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.26	top5: 85.30	
[09/22 11:53:23][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 6.25
[09/22 11:54:32][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 1.96e-02, avg batch time: 0.8094, average train loss: 2.3029average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:54:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.10e-05, avg batch time: 0.1236, average loss: 2.2023
[09/22 11:54:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.50	top5: 87.00	
[09/22 11:54:48][INFO] visual_prompt:  435: Inference (test):avg data time: 9.93e-05, avg batch time: 0.1295, average loss: 2.1781
[09/22 11:54:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.34	top5: 87.12	
[09/22 11:54:48][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 6.031878145609371
[09/22 11:55:57][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.94e-02, avg batch time: 0.8093, average train loss: 1.9436average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:56:00][INFO] visual_prompt:  435: Inference (val):avg data time: 6.35e-05, avg batch time: 0.1213, average loss: 1.6493
[09/22 11:56:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.17	top5: 90.67	
[09/22 11:56:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1295, average loss: 1.7890
[09/22 11:56:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.37	top5: 89.64	
[09/22 11:56:13][INFO] visual_prompt:  357: Best epoch 57: best metric: 0.702
[09/22 11:56:13][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 5.814022039099217
[09/22 11:57:22][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 2.02e-02, avg batch time: 0.8104, average train loss: 1.8548average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:57:25][INFO] visual_prompt:  435: Inference (val):avg data time: 5.61e-05, avg batch time: 0.1234, average loss: 2.0949
[09/22 11:57:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.33	top5: 87.00	
[09/22 11:57:38][INFO] visual_prompt:  435: Inference (test):avg data time: 5.16e-05, avg batch time: 0.1302, average loss: 2.1188
[09/22 11:57:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.16	top5: 86.45	
[09/22 11:57:38][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 5.596697104577167
[09/22 11:58:47][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.89e-02, avg batch time: 0.8092, average train loss: 1.7835average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 11:58:49][INFO] visual_prompt:  435: Inference (val):avg data time: 9.99e-05, avg batch time: 0.1209, average loss: 2.0193
[09/22 11:58:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.83	top5: 87.50	
[09/22 11:59:03][INFO] visual_prompt:  435: Inference (test):avg data time: 6.87e-05, avg batch time: 0.1300, average loss: 1.9043
[09/22 11:59:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.55	top5: 88.19	
[09/22 11:59:03][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 5.380168118999593
[09/22 12:00:12][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 1.85e-02, avg batch time: 0.8088, average train loss: 1.6008average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:00:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.82e-05, avg batch time: 0.1229, average loss: 1.6831
[09/22 12:00:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.83	top5: 88.33	
[09/22 12:00:28][INFO] visual_prompt:  435: Inference (test):avg data time: 8.77e-05, avg batch time: 0.1295, average loss: 1.6483
[09/22 12:00:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.36	top5: 88.92	
[09/22 12:00:28][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 5.164698889581685
[09/22 12:01:37][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 2.00e-02, avg batch time: 0.8099, average train loss: 1.3084average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:01:39][INFO] visual_prompt:  435: Inference (val):avg data time: 5.07e-05, avg batch time: 0.1233, average loss: 1.6223
[09/22 12:01:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.17	top5: 89.33	
[09/22 12:01:54][INFO] visual_prompt:  435: Inference (test):avg data time: 8.07e-05, avg batch time: 0.1292, average loss: 1.7334
[09/22 12:01:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.00	top5: 89.49	
[09/22 12:01:54][INFO] visual_prompt:  357: Best epoch 61: best metric: 0.712
[09/22 12:01:54][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 4.950551932389005
[09/22 12:03:03][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.89e-02, avg batch time: 0.8089, average train loss: 1.2198average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:03:05][INFO] visual_prompt:  435: Inference (val):avg data time: 5.98e-05, avg batch time: 0.1225, average loss: 1.4892
[09/22 12:03:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.67	top5: 91.00	
[09/22 12:03:18][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1302, average loss: 1.5084
[09/22 12:03:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.28	top5: 90.37	
[09/22 12:03:18][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 4.737988152502077
[09/22 12:04:27][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 1.93e-02, avg batch time: 0.8092, average train loss: 1.7425average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:04:29][INFO] visual_prompt:  435: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1217, average loss: 2.8220
[09/22 12:04:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 49.33	top5: 72.50	
[09/22 12:04:43][INFO] visual_prompt:  435: Inference (test):avg data time: 5.63e-05, avg batch time: 0.1311, average loss: 2.8613
[09/22 12:04:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 47.79	top5: 74.28	
[09/22 12:04:43][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 4.527266526143755
[09/22 12:05:52][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.93e-02, avg batch time: 0.8102, average train loss: 1.3922average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:05:54][INFO] visual_prompt:  435: Inference (val):avg data time: 5.22e-05, avg batch time: 0.1234, average loss: 1.3194
[09/22 12:05:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.17	top5: 92.33	
[09/22 12:06:08][INFO] visual_prompt:  435: Inference (test):avg data time: 8.65e-05, avg batch time: 0.1293, average loss: 1.3057
[09/22 12:06:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.06	top5: 91.80	
[09/22 12:06:08][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 4.3186437851565795
[09/22 12:07:17][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.94e-02, avg batch time: 0.8099, average train loss: 1.0554average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:07:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.60e-05, avg batch time: 0.1237, average loss: 1.2580
[09/22 12:07:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.00	top5: 92.33	
[09/22 12:07:33][INFO] visual_prompt:  435: Inference (test):avg data time: 6.64e-05, avg batch time: 0.1296, average loss: 1.2276
[09/22 12:07:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.46	top5: 93.42	
[09/22 12:07:33][INFO] visual_prompt:  357: Best epoch 65: best metric: 0.740
[09/22 12:07:33][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 4.112374104214571
[09/22 12:08:42][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.93e-02, avg batch time: 0.8099, average train loss: 1.0637average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:08:44][INFO] visual_prompt:  435: Inference (val):avg data time: 6.51e-05, avg batch time: 0.1232, average loss: 1.5284
[09/22 12:08:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.50	top5: 90.67	
[09/22 12:08:58][INFO] visual_prompt:  435: Inference (test):avg data time: 6.92e-05, avg batch time: 0.1297, average loss: 1.5057
[09/22 12:08:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.78	top5: 90.96	
[09/22 12:08:58][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 3.9087087911505494
[09/22 12:10:07][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.88e-02, avg batch time: 0.8093, average train loss: 1.0792average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:10:09][INFO] visual_prompt:  435: Inference (val):avg data time: 5.76e-05, avg batch time: 0.1233, average loss: 1.4311
[09/22 12:10:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.17	top5: 93.17	
[09/22 12:10:23][INFO] visual_prompt:  435: Inference (test):avg data time: 5.44e-05, avg batch time: 0.1302, average loss: 1.4195
[09/22 12:10:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.13	top5: 92.27	
[09/22 12:10:23][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 3.7078959807762497
[09/22 12:11:32][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.88e-02, avg batch time: 0.8095, average train loss: 1.0300average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:11:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1227, average loss: 1.1860
[09/22 12:11:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.50	top5: 92.33	
[09/22 12:11:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1301, average loss: 1.1851
[09/22 12:11:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.63	top5: 92.01	
[09/22 12:11:48][INFO] visual_prompt:  357: Best epoch 68: best metric: 0.745
[09/22 12:11:48][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 3.5101803325682654
[09/22 12:12:57][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 1.96e-02, avg batch time: 0.8111, average train loss: 0.8035average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:12:59][INFO] visual_prompt:  435: Inference (val):avg data time: 5.51e-05, avg batch time: 0.1228, average loss: 1.0110
[09/22 12:12:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 95.17	
[09/22 12:13:13][INFO] visual_prompt:  435: Inference (test):avg data time: 1.07e-04, avg batch time: 0.1304, average loss: 1.0685
[09/22 12:13:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.99	top5: 94.37	
[09/22 12:13:13][INFO] visual_prompt:  357: Best epoch 69: best metric: 0.795
[09/22 12:13:13][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 3.315802732588184
[09/22 12:14:22][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.83e-02, avg batch time: 0.8097, average train loss: 0.7201average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:14:24][INFO] visual_prompt:  435: Inference (val):avg data time: 6.19e-05, avg batch time: 0.1224, average loss: 1.1376
[09/22 12:14:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.83	top5: 93.00	
[09/22 12:14:37][INFO] visual_prompt:  435: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1303, average loss: 1.1024
[09/22 12:14:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.08	top5: 93.25	
[09/22 12:14:38][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 3.1250000000000013
[09/22 12:15:47][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 1.86e-02, avg batch time: 0.8102, average train loss: 0.7859average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:15:49][INFO] visual_prompt:  435: Inference (val):avg data time: 7.11e-05, avg batch time: 0.1230, average loss: 1.1955
[09/22 12:15:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.67	top5: 93.17	
[09/22 12:16:02][INFO] visual_prompt:  435: Inference (test):avg data time: 6.90e-05, avg batch time: 0.1303, average loss: 1.1630
[09/22 12:16:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.72	top5: 93.55	
[09/22 12:16:02][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 2.93800459854247
[09/22 12:17:11][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.89e-02, avg batch time: 0.8101, average train loss: 0.7091average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:17:14][INFO] visual_prompt:  435: Inference (val):avg data time: 4.16e-05, avg batch time: 0.1227, average loss: 0.9264
[09/22 12:17:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 94.67	
[09/22 12:17:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.87e-05, avg batch time: 0.1292, average loss: 0.9937
[09/22 12:17:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.22	top5: 93.99	
[09/22 12:17:28][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 2.755044353307833
[09/22 12:18:37][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 1.86e-02, avg batch time: 0.8101, average train loss: 0.5639average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:18:39][INFO] visual_prompt:  435: Inference (val):avg data time: 7.26e-05, avg batch time: 0.1236, average loss: 0.8034
[09/22 12:18:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 96.17	
[09/22 12:18:53][INFO] visual_prompt:  435: Inference (test):avg data time: 6.64e-05, avg batch time: 0.1304, average loss: 0.8207
[09/22 12:18:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.31	top5: 95.27	
[09/22 12:18:53][INFO] visual_prompt:  357: Best epoch 73: best metric: 0.802
[09/22 12:18:53][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 2.5763421731720437
[09/22 12:20:02][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.84e-02, avg batch time: 0.8101, average train loss: 0.5524average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:20:04][INFO] visual_prompt:  435: Inference (val):avg data time: 8.70e-05, avg batch time: 0.1226, average loss: 0.8901
[09/22 12:20:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 95.67	
[09/22 12:20:17][INFO] visual_prompt:  435: Inference (test):avg data time: 6.52e-05, avg batch time: 0.1309, average loss: 0.8537
[09/22 12:20:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.03	top5: 95.67	
[09/22 12:20:18][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 2.4021157792146357
[09/22 12:21:26][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.70e-02, avg batch time: 0.8086, average train loss: 0.4767average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:21:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.55e-05, avg batch time: 0.1224, average loss: 0.8981
[09/22 12:21:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 94.67	
[09/22 12:21:42][INFO] visual_prompt:  435: Inference (test):avg data time: 6.54e-05, avg batch time: 0.1306, average loss: 0.9003
[09/22 12:21:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.38	top5: 94.96	
[09/22 12:21:42][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 2.232577439459129
[09/22 12:22:51][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.87e-02, avg batch time: 0.8102, average train loss: 0.4139average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:22:54][INFO] visual_prompt:  435: Inference (val):avg data time: 7.15e-05, avg batch time: 0.1220, average loss: 0.8525
[09/22 12:22:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 95.83	
[09/22 12:23:07][INFO] visual_prompt:  435: Inference (test):avg data time: 8.05e-05, avg batch time: 0.1298, average loss: 0.8049
[09/22 12:23:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.51	top5: 96.03	
[09/22 12:23:07][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 2.067933710257138
[09/22 12:24:16][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 1.91e-02, avg batch time: 0.8110, average train loss: 0.3842average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:24:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.28e-05, avg batch time: 0.1221, average loss: 0.7782
[09/22 12:24:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.50	top5: 95.67	
[09/22 12:24:32][INFO] visual_prompt:  435: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1300, average loss: 0.7945
[09/22 12:24:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.36	top5: 96.12	
[09/22 12:24:33][INFO] visual_prompt:  357: Best epoch 77: best metric: 0.815
[09/22 12:24:33][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 1.9083851846312665
[09/22 12:25:42][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 1.87e-02, avg batch time: 0.8106, average train loss: 0.3415average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:25:44][INFO] visual_prompt:  435: Inference (val):avg data time: 5.30e-05, avg batch time: 0.1234, average loss: 0.6839
[09/22 12:25:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 96.83	
[09/22 12:25:57][INFO] visual_prompt:  435: Inference (test):avg data time: 6.15e-05, avg batch time: 0.1301, average loss: 0.7009
[09/22 12:25:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.34	top5: 96.96	
[09/22 12:25:57][INFO] visual_prompt:  357: Best epoch 78: best metric: 0.820
[09/22 12:25:57][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 1.7541262478834314
[09/22 12:27:07][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.99e-02, avg batch time: 0.8116, average train loss: 0.3087average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:27:09][INFO] visual_prompt:  435: Inference (val):avg data time: 5.81e-05, avg batch time: 0.1237, average loss: 0.7490
[09/22 12:27:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.50	top5: 96.67	
[09/22 12:27:23][INFO] visual_prompt:  435: Inference (test):avg data time: 6.63e-05, avg batch time: 0.1301, average loss: 0.7575
[09/22 12:27:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.90	top5: 96.32	
[09/22 12:27:23][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 1.6053448407662854
[09/22 12:28:32][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 1.80e-02, avg batch time: 0.8099, average train loss: 0.2733average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:28:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1235, average loss: 0.6759
[09/22 12:28:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 96.67	
[09/22 12:28:48][INFO] visual_prompt:  435: Inference (test):avg data time: 7.24e-05, avg batch time: 0.1303, average loss: 0.6727
[09/22 12:28:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.47	top5: 96.77	
[09/22 12:28:48][INFO] visual_prompt:  357: Best epoch 80: best metric: 0.828
[09/22 12:28:48][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 1.462222230506388
[09/22 12:29:57][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.92e-02, avg batch time: 0.8111, average train loss: 0.2396average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:29:59][INFO] visual_prompt:  435: Inference (val):avg data time: 7.09e-05, avg batch time: 0.1225, average loss: 0.6706
[09/22 12:29:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 96.33	
[09/22 12:30:13][INFO] visual_prompt:  435: Inference (test):avg data time: 8.14e-05, avg batch time: 0.1301, average loss: 0.6529
[09/22 12:30:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.04	top5: 96.98	
[09/22 12:30:13][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 1.3249327899579881
[09/22 12:31:22][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 2.13e-02, avg batch time: 0.8130, average train loss: 0.2017average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:31:25][INFO] visual_prompt:  435: Inference (val):avg data time: 8.60e-05, avg batch time: 0.1223, average loss: 0.6401
[09/22 12:31:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.33	
[09/22 12:31:38][INFO] visual_prompt:  435: Inference (test):avg data time: 6.48e-05, avg batch time: 0.1305, average loss: 0.6226
[09/22 12:31:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.62	top5: 97.27	
[09/22 12:31:38][INFO] visual_prompt:  357: Best epoch 82: best metric: 0.847
[09/22 12:31:38][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 1.193643785156579
[09/22 12:32:47][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.92e-02, avg batch time: 0.8107, average train loss: 0.1961average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:32:50][INFO] visual_prompt:  435: Inference (val):avg data time: 6.05e-05, avg batch time: 0.1227, average loss: 0.5874
[09/22 12:32:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 97.33	
[09/22 12:33:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1301, average loss: 0.5903
[09/22 12:33:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.35	top5: 97.32	
[09/22 12:33:03][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 1.06851517153099
[09/22 12:34:12][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.87e-02, avg batch time: 0.8105, average train loss: 0.1673average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:34:15][INFO] visual_prompt:  435: Inference (val):avg data time: 4.91e-05, avg batch time: 0.1223, average loss: 0.5565
[09/22 12:34:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.83	
[09/22 12:34:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.49e-05, avg batch time: 0.1303, average loss: 0.5583
[09/22 12:34:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.33	top5: 97.57	
[09/22 12:34:28][INFO] visual_prompt:  357: Best epoch 84: best metric: 0.860
[09/22 12:34:28][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.9496993990223378
[09/22 12:35:37][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.94e-02, avg batch time: 0.8110, average train loss: 0.1562average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:35:40][INFO] visual_prompt:  435: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1221, average loss: 0.5395
[09/22 12:35:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.33	
[09/22 12:35:53][INFO] visual_prompt:  435: Inference (test):avg data time: 6.39e-05, avg batch time: 0.1302, average loss: 0.5509
[09/22 12:35:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.00	top5: 97.39	
[09/22 12:35:54][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.837341226347258
[09/22 12:37:03][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.89e-02, avg batch time: 0.8108, average train loss: 0.1446average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:37:05][INFO] visual_prompt:  435: Inference (val):avg data time: 5.61e-05, avg batch time: 0.1227, average loss: 0.5481
[09/22 12:37:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 97.67	
[09/22 12:37:19][INFO] visual_prompt:  435: Inference (test):avg data time: 7.31e-05, avg batch time: 0.1301, average loss: 0.5455
[09/22 12:37:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.47	top5: 97.48	
[09/22 12:37:19][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.7315775446317063
[09/22 12:38:28][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.89e-02, avg batch time: 0.8108, average train loss: 0.1444average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:38:30][INFO] visual_prompt:  435: Inference (val):avg data time: 6.02e-05, avg batch time: 0.1223, average loss: 0.5393
[09/22 12:38:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.00	
[09/22 12:38:43][INFO] visual_prompt:  435: Inference (test):avg data time: 5.82e-05, avg batch time: 0.1305, average loss: 0.5281
[09/22 12:38:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.66	top5: 97.74	
[09/22 12:38:44][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.6325372106302074
[09/22 12:39:53][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.87e-02, avg batch time: 0.8101, average train loss: 0.1326average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:39:55][INFO] visual_prompt:  435: Inference (val):avg data time: 6.40e-05, avg batch time: 0.1223, average loss: 0.5064
[09/22 12:39:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.33	
[09/22 12:40:08][INFO] visual_prompt:  435: Inference (test):avg data time: 7.61e-05, avg batch time: 0.1304, average loss: 0.5125
[09/22 12:40:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.14	top5: 97.76	
[09/22 12:40:08][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.5403408897337438
[09/22 12:41:17][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.92e-02, avg batch time: 0.8112, average train loss: 0.1265average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:41:20][INFO] visual_prompt:  435: Inference (val):avg data time: 8.70e-05, avg batch time: 0.1220, average loss: 0.5248
[09/22 12:41:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.00	
[09/22 12:41:34][INFO] visual_prompt:  435: Inference (test):avg data time: 8.21e-05, avg batch time: 0.1296, average loss: 0.5201
[09/22 12:41:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.14	top5: 97.62	
[09/22 12:41:34][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.45510090895757926
[09/22 12:42:43][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.99e-02, avg batch time: 0.8117, average train loss: 0.1179average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:42:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.75e-05, avg batch time: 0.1224, average loss: 0.5128
[09/22 12:42:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.17	
[09/22 12:42:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.44e-05, avg batch time: 0.1303, average loss: 0.5104
[09/22 12:42:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.09	top5: 97.81	
[09/22 12:42:59][INFO] visual_prompt:  357: Best epoch 90: best metric: 0.862
[09/22 12:42:59][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.376921120088073
[09/22 12:44:08][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 2.03e-02, avg batch time: 0.8120, average train loss: 0.1157average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:44:10][INFO] visual_prompt:  435: Inference (val):avg data time: 7.53e-05, avg batch time: 0.1218, average loss: 0.5030
[09/22 12:44:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.00	
[09/22 12:44:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.69e-05, avg batch time: 0.1299, average loss: 0.5056
[09/22 12:44:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.31	top5: 97.70	
[09/22 12:44:24][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.3058967731552904
[09/22 12:45:33][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.89e-02, avg batch time: 0.8110, average train loss: 0.1093average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:45:36][INFO] visual_prompt:  435: Inference (val):avg data time: 7.97e-05, avg batch time: 0.1219, average loss: 0.4865
[09/22 12:45:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.17	
[09/22 12:45:49][INFO] visual_prompt:  435: Inference (test):avg data time: 6.06e-05, avg batch time: 0.1301, average loss: 0.4956
[09/22 12:45:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.71	top5: 97.77	
[09/22 12:45:49][INFO] visual_prompt:  357: Best epoch 92: best metric: 0.870
[09/22 12:45:49][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.2421144003855069
[09/22 12:46:58][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.90e-02, avg batch time: 0.8108, average train loss: 0.1015average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:47:01][INFO] visual_prompt:  435: Inference (val):avg data time: 8.69e-05, avg batch time: 0.1221, average loss: 0.5072
[09/22 12:47:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.83	
[09/22 12:47:15][INFO] visual_prompt:  435: Inference (test):avg data time: 6.57e-05, avg batch time: 0.1303, average loss: 0.5025
[09/22 12:47:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.81	top5: 97.83	
[09/22 12:47:15][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.18565171077502204
[09/22 12:48:24][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.93e-02, avg batch time: 0.8113, average train loss: 0.0962average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:48:26][INFO] visual_prompt:  435: Inference (val):avg data time: 7.58e-05, avg batch time: 0.1227, average loss: 0.4940
[09/22 12:48:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.00	
[09/22 12:48:40][INFO] visual_prompt:  435: Inference (test):avg data time: 8.93e-05, avg batch time: 0.1297, average loss: 0.4873
[09/22 12:48:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.75	top5: 97.83	
[09/22 12:48:40][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.13657749541371444
[09/22 12:49:50][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 2.11e-02, avg batch time: 0.8131, average train loss: 0.0932average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:49:52][INFO] visual_prompt:  435: Inference (val):avg data time: 4.38e-05, avg batch time: 0.1223, average loss: 0.4950
[09/22 12:49:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.17	
[09/22 12:50:06][INFO] visual_prompt:  435: Inference (test):avg data time: 6.66e-05, avg batch time: 0.1302, average loss: 0.4876
[09/22 12:50:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.92	top5: 97.86	
[09/22 12:50:06][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.09495154367369987
[09/22 12:51:15][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.93e-02, avg batch time: 0.8112, average train loss: 0.0945average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:51:17][INFO] visual_prompt:  435: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1239, average loss: 0.4921
[09/22 12:51:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.83	
[09/22 12:51:30][INFO] visual_prompt:  435: Inference (test):avg data time: 5.54e-05, avg batch time: 0.1306, average loss: 0.4867
[09/22 12:51:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.09	top5: 97.86	
[09/22 12:51:30][INFO] visual_prompt:  357: Best epoch 96: best metric: 0.873
[09/22 12:51:30][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.06082457036518524
[09/22 12:52:39][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.94e-02, avg batch time: 0.8114, average train loss: 0.0910average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:52:42][INFO] visual_prompt:  435: Inference (val):avg data time: 8.68e-05, avg batch time: 0.1229, average loss: 0.4895
[09/22 12:52:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.17	
[09/22 12:52:56][INFO] visual_prompt:  435: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1300, average loss: 0.4858
[09/22 12:52:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.94	top5: 97.84	
[09/22 12:52:56][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.03423815394829194
[09/22 12:54:05][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 1.76e-02, avg batch time: 0.8092, average train loss: 0.0902average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:54:07][INFO] visual_prompt:  435: Inference (val):avg data time: 6.25e-05, avg batch time: 0.1219, average loss: 0.4887
[09/22 12:54:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.00	
[09/22 12:54:21][INFO] visual_prompt:  435: Inference (test):avg data time: 7.13e-05, avg batch time: 0.1301, average loss: 0.4851
[09/22 12:54:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.99	top5: 97.79	
[09/22 12:54:21][INFO] visual_prompt:  357: Best epoch 98: best metric: 0.875
[09/22 12:54:21][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.015224685876098765
[09/22 12:55:30][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.92e-02, avg batch time: 0.8109, average train loss: 0.0880average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:55:32][INFO] visual_prompt:  435: Inference (val):avg data time: 8.77e-05, avg batch time: 0.1218, average loss: 0.4859
[09/22 12:55:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.00	
[09/22 12:55:46][INFO] visual_prompt:  435: Inference (test):avg data time: 8.92e-05, avg batch time: 0.1301, average loss: 0.4830
[09/22 12:55:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.09	top5: 97.79	
[09/22 12:55:46][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 0.0038073311306514868
[09/22 12:56:55][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.90e-02, avg batch time: 0.8108, average train loss: 0.0845average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 12:56:58][INFO] visual_prompt:  435: Inference (val):avg data time: 6.18e-05, avg batch time: 0.1228, average loss: 0.4873
[09/22 12:56:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.00	
[09/22 12:57:12][INFO] visual_prompt:  435: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1296, average loss: 0.4840
[09/22 12:57:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.07	top5: 97.81	
