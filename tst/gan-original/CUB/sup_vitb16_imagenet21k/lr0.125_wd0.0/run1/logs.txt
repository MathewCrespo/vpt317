[09/23 17:17:08][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 17:17:08][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 17:17:08][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/23 17:17:08][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 17:17:08][INFO] visual_prompt:  109: Training with config:
[09/23 17:17:08][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr0.125_wd0.0/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 0.125,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 17:17:08][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 17:17:08][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 17:17:08][INFO] visual_prompt:   77: Number of images: 5394
[09/23 17:17:08][INFO] visual_prompt:   78: Number of classes: 200
[09/23 17:17:08][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 17:17:08][INFO] visual_prompt:   73: Loading validation data...
[09/23 17:17:08][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 17:17:08][INFO] visual_prompt:   77: Number of images: 600
[09/23 17:17:08][INFO] visual_prompt:   78: Number of classes: 200
[09/23 17:17:08][INFO] visual_prompt:   76: Loading test data...
[09/23 17:17:08][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 17:17:08][INFO] visual_prompt:   77: Number of images: 5794
[09/23 17:17:08][INFO] visual_prompt:   78: Number of classes: 200
[09/23 17:17:08][INFO] visual_prompt:  103: Constructing models...
[09/23 17:17:14][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 17:17:14][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 17:17:14][INFO] visual_prompt:   41: Device used for model: 0
[09/23 17:17:14][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 17:17:14][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 17:17:14][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 17:17:14][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/23 17:18:22][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.92e-02, avg batch time: 0.8017, average train loss: 5.3366average G loss: 4.3914, average realD loss: 12.2656, average fakeD loss: 0.9511, 
[09/23 17:18:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.11e-05, avg batch time: 0.1206, average loss: 5.3357
[09/23 17:18:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 1.83	
[09/23 17:18:38][INFO] visual_prompt:  435: Inference (test):avg data time: 7.84e-05, avg batch time: 0.1274, average loss: 5.3368
[09/23 17:18:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.28	top5: 1.69	
[09/23 17:18:39][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.003
[09/23 17:18:39][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.0125
[09/23 17:19:47][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 2.03e-02, avg batch time: 0.8000, average train loss: 5.3202average G loss: 0.0437, average realD loss: 3.1570, average fakeD loss: 1.8016, 
[09/23 17:19:49][INFO] visual_prompt:  435: Inference (val):avg data time: 7.34e-05, avg batch time: 0.1209, average loss: 5.3107
[09/23 17:19:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 3.00	
[09/23 17:20:03][INFO] visual_prompt:  435: Inference (test):avg data time: 9.15e-05, avg batch time: 0.1273, average loss: 5.3089
[09/23 17:20:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.69	top5: 2.73	
[09/23 17:20:03][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.008
[09/23 17:20:03][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.025
[09/23 17:21:12][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.92e-02, avg batch time: 0.7994, average train loss: 5.3095average G loss: 0.0000, average realD loss: 0.8716, average fakeD loss: 0.7059, 
[09/23 17:21:14][INFO] visual_prompt:  435: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1208, average loss: 5.2949
[09/23 17:21:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 3.67	
[09/23 17:21:27][INFO] visual_prompt:  435: Inference (test):avg data time: 8.42e-05, avg batch time: 0.1280, average loss: 5.2941
[09/23 17:21:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.67	top5: 3.35	
[09/23 17:21:28][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.0375
[09/23 17:22:36][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.94e-02, avg batch time: 0.7995, average train loss: 5.2954average G loss: 0.0000, average realD loss: 0.3058, average fakeD loss: 0.2939, 
[09/23 17:22:38][INFO] visual_prompt:  435: Inference (val):avg data time: 7.00e-05, avg batch time: 0.1215, average loss: 5.2696
[09/23 17:22:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.50	top5: 5.17	
[09/23 17:22:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.03e-05, avg batch time: 0.1276, average loss: 5.2683
[09/23 17:22:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.21	top5: 5.01	
[09/23 17:22:52][INFO] visual_prompt:  357: Best epoch 4: best metric: 0.015
[09/23 17:22:52][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 0.05
[09/23 17:24:00][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.81e-02, avg batch time: 0.7981, average train loss: 5.1801average G loss: 0.0000, average realD loss: 0.1439, average fakeD loss: 0.1585, 
[09/23 17:24:02][INFO] visual_prompt:  435: Inference (val):avg data time: 8.99e-05, avg batch time: 0.1200, average loss: 4.9790
[09/23 17:24:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 2.33	top5: 10.00	
[09/23 17:24:16][INFO] visual_prompt:  435: Inference (test):avg data time: 8.16e-05, avg batch time: 0.1274, average loss: 4.9758
[09/23 17:24:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 2.62	top5: 9.03	
[09/23 17:24:16][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.023
[09/23 17:24:16][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 0.0625
[09/23 17:25:24][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.97e-02, avg batch time: 0.7998, average train loss: 4.8102average G loss: 0.0000, average realD loss: 0.0798, average fakeD loss: 0.1965, 
[09/23 17:25:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1199, average loss: 4.3584
[09/23 17:25:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 8.33	top5: 26.50	
[09/23 17:25:40][INFO] visual_prompt:  435: Inference (test):avg data time: 7.74e-05, avg batch time: 0.1276, average loss: 4.3553
[09/23 17:25:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 8.06	top5: 26.13	
[09/23 17:25:40][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.083
[09/23 17:25:40][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 0.075
[09/23 17:26:49][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.90e-02, avg batch time: 0.7995, average train loss: 3.7028average G loss: 0.0010, average realD loss: 0.0596, average fakeD loss: 0.1113, 
[09/23 17:26:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1201, average loss: 2.7357
[09/23 17:26:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 48.67	top5: 78.67	
[09/23 17:27:05][INFO] visual_prompt:  435: Inference (test):avg data time: 8.57e-05, avg batch time: 0.1270, average loss: 2.7248
[09/23 17:27:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 49.62	top5: 79.27	
[09/23 17:27:05][INFO] visual_prompt:  357: Best epoch 7: best metric: 0.487
[09/23 17:27:05][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 0.0875
[09/23 17:28:13][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.83e-02, avg batch time: 0.7987, average train loss: 2.0253average G loss: 0.0031, average realD loss: 0.0423, average fakeD loss: 0.0807, 
[09/23 17:28:16][INFO] visual_prompt:  435: Inference (val):avg data time: 7.47e-05, avg batch time: 0.1200, average loss: 1.3600
[09/23 17:28:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.17	top5: 93.67	
[09/23 17:28:30][INFO] visual_prompt:  435: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1273, average loss: 1.3435
[09/23 17:28:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.89	top5: 94.65	
[09/23 17:28:30][INFO] visual_prompt:  357: Best epoch 8: best metric: 0.722
[09/23 17:28:30][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 0.1
[09/23 17:29:38][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.91e-02, avg batch time: 0.7993, average train loss: 1.1042average G loss: 0.0024, average realD loss: 0.0414, average fakeD loss: 0.0695, 
[09/23 17:29:40][INFO] visual_prompt:  435: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1195, average loss: 0.8933
[09/23 17:29:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 96.83	
[09/23 17:29:55][INFO] visual_prompt:  435: Inference (test):avg data time: 8.24e-05, avg batch time: 0.1268, average loss: 0.8731
[09/23 17:29:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.17	top5: 97.24	
[09/23 17:29:55][INFO] visual_prompt:  357: Best epoch 9: best metric: 0.803
[09/23 17:29:55][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 0.1125
[09/23 17:31:03][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 2.00e-02, avg batch time: 0.8001, average train loss: 0.7579average G loss: 0.0016, average realD loss: 0.0289, average fakeD loss: 0.0830, 
[09/23 17:31:05][INFO] visual_prompt:  435: Inference (val):avg data time: 7.41e-05, avg batch time: 0.1205, average loss: 0.7458
[09/23 17:31:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 97.33	
[09/23 17:31:20][INFO] visual_prompt:  435: Inference (test):avg data time: 8.53e-05, avg batch time: 0.1271, average loss: 0.7171
[09/23 17:31:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.33	top5: 97.77	
[09/23 17:31:20][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 0.125
[09/23 17:32:28][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 2.12e-02, avg batch time: 0.8015, average train loss: 0.6107average G loss: 0.0009, average realD loss: 0.0349, average fakeD loss: 0.0613, 
[09/23 17:32:30][INFO] visual_prompt:  435: Inference (val):avg data time: 8.04e-05, avg batch time: 0.1200, average loss: 0.6394
[09/23 17:32:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 97.83	
[09/23 17:32:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.98e-05, avg batch time: 0.1270, average loss: 0.6164
[09/23 17:32:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.55	top5: 98.07	
[09/23 17:32:44][INFO] visual_prompt:  357: Best epoch 11: best metric: 0.838
[09/23 17:32:44][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 0.12496192668869349
[09/23 17:33:52][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.87e-02, avg batch time: 0.7990, average train loss: 0.5005average G loss: 0.0010, average realD loss: 0.0229, average fakeD loss: 0.0682, 
[09/23 17:33:55][INFO] visual_prompt:  435: Inference (val):avg data time: 7.81e-05, avg batch time: 0.1200, average loss: 0.5735
[09/23 17:33:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 97.83	
[09/23 17:34:08][INFO] visual_prompt:  435: Inference (test):avg data time: 6.68e-05, avg batch time: 0.1280, average loss: 0.5675
[09/23 17:34:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.05	top5: 97.93	
[09/23 17:34:08][INFO] visual_prompt:  357: Best epoch 12: best metric: 0.840
[09/23 17:34:08][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 0.12484775314123901
[09/23 17:35:17][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.97e-02, avg batch time: 0.8005, average train loss: 0.4271average G loss: 0.0011, average realD loss: 0.0237, average fakeD loss: 0.0314, 
[09/23 17:35:19][INFO] visual_prompt:  435: Inference (val):avg data time: 7.39e-05, avg batch time: 0.1206, average loss: 0.5455
[09/23 17:35:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.33	
[09/23 17:35:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.08e-05, avg batch time: 0.1275, average loss: 0.5376
[09/23 17:35:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.12	top5: 98.00	
[09/23 17:35:33][INFO] visual_prompt:  357: Best epoch 13: best metric: 0.847
[09/23 17:35:33][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 0.12465761846051708
[09/23 17:36:41][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.84e-02, avg batch time: 0.7988, average train loss: 0.3801average G loss: 0.0006, average realD loss: 0.0212, average fakeD loss: 0.0519, 
[09/23 17:36:43][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1202, average loss: 0.5267
[09/23 17:36:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.00	
[09/23 17:36:57][INFO] visual_prompt:  435: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1274, average loss: 0.5142
[09/23 17:36:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.09	top5: 98.15	
[09/23 17:36:57][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 0.12439175429634815
[09/23 17:38:05][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.86e-02, avg batch time: 0.7992, average train loss: 0.3393average G loss: 0.0005, average realD loss: 0.0138, average fakeD loss: 0.0439, 
[09/23 17:38:07][INFO] visual_prompt:  435: Inference (val):avg data time: 7.89e-05, avg batch time: 0.1192, average loss: 0.5101
[09/23 17:38:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.83	
[09/23 17:38:21][INFO] visual_prompt:  435: Inference (test):avg data time: 7.96e-05, avg batch time: 0.1275, average loss: 0.5031
[09/23 17:38:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 98.02	
[09/23 17:38:21][INFO] visual_prompt:  357: Best epoch 15: best metric: 0.857
[09/23 17:38:21][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 0.12405048456326301
[09/23 17:39:29][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.92e-02, avg batch time: 0.7998, average train loss: 0.3086average G loss: 0.0011, average realD loss: 0.0213, average fakeD loss: 0.0632, 
[09/23 17:39:32][INFO] visual_prompt:  435: Inference (val):avg data time: 8.10e-05, avg batch time: 0.1200, average loss: 0.5220
[09/23 17:39:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 97.67	
[09/23 17:39:45][INFO] visual_prompt:  435: Inference (test):avg data time: 6.95e-05, avg batch time: 0.1277, average loss: 0.4996
[09/23 17:39:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.73	top5: 97.91	
[09/23 17:39:45][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 0.12363422504586286
[09/23 17:40:53][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.80e-02, avg batch time: 0.7986, average train loss: 0.2766average G loss: 0.0003, average realD loss: 0.0136, average fakeD loss: 0.0451, 
[09/23 17:40:56][INFO] visual_prompt:  435: Inference (val):avg data time: 6.06e-05, avg batch time: 0.1206, average loss: 0.4935
[09/23 17:40:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.17	
[09/23 17:41:09][INFO] visual_prompt:  435: Inference (test):avg data time: 8.17e-05, avg batch time: 0.1277, average loss: 0.4884
[09/23 17:41:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 98.10	
[09/23 17:41:09][INFO] visual_prompt:  357: Best epoch 17: best metric: 0.863
[09/23 17:41:09][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 0.12314348289224977
[09/23 17:42:18][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 2.15e-02, avg batch time: 0.8023, average train loss: 0.2608average G loss: 0.0006, average realD loss: 0.0157, average fakeD loss: 0.0591, 
[09/23 17:42:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.09e-05, avg batch time: 0.1199, average loss: 0.5178
[09/23 17:42:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.83	
[09/23 17:42:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.20e-05, avg batch time: 0.1275, average loss: 0.5008
[09/23 17:42:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.31	top5: 97.95	
[09/23 17:42:34][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 0.12257885599614493
[09/23 17:43:42][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.77e-02, avg batch time: 0.7983, average train loss: 0.2381average G loss: 0.0002, average realD loss: 0.0162, average fakeD loss: 0.0846, 
[09/23 17:43:44][INFO] visual_prompt:  435: Inference (val):avg data time: 5.09e-05, avg batch time: 0.1203, average loss: 0.5086
[09/23 17:43:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.33	
[09/23 17:43:58][INFO] visual_prompt:  435: Inference (test):avg data time: 6.92e-05, avg batch time: 0.1275, average loss: 0.4873
[09/23 17:43:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.74	top5: 98.02	
[09/23 17:43:58][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 0.1219410322684471
[09/23 17:45:06][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.82e-02, avg batch time: 0.7993, average train loss: 0.2149average G loss: 0.0003, average realD loss: 0.0156, average fakeD loss: 0.0156, 
[09/23 17:45:08][INFO] visual_prompt:  435: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1203, average loss: 0.4880
[09/23 17:45:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.33	
[09/23 17:45:22][INFO] visual_prompt:  435: Inference (test):avg data time: 7.79e-05, avg batch time: 0.1280, average loss: 0.4756
[09/23 17:45:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.19	top5: 98.00	
[09/23 17:45:22][INFO] visual_prompt:  357: Best epoch 20: best metric: 0.868
[09/23 17:45:22][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 0.12123078879911928
[09/23 17:46:30][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.93e-02, avg batch time: 0.8001, average train loss: 0.2012average G loss: 0.0003, average realD loss: 0.0129, average fakeD loss: 0.0737, 
[09/23 17:46:32][INFO] visual_prompt:  435: Inference (val):avg data time: 6.89e-05, avg batch time: 0.1204, average loss: 0.4843
[09/23 17:46:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.33	
[09/23 17:46:46][INFO] visual_prompt:  435: Inference (test):avg data time: 9.16e-05, avg batch time: 0.1274, average loss: 0.4784
[09/23 17:46:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.98	
[09/23 17:46:46][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 0.12044899091042421
[09/23 17:47:54][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.83e-02, avg batch time: 0.7994, average train loss: 0.1863average G loss: 0.0003, average realD loss: 0.0126, average fakeD loss: 0.0878, 
[09/23 17:47:57][INFO] visual_prompt:  435: Inference (val):avg data time: 7.74e-05, avg batch time: 0.1204, average loss: 0.4810
[09/23 17:47:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.33	
[09/23 17:48:11][INFO] visual_prompt:  435: Inference (test):avg data time: 8.21e-05, avg batch time: 0.1277, average loss: 0.4806
[09/23 17:48:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 98.05	
[09/23 17:48:11][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 0.11959659110266255
[09/23 17:49:19][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.76e-02, avg batch time: 0.7988, average train loss: 0.1711average G loss: 0.0002, average realD loss: 0.0155, average fakeD loss: 0.0561, 
[09/23 17:49:21][INFO] visual_prompt:  435: Inference (val):avg data time: 6.23e-05, avg batch time: 0.1203, average loss: 0.4817
[09/23 17:49:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.17	
[09/23 17:49:34][INFO] visual_prompt:  435: Inference (test):avg data time: 9.80e-05, avg batch time: 0.1283, average loss: 0.4757
[09/23 17:49:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.37	top5: 98.02	
[09/23 17:49:34][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 0.11867462789369794
[09/23 17:50:42][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.87e-02, avg batch time: 0.7998, average train loss: 0.1578average G loss: 0.0003, average realD loss: 0.0091, average fakeD loss: 0.0340, 
[09/23 17:50:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.90e-05, avg batch time: 0.1197, average loss: 0.4804
[09/23 17:50:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.17	
[09/23 17:50:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.78e-05, avg batch time: 0.1270, average loss: 0.4855
[09/23 17:50:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.61	top5: 98.00	
[09/23 17:50:59][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 0.11768422455368294
[09/23 17:52:07][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.81e-02, avg batch time: 0.7991, average train loss: 0.1469average G loss: 0.0002, average realD loss: 0.0127, average fakeD loss: 0.0268, 
[09/23 17:52:09][INFO] visual_prompt:  435: Inference (val):avg data time: 5.11e-05, avg batch time: 0.1202, average loss: 0.4904
[09/23 17:52:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.17	
[09/23 17:52:23][INFO] visual_prompt:  435: Inference (test):avg data time: 8.94e-05, avg batch time: 0.1274, average loss: 0.4767
[09/23 17:52:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 98.03	
[09/23 17:52:23][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 0.11662658773652743
[09/23 17:53:31][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.82e-02, avg batch time: 0.7991, average train loss: 0.1440average G loss: 0.0002, average realD loss: 0.0146, average fakeD loss: 0.0326, 
[09/23 17:53:33][INFO] visual_prompt:  435: Inference (val):avg data time: 7.26e-05, avg batch time: 0.1201, average loss: 0.4777
[09/23 17:53:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.17	
[09/23 17:53:48][INFO] visual_prompt:  435: Inference (test):avg data time: 8.27e-05, avg batch time: 0.1277, average loss: 0.4741
[09/23 17:53:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.18	top5: 98.03	
[09/23 17:53:48][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 0.11550300600977662
[09/23 17:54:56][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.96e-02, avg batch time: 0.8006, average train loss: 0.1411average G loss: 0.0002, average realD loss: 0.0124, average fakeD loss: 0.0511, 
[09/23 17:54:58][INFO] visual_prompt:  435: Inference (val):avg data time: 9.38e-05, avg batch time: 0.1199, average loss: 0.4976
[09/23 17:54:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.33	
[09/23 17:55:12][INFO] visual_prompt:  435: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1277, average loss: 0.4807
[09/23 17:55:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.18	top5: 98.12	
[09/23 17:55:12][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 0.1143148482846901
[09/23 17:56:20][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.85e-02, avg batch time: 0.7994, average train loss: 0.1256average G loss: 0.0003, average realD loss: 0.0101, average fakeD loss: 0.0178, 
[09/23 17:56:22][INFO] visual_prompt:  435: Inference (val):avg data time: 9.32e-05, avg batch time: 0.1204, average loss: 0.4918
[09/23 17:56:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.00	
[09/23 17:56:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.49e-05, avg batch time: 0.1270, average loss: 0.4792
[09/23 17:56:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.99	top5: 98.05	
[09/23 17:56:36][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 0.11306356214843422
[09/23 17:57:44][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.80e-02, avg batch time: 0.7987, average train loss: 0.1215average G loss: 0.0002, average realD loss: 0.0096, average fakeD loss: 0.0580, 
[09/23 17:57:47][INFO] visual_prompt:  435: Inference (val):avg data time: 5.68e-05, avg batch time: 0.1201, average loss: 0.4899
[09/23 17:57:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.83	
[09/23 17:58:00][INFO] visual_prompt:  435: Inference (test):avg data time: 8.27e-05, avg batch time: 0.1276, average loss: 0.4748
[09/23 17:58:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.09	top5: 98.14	
[09/23 17:58:01][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 0.11175067210042011
[09/23 17:59:09][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.91e-02, avg batch time: 0.7998, average train loss: 0.1121average G loss: 0.0002, average realD loss: 0.0150, average fakeD loss: 0.0203, 
[09/23 17:59:11][INFO] visual_prompt:  435: Inference (val):avg data time: 8.32e-05, avg batch time: 0.1201, average loss: 0.5017
[09/23 17:59:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.00	
[09/23 17:59:24][INFO] visual_prompt:  435: Inference (test):avg data time: 8.44e-05, avg batch time: 0.1277, average loss: 0.4849
[09/23 17:59:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.43	top5: 97.96	
[09/23 17:59:24][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 0.11037777769493612
[09/23 18:00:33][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.86e-02, avg batch time: 0.7994, average train loss: 0.1134average G loss: 0.0003, average realD loss: 0.0114, average fakeD loss: 0.0136, 
[09/23 18:00:35][INFO] visual_prompt:  435: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1212, average loss: 0.4988
[09/23 18:00:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.67	
[09/23 18:00:48][INFO] visual_prompt:  435: Inference (test):avg data time: 9.58e-05, avg batch time: 0.1277, average loss: 0.4774
[09/23 18:00:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.97	top5: 98.08	
[09/23 18:00:48][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 0.10894655159233714
[09/23 18:01:57][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 2.02e-02, avg batch time: 0.8008, average train loss: 0.1079average G loss: 0.0003, average realD loss: 0.0116, average fakeD loss: 0.0329, 
[09/23 18:01:59][INFO] visual_prompt:  435: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1197, average loss: 0.4870
[09/23 18:01:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 97.83	
[09/23 18:02:12][INFO] visual_prompt:  435: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1279, average loss: 0.4797
[09/23 18:02:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.98	
[09/23 18:02:12][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 0.10745873752116569
[09/23 18:03:21][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.90e-02, avg batch time: 0.7998, average train loss: 0.1024average G loss: 0.0002, average realD loss: 0.0089, average fakeD loss: 0.0331, 
[09/23 18:03:23][INFO] visual_prompt:  435: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1201, average loss: 0.4928
[09/23 18:03:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.67	
[09/23 18:03:36][INFO] visual_prompt:  435: Inference (test):avg data time: 6.94e-05, avg batch time: 0.1275, average loss: 0.4799
[09/23 18:03:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.71	top5: 98.03	
[09/23 18:03:37][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 0.10591614815368733
[09/23 18:04:45][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.80e-02, avg batch time: 0.7988, average train loss: 0.0957average G loss: 0.0003, average realD loss: 0.0083, average fakeD loss: 0.0175, 
[09/23 18:04:47][INFO] visual_prompt:  435: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1203, average loss: 0.5000
[09/23 18:04:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.50	
[09/23 18:05:01][INFO] visual_prompt:  435: Inference (test):avg data time: 7.97e-05, avg batch time: 0.1276, average loss: 0.4902
[09/23 18:05:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.68	top5: 97.86	
[09/23 18:05:01][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 0.10432066289742864
[09/23 18:06:09][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.95e-02, avg batch time: 0.8003, average train loss: 0.0930average G loss: 0.0002, average realD loss: 0.0097, average fakeD loss: 0.0307, 
[09/23 18:06:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.58e-05, avg batch time: 0.1206, average loss: 0.4884
[09/23 18:06:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.50	
[09/23 18:06:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1278, average loss: 0.4809
[09/23 18:06:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 98.03	
[09/23 18:06:25][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 0.1026742256054087
[09/23 18:07:33][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.85e-02, avg batch time: 0.7993, average train loss: 0.0888average G loss: 0.0002, average realD loss: 0.0105, average fakeD loss: 0.0250, 
[09/23 18:07:35][INFO] visual_prompt:  435: Inference (val):avg data time: 7.29e-05, avg batch time: 0.1201, average loss: 0.4909
[09/23 18:07:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.83	
[09/23 18:07:49][INFO] visual_prompt:  435: Inference (test):avg data time: 7.38e-05, avg batch time: 0.1272, average loss: 0.4850
[09/23 18:07:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.68	top5: 97.86	
[09/23 18:07:49][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 0.10097884220785364
[09/23 18:08:57][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.89e-02, avg batch time: 0.7998, average train loss: 0.0881average G loss: 0.0003, average realD loss: 0.0089, average fakeD loss: 0.0152, 
[09/23 18:09:00][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1202, average loss: 0.5133
[09/23 18:09:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/23 18:09:14][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1271, average loss: 0.4956
[09/23 18:09:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.86	
[09/23 18:09:14][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 0.09923657826827957
[09/23 18:10:22][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 2.07e-02, avg batch time: 0.8014, average train loss: 0.0764average G loss: 0.0002, average realD loss: 0.0079, average fakeD loss: 0.0144, 
[09/23 18:10:25][INFO] visual_prompt:  435: Inference (val):avg data time: 7.25e-05, avg batch time: 0.1193, average loss: 0.4933
[09/23 18:10:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 97.50	
[09/23 18:10:39][INFO] visual_prompt:  435: Inference (test):avg data time: 8.17e-05, avg batch time: 0.1272, average loss: 0.4839
[09/23 18:10:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.89	
[09/23 18:10:39][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 0.09744955646692167
[09/23 18:11:47][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 1.87e-02, avg batch time: 0.7995, average train loss: 0.0810average G loss: 0.0001, average realD loss: 0.0087, average fakeD loss: 0.0157, 
[09/23 18:11:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.16e-05, avg batch time: 0.1196, average loss: 0.5019
[09/23 18:11:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.33	
[09/23 18:12:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.73e-05, avg batch time: 0.1274, average loss: 0.4845
[09/23 18:12:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.91	
[09/23 18:12:03][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 0.0956199540145753
[09/23 18:13:11][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.87e-02, avg batch time: 0.7996, average train loss: 0.0751average G loss: 0.0001, average realD loss: 0.0072, average fakeD loss: 0.0484, 
[09/23 18:13:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.67e-05, avg batch time: 0.1205, average loss: 0.4904
[09/23 18:13:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.17	
[09/23 18:13:28][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1274, average loss: 0.4824
[09/23 18:13:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.93	
[09/23 18:13:28][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 0.09375
[09/23 18:14:36][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.92e-02, avg batch time: 0.8002, average train loss: 0.0733average G loss: 0.0001, average realD loss: 0.0100, average fakeD loss: 0.0160, 
[09/23 18:14:38][INFO] visual_prompt:  435: Inference (val):avg data time: 8.68e-05, avg batch time: 0.1215, average loss: 0.4906
[09/23 18:14:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.00	
[09/23 18:14:52][INFO] visual_prompt:  435: Inference (test):avg data time: 8.97e-05, avg batch time: 0.1272, average loss: 0.4845
[09/23 18:14:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.85	top5: 97.98	
[09/23 18:14:52][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 0.09184197267411817
[09/23 18:16:00][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 1.85e-02, avg batch time: 0.7995, average train loss: 0.0742average G loss: 0.0003, average realD loss: 0.0076, average fakeD loss: 0.0332, 
[09/23 18:16:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1201, average loss: 0.5014
[09/23 18:16:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.67	
[09/23 18:16:17][INFO] visual_prompt:  435: Inference (test):avg data time: 9.87e-05, avg batch time: 0.1271, average loss: 0.4858
[09/23 18:16:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 97.98	
[09/23 18:16:17][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 0.08989819667431734
[09/23 18:17:25][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.95e-02, avg batch time: 0.8003, average train loss: 0.0651average G loss: 0.0001, average realD loss: 0.0079, average fakeD loss: 0.0061, 
[09/23 18:17:28][INFO] visual_prompt:  435: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1205, average loss: 0.4978
[09/23 18:17:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 97.33	
[09/23 18:17:41][INFO] visual_prompt:  435: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1275, average loss: 0.4837
[09/23 18:17:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.96	
[09/23 18:17:42][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 0.08792104019223752
[09/23 18:18:50][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 1.88e-02, avg batch time: 0.7998, average train loss: 0.0618average G loss: 0.0001, average realD loss: 0.0055, average fakeD loss: 0.0338, 
[09/23 18:18:52][INFO] visual_prompt:  435: Inference (val):avg data time: 5.48e-05, avg batch time: 0.1194, average loss: 0.4936
[09/23 18:18:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.50	
[09/23 18:19:06][INFO] visual_prompt:  435: Inference (test):avg data time: 8.39e-05, avg batch time: 0.1272, average loss: 0.4877
[09/23 18:19:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.93	
[09/23 18:19:06][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 0.08591291208849451
[09/23 18:20:15][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 2.08e-02, avg batch time: 0.8022, average train loss: 0.0627average G loss: 0.0002, average realD loss: 0.0052, average fakeD loss: 0.0128, 
[09/23 18:20:17][INFO] visual_prompt:  435: Inference (val):avg data time: 8.14e-05, avg batch time: 0.1198, average loss: 0.5010
[09/23 18:20:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 18:20:31][INFO] visual_prompt:  435: Inference (test):avg data time: 9.42e-05, avg batch time: 0.1273, average loss: 0.4898
[09/23 18:20:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.00	top5: 97.83	
[09/23 18:20:31][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 0.0838762589578543
[09/23 18:21:39][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 1.76e-02, avg batch time: 0.7990, average train loss: 0.0644average G loss: 0.0002, average realD loss: 0.0066, average fakeD loss: 0.0290, 
[09/23 18:21:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.37e-05, avg batch time: 0.1205, average loss: 0.4947
[09/23 18:21:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/23 18:21:55][INFO] visual_prompt:  435: Inference (test):avg data time: 8.48e-05, avg batch time: 0.1274, average loss: 0.4870
[09/23 18:21:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.91	
[09/23 18:21:55][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 0.08181356214843422
[09/23 18:23:04][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 2.12e-02, avg batch time: 0.8024, average train loss: 0.0601average G loss: 0.0001, average realD loss: 0.0081, average fakeD loss: 0.0145, 
[09/23 18:23:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.85e-05, avg batch time: 0.1206, average loss: 0.5142
[09/23 18:23:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.50	
[09/23 18:23:20][INFO] visual_prompt:  435: Inference (test):avg data time: 9.91e-05, avg batch time: 0.1274, average loss: 0.4932
[09/23 18:23:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.93	top5: 97.88	
[09/23 18:23:20][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 0.07972733473856244
[09/23 18:24:28][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.86e-02, avg batch time: 0.7998, average train loss: 0.0609average G loss: 0.0002, average realD loss: 0.0065, average fakeD loss: 0.0322, 
[09/23 18:24:31][INFO] visual_prompt:  435: Inference (val):avg data time: 7.25e-05, avg batch time: 0.1197, average loss: 0.5033
[09/23 18:24:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.67	
[09/23 18:24:45][INFO] visual_prompt:  435: Inference (test):avg data time: 8.56e-05, avg batch time: 0.1275, average loss: 0.4897
[09/23 18:24:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.96	
[09/23 18:24:45][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 0.07762011847497922
[09/23 18:25:53][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.89e-02, avg batch time: 0.8001, average train loss: 0.0568average G loss: 0.0002, average realD loss: 0.0098, average fakeD loss: 0.0166, 
[09/23 18:25:55][INFO] visual_prompt:  435: Inference (val):avg data time: 6.53e-05, avg batch time: 0.1200, average loss: 0.5159
[09/23 18:25:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 97.33	
[09/23 18:26:09][INFO] visual_prompt:  435: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1274, average loss: 0.4957
[09/23 18:26:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.83	
[09/23 18:26:09][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 0.07549448067610995
[09/23 18:27:17][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 1.84e-02, avg batch time: 0.7994, average train loss: 0.0589average G loss: 0.0001, average realD loss: 0.0077, average fakeD loss: 0.0142, 
[09/23 18:27:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1194, average loss: 0.5153
[09/23 18:27:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.00	
[09/23 18:27:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1274, average loss: 0.4980
[09/23 18:27:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.84	
[09/23 18:27:34][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 0.07335301110418316
[09/23 18:28:42][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.88e-02, avg batch time: 0.8000, average train loss: 0.0564average G loss: 0.0001, average realD loss: 0.0064, average fakeD loss: 0.0131, 
[09/23 18:28:44][INFO] visual_prompt:  435: Inference (val):avg data time: 6.50e-05, avg batch time: 0.1199, average loss: 0.5070
[09/23 18:28:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.83	
[09/23 18:28:58][INFO] visual_prompt:  435: Inference (test):avg data time: 7.03e-05, avg batch time: 0.1274, average loss: 0.4892
[09/23 18:28:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.09	top5: 97.95	
[09/23 18:28:58][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 0.07119831881000409
[09/23 18:30:06][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.81e-02, avg batch time: 0.7992, average train loss: 0.0521average G loss: 0.0001, average realD loss: 0.0049, average fakeD loss: 0.0292, 
[09/23 18:30:09][INFO] visual_prompt:  435: Inference (val):avg data time: 7.52e-05, avg batch time: 0.1221, average loss: 0.5185
[09/23 18:30:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.67	
[09/23 18:30:22][INFO] visual_prompt:  435: Inference (test):avg data time: 8.68e-05, avg batch time: 0.1277, average loss: 0.5011
[09/23 18:30:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.78	top5: 97.72	
[09/23 18:30:23][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 0.06903302895422835
[09/23 18:31:31][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.95e-02, avg batch time: 0.8006, average train loss: 0.0480average G loss: 0.0003, average realD loss: 0.0049, average fakeD loss: 0.0126, 
[09/23 18:31:33][INFO] visual_prompt:  435: Inference (val):avg data time: 6.83e-05, avg batch time: 0.1211, average loss: 0.5087
[09/23 18:31:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.33	
[09/23 18:31:46][INFO] visual_prompt:  435: Inference (test):avg data time: 7.24e-05, avg batch time: 0.1279, average loss: 0.4948
[09/23 18:31:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.79	
[09/23 18:31:46][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 0.06685977960900782
[09/23 18:32:55][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.91e-02, avg batch time: 0.8000, average train loss: 0.0540average G loss: 0.0001, average realD loss: 0.0094, average fakeD loss: 0.0124, 
[09/23 18:32:57][INFO] visual_prompt:  435: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1199, average loss: 0.5059
[09/23 18:32:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.00	
[09/23 18:33:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.53e-05, avg batch time: 0.1280, average loss: 0.4975
[09/23 18:33:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.00	top5: 97.88	
[09/23 18:33:10][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 0.06468121854390632
[09/23 18:34:18][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.84e-02, avg batch time: 0.7992, average train loss: 0.0532average G loss: 0.0001, average realD loss: 0.0083, average fakeD loss: 0.0254, 
[09/23 18:34:21][INFO] visual_prompt:  435: Inference (val):avg data time: 6.81e-05, avg batch time: 0.1201, average loss: 0.5066
[09/23 18:34:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 18:34:35][INFO] visual_prompt:  435: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1268, average loss: 0.4957
[09/23 18:34:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.97	top5: 97.88	
[09/23 18:34:35][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 0.0625
[09/23 18:35:43][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 1.97e-02, avg batch time: 0.8003, average train loss: 0.0479average G loss: 0.0002, average realD loss: 0.0075, average fakeD loss: 0.0164, 
[09/23 18:35:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1195, average loss: 0.5069
[09/23 18:35:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.83	
[09/23 18:35:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.94e-05, avg batch time: 0.1268, average loss: 0.4961
[09/23 18:35:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.86	
[09/23 18:35:59][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 0.060318781456093706
[09/23 18:37:07][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.84e-02, avg batch time: 0.7987, average train loss: 0.0464average G loss: 0.0001, average realD loss: 0.0055, average fakeD loss: 0.0127, 
[09/23 18:37:10][INFO] visual_prompt:  435: Inference (val):avg data time: 8.23e-05, avg batch time: 0.1201, average loss: 0.5018
[09/23 18:37:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 97.67	
[09/23 18:37:24][INFO] visual_prompt:  435: Inference (test):avg data time: 8.29e-05, avg batch time: 0.1271, average loss: 0.4975
[09/23 18:37:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.91	
[09/23 18:37:24][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 0.05814022039099217
[09/23 18:38:32][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 1.81e-02, avg batch time: 0.7986, average train loss: 0.0479average G loss: 0.0001, average realD loss: 0.0087, average fakeD loss: 0.0360, 
[09/23 18:38:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.33e-05, avg batch time: 0.1196, average loss: 0.5011
[09/23 18:38:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.50	
[09/23 18:38:48][INFO] visual_prompt:  435: Inference (test):avg data time: 9.11e-05, avg batch time: 0.1270, average loss: 0.4980
[09/23 18:38:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.77	
[09/23 18:38:48][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 0.05596697104577167
[09/23 18:39:56][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.92e-02, avg batch time: 0.7994, average train loss: 0.0444average G loss: 0.0003, average realD loss: 0.0072, average fakeD loss: 0.0107, 
[09/23 18:39:59][INFO] visual_prompt:  435: Inference (val):avg data time: 6.57e-05, avg batch time: 0.1201, average loss: 0.5061
[09/23 18:39:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.83	
[09/23 18:40:12][INFO] visual_prompt:  435: Inference (test):avg data time: 7.55e-05, avg batch time: 0.1273, average loss: 0.4978
[09/23 18:40:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.91	
[09/23 18:40:12][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 0.053801681189995926
[09/23 18:41:21][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 2.04e-02, avg batch time: 0.8005, average train loss: 0.0484average G loss: 0.0001, average realD loss: 0.0040, average fakeD loss: 0.0688, 
[09/23 18:41:23][INFO] visual_prompt:  435: Inference (val):avg data time: 8.06e-05, avg batch time: 0.1199, average loss: 0.5098
[09/23 18:41:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 97.67	
[09/23 18:41:37][INFO] visual_prompt:  435: Inference (test):avg data time: 8.63e-05, avg batch time: 0.1274, average loss: 0.4976
[09/23 18:41:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.79	
[09/23 18:41:37][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 0.051646988895816856
[09/23 18:42:45][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.99e-02, avg batch time: 0.8002, average train loss: 0.0430average G loss: 0.0001, average realD loss: 0.0061, average fakeD loss: 0.0082, 
[09/23 18:42:47][INFO] visual_prompt:  435: Inference (val):avg data time: 7.54e-05, avg batch time: 0.1212, average loss: 0.5117
[09/23 18:42:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.83	
[09/23 18:43:01][INFO] visual_prompt:  435: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1272, average loss: 0.4954
[09/23 18:43:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.83	
[09/23 18:43:01][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 0.04950551932389005
[09/23 18:44:09][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.98e-02, avg batch time: 0.8005, average train loss: 0.0433average G loss: 0.0001, average realD loss: 0.0064, average fakeD loss: 0.0287, 
[09/23 18:44:11][INFO] visual_prompt:  435: Inference (val):avg data time: 6.90e-05, avg batch time: 0.1199, average loss: 0.5165
[09/23 18:44:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 97.67	
[09/23 18:44:25][INFO] visual_prompt:  435: Inference (test):avg data time: 6.86e-05, avg batch time: 0.1277, average loss: 0.4998
[09/23 18:44:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.99	top5: 97.86	
[09/23 18:44:25][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 0.047379881525020776
[09/23 18:45:33][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 1.85e-02, avg batch time: 0.7989, average train loss: 0.0437average G loss: 0.0003, average realD loss: 0.0057, average fakeD loss: 0.0138, 
[09/23 18:45:35][INFO] visual_prompt:  435: Inference (val):avg data time: 7.28e-05, avg batch time: 0.1195, average loss: 0.5070
[09/23 18:45:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.00	
[09/23 18:45:50][INFO] visual_prompt:  435: Inference (test):avg data time: 8.19e-05, avg batch time: 0.1269, average loss: 0.4954
[09/23 18:45:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 97.91	
[09/23 18:45:50][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 0.045272665261437556
[09/23 18:46:58][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.84e-02, avg batch time: 0.7987, average train loss: 0.0411average G loss: 0.0000, average realD loss: 0.0054, average fakeD loss: 0.0124, 
[09/23 18:47:00][INFO] visual_prompt:  435: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1202, average loss: 0.5111
[09/23 18:47:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.67	
[09/23 18:47:14][INFO] visual_prompt:  435: Inference (test):avg data time: 8.11e-05, avg batch time: 0.1273, average loss: 0.4968
[09/23 18:47:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.88	
[09/23 18:47:14][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 0.04318643785156579
[09/23 18:48:22][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.77e-02, avg batch time: 0.7981, average train loss: 0.0407average G loss: 0.0003, average realD loss: 0.0046, average fakeD loss: 0.0117, 
[09/23 18:48:25][INFO] visual_prompt:  435: Inference (val):avg data time: 5.05e-05, avg batch time: 0.1194, average loss: 0.5178
[09/23 18:48:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.83	
[09/23 18:48:38][INFO] visual_prompt:  435: Inference (test):avg data time: 9.98e-05, avg batch time: 0.1269, average loss: 0.4984
[09/23 18:48:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.00	top5: 97.79	
[09/23 18:48:39][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 0.04112374104214571
[09/23 18:49:47][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.84e-02, avg batch time: 0.7988, average train loss: 0.0410average G loss: 0.0005, average realD loss: 0.0056, average fakeD loss: 0.0063, 
[09/23 18:49:49][INFO] visual_prompt:  435: Inference (val):avg data time: 7.09e-05, avg batch time: 0.1196, average loss: 0.5197
[09/23 18:49:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 18:50:03][INFO] visual_prompt:  435: Inference (test):avg data time: 6.82e-05, avg batch time: 0.1276, average loss: 0.5038
[09/23 18:50:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.76	
[09/23 18:50:03][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 0.039087087911505496
[09/23 18:51:11][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.85e-02, avg batch time: 0.7989, average train loss: 0.0414average G loss: 0.0000, average realD loss: 0.0042, average fakeD loss: 0.0303, 
[09/23 18:51:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.98e-05, avg batch time: 0.1198, average loss: 0.5189
[09/23 18:51:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.67	
[09/23 18:51:27][INFO] visual_prompt:  435: Inference (test):avg data time: 1.03e-04, avg batch time: 0.1271, average loss: 0.5023
[09/23 18:51:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 97.72	
[09/23 18:51:27][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 0.0370789598077625
[09/23 18:52:35][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.84e-02, avg batch time: 0.7987, average train loss: 0.0395average G loss: 0.0001, average realD loss: 0.0056, average fakeD loss: 0.0117, 
[09/23 18:52:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.19e-05, avg batch time: 0.1202, average loss: 0.5189
[09/23 18:52:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 18:52:52][INFO] visual_prompt:  435: Inference (test):avg data time: 8.17e-05, avg batch time: 0.1271, average loss: 0.5023
[09/23 18:52:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.74	
[09/23 18:52:52][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 0.035101803325682655
[09/23 18:54:00][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 2.17e-02, avg batch time: 0.8024, average train loss: 0.0403average G loss: 0.0001, average realD loss: 0.0053, average fakeD loss: 0.0118, 
[09/23 18:54:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.50e-05, avg batch time: 0.1202, average loss: 0.5206
[09/23 18:54:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.33	
[09/23 18:54:17][INFO] visual_prompt:  435: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1271, average loss: 0.5028
[09/23 18:54:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.84	
[09/23 18:54:17][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 0.03315802732588184
[09/23 18:55:25][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 2.26e-02, avg batch time: 0.8033, average train loss: 0.0374average G loss: 0.0001, average realD loss: 0.0057, average fakeD loss: 0.0259, 
[09/23 18:55:28][INFO] visual_prompt:  435: Inference (val):avg data time: 6.88e-05, avg batch time: 0.1199, average loss: 0.5192
[09/23 18:55:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.33	
[09/23 18:55:41][INFO] visual_prompt:  435: Inference (test):avg data time: 8.31e-05, avg batch time: 0.1277, average loss: 0.5010
[09/23 18:55:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.18	top5: 97.79	
[09/23 18:55:41][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 0.031250000000000014
[09/23 18:56:49][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 1.81e-02, avg batch time: 0.7988, average train loss: 0.0398average G loss: 0.0001, average realD loss: 0.0058, average fakeD loss: 0.0163, 
[09/23 18:56:52][INFO] visual_prompt:  435: Inference (val):avg data time: 8.26e-05, avg batch time: 0.1201, average loss: 0.5211
[09/23 18:56:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.33	
[09/23 18:57:06][INFO] visual_prompt:  435: Inference (test):avg data time: 9.36e-05, avg batch time: 0.1272, average loss: 0.5032
[09/23 18:57:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.74	
[09/23 18:57:06][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 0.0293800459854247
[09/23 18:58:14][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.91e-02, avg batch time: 0.8000, average train loss: 0.0415average G loss: 0.0004, average realD loss: 0.0055, average fakeD loss: 0.0156, 
[09/23 18:58:16][INFO] visual_prompt:  435: Inference (val):avg data time: 7.70e-05, avg batch time: 0.1199, average loss: 0.5157
[09/23 18:58:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.50	
[09/23 18:58:29][INFO] visual_prompt:  435: Inference (test):avg data time: 8.82e-05, avg batch time: 0.1279, average loss: 0.4975
[09/23 18:58:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.11	top5: 97.83	
[09/23 18:58:30][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 0.027550443533078332
[09/23 18:59:38][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 2.05e-02, avg batch time: 0.8010, average train loss: 0.0387average G loss: 0.0001, average realD loss: 0.0057, average fakeD loss: 0.0129, 
[09/23 18:59:40][INFO] visual_prompt:  435: Inference (val):avg data time: 6.72e-05, avg batch time: 0.1198, average loss: 0.5176
[09/23 18:59:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 18:59:54][INFO] visual_prompt:  435: Inference (test):avg data time: 7.06e-05, avg batch time: 0.1275, average loss: 0.5014
[09/23 18:59:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 97.83	
[09/23 18:59:54][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 0.025763421731720436
[09/23 19:01:02][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.84e-02, avg batch time: 0.7987, average train loss: 0.0369average G loss: 0.0001, average realD loss: 0.0052, average fakeD loss: 0.0079, 
[09/23 19:01:04][INFO] visual_prompt:  435: Inference (val):avg data time: 5.92e-05, avg batch time: 0.1198, average loss: 0.5115
[09/23 19:01:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:01:18][INFO] visual_prompt:  435: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1271, average loss: 0.5026
[09/23 19:01:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.04	top5: 97.79	
[09/23 19:01:19][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 0.024021157792146357
[09/23 19:02:27][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.78e-02, avg batch time: 0.7984, average train loss: 0.0412average G loss: 0.0001, average realD loss: 0.0056, average fakeD loss: 0.0131, 
[09/23 19:02:29][INFO] visual_prompt:  435: Inference (val):avg data time: 4.93e-05, avg batch time: 0.1203, average loss: 0.5112
[09/23 19:02:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 97.67	
[09/23 19:02:43][INFO] visual_prompt:  435: Inference (test):avg data time: 8.37e-05, avg batch time: 0.1272, average loss: 0.5012
[09/23 19:02:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 97.79	
[09/23 19:02:43][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 0.02232577439459129
[09/23 19:03:51][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.88e-02, avg batch time: 0.7992, average train loss: 0.0360average G loss: 0.0000, average realD loss: 0.0064, average fakeD loss: 0.0268, 
[09/23 19:03:53][INFO] visual_prompt:  435: Inference (val):avg data time: 5.58e-05, avg batch time: 0.1208, average loss: 0.5179
[09/23 19:03:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 97.33	
[09/23 19:04:07][INFO] visual_prompt:  435: Inference (test):avg data time: 9.31e-05, avg batch time: 0.1273, average loss: 0.5011
[09/23 19:04:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.72	
[09/23 19:04:07][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 0.02067933710257138
[09/23 19:05:15][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 1.82e-02, avg batch time: 0.7985, average train loss: 0.0364average G loss: 0.0001, average realD loss: 0.0044, average fakeD loss: 0.0303, 
[09/23 19:05:18][INFO] visual_prompt:  435: Inference (val):avg data time: 7.55e-05, avg batch time: 0.1208, average loss: 0.5194
[09/23 19:05:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.67	
[09/23 19:05:32][INFO] visual_prompt:  435: Inference (test):avg data time: 7.80e-05, avg batch time: 0.1269, average loss: 0.5022
[09/23 19:05:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.70	
[09/23 19:05:32][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.019083851846312665
[09/23 19:06:40][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 1.82e-02, avg batch time: 0.7986, average train loss: 0.0364average G loss: 0.0001, average realD loss: 0.0045, average fakeD loss: 0.0086, 
[09/23 19:06:42][INFO] visual_prompt:  435: Inference (val):avg data time: 6.72e-05, avg batch time: 0.1200, average loss: 0.5158
[09/23 19:06:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.67	
[09/23 19:06:56][INFO] visual_prompt:  435: Inference (test):avg data time: 8.11e-05, avg batch time: 0.1272, average loss: 0.5030
[09/23 19:06:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.72	
[09/23 19:06:57][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.017541262478834314
[09/23 19:08:05][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.87e-02, avg batch time: 0.7990, average train loss: 0.0350average G loss: 0.0001, average realD loss: 0.0052, average fakeD loss: 0.0110, 
[09/23 19:08:07][INFO] visual_prompt:  435: Inference (val):avg data time: 6.46e-05, avg batch time: 0.1196, average loss: 0.5150
[09/23 19:08:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:08:21][INFO] visual_prompt:  435: Inference (test):avg data time: 8.33e-05, avg batch time: 0.1272, average loss: 0.5032
[09/23 19:08:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.93	top5: 97.74	
[09/23 19:08:21][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.016053448407662853
[09/23 19:09:29][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 1.86e-02, avg batch time: 0.7989, average train loss: 0.0377average G loss: 0.0001, average realD loss: 0.0062, average fakeD loss: 0.0170, 
[09/23 19:09:32][INFO] visual_prompt:  435: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1195, average loss: 0.5162
[09/23 19:09:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.67	
[09/23 19:09:46][INFO] visual_prompt:  435: Inference (test):avg data time: 7.55e-05, avg batch time: 0.1268, average loss: 0.5032
[09/23 19:09:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.74	
[09/23 19:09:46][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.014622222305063881
[09/23 19:10:54][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.85e-02, avg batch time: 0.7987, average train loss: 0.0378average G loss: 0.0001, average realD loss: 0.0033, average fakeD loss: 0.0036, 
[09/23 19:10:56][INFO] visual_prompt:  435: Inference (val):avg data time: 7.48e-05, avg batch time: 0.1201, average loss: 0.5167
[09/23 19:10:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.67	
[09/23 19:11:11][INFO] visual_prompt:  435: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1270, average loss: 0.5020
[09/23 19:11:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.99	top5: 97.74	
[09/23 19:11:11][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.013249327899579881
[09/23 19:12:19][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.93e-02, avg batch time: 0.7998, average train loss: 0.0340average G loss: 0.0002, average realD loss: 0.0066, average fakeD loss: 0.0446, 
[09/23 19:12:21][INFO] visual_prompt:  435: Inference (val):avg data time: 7.45e-05, avg batch time: 0.1201, average loss: 0.5169
[09/23 19:12:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.67	
[09/23 19:12:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.93e-05, avg batch time: 0.1272, average loss: 0.5028
[09/23 19:12:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.76	
[09/23 19:12:36][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.011936437851565791
[09/23 19:13:44][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.87e-02, avg batch time: 0.7991, average train loss: 0.0362average G loss: 0.0001, average realD loss: 0.0033, average fakeD loss: 0.0318, 
[09/23 19:13:46][INFO] visual_prompt:  435: Inference (val):avg data time: 6.85e-05, avg batch time: 0.1200, average loss: 0.5218
[09/23 19:13:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:14:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.44e-05, avg batch time: 0.1272, average loss: 0.5040
[09/23 19:14:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.76	
[09/23 19:14:00][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.010685151715309898
[09/23 19:15:08][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.83e-02, avg batch time: 0.7987, average train loss: 0.0351average G loss: 0.0001, average realD loss: 0.0066, average fakeD loss: 0.0142, 
[09/23 19:15:10][INFO] visual_prompt:  435: Inference (val):avg data time: 7.84e-05, avg batch time: 0.1197, average loss: 0.5223
[09/23 19:15:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 97.50	
[09/23 19:15:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.57e-05, avg batch time: 0.1274, average loss: 0.5037
[09/23 19:15:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.99	top5: 97.74	
[09/23 19:15:24][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.009496993990223378
[09/23 19:16:32][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.94e-02, avg batch time: 0.7998, average train loss: 0.0361average G loss: 0.0001, average realD loss: 0.0056, average fakeD loss: 0.0051, 
[09/23 19:16:34][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1201, average loss: 0.5211
[09/23 19:16:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.50	
[09/23 19:16:48][INFO] visual_prompt:  435: Inference (test):avg data time: 8.37e-05, avg batch time: 0.1275, average loss: 0.5031
[09/23 19:16:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 97.77	
[09/23 19:16:48][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.00837341226347258
[09/23 19:17:56][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.87e-02, avg batch time: 0.7994, average train loss: 0.0340average G loss: 0.0001, average realD loss: 0.0058, average fakeD loss: 0.0114, 
[09/23 19:17:58][INFO] visual_prompt:  435: Inference (val):avg data time: 7.95e-05, avg batch time: 0.1203, average loss: 0.5215
[09/23 19:17:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:18:12][INFO] visual_prompt:  435: Inference (test):avg data time: 6.92e-05, avg batch time: 0.1286, average loss: 0.5046
[09/23 19:18:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.93	top5: 97.76	
[09/23 19:18:12][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.007315775446317063
[09/23 19:19:20][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.82e-02, avg batch time: 0.7988, average train loss: 0.0355average G loss: 0.0001, average realD loss: 0.0049, average fakeD loss: 0.0256, 
[09/23 19:19:22][INFO] visual_prompt:  435: Inference (val):avg data time: 5.14e-05, avg batch time: 0.1209, average loss: 0.5229
[09/23 19:19:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:19:36][INFO] visual_prompt:  435: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1281, average loss: 0.5048
[09/23 19:19:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.00	top5: 97.76	
[09/23 19:19:36][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.006325372106302074
[09/23 19:20:44][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.82e-02, avg batch time: 0.7990, average train loss: 0.0337average G loss: 0.0001, average realD loss: 0.0091, average fakeD loss: 0.0089, 
[09/23 19:20:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.00e-05, avg batch time: 0.1208, average loss: 0.5230
[09/23 19:20:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:21:00][INFO] visual_prompt:  435: Inference (test):avg data time: 6.46e-05, avg batch time: 0.1275, average loss: 0.5046
[09/23 19:21:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.00	top5: 97.77	
[09/23 19:21:00][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.005403408897337439
[09/23 19:22:08][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.93e-02, avg batch time: 0.8002, average train loss: 0.0352average G loss: 0.0000, average realD loss: 0.0044, average fakeD loss: 0.0335, 
[09/23 19:22:10][INFO] visual_prompt:  435: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1205, average loss: 0.5217
[09/23 19:22:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:22:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1276, average loss: 0.5043
[09/23 19:22:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.76	
[09/23 19:22:24][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.004551009089575793
[09/23 19:23:32][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.77e-02, avg batch time: 0.7983, average train loss: 0.0358average G loss: 0.0001, average realD loss: 0.0033, average fakeD loss: 0.0142, 
[09/23 19:23:34][INFO] visual_prompt:  435: Inference (val):avg data time: 7.76e-05, avg batch time: 0.1204, average loss: 0.5209
[09/23 19:23:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:23:48][INFO] visual_prompt:  435: Inference (test):avg data time: 8.74e-05, avg batch time: 0.1280, average loss: 0.5043
[09/23 19:23:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.76	
[09/23 19:23:48][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.00376921120088073
[09/23 19:24:56][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 2.14e-02, avg batch time: 0.8019, average train loss: 0.0363average G loss: 0.0001, average realD loss: 0.0058, average fakeD loss: 0.0090, 
[09/23 19:24:58][INFO] visual_prompt:  435: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1221, average loss: 0.5203
[09/23 19:24:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:25:12][INFO] visual_prompt:  435: Inference (test):avg data time: 7.99e-05, avg batch time: 0.1275, average loss: 0.5037
[09/23 19:25:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.76	
[09/23 19:25:12][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.0030589677315529043
[09/23 19:26:20][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.70e-02, avg batch time: 0.7974, average train loss: 0.0344average G loss: 0.0001, average realD loss: 0.0096, average fakeD loss: 0.0126, 
[09/23 19:26:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.82e-05, avg batch time: 0.1206, average loss: 0.5200
[09/23 19:26:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:26:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.13e-05, avg batch time: 0.1276, average loss: 0.5041
[09/23 19:26:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.11	top5: 97.74	
[09/23 19:26:36][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.002421144003855069
[09/23 19:27:44][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.91e-02, avg batch time: 0.7996, average train loss: 0.0355average G loss: 0.0001, average realD loss: 0.0096, average fakeD loss: 0.0289, 
[09/23 19:27:47][INFO] visual_prompt:  435: Inference (val):avg data time: 4.89e-05, avg batch time: 0.1205, average loss: 0.5198
[09/23 19:27:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.50	
[09/23 19:28:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1275, average loss: 0.5041
[09/23 19:28:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.76	
[09/23 19:28:00][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.0018565171077502204
[09/23 19:29:08][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.85e-02, avg batch time: 0.7991, average train loss: 0.0341average G loss: 0.0002, average realD loss: 0.0062, average fakeD loss: 0.0083, 
[09/23 19:29:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.76e-05, avg batch time: 0.1206, average loss: 0.5191
[09/23 19:29:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:29:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.69e-05, avg batch time: 0.1280, average loss: 0.5038
[09/23 19:29:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.04	top5: 97.76	
[09/23 19:29:24][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.0013657749541371444
[09/23 19:30:32][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 1.95e-02, avg batch time: 0.8003, average train loss: 0.0333average G loss: 0.0001, average realD loss: 0.0073, average fakeD loss: 0.0106, 
[09/23 19:30:35][INFO] visual_prompt:  435: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1198, average loss: 0.5192
[09/23 19:30:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:30:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.83e-05, avg batch time: 0.1271, average loss: 0.5039
[09/23 19:30:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.09	top5: 97.74	
[09/23 19:30:49][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.0009495154367369987
[09/23 19:31:57][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.98e-02, avg batch time: 0.8008, average train loss: 0.0334average G loss: 0.0005, average realD loss: 0.0087, average fakeD loss: 0.0253, 
[09/23 19:31:59][INFO] visual_prompt:  435: Inference (val):avg data time: 7.33e-05, avg batch time: 0.1201, average loss: 0.5191
[09/23 19:31:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:32:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.14e-05, avg batch time: 0.1276, average loss: 0.5038
[09/23 19:32:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.76	
[09/23 19:32:13][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.0006082457036518524
[09/23 19:33:21][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.87e-02, avg batch time: 0.7993, average train loss: 0.0357average G loss: 0.0001, average realD loss: 0.0078, average fakeD loss: 0.0135, 
[09/23 19:33:23][INFO] visual_prompt:  435: Inference (val):avg data time: 6.39e-05, avg batch time: 0.1204, average loss: 0.5192
[09/23 19:33:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:33:36][INFO] visual_prompt:  435: Inference (test):avg data time: 7.16e-05, avg batch time: 0.1279, average loss: 0.5039
[09/23 19:33:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.11	top5: 97.76	
[09/23 19:33:36][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.0003423815394829194
[09/23 19:34:45][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 1.97e-02, avg batch time: 0.8004, average train loss: 0.0330average G loss: 0.0001, average realD loss: 0.0099, average fakeD loss: 0.0083, 
[09/23 19:34:47][INFO] visual_prompt:  435: Inference (val):avg data time: 6.84e-05, avg batch time: 0.1200, average loss: 0.5192
[09/23 19:34:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:35:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.41e-05, avg batch time: 0.1274, average loss: 0.5039
[09/23 19:35:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.76	
[09/23 19:35:01][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.00015224685876098765
[09/23 19:36:09][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.92e-02, avg batch time: 0.7999, average train loss: 0.0351average G loss: 0.0001, average realD loss: 0.0053, average fakeD loss: 0.0091, 
[09/23 19:36:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1211, average loss: 0.5193
[09/23 19:36:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:36:24][INFO] visual_prompt:  435: Inference (test):avg data time: 6.61e-05, avg batch time: 0.1274, average loss: 0.5039
[09/23 19:36:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.77	
[09/23 19:36:25][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 3.807331130651487e-05
[09/23 19:37:33][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.80e-02, avg batch time: 0.7988, average train loss: 0.0334average G loss: 0.0002, average realD loss: 0.0041, average fakeD loss: 0.0120, 
[09/23 19:37:35][INFO] visual_prompt:  435: Inference (val):avg data time: 8.10e-05, avg batch time: 0.1202, average loss: 0.5193
[09/23 19:37:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.50	
[09/23 19:37:49][INFO] visual_prompt:  435: Inference (test):avg data time: 8.81e-05, avg batch time: 0.1274, average loss: 0.5039
[09/23 19:37:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.77	
