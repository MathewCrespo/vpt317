[09/23 10:10:46][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 10:10:46][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 10:10:46][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/23 10:10:46][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 10:10:46][INFO] visual_prompt:  109: Training with config:
[09/23 10:10:46][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr0.125_wd0.01/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 0.125,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.01,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 10:10:46][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 10:10:46][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 10:10:46][INFO] visual_prompt:   77: Number of images: 5394
[09/23 10:10:46][INFO] visual_prompt:   78: Number of classes: 200
[09/23 10:10:46][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 10:10:46][INFO] visual_prompt:   73: Loading validation data...
[09/23 10:10:46][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 10:10:46][INFO] visual_prompt:   77: Number of images: 600
[09/23 10:10:46][INFO] visual_prompt:   78: Number of classes: 200
[09/23 10:10:46][INFO] visual_prompt:   76: Loading test data...
[09/23 10:10:46][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 10:10:46][INFO] visual_prompt:   77: Number of images: 5794
[09/23 10:10:46][INFO] visual_prompt:   78: Number of classes: 200
[09/23 10:10:46][INFO] visual_prompt:  103: Constructing models...
[09/23 10:10:52][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 10:10:52][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 10:10:52][INFO] visual_prompt:   41: Device used for model: 0
[09/23 10:10:52][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 10:10:52][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 10:10:52][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 10:10:52][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/23 10:12:00][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.93e-02, avg batch time: 0.8028, average train loss: 5.3283average G loss: 6.8687, average realD loss: 11.3587, average fakeD loss: 0.6610, 
[09/23 10:12:02][INFO] visual_prompt:  435: Inference (val):avg data time: 5.65e-05, avg batch time: 0.1213, average loss: 5.3248
[09/23 10:12:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.00	top5: 2.00	
[09/23 10:12:16][INFO] visual_prompt:  435: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1278, average loss: 5.3260
[09/23 10:12:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.29	top5: 2.68	
[09/23 10:12:16][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.0125
[09/23 10:13:25][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.99e-02, avg batch time: 0.8045, average train loss: 5.3150average G loss: 0.0719, average realD loss: 1.9147, average fakeD loss: 1.0629, 
[09/23 10:13:27][INFO] visual_prompt:  435: Inference (val):avg data time: 4.91e-05, avg batch time: 0.1203, average loss: 5.3056
[09/23 10:13:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 10:13:40][INFO] visual_prompt:  435: Inference (test):avg data time: 7.70e-05, avg batch time: 0.1281, average loss: 5.3055
[09/23 10:13:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.60	top5: 2.30	
[09/23 10:13:40][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.005
[09/23 10:13:40][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.025
[09/23 10:14:49][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 2.00e-02, avg batch time: 0.8054, average train loss: 5.3085average G loss: 0.0000, average realD loss: 0.5050, average fakeD loss: 0.3460, 
[09/23 10:14:51][INFO] visual_prompt:  435: Inference (val):avg data time: 5.42e-05, avg batch time: 0.1211, average loss: 5.2985
[09/23 10:14:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/23 10:15:05][INFO] visual_prompt:  435: Inference (test):avg data time: 7.20e-05, avg batch time: 0.1279, average loss: 5.2985
[09/23 10:15:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.62	top5: 2.38	
[09/23 10:15:05][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.0375
[09/23 10:16:14][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 2.07e-02, avg batch time: 0.8064, average train loss: 5.3077average G loss: 0.0002, average realD loss: 0.1788, average fakeD loss: 0.1386, 
[09/23 10:16:16][INFO] visual_prompt:  435: Inference (val):avg data time: 7.00e-05, avg batch time: 0.1201, average loss: 5.2971
[09/23 10:16:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.00	top5: 3.50	
[09/23 10:16:30][INFO] visual_prompt:  435: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1277, average loss: 5.2972
[09/23 10:16:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.81	top5: 2.83	
[09/23 10:16:30][INFO] visual_prompt:  357: Best epoch 4: best metric: 0.010
[09/23 10:16:30][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 0.05
[09/23 10:17:38][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.79e-02, avg batch time: 0.8033, average train loss: 5.2997average G loss: 0.0006, average realD loss: 0.0817, average fakeD loss: 0.0748, 
[09/23 10:17:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.76e-05, avg batch time: 0.1208, average loss: 5.1894
[09/23 10:17:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 2.17	top5: 11.00	
[09/23 10:17:54][INFO] visual_prompt:  435: Inference (test):avg data time: 8.22e-05, avg batch time: 0.1279, average loss: 5.1899
[09/23 10:17:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 2.74	top5: 11.48	
[09/23 10:17:54][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.022
[09/23 10:17:54][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 0.0625
[09/23 10:19:03][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.96e-02, avg batch time: 0.8057, average train loss: 4.2572average G loss: 0.0052, average realD loss: 0.0714, average fakeD loss: 0.0681, 
[09/23 10:19:06][INFO] visual_prompt:  435: Inference (val):avg data time: 8.84e-05, avg batch time: 0.1204, average loss: 3.2365
[09/23 10:19:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 57.33	top5: 90.00	
[09/23 10:19:19][INFO] visual_prompt:  435: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1278, average loss: 3.2280
[09/23 10:19:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 60.04	top5: 89.14	
[09/23 10:19:20][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.573
[09/23 10:19:20][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 0.075
[09/23 10:20:28][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.98e-02, avg batch time: 0.8058, average train loss: 2.7883average G loss: 0.0133, average realD loss: 0.0756, average fakeD loss: 0.0724, 
[09/23 10:20:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.38e-05, avg batch time: 0.1199, average loss: 2.4262
[09/23 10:20:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.17	top5: 94.67	
[09/23 10:20:44][INFO] visual_prompt:  435: Inference (test):avg data time: 8.26e-05, avg batch time: 0.1280, average loss: 2.4287
[09/23 10:20:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.19	top5: 95.03	
[09/23 10:20:44][INFO] visual_prompt:  357: Best epoch 7: best metric: 0.662
[09/23 10:20:44][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 0.0875
[09/23 10:21:53][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.84e-02, avg batch time: 0.8044, average train loss: 2.4144average G loss: 0.0167, average realD loss: 0.0758, average fakeD loss: 0.0745, 
[09/23 10:21:55][INFO] visual_prompt:  435: Inference (val):avg data time: 5.27e-05, avg batch time: 0.1221, average loss: 2.2881
[09/23 10:21:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.17	top5: 94.00	
[09/23 10:22:08][INFO] visual_prompt:  435: Inference (test):avg data time: 5.94e-05, avg batch time: 0.1282, average loss: 2.2837
[09/23 10:22:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.67	top5: 94.05	
[09/23 10:22:09][INFO] visual_prompt:  357: Best epoch 8: best metric: 0.672
[09/23 10:22:09][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 0.1
[09/23 10:23:17][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.88e-02, avg batch time: 0.8050, average train loss: 2.4023average G loss: 0.0180, average realD loss: 0.0763, average fakeD loss: 0.0789, 
[09/23 10:23:19][INFO] visual_prompt:  435: Inference (val):avg data time: 6.05e-05, avg batch time: 0.1211, average loss: 2.2927
[09/23 10:23:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.33	top5: 92.83	
[09/23 10:23:33][INFO] visual_prompt:  435: Inference (test):avg data time: 6.00e-05, avg batch time: 0.1281, average loss: 2.2924
[09/23 10:23:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.34	top5: 93.30	
[09/23 10:23:33][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 0.1125
[09/23 10:24:42][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.94e-02, avg batch time: 0.8056, average train loss: 2.4047average G loss: 0.0182, average realD loss: 0.0769, average fakeD loss: 0.0770, 
[09/23 10:24:44][INFO] visual_prompt:  435: Inference (val):avg data time: 7.13e-05, avg batch time: 0.1209, average loss: 2.2490
[09/23 10:24:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.00	top5: 95.67	
[09/23 10:24:58][INFO] visual_prompt:  435: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1277, average loss: 2.2385
[09/23 10:24:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.90	top5: 95.67	
[09/23 10:24:58][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 0.125
[09/23 10:26:06][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.84e-02, avg batch time: 0.8048, average train loss: 2.4305average G loss: 0.0188, average realD loss: 0.0720, average fakeD loss: 0.0768, 
[09/23 10:26:09][INFO] visual_prompt:  435: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1209, average loss: 2.2758
[09/23 10:26:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.50	top5: 93.17	
[09/23 10:26:22][INFO] visual_prompt:  435: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1284, average loss: 2.2853
[09/23 10:26:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.40	top5: 93.20	
[09/23 10:26:22][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 0.12496192668869349
[09/23 10:27:31][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.93e-02, avg batch time: 0.8057, average train loss: 2.4337average G loss: 0.0170, average realD loss: 0.0740, average fakeD loss: 0.0780, 
[09/23 10:27:33][INFO] visual_prompt:  435: Inference (val):avg data time: 6.90e-05, avg batch time: 0.1203, average loss: 2.2983
[09/23 10:27:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.50	top5: 93.33	
[09/23 10:27:47][INFO] visual_prompt:  435: Inference (test):avg data time: 8.16e-05, avg batch time: 0.1283, average loss: 2.2914
[09/23 10:27:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.34	top5: 92.99	
[09/23 10:27:47][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 0.12484775314123901
[09/23 10:28:55][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.85e-02, avg batch time: 0.8049, average train loss: 2.4242average G loss: 0.0179, average realD loss: 0.0739, average fakeD loss: 0.0787, 
[09/23 10:28:58][INFO] visual_prompt:  435: Inference (val):avg data time: 5.52e-05, avg batch time: 0.1219, average loss: 2.3078
[09/23 10:28:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.33	top5: 93.33	
[09/23 10:29:11][INFO] visual_prompt:  435: Inference (test):avg data time: 6.28e-05, avg batch time: 0.1286, average loss: 2.3182
[09/23 10:29:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.05	top5: 93.73	
[09/23 10:29:11][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 0.12465761846051708
[09/23 10:30:20][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.83e-02, avg batch time: 0.8048, average train loss: 2.8931average G loss: 0.0242, average realD loss: 0.0817, average fakeD loss: 0.0843, 
[09/23 10:30:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.08e-05, avg batch time: 0.1225, average loss: 3.0007
[09/23 10:30:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.33	top5: 92.33	
[09/23 10:30:35][INFO] visual_prompt:  435: Inference (test):avg data time: 5.51e-05, avg batch time: 0.1285, average loss: 3.0004
[09/23 10:30:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.70	top5: 92.79	
[09/23 10:30:35][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 0.12439175429634815
[09/23 10:31:44][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.82e-02, avg batch time: 0.8051, average train loss: 2.6144average G loss: 0.0168, average realD loss: 0.0777, average fakeD loss: 0.0827, 
[09/23 10:31:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.22e-05, avg batch time: 0.1205, average loss: 2.3142
[09/23 10:31:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.67	top5: 92.67	
[09/23 10:32:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.66e-05, avg batch time: 0.1279, average loss: 2.2933
[09/23 10:32:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.60	top5: 93.34	
[09/23 10:32:00][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 0.12405048456326301
[09/23 10:33:08][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.94e-02, avg batch time: 0.8060, average train loss: 2.4322average G loss: 0.0181, average realD loss: 0.0736, average fakeD loss: 0.0809, 
[09/23 10:33:11][INFO] visual_prompt:  435: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1205, average loss: 2.3849
[09/23 10:33:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.50	top5: 93.83	
[09/23 10:33:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.50e-05, avg batch time: 0.1280, average loss: 2.3920
[09/23 10:33:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.31	top5: 93.75	
[09/23 10:33:25][INFO] visual_prompt:  357: Best epoch 16: best metric: 0.695
[09/23 10:33:25][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 0.12363422504586286
[09/23 10:34:33][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.98e-02, avg batch time: 0.8067, average train loss: 2.4133average G loss: 0.0183, average realD loss: 0.0767, average fakeD loss: 0.0832, 
[09/23 10:34:35][INFO] visual_prompt:  435: Inference (val):avg data time: 7.04e-05, avg batch time: 0.1209, average loss: 2.2942
[09/23 10:34:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.00	top5: 95.67	
[09/23 10:34:49][INFO] visual_prompt:  435: Inference (test):avg data time: 8.86e-05, avg batch time: 0.1280, average loss: 2.2950
[09/23 10:34:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.53	top5: 94.74	
[09/23 10:34:49][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 0.12314348289224977
[09/23 10:35:58][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.86e-02, avg batch time: 0.8057, average train loss: 2.3909average G loss: 0.0175, average realD loss: 0.0721, average fakeD loss: 0.0786, 
[09/23 10:36:00][INFO] visual_prompt:  435: Inference (val):avg data time: 7.43e-05, avg batch time: 0.1212, average loss: 2.3185
[09/23 10:36:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.33	top5: 94.67	
[09/23 10:36:14][INFO] visual_prompt:  435: Inference (test):avg data time: 8.29e-05, avg batch time: 0.1278, average loss: 2.3355
[09/23 10:36:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.21	top5: 95.13	
[09/23 10:36:14][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 0.12257885599614493
[09/23 10:37:23][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.88e-02, avg batch time: 0.8058, average train loss: 2.4152average G loss: 0.0184, average realD loss: 0.0736, average fakeD loss: 0.0823, 
[09/23 10:37:25][INFO] visual_prompt:  435: Inference (val):avg data time: 7.72e-05, avg batch time: 0.1208, average loss: 2.3246
[09/23 10:37:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.33	top5: 93.83	
[09/23 10:37:39][INFO] visual_prompt:  435: Inference (test):avg data time: 9.70e-05, avg batch time: 0.1280, average loss: 2.3227
[09/23 10:37:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.93	top5: 94.36	
[09/23 10:37:39][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 0.1219410322684471
[09/23 10:38:48][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.93e-02, avg batch time: 0.8063, average train loss: 2.4346average G loss: 0.0176, average realD loss: 0.0725, average fakeD loss: 0.0800, 
[09/23 10:38:50][INFO] visual_prompt:  435: Inference (val):avg data time: 6.09e-05, avg batch time: 0.1210, average loss: 2.2679
[09/23 10:38:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.50	top5: 94.33	
[09/23 10:39:03][INFO] visual_prompt:  435: Inference (test):avg data time: 8.75e-05, avg batch time: 0.1281, average loss: 2.2717
[09/23 10:39:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.50	top5: 94.79	
[09/23 10:39:03][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 0.12123078879911928
[09/23 10:40:12][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.92e-02, avg batch time: 0.8065, average train loss: 2.4250average G loss: 0.0182, average realD loss: 0.0738, average fakeD loss: 0.0809, 
[09/23 10:40:14][INFO] visual_prompt:  435: Inference (val):avg data time: 7.56e-05, avg batch time: 0.1209, average loss: 2.3303
[09/23 10:40:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.33	top5: 94.00	
[09/23 10:40:28][INFO] visual_prompt:  435: Inference (test):avg data time: 8.33e-05, avg batch time: 0.1283, average loss: 2.3213
[09/23 10:40:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.89	top5: 93.42	
[09/23 10:40:28][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 0.12044899091042421
[09/23 10:41:37][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.89e-02, avg batch time: 0.8062, average train loss: 2.4681average G loss: 0.0188, average realD loss: 0.0748, average fakeD loss: 0.0809, 
[09/23 10:41:39][INFO] visual_prompt:  435: Inference (val):avg data time: 8.28e-05, avg batch time: 0.1215, average loss: 2.3815
[09/23 10:41:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.50	top5: 94.17	
[09/23 10:41:53][INFO] visual_prompt:  435: Inference (test):avg data time: 8.00e-05, avg batch time: 0.1281, average loss: 2.3679
[09/23 10:41:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.50	top5: 94.43	
[09/23 10:41:53][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 0.11959659110266255
[09/23 10:43:02][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.88e-02, avg batch time: 0.8063, average train loss: 2.4477average G loss: 0.0177, average realD loss: 0.0722, average fakeD loss: 0.0805, 
[09/23 10:43:04][INFO] visual_prompt:  435: Inference (val):avg data time: 6.46e-05, avg batch time: 0.1200, average loss: 2.3152
[09/23 10:43:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.83	top5: 95.00	
[09/23 10:43:18][INFO] visual_prompt:  435: Inference (test):avg data time: 8.18e-05, avg batch time: 0.1278, average loss: 2.3095
[09/23 10:43:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.95	top5: 95.17	
[09/23 10:43:18][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 0.11867462789369794
[09/23 10:44:27][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.85e-02, avg batch time: 0.8060, average train loss: 2.3900average G loss: 0.0168, average realD loss: 0.0748, average fakeD loss: 0.0793, 
[09/23 10:44:29][INFO] visual_prompt:  435: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1221, average loss: 2.2621
[09/23 10:44:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.67	top5: 95.17	
[09/23 10:44:43][INFO] visual_prompt:  435: Inference (test):avg data time: 8.51e-05, avg batch time: 0.1284, average loss: 2.2747
[09/23 10:44:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.41	top5: 94.63	
[09/23 10:44:43][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 0.11768422455368294
[09/23 10:45:51][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.88e-02, avg batch time: 0.8059, average train loss: 2.3954average G loss: 0.0177, average realD loss: 0.0759, average fakeD loss: 0.0823, 
[09/23 10:45:54][INFO] visual_prompt:  435: Inference (val):avg data time: 6.77e-05, avg batch time: 0.1198, average loss: 2.2771
[09/23 10:45:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.83	top5: 94.50	
[09/23 10:46:08][INFO] visual_prompt:  435: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1279, average loss: 2.2726
[09/23 10:46:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.86	top5: 94.60	
[09/23 10:46:08][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 0.11662658773652743
[09/23 10:47:16][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.85e-02, avg batch time: 0.8061, average train loss: 2.4028average G loss: 0.0189, average realD loss: 0.0747, average fakeD loss: 0.0811, 
[09/23 10:47:19][INFO] visual_prompt:  435: Inference (val):avg data time: 8.72e-05, avg batch time: 0.1200, average loss: 2.2811
[09/23 10:47:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.00	top5: 94.50	
[09/23 10:47:33][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1280, average loss: 2.2913
[09/23 10:47:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.67	top5: 93.92	
[09/23 10:47:33][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 0.11550300600977662
[09/23 10:48:42][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.96e-02, avg batch time: 0.8082, average train loss: 2.4060average G loss: 0.0178, average realD loss: 0.0733, average fakeD loss: 0.0803, 
[09/23 10:48:45][INFO] visual_prompt:  435: Inference (val):avg data time: 9.08e-05, avg batch time: 0.1214, average loss: 2.3209
[09/23 10:48:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.50	top5: 95.00	
[09/23 10:49:05][INFO] visual_prompt:  435: Inference (test):avg data time: 1.96e-04, avg batch time: 0.1282, average loss: 2.3195
[09/23 10:49:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.70	top5: 94.51	
[09/23 10:49:05][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 0.1143148482846901
[09/23 10:50:15][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 3.21e-02, avg batch time: 0.8205, average train loss: 2.4342average G loss: 0.0185, average realD loss: 0.0771, average fakeD loss: 0.0801, 
[09/23 10:50:18][INFO] visual_prompt:  435: Inference (val):avg data time: 8.69e-05, avg batch time: 0.1205, average loss: 2.3408
[09/23 10:50:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.83	top5: 94.50	
[09/23 10:50:37][INFO] visual_prompt:  435: Inference (test):avg data time: 1.96e-04, avg batch time: 0.1277, average loss: 2.3465
[09/23 10:50:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.03	top5: 94.48	
[09/23 10:50:37][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 0.11306356214843422
[09/23 10:51:46][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 2.38e-02, avg batch time: 0.8131, average train loss: 2.4256average G loss: 0.0170, average realD loss: 0.0756, average fakeD loss: 0.0806, 
[09/23 10:51:49][INFO] visual_prompt:  435: Inference (val):avg data time: 1.12e-04, avg batch time: 0.1217, average loss: 2.2935
[09/23 10:51:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 95.17	
[09/23 10:52:04][INFO] visual_prompt:  435: Inference (test):avg data time: 1.72e-04, avg batch time: 0.1278, average loss: 2.2936
[09/23 10:52:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.04	top5: 95.41	
[09/23 10:52:04][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 0.11175067210042011
[09/23 10:53:14][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 2.99e-02, avg batch time: 0.8190, average train loss: 2.3942average G loss: 0.0175, average realD loss: 0.0762, average fakeD loss: 0.0794, 
[09/23 10:53:17][INFO] visual_prompt:  435: Inference (val):avg data time: 1.18e-04, avg batch time: 0.1206, average loss: 2.2888
[09/23 10:53:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.67	top5: 94.67	
[09/23 10:53:34][INFO] visual_prompt:  435: Inference (test):avg data time: 1.74e-04, avg batch time: 0.1279, average loss: 2.2839
[09/23 10:53:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.72	top5: 94.22	
[09/23 10:53:34][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 0.11037777769493612
[09/23 10:54:44][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.98e-02, avg batch time: 0.8093, average train loss: 2.3883average G loss: 0.0171, average realD loss: 0.0726, average fakeD loss: 0.0816, 
[09/23 10:54:47][INFO] visual_prompt:  435: Inference (val):avg data time: 1.07e-04, avg batch time: 0.1202, average loss: 2.2825
[09/23 10:54:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.33	top5: 95.00	
[09/23 10:55:07][INFO] visual_prompt:  435: Inference (test):avg data time: 2.52e-04, avg batch time: 0.1284, average loss: 2.2824
[09/23 10:55:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.00	top5: 95.10	
[09/23 10:55:07][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 0.10894655159233714
[09/23 10:56:16][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 2.58e-02, avg batch time: 0.8134, average train loss: 2.4033average G loss: 0.0178, average realD loss: 0.0753, average fakeD loss: 0.0795, 
[09/23 10:56:19][INFO] visual_prompt:  435: Inference (val):avg data time: 6.76e-05, avg batch time: 0.1206, average loss: 2.3115
[09/23 10:56:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.33	top5: 94.17	
[09/23 10:56:43][INFO] visual_prompt:  435: Inference (test):avg data time: 1.84e-04, avg batch time: 0.1282, average loss: 2.3084
[09/23 10:56:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.57	top5: 94.94	
[09/23 10:56:43][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 0.10745873752116569
[09/23 10:57:52][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 2.53e-02, avg batch time: 0.8123, average train loss: 2.3718average G loss: 0.0175, average realD loss: 0.0738, average fakeD loss: 0.0800, 
[09/23 10:57:55][INFO] visual_prompt:  435: Inference (val):avg data time: 1.01e-04, avg batch time: 0.1202, average loss: 2.2586
[09/23 10:57:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.50	top5: 94.33	
[09/23 10:58:12][INFO] visual_prompt:  435: Inference (test):avg data time: 1.92e-04, avg batch time: 0.1284, average loss: 2.2533
[09/23 10:58:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.91	top5: 94.79	
[09/23 10:58:12][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 0.10591614815368733
[09/23 10:59:22][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 3.05e-02, avg batch time: 0.8175, average train loss: 2.3578average G loss: 0.0175, average realD loss: 0.0776, average fakeD loss: 0.0827, 
[09/23 10:59:25][INFO] visual_prompt:  435: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1203, average loss: 2.2534
[09/23 10:59:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 95.17	
[09/23 10:59:44][INFO] visual_prompt:  435: Inference (test):avg data time: 1.80e-04, avg batch time: 0.1278, average loss: 2.2507
[09/23 10:59:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.50	top5: 94.67	
[09/23 10:59:44][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 0.10432066289742864
[09/23 11:00:53][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 2.71e-02, avg batch time: 0.8143, average train loss: 2.3997average G loss: 0.0183, average realD loss: 0.0741, average fakeD loss: 0.0785, 
[09/23 11:00:56][INFO] visual_prompt:  435: Inference (val):avg data time: 1.15e-04, avg batch time: 0.1206, average loss: 2.2698
[09/23 11:00:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.00	top5: 95.67	
[09/23 11:01:13][INFO] visual_prompt:  435: Inference (test):avg data time: 1.91e-04, avg batch time: 0.1274, average loss: 2.2778
[09/23 11:01:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.21	top5: 95.84	
[09/23 11:01:13][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 0.1026742256054087
[09/23 11:02:23][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 2.52e-02, avg batch time: 0.8126, average train loss: 2.3700average G loss: 0.0166, average realD loss: 0.0752, average fakeD loss: 0.0805, 
[09/23 11:02:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.82e-05, avg batch time: 0.1197, average loss: 2.3715
[09/23 11:02:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.33	top5: 94.00	
[09/23 11:02:44][INFO] visual_prompt:  435: Inference (test):avg data time: 2.00e-04, avg batch time: 0.1276, average loss: 2.3751
[09/23 11:02:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.54	top5: 94.27	
[09/23 11:02:44][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 0.10097884220785364
[09/23 11:03:53][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 2.61e-02, avg batch time: 0.8137, average train loss: 2.3628average G loss: 0.0175, average realD loss: 0.0738, average fakeD loss: 0.0781, 
[09/23 11:03:57][INFO] visual_prompt:  435: Inference (val):avg data time: 8.92e-05, avg batch time: 0.1207, average loss: 2.2569
[09/23 11:03:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.00	top5: 95.50	
[09/23 11:04:14][INFO] visual_prompt:  435: Inference (test):avg data time: 1.55e-04, avg batch time: 0.1274, average loss: 2.2519
[09/23 11:04:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.78	top5: 95.41	
[09/23 11:04:14][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 0.09923657826827957
[09/23 11:05:24][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 2.85e-02, avg batch time: 0.8158, average train loss: 2.3677average G loss: 0.0173, average realD loss: 0.0748, average fakeD loss: 0.0825, 
[09/23 11:05:27][INFO] visual_prompt:  435: Inference (val):avg data time: 8.24e-05, avg batch time: 0.1201, average loss: 2.2623
[09/23 11:05:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 95.17	
[09/23 11:05:45][INFO] visual_prompt:  435: Inference (test):avg data time: 1.42e-04, avg batch time: 0.1284, average loss: 2.2603
[09/23 11:05:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.31	top5: 95.08	
[09/23 11:05:45][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 0.09744955646692167
[09/23 11:06:54][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 2.30e-02, avg batch time: 0.8119, average train loss: 2.3823average G loss: 0.0169, average realD loss: 0.0744, average fakeD loss: 0.0794, 
[09/23 11:06:58][INFO] visual_prompt:  435: Inference (val):avg data time: 1.47e-04, avg batch time: 0.1212, average loss: 2.2779
[09/23 11:06:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.17	top5: 96.33	
[09/23 11:07:16][INFO] visual_prompt:  435: Inference (test):avg data time: 1.54e-04, avg batch time: 0.1280, average loss: 2.2701
[09/23 11:07:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.94	top5: 96.25	
[09/23 11:07:16][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 0.0956199540145753
[09/23 11:08:25][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.99e-02, avg batch time: 0.8078, average train loss: 2.3367average G loss: 0.0162, average realD loss: 0.0709, average fakeD loss: 0.0777, 
[09/23 11:08:29][INFO] visual_prompt:  435: Inference (val):avg data time: 1.03e-04, avg batch time: 0.1207, average loss: 2.2777
[09/23 11:08:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.50	top5: 94.50	
[09/23 11:08:47][INFO] visual_prompt:  435: Inference (test):avg data time: 1.73e-04, avg batch time: 0.1275, average loss: 2.2631
[09/23 11:08:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.91	top5: 95.18	
[09/23 11:08:47][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 0.09375
[09/23 11:09:56][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 2.28e-02, avg batch time: 0.8117, average train loss: 2.3435average G loss: 0.0161, average realD loss: 0.0727, average fakeD loss: 0.0783, 
[09/23 11:09:59][INFO] visual_prompt:  435: Inference (val):avg data time: 7.32e-05, avg batch time: 0.1210, average loss: 2.2302
[09/23 11:09:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.00	top5: 95.50	
[09/23 11:10:17][INFO] visual_prompt:  435: Inference (test):avg data time: 1.95e-04, avg batch time: 0.1278, average loss: 2.2271
[09/23 11:10:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.05	top5: 96.19	
[09/23 11:10:17][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 0.09184197267411817
[09/23 11:11:26][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 2.81e-02, avg batch time: 0.8165, average train loss: 2.3762average G loss: 0.0168, average realD loss: 0.0750, average fakeD loss: 0.0814, 
[09/23 11:11:29][INFO] visual_prompt:  435: Inference (val):avg data time: 1.03e-04, avg batch time: 0.1204, average loss: 2.2438
[09/23 11:11:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.83	top5: 94.67	
[09/23 11:11:45][INFO] visual_prompt:  435: Inference (test):avg data time: 1.46e-04, avg batch time: 0.1278, average loss: 2.2352
[09/23 11:11:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.31	top5: 94.80	
[09/23 11:11:45][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 0.08989819667431734
[09/23 11:12:55][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 3.08e-02, avg batch time: 0.8198, average train loss: 2.3235average G loss: 0.0164, average realD loss: 0.0717, average fakeD loss: 0.0792, 
[09/23 11:13:00][INFO] visual_prompt:  435: Inference (val):avg data time: 1.08e-04, avg batch time: 0.1217, average loss: 2.2261
[09/23 11:13:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.00	top5: 95.00	
[09/23 11:13:19][INFO] visual_prompt:  435: Inference (test):avg data time: 1.49e-04, avg batch time: 0.1287, average loss: 2.2258
[09/23 11:13:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.18	top5: 94.75	
[09/23 11:13:19][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 0.08792104019223752
[09/23 11:14:29][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 2.56e-02, avg batch time: 0.8141, average train loss: 2.3124average G loss: 0.0162, average realD loss: 0.0723, average fakeD loss: 0.0779, 
[09/23 11:14:31][INFO] visual_prompt:  435: Inference (val):avg data time: 8.36e-05, avg batch time: 0.1203, average loss: 2.2085
[09/23 11:14:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.50	top5: 94.67	
[09/23 11:14:49][INFO] visual_prompt:  435: Inference (test):avg data time: 1.05e-04, avg batch time: 0.1279, average loss: 2.2121
[09/23 11:14:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.81	top5: 95.22	
[09/23 11:14:49][INFO] visual_prompt:  357: Best epoch 44: best metric: 0.715
[09/23 11:14:49][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 0.08591291208849451
[09/23 11:15:58][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 2.29e-02, avg batch time: 0.8106, average train loss: 2.3293average G loss: 0.0166, average realD loss: 0.0740, average fakeD loss: 0.0787, 
[09/23 11:16:00][INFO] visual_prompt:  435: Inference (val):avg data time: 8.69e-05, avg batch time: 0.1211, average loss: 2.2233
[09/23 11:16:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.50	top5: 96.50	
[09/23 11:16:14][INFO] visual_prompt:  435: Inference (test):avg data time: 8.58e-05, avg batch time: 0.1278, average loss: 2.2307
[09/23 11:16:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.80	top5: 96.01	
[09/23 11:16:15][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 0.0838762589578543
[09/23 11:17:24][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 2.39e-02, avg batch time: 0.8114, average train loss: 2.3087average G loss: 0.0164, average realD loss: 0.0715, average fakeD loss: 0.0778, 
[09/23 11:17:26][INFO] visual_prompt:  435: Inference (val):avg data time: 8.09e-05, avg batch time: 0.1203, average loss: 2.2174
[09/23 11:17:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.00	top5: 95.67	
[09/23 11:17:44][INFO] visual_prompt:  435: Inference (test):avg data time: 1.19e-04, avg batch time: 0.1276, average loss: 2.2149
[09/23 11:17:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.45	top5: 95.56	
[09/23 11:17:44][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 0.08181356214843422
[09/23 11:18:53][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 2.44e-02, avg batch time: 0.8113, average train loss: 2.3076average G loss: 0.0157, average realD loss: 0.0718, average fakeD loss: 0.0783, 
[09/23 11:18:56][INFO] visual_prompt:  435: Inference (val):avg data time: 9.68e-05, avg batch time: 0.1213, average loss: 2.2037
[09/23 11:18:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.33	top5: 96.50	
[09/23 11:19:10][INFO] visual_prompt:  435: Inference (test):avg data time: 9.45e-05, avg batch time: 0.1280, average loss: 2.2131
[09/23 11:19:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.18	top5: 95.67	
[09/23 11:19:10][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 0.07972733473856244
[09/23 11:20:19][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 2.27e-02, avg batch time: 0.8098, average train loss: 2.3096average G loss: 0.0164, average realD loss: 0.0728, average fakeD loss: 0.0792, 
[09/23 11:20:22][INFO] visual_prompt:  435: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1213, average loss: 2.2439
[09/23 11:20:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.67	top5: 96.83	
[09/23 11:20:37][INFO] visual_prompt:  435: Inference (test):avg data time: 1.04e-04, avg batch time: 0.1276, average loss: 2.2360
[09/23 11:20:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.02	top5: 96.03	
[09/23 11:20:37][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 0.07762011847497922
[09/23 11:21:46][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.84e-02, avg batch time: 0.8060, average train loss: 2.3047average G loss: 0.0159, average realD loss: 0.0743, average fakeD loss: 0.0814, 
[09/23 11:21:48][INFO] visual_prompt:  435: Inference (val):avg data time: 8.24e-05, avg batch time: 0.1209, average loss: 2.2170
[09/23 11:21:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.50	top5: 95.67	
[09/23 11:22:03][INFO] visual_prompt:  435: Inference (test):avg data time: 8.64e-05, avg batch time: 0.1281, average loss: 2.2114
[09/23 11:22:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.99	top5: 95.75	
[09/23 11:22:03][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 0.07549448067610995
[09/23 11:23:13][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 2.35e-02, avg batch time: 0.8104, average train loss: 2.3041average G loss: 0.0163, average realD loss: 0.0741, average fakeD loss: 0.0785, 
[09/23 11:23:15][INFO] visual_prompt:  435: Inference (val):avg data time: 8.03e-05, avg batch time: 0.1209, average loss: 2.2326
[09/23 11:23:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.33	top5: 94.50	
[09/23 11:23:29][INFO] visual_prompt:  435: Inference (test):avg data time: 8.31e-05, avg batch time: 0.1285, average loss: 2.2418
[09/23 11:23:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.78	top5: 95.17	
[09/23 11:23:29][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 0.07335301110418316
[09/23 11:24:38][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 2.49e-02, avg batch time: 0.8119, average train loss: 2.3581average G loss: 0.0162, average realD loss: 0.0738, average fakeD loss: 0.0788, 
[09/23 11:24:41][INFO] visual_prompt:  435: Inference (val):avg data time: 6.85e-05, avg batch time: 0.1210, average loss: 2.2295
[09/23 11:24:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.33	top5: 96.17	
[09/23 11:24:58][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1276, average loss: 2.2300
[09/23 11:24:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.19	top5: 95.70	
[09/23 11:24:58][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 0.07119831881000409
[09/23 11:26:06][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 2.08e-02, avg batch time: 0.8075, average train loss: 2.2892average G loss: 0.0160, average realD loss: 0.0711, average fakeD loss: 0.0757, 
[09/23 11:26:09][INFO] visual_prompt:  435: Inference (val):avg data time: 5.88e-05, avg batch time: 0.1215, average loss: 2.2040
[09/23 11:26:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.33	top5: 95.83	
[09/23 11:26:26][INFO] visual_prompt:  435: Inference (test):avg data time: 1.15e-04, avg batch time: 0.1271, average loss: 2.2047
[09/23 11:26:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.84	top5: 96.03	
[09/23 11:26:26][INFO] visual_prompt:  357: Best epoch 52: best metric: 0.743
[09/23 11:26:26][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 0.06903302895422835
[09/23 11:27:34][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 2.01e-02, avg batch time: 0.8067, average train loss: 2.2975average G loss: 0.0165, average realD loss: 0.0722, average fakeD loss: 0.0779, 
[09/23 11:27:37][INFO] visual_prompt:  435: Inference (val):avg data time: 1.44e-04, avg batch time: 0.1211, average loss: 2.1941
[09/23 11:27:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.17	top5: 96.00	
[09/23 11:27:51][INFO] visual_prompt:  435: Inference (test):avg data time: 8.25e-05, avg batch time: 0.1279, average loss: 2.2010
[09/23 11:27:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.33	top5: 96.84	
[09/23 11:27:51][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 0.06685977960900782
[09/23 11:29:00][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.97e-02, avg batch time: 0.8070, average train loss: 2.2740average G loss: 0.0153, average realD loss: 0.0693, average fakeD loss: 0.0777, 
[09/23 11:29:03][INFO] visual_prompt:  435: Inference (val):avg data time: 7.63e-05, avg batch time: 0.1215, average loss: 2.2077
[09/23 11:29:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.33	top5: 96.00	
[09/23 11:29:19][INFO] visual_prompt:  435: Inference (test):avg data time: 9.06e-05, avg batch time: 0.1275, average loss: 2.2090
[09/23 11:29:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.56	top5: 96.69	
[09/23 11:29:19][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 0.06468121854390632
[09/23 11:30:27][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.89e-02, avg batch time: 0.8065, average train loss: 2.2739average G loss: 0.0157, average realD loss: 0.0733, average fakeD loss: 0.0787, 
[09/23 11:30:30][INFO] visual_prompt:  435: Inference (val):avg data time: 6.23e-05, avg batch time: 0.1211, average loss: 2.4025
[09/23 11:30:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.67	top5: 95.50	
[09/23 11:30:45][INFO] visual_prompt:  435: Inference (test):avg data time: 9.51e-05, avg batch time: 0.1280, average loss: 2.3958
[09/23 11:30:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.61	top5: 95.84	
[09/23 11:30:45][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 0.0625
[09/23 11:31:54][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 2.20e-02, avg batch time: 0.8095, average train loss: 2.3021average G loss: 0.0167, average realD loss: 0.0720, average fakeD loss: 0.0796, 
[09/23 11:31:57][INFO] visual_prompt:  435: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1216, average loss: 2.2202
[09/23 11:31:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 97.17	
[09/23 11:32:11][INFO] visual_prompt:  435: Inference (test):avg data time: 8.99e-05, avg batch time: 0.1285, average loss: 2.2232
[09/23 11:32:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.87	top5: 96.63	
[09/23 11:32:11][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 0.060318781456093706
[09/23 11:33:20][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 2.23e-02, avg batch time: 0.8097, average train loss: 2.2707average G loss: 0.0154, average realD loss: 0.0689, average fakeD loss: 0.0765, 
[09/23 11:33:22][INFO] visual_prompt:  435: Inference (val):avg data time: 7.45e-05, avg batch time: 0.1209, average loss: 2.1638
[09/23 11:33:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 97.00	
[09/23 11:33:37][INFO] visual_prompt:  435: Inference (test):avg data time: 1.30e-04, avg batch time: 0.1275, average loss: 2.1532
[09/23 11:33:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.58	top5: 97.17	
[09/23 11:33:37][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 0.05814022039099217
[09/23 11:34:46][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 2.14e-02, avg batch time: 0.8093, average train loss: 2.2488average G loss: 0.0154, average realD loss: 0.0737, average fakeD loss: 0.0811, 
[09/23 11:34:49][INFO] visual_prompt:  435: Inference (val):avg data time: 8.20e-05, avg batch time: 0.1211, average loss: 2.1733
[09/23 11:34:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.00	top5: 96.67	
[09/23 11:35:05][INFO] visual_prompt:  435: Inference (test):avg data time: 1.21e-04, avg batch time: 0.1277, average loss: 2.1681
[09/23 11:35:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.40	top5: 96.86	
[09/23 11:35:05][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 0.05596697104577167
[09/23 11:36:14][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 2.19e-02, avg batch time: 0.8097, average train loss: 2.2561average G loss: 0.0160, average realD loss: 0.0729, average fakeD loss: 0.0784, 
[09/23 11:36:16][INFO] visual_prompt:  435: Inference (val):avg data time: 8.40e-05, avg batch time: 0.1199, average loss: 2.1787
[09/23 11:36:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.50	top5: 96.83	
[09/23 11:36:30][INFO] visual_prompt:  435: Inference (test):avg data time: 9.20e-05, avg batch time: 0.1280, average loss: 2.1852
[09/23 11:36:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.39	top5: 96.77	
[09/23 11:36:30][INFO] visual_prompt:  357: Best epoch 59: best metric: 0.765
[09/23 11:36:30][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 0.053801681189995926
[09/23 11:37:39][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 1.86e-02, avg batch time: 0.8056, average train loss: 2.2435average G loss: 0.0152, average realD loss: 0.0696, average fakeD loss: 0.0750, 
[09/23 11:37:41][INFO] visual_prompt:  435: Inference (val):avg data time: 5.21e-05, avg batch time: 0.1210, average loss: 2.1627
[09/23 11:37:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.83	top5: 97.67	
[09/23 11:37:55][INFO] visual_prompt:  435: Inference (test):avg data time: 9.43e-05, avg batch time: 0.1282, average loss: 2.1625
[09/23 11:37:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.25	top5: 96.88	
[09/23 11:37:55][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 0.051646988895816856
[09/23 11:39:04][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.86e-02, avg batch time: 0.8057, average train loss: 2.2228average G loss: 0.0152, average realD loss: 0.0708, average fakeD loss: 0.0753, 
[09/23 11:39:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.08e-05, avg batch time: 0.1212, average loss: 2.1655
[09/23 11:39:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.83	top5: 96.67	
[09/23 11:39:20][INFO] visual_prompt:  435: Inference (test):avg data time: 9.24e-05, avg batch time: 0.1282, average loss: 2.1632
[09/23 11:39:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.28	top5: 96.76	
[09/23 11:39:20][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 0.04950551932389005
[09/23 11:40:28][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.80e-02, avg batch time: 0.8048, average train loss: 2.2254average G loss: 0.0150, average realD loss: 0.0689, average fakeD loss: 0.0777, 
[09/23 11:40:31][INFO] visual_prompt:  435: Inference (val):avg data time: 7.18e-05, avg batch time: 0.1213, average loss: 2.1489
[09/23 11:40:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.17	top5: 96.83	
[09/23 11:40:44][INFO] visual_prompt:  435: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1279, average loss: 2.1491
[09/23 11:40:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.39	top5: 97.07	
[09/23 11:40:44][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 0.047379881525020776
[09/23 11:41:53][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 2.09e-02, avg batch time: 0.8074, average train loss: 2.2222average G loss: 0.0149, average realD loss: 0.0697, average fakeD loss: 0.0759, 
[09/23 11:41:55][INFO] visual_prompt:  435: Inference (val):avg data time: 6.70e-05, avg batch time: 0.1217, average loss: 2.1378
[09/23 11:41:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.17	top5: 96.17	
[09/23 11:42:09][INFO] visual_prompt:  435: Inference (test):avg data time: 6.65e-05, avg batch time: 0.1284, average loss: 2.1350
[09/23 11:42:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.08	top5: 96.81	
[09/23 11:42:09][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 0.045272665261437556
[09/23 11:43:18][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 2.16e-02, avg batch time: 0.8079, average train loss: 2.1970average G loss: 0.0148, average realD loss: 0.0732, average fakeD loss: 0.0773, 
[09/23 11:43:20][INFO] visual_prompt:  435: Inference (val):avg data time: 4.84e-05, avg batch time: 0.1210, average loss: 2.1234
[09/23 11:43:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.17	top5: 98.00	
[09/23 11:43:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1285, average loss: 2.1241
[09/23 11:43:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.58	top5: 97.22	
[09/23 11:43:34][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 0.04318643785156579
[09/23 11:44:42][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.88e-02, avg batch time: 0.8050, average train loss: 2.2113average G loss: 0.0154, average realD loss: 0.0729, average fakeD loss: 0.0773, 
[09/23 11:44:45][INFO] visual_prompt:  435: Inference (val):avg data time: 5.81e-05, avg batch time: 0.1198, average loss: 2.1772
[09/23 11:44:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 97.17	
[09/23 11:44:58][INFO] visual_prompt:  435: Inference (test):avg data time: 5.31e-05, avg batch time: 0.1287, average loss: 2.1810
[09/23 11:44:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.90	top5: 97.07	
[09/23 11:44:58][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 0.04112374104214571
[09/23 11:46:06][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 2.00e-02, avg batch time: 0.8064, average train loss: 2.2179average G loss: 0.0150, average realD loss: 0.0708, average fakeD loss: 0.0771, 
[09/23 11:46:09][INFO] visual_prompt:  435: Inference (val):avg data time: 8.05e-05, avg batch time: 0.1206, average loss: 2.1481
[09/23 11:46:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.50	top5: 98.00	
[09/23 11:46:23][INFO] visual_prompt:  435: Inference (test):avg data time: 8.35e-05, avg batch time: 0.1278, average loss: 2.1477
[09/23 11:46:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.49	top5: 97.34	
[09/23 11:46:23][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 0.039087087911505496
[09/23 11:47:31][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.97e-02, avg batch time: 0.8061, average train loss: 2.1899average G loss: 0.0149, average realD loss: 0.0703, average fakeD loss: 0.0754, 
[09/23 11:47:34][INFO] visual_prompt:  435: Inference (val):avg data time: 5.44e-05, avg batch time: 0.1211, average loss: 2.1464
[09/23 11:47:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 97.83	
[09/23 11:47:48][INFO] visual_prompt:  435: Inference (test):avg data time: 9.07e-05, avg batch time: 0.1276, average loss: 2.1451
[09/23 11:47:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.46	top5: 97.43	
[09/23 11:47:48][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 0.0370789598077625
[09/23 11:48:57][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.87e-02, avg batch time: 0.8049, average train loss: 2.2241average G loss: 0.0151, average realD loss: 0.0706, average fakeD loss: 0.0774, 
[09/23 11:48:59][INFO] visual_prompt:  435: Inference (val):avg data time: 6.17e-05, avg batch time: 0.1202, average loss: 2.1431
[09/23 11:48:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.00	top5: 97.33	
[09/23 11:49:13][INFO] visual_prompt:  435: Inference (test):avg data time: 6.18e-05, avg batch time: 0.1282, average loss: 2.1443
[09/23 11:49:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.82	top5: 97.27	
[09/23 11:49:13][INFO] visual_prompt:  357: Best epoch 68: best metric: 0.790
[09/23 11:49:13][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 0.035101803325682655
[09/23 11:50:21][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 1.84e-02, avg batch time: 0.8046, average train loss: 2.1712average G loss: 0.0142, average realD loss: 0.0722, average fakeD loss: 0.0755, 
[09/23 11:50:24][INFO] visual_prompt:  435: Inference (val):avg data time: 6.99e-05, avg batch time: 0.1196, average loss: 2.1333
[09/23 11:50:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 97.00	
[09/23 11:50:37][INFO] visual_prompt:  435: Inference (test):avg data time: 9.08e-05, avg batch time: 0.1278, average loss: 2.1259
[09/23 11:50:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.13	top5: 97.26	
[09/23 11:50:38][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 0.03315802732588184
[09/23 11:51:46][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.94e-02, avg batch time: 0.8058, average train loss: 2.1634average G loss: 0.0143, average realD loss: 0.0733, average fakeD loss: 0.0779, 
[09/23 11:51:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1198, average loss: 2.1370
[09/23 11:51:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 97.00	
[09/23 11:52:02][INFO] visual_prompt:  435: Inference (test):avg data time: 5.96e-05, avg batch time: 0.1282, average loss: 2.1407
[09/23 11:52:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.15	top5: 97.00	
[09/23 11:52:02][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 0.031250000000000014
[09/23 11:53:11][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 2.01e-02, avg batch time: 0.8064, average train loss: 2.1616average G loss: 0.0144, average realD loss: 0.0701, average fakeD loss: 0.0752, 
[09/23 11:53:13][INFO] visual_prompt:  435: Inference (val):avg data time: 7.12e-05, avg batch time: 0.1203, average loss: 2.1058
[09/23 11:53:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.33	
[09/23 11:53:27][INFO] visual_prompt:  435: Inference (test):avg data time: 8.44e-05, avg batch time: 0.1285, average loss: 2.0970
[09/23 11:53:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.39	top5: 97.62	
[09/23 11:53:27][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 0.0293800459854247
[09/23 11:54:36][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 2.03e-02, avg batch time: 0.8070, average train loss: 2.1390average G loss: 0.0140, average realD loss: 0.0686, average fakeD loss: 0.0746, 
[09/23 11:54:38][INFO] visual_prompt:  435: Inference (val):avg data time: 8.36e-05, avg batch time: 0.1209, average loss: 2.0908
[09/23 11:54:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 97.33	
[09/23 11:54:52][INFO] visual_prompt:  435: Inference (test):avg data time: 8.75e-05, avg batch time: 0.1277, average loss: 2.0888
[09/23 11:54:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.68	top5: 97.67	
[09/23 11:54:52][INFO] visual_prompt:  357: Best epoch 72: best metric: 0.793
[09/23 11:54:52][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 0.027550443533078332
[09/23 11:56:00][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 1.97e-02, avg batch time: 0.8061, average train loss: 2.1345average G loss: 0.0137, average realD loss: 0.0691, average fakeD loss: 0.0752, 
[09/23 11:56:03][INFO] visual_prompt:  435: Inference (val):avg data time: 5.08e-05, avg batch time: 0.1211, average loss: 2.0992
[09/23 11:56:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.17	top5: 97.67	
[09/23 11:56:16][INFO] visual_prompt:  435: Inference (test):avg data time: 6.67e-05, avg batch time: 0.1284, average loss: 2.0947
[09/23 11:56:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.84	top5: 97.41	
[09/23 11:56:16][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 0.025763421731720436
[09/23 11:57:25][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 2.04e-02, avg batch time: 0.8069, average train loss: 2.1224average G loss: 0.0139, average realD loss: 0.0705, average fakeD loss: 0.0745, 
[09/23 11:57:27][INFO] visual_prompt:  435: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1201, average loss: 2.0783
[09/23 11:57:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.00	top5: 97.17	
[09/23 11:57:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.17e-05, avg batch time: 0.1278, average loss: 2.0835
[09/23 11:57:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.72	top5: 97.34	
[09/23 11:57:41][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 0.024021157792146357
[09/23 11:58:50][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.82e-02, avg batch time: 0.8048, average train loss: 2.1118average G loss: 0.0134, average realD loss: 0.0703, average fakeD loss: 0.0773, 
[09/23 11:58:52][INFO] visual_prompt:  435: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1208, average loss: 2.0785
[09/23 11:58:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 96.67	
[09/23 11:59:06][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1277, average loss: 2.0703
[09/23 11:59:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.86	top5: 97.62	
[09/23 11:59:06][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 0.02232577439459129
[09/23 12:00:15][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.89e-02, avg batch time: 0.8055, average train loss: 2.1051average G loss: 0.0135, average realD loss: 0.0704, average fakeD loss: 0.0746, 
[09/23 12:00:17][INFO] visual_prompt:  435: Inference (val):avg data time: 7.74e-05, avg batch time: 0.1206, average loss: 2.0842
[09/23 12:00:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.50	
[09/23 12:00:31][INFO] visual_prompt:  435: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1281, average loss: 2.0680
[09/23 12:00:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.77	top5: 97.57	
[09/23 12:00:31][INFO] visual_prompt:  357: Best epoch 76: best metric: 0.805
[09/23 12:00:31][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 0.02067933710257138
[09/23 12:01:40][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 1.96e-02, avg batch time: 0.8060, average train loss: 2.0875average G loss: 0.0134, average realD loss: 0.0704, average fakeD loss: 0.0764, 
[09/23 12:01:42][INFO] visual_prompt:  435: Inference (val):avg data time: 6.94e-05, avg batch time: 0.1205, average loss: 2.0611
[09/23 12:01:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.33	
[09/23 12:01:56][INFO] visual_prompt:  435: Inference (test):avg data time: 7.95e-05, avg batch time: 0.1280, average loss: 2.0622
[09/23 12:01:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.86	top5: 97.48	
[09/23 12:01:56][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.019083851846312665
[09/23 12:03:04][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 1.93e-02, avg batch time: 0.8057, average train loss: 2.0736average G loss: 0.0133, average realD loss: 0.0689, average fakeD loss: 0.0750, 
[09/23 12:03:07][INFO] visual_prompt:  435: Inference (val):avg data time: 5.72e-05, avg batch time: 0.1200, average loss: 2.0542
[09/23 12:03:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 97.67	
[09/23 12:03:21][INFO] visual_prompt:  435: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1276, average loss: 2.0552
[09/23 12:03:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.12	top5: 97.69	
[09/23 12:03:21][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.017541262478834314
[09/23 12:04:30][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.90e-02, avg batch time: 0.8054, average train loss: 2.0746average G loss: 0.0133, average realD loss: 0.0688, average fakeD loss: 0.0730, 
[09/23 12:04:32][INFO] visual_prompt:  435: Inference (val):avg data time: 6.16e-05, avg batch time: 0.1206, average loss: 2.0462
[09/23 12:04:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.67	
[09/23 12:04:46][INFO] visual_prompt:  435: Inference (test):avg data time: 1.12e-04, avg batch time: 0.1278, average loss: 2.0441
[09/23 12:04:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.58	top5: 97.51	
[09/23 12:04:46][INFO] visual_prompt:  357: Best epoch 79: best metric: 0.820
[09/23 12:04:46][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.016053448407662853
[09/23 12:05:55][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 2.00e-02, avg batch time: 0.8064, average train loss: 2.0603average G loss: 0.0132, average realD loss: 0.0677, average fakeD loss: 0.0756, 
[09/23 12:05:57][INFO] visual_prompt:  435: Inference (val):avg data time: 6.14e-05, avg batch time: 0.1206, average loss: 2.0524
[09/23 12:05:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 97.67	
[09/23 12:06:11][INFO] visual_prompt:  435: Inference (test):avg data time: 7.43e-05, avg batch time: 0.1281, average loss: 2.0423
[09/23 12:06:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.91	top5: 97.60	
[09/23 12:06:11][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.014622222305063881
[09/23 12:07:20][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.86e-02, avg batch time: 0.8050, average train loss: 2.0553average G loss: 0.0127, average realD loss: 0.0699, average fakeD loss: 0.0731, 
[09/23 12:07:22][INFO] visual_prompt:  435: Inference (val):avg data time: 5.25e-05, avg batch time: 0.1211, average loss: 2.0301
[09/23 12:07:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 97.67	
[09/23 12:07:35][INFO] visual_prompt:  435: Inference (test):avg data time: 5.60e-05, avg batch time: 0.1283, average loss: 2.0209
[09/23 12:07:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.60	top5: 97.62	
[09/23 12:07:36][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.013249327899579881
[09/23 12:08:44][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 2.02e-02, avg batch time: 0.8065, average train loss: 2.0425average G loss: 0.0126, average realD loss: 0.0698, average fakeD loss: 0.0763, 
[09/23 12:08:46][INFO] visual_prompt:  435: Inference (val):avg data time: 6.94e-05, avg batch time: 0.1207, average loss: 2.0485
[09/23 12:08:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 97.17	
[09/23 12:09:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1287, average loss: 2.0409
[09/23 12:09:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.69	top5: 97.38	
[09/23 12:09:00][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.011936437851565791
[09/23 12:10:09][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.98e-02, avg batch time: 0.8062, average train loss: 2.0336average G loss: 0.0126, average realD loss: 0.0680, average fakeD loss: 0.0755, 
[09/23 12:10:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.73e-05, avg batch time: 0.1201, average loss: 2.0142
[09/23 12:10:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 97.50	
[09/23 12:10:25][INFO] visual_prompt:  435: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1280, average loss: 2.0087
[09/23 12:10:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.22	top5: 97.74	
[09/23 12:10:25][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.010685151715309898
[09/23 12:11:33][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 2.02e-02, avg batch time: 0.8067, average train loss: 2.0190average G loss: 0.0123, average realD loss: 0.0684, average fakeD loss: 0.0733, 
[09/23 12:11:36][INFO] visual_prompt:  435: Inference (val):avg data time: 1.03e-04, avg batch time: 0.1204, average loss: 2.0031
[09/23 12:11:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.00	
[09/23 12:11:49][INFO] visual_prompt:  435: Inference (test):avg data time: 1.11e-04, avg batch time: 0.1282, average loss: 1.9938
[09/23 12:11:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.48	top5: 97.76	
[09/23 12:11:50][INFO] visual_prompt:  357: Best epoch 84: best metric: 0.822
[09/23 12:11:50][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.009496993990223378
[09/23 12:12:58][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 2.03e-02, avg batch time: 0.8070, average train loss: 2.0089average G loss: 0.0120, average realD loss: 0.0696, average fakeD loss: 0.0752, 
[09/23 12:13:01][INFO] visual_prompt:  435: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1204, average loss: 2.0063
[09/23 12:13:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 97.33	
[09/23 12:13:14][INFO] visual_prompt:  435: Inference (test):avg data time: 7.58e-05, avg batch time: 0.1276, average loss: 1.9994
[09/23 12:13:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.76	top5: 97.72	
[09/23 12:13:15][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.00837341226347258
[09/23 12:14:23][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.95e-02, avg batch time: 0.8060, average train loss: 1.9913average G loss: 0.0120, average realD loss: 0.0702, average fakeD loss: 0.0719, 
[09/23 12:14:26][INFO] visual_prompt:  435: Inference (val):avg data time: 5.85e-05, avg batch time: 0.1205, average loss: 2.0190
[09/23 12:14:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 97.67	
[09/23 12:14:39][INFO] visual_prompt:  435: Inference (test):avg data time: 6.45e-05, avg batch time: 0.1288, average loss: 2.0114
[09/23 12:14:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.22	top5: 97.62	
[09/23 12:14:39][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.007315775446317063
[09/23 12:15:48][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 2.09e-02, avg batch time: 0.8071, average train loss: 2.0026average G loss: 0.0120, average realD loss: 0.0677, average fakeD loss: 0.0742, 
[09/23 12:15:50][INFO] visual_prompt:  435: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1200, average loss: 1.9898
[09/23 12:15:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.17	
[09/23 12:16:04][INFO] visual_prompt:  435: Inference (test):avg data time: 6.52e-05, avg batch time: 0.1276, average loss: 1.9934
[09/23 12:16:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.65	top5: 97.79	
[09/23 12:16:04][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.006325372106302074
[09/23 12:17:13][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.83e-02, avg batch time: 0.8046, average train loss: 1.9826average G loss: 0.0116, average realD loss: 0.0667, average fakeD loss: 0.0759, 
[09/23 12:17:15][INFO] visual_prompt:  435: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1204, average loss: 1.9924
[09/23 12:17:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.00	
[09/23 12:17:28][INFO] visual_prompt:  435: Inference (test):avg data time: 7.43e-05, avg batch time: 0.1282, average loss: 1.9836
[09/23 12:17:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.39	top5: 97.76	
[09/23 12:17:29][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.005403408897337439
[09/23 12:18:37][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.85e-02, avg batch time: 0.8049, average train loss: 1.9682average G loss: 0.0114, average realD loss: 0.0685, average fakeD loss: 0.0739, 
[09/23 12:18:39][INFO] visual_prompt:  435: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1206, average loss: 1.9763
[09/23 12:18:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 96.50	
[09/23 12:18:53][INFO] visual_prompt:  435: Inference (test):avg data time: 6.76e-05, avg batch time: 0.1287, average loss: 1.9720
[09/23 12:18:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.10	top5: 97.70	
[09/23 12:18:53][INFO] visual_prompt:  357: Best epoch 89: best metric: 0.837
[09/23 12:18:53][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.004551009089575793
[09/23 12:20:02][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 2.02e-02, avg batch time: 0.8067, average train loss: 1.9516average G loss: 0.0114, average realD loss: 0.0678, average fakeD loss: 0.0745, 
[09/23 12:20:04][INFO] visual_prompt:  435: Inference (val):avg data time: 6.42e-05, avg batch time: 0.1210, average loss: 1.9663
[09/23 12:20:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 97.00	
[09/23 12:20:18][INFO] visual_prompt:  435: Inference (test):avg data time: 5.88e-05, avg batch time: 0.1276, average loss: 1.9662
[09/23 12:20:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.71	top5: 97.81	
[09/23 12:20:18][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.00376921120088073
[09/23 12:21:27][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.90e-02, avg batch time: 0.8054, average train loss: 1.9426average G loss: 0.0111, average realD loss: 0.0687, average fakeD loss: 0.0731, 
[09/23 12:21:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.33e-05, avg batch time: 0.1199, average loss: 1.9563
[09/23 12:21:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 96.67	
[09/23 12:21:43][INFO] visual_prompt:  435: Inference (test):avg data time: 7.54e-05, avg batch time: 0.1279, average loss: 1.9541
[09/23 12:21:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.57	top5: 97.70	
[09/23 12:21:43][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.0030589677315529043
[09/23 12:22:52][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.99e-02, avg batch time: 0.8061, average train loss: 1.9211average G loss: 0.0109, average realD loss: 0.0684, average fakeD loss: 0.0718, 
[09/23 12:22:54][INFO] visual_prompt:  435: Inference (val):avg data time: 5.69e-05, avg batch time: 0.1207, average loss: 1.9498
[09/23 12:22:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.00	top5: 97.33	
[09/23 12:23:08][INFO] visual_prompt:  435: Inference (test):avg data time: 5.82e-05, avg batch time: 0.1280, average loss: 1.9454
[09/23 12:23:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.29	top5: 97.79	
[09/23 12:23:08][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.002421144003855069
[09/23 12:24:16][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.95e-02, avg batch time: 0.8057, average train loss: 1.9171average G loss: 0.0108, average realD loss: 0.0681, average fakeD loss: 0.0750, 
[09/23 12:24:19][INFO] visual_prompt:  435: Inference (val):avg data time: 5.43e-05, avg batch time: 0.1207, average loss: 1.9487
[09/23 12:24:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 96.67	
[09/23 12:24:32][INFO] visual_prompt:  435: Inference (test):avg data time: 7.49e-05, avg batch time: 0.1279, average loss: 1.9405
[09/23 12:24:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.39	top5: 97.88	
[09/23 12:24:32][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.0018565171077502204
[09/23 12:25:41][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.97e-02, avg batch time: 0.8059, average train loss: 1.9094average G loss: 0.0108, average realD loss: 0.0676, average fakeD loss: 0.0758, 
[09/23 12:25:43][INFO] visual_prompt:  435: Inference (val):avg data time: 6.01e-05, avg batch time: 0.1209, average loss: 1.9378
[09/23 12:25:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 96.83	
[09/23 12:25:57][INFO] visual_prompt:  435: Inference (test):avg data time: 4.99e-05, avg batch time: 0.1287, average loss: 1.9388
[09/23 12:25:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.39	top5: 97.74	
[09/23 12:25:57][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.0013657749541371444
[09/23 12:27:05][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 1.77e-02, avg batch time: 0.8038, average train loss: 1.9047average G loss: 0.0107, average realD loss: 0.0695, average fakeD loss: 0.0717, 
[09/23 12:27:08][INFO] visual_prompt:  435: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1216, average loss: 1.9373
[09/23 12:27:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.00	
[09/23 12:27:21][INFO] visual_prompt:  435: Inference (test):avg data time: 8.01e-05, avg batch time: 0.1278, average loss: 1.9318
[09/23 12:27:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.62	top5: 97.69	
[09/23 12:27:21][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.0009495154367369987
[09/23 12:28:30][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.92e-02, avg batch time: 0.8054, average train loss: 1.8942average G loss: 0.0106, average realD loss: 0.0686, average fakeD loss: 0.0744, 
[09/23 12:28:32][INFO] visual_prompt:  435: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1205, average loss: 1.9278
[09/23 12:28:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.17	
[09/23 12:28:45][INFO] visual_prompt:  435: Inference (test):avg data time: 6.59e-05, avg batch time: 0.1283, average loss: 1.9249
[09/23 12:28:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.38	top5: 97.65	
[09/23 12:28:45][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.0006082457036518524
[09/23 12:29:54][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.91e-02, avg batch time: 0.8052, average train loss: 1.8834average G loss: 0.0105, average realD loss: 0.0716, average fakeD loss: 0.0728, 
[09/23 12:29:56][INFO] visual_prompt:  435: Inference (val):avg data time: 5.79e-05, avg batch time: 0.1201, average loss: 1.9292
[09/23 12:29:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.00	
[09/23 12:30:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.93e-05, avg batch time: 0.1277, average loss: 1.9248
[09/23 12:30:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.52	top5: 97.70	
[09/23 12:30:11][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.0003423815394829194
[09/23 12:31:19][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 2.04e-02, avg batch time: 0.8064, average train loss: 1.8790average G loss: 0.0100, average realD loss: 0.0661, average fakeD loss: 0.0747, 
[09/23 12:31:21][INFO] visual_prompt:  435: Inference (val):avg data time: 7.18e-05, avg batch time: 0.1214, average loss: 1.9241
[09/23 12:31:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.17	
[09/23 12:31:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.35e-05, avg batch time: 0.1282, average loss: 1.9192
[09/23 12:31:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.67	top5: 97.77	
[09/23 12:31:35][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.00015224685876098765
[09/23 12:32:44][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 2.02e-02, avg batch time: 0.8064, average train loss: 1.8697average G loss: 0.0102, average realD loss: 0.0668, average fakeD loss: 0.0747, 
[09/23 12:32:46][INFO] visual_prompt:  435: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1213, average loss: 1.9224
[09/23 12:32:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.00	
[09/23 12:33:00][INFO] visual_prompt:  435: Inference (test):avg data time: 6.88e-05, avg batch time: 0.1281, average loss: 1.9175
[09/23 12:33:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.45	top5: 97.69	
[09/23 12:33:00][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 3.807331130651487e-05
[09/23 12:34:08][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.88e-02, avg batch time: 0.8051, average train loss: 1.8725average G loss: 0.0100, average realD loss: 0.0688, average fakeD loss: 0.0737, 
[09/23 12:34:11][INFO] visual_prompt:  435: Inference (val):avg data time: 7.54e-05, avg batch time: 0.1202, average loss: 1.9215
[09/23 12:34:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.00	
[09/23 12:34:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.26e-05, avg batch time: 0.1283, average loss: 1.9162
[09/23 12:34:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.39	top5: 97.72	
