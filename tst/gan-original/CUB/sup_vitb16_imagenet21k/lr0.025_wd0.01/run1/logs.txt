[09/24 05:00:58][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/24 05:00:58][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/24 05:00:58][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/24 05:00:58][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/24 05:00:58][INFO] visual_prompt:  109: Training with config:
[09/24 05:00:58][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr0.025_wd0.01/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 0.025,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.01,
            'WEIGHT_DECAY_BIAS': 0}}
[09/24 05:00:58][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/24 05:00:58][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/24 05:00:58][INFO] visual_prompt:   77: Number of images: 5394
[09/24 05:00:58][INFO] visual_prompt:   78: Number of classes: 200
[09/24 05:00:58][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/24 05:00:58][INFO] visual_prompt:   73: Loading validation data...
[09/24 05:00:58][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/24 05:00:58][INFO] visual_prompt:   77: Number of images: 600
[09/24 05:00:58][INFO] visual_prompt:   78: Number of classes: 200
[09/24 05:00:58][INFO] visual_prompt:   76: Loading test data...
[09/24 05:00:58][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/24 05:00:58][INFO] visual_prompt:   77: Number of images: 5794
[09/24 05:00:58][INFO] visual_prompt:   78: Number of classes: 200
[09/24 05:00:58][INFO] visual_prompt:  103: Constructing models...
[09/24 05:01:04][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/24 05:01:04][INFO] visual_prompt:   55: tuned percent:0.143
[09/24 05:01:04][INFO] visual_prompt:   41: Device used for model: 0
[09/24 05:01:04][INFO] visual_prompt:  106: Setting up Evalutator...
[09/24 05:01:04][INFO] visual_prompt:  108: Setting up Trainer...
[09/24 05:01:04][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/24 05:01:04][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/24 05:02:12][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.85e-02, avg batch time: 0.8042, average train loss: 5.3376average G loss: 2.6237, average realD loss: 6.2416, average fakeD loss: 1.1602, 
[09/24 05:02:15][INFO] visual_prompt:  435: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1202, average loss: 5.3397
[09/24 05:02:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 3.17	
[09/24 05:02:29][INFO] visual_prompt:  435: Inference (test):avg data time: 6.82e-05, avg batch time: 0.1280, average loss: 5.3384
[09/24 05:02:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.72	top5: 2.40	
[09/24 05:02:29][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.008
[09/24 05:02:29][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.0025000000000000005
[09/24 05:03:37][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.93e-02, avg batch time: 0.8056, average train loss: 5.3170average G loss: 0.0273, average realD loss: 3.1006, average fakeD loss: 1.2230, 
[09/24 05:03:40][INFO] visual_prompt:  435: Inference (val):avg data time: 5.30e-05, avg batch time: 0.1202, average loss: 5.3142
[09/24 05:03:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/24 05:03:53][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1281, average loss: 5.3168
[09/24 05:03:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.24	
[09/24 05:03:53][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.005000000000000001
[09/24 05:05:02][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.89e-02, avg batch time: 0.8055, average train loss: 5.3131average G loss: 0.0000, average realD loss: 2.1197, average fakeD loss: 1.0311, 
[09/24 05:05:04][INFO] visual_prompt:  435: Inference (val):avg data time: 6.18e-05, avg batch time: 0.1204, average loss: 5.3081
[09/24 05:05:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/24 05:05:17][INFO] visual_prompt:  435: Inference (test):avg data time: 6.62e-05, avg batch time: 0.1281, average loss: 5.3104
[09/24 05:05:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.19	
[09/24 05:05:18][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.0075
[09/24 05:06:26][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.97e-02, avg batch time: 0.8061, average train loss: 5.3082average G loss: 0.0000, average realD loss: 1.2880, average fakeD loss: 0.7327, 
[09/24 05:06:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.81e-05, avg batch time: 0.1205, average loss: 5.3029
[09/24 05:06:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.83	
[09/24 05:06:42][INFO] visual_prompt:  435: Inference (test):avg data time: 9.74e-05, avg batch time: 0.1276, average loss: 5.3046
[09/24 05:06:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.33	
[09/24 05:06:42][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 0.010000000000000002
[09/24 05:07:51][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.86e-02, avg batch time: 0.8042, average train loss: 5.3045average G loss: 0.0000, average realD loss: 0.7617, average fakeD loss: 0.5011, 
[09/24 05:07:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.49e-05, avg batch time: 0.1204, average loss: 5.2993
[09/24 05:07:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.00	top5: 3.00	
[09/24 05:08:07][INFO] visual_prompt:  435: Inference (test):avg data time: 7.44e-05, avg batch time: 0.1276, average loss: 5.3004
[09/24 05:08:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.57	top5: 2.49	
[09/24 05:08:07][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.010
[09/24 05:08:07][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 0.0125
[09/24 05:09:15][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.89e-02, avg batch time: 0.8036, average train loss: 5.3033average G loss: 0.0001, average realD loss: 0.4343, average fakeD loss: 0.2840, 
[09/24 05:09:18][INFO] visual_prompt:  435: Inference (val):avg data time: 7.56e-05, avg batch time: 0.1206, average loss: 5.2972
[09/24 05:09:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.00	top5: 3.33	
[09/24 05:09:31][INFO] visual_prompt:  435: Inference (test):avg data time: 6.69e-05, avg batch time: 0.1274, average loss: 5.2978
[09/24 05:09:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.57	top5: 2.90	
[09/24 05:09:31][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 0.015
[09/24 05:10:39][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.81e-02, avg batch time: 0.8018, average train loss: 5.3021average G loss: 0.0001, average realD loss: 0.2668, average fakeD loss: 0.2058, 
[09/24 05:10:42][INFO] visual_prompt:  435: Inference (val):avg data time: 5.77e-05, avg batch time: 0.1203, average loss: 5.2958
[09/24 05:10:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 4.17	
[09/24 05:10:55][INFO] visual_prompt:  435: Inference (test):avg data time: 8.46e-05, avg batch time: 0.1275, average loss: 5.2960
[09/24 05:10:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.62	top5: 3.43	
[09/24 05:10:55][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 0.017499999999999998
[09/24 05:12:04][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.86e-02, avg batch time: 0.8019, average train loss: 5.3009average G loss: 0.0001, average realD loss: 0.1552, average fakeD loss: 0.1322, 
[09/24 05:12:06][INFO] visual_prompt:  435: Inference (val):avg data time: 5.85e-05, avg batch time: 0.1208, average loss: 5.2942
[09/24 05:12:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 4.00	
[09/24 05:12:19][INFO] visual_prompt:  435: Inference (test):avg data time: 6.77e-05, avg batch time: 0.1277, average loss: 5.2939
[09/24 05:12:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.69	top5: 4.12	
[09/24 05:12:19][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 0.020000000000000004
[09/24 05:13:27][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.86e-02, avg batch time: 0.7998, average train loss: 5.2848average G loss: 0.0003, average realD loss: 0.1249, average fakeD loss: 0.0947, 
[09/24 05:13:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.23e-05, avg batch time: 0.1199, average loss: 5.1780
[09/24 05:13:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 5.67	top5: 18.33	
[09/24 05:13:43][INFO] visual_prompt:  435: Inference (test):avg data time: 8.36e-05, avg batch time: 0.1270, average loss: 5.1753
[09/24 05:13:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 6.40	top5: 18.16	
[09/24 05:13:44][INFO] visual_prompt:  357: Best epoch 9: best metric: 0.057
[09/24 05:13:44][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 0.022500000000000003
[09/24 05:14:52][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.91e-02, avg batch time: 0.8009, average train loss: 4.7297average G loss: 0.0017, average realD loss: 0.0888, average fakeD loss: 0.0792, 
[09/24 05:14:54][INFO] visual_prompt:  435: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1198, average loss: 4.0883
[09/24 05:14:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 56.83	top5: 89.33	
[09/24 05:15:08][INFO] visual_prompt:  435: Inference (test):avg data time: 7.48e-05, avg batch time: 0.1270, average loss: 4.0936
[09/24 05:15:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 56.23	top5: 88.33	
[09/24 05:15:08][INFO] visual_prompt:  357: Best epoch 10: best metric: 0.568
[09/24 05:15:08][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 0.025
[09/24 05:16:16][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.82e-02, avg batch time: 0.8006, average train loss: 3.6787average G loss: 0.0042, average realD loss: 0.0790, average fakeD loss: 0.0710, 
[09/24 05:16:18][INFO] visual_prompt:  435: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1199, average loss: 3.1876
[09/24 05:16:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.83	top5: 95.33	
[09/24 05:16:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.78e-05, avg batch time: 0.1271, average loss: 3.1860
[09/24 05:16:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.93	top5: 95.12	
[09/24 05:16:33][INFO] visual_prompt:  357: Best epoch 11: best metric: 0.698
[09/24 05:16:33][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 0.0249923853377387
[09/24 05:17:41][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.70e-02, avg batch time: 0.8001, average train loss: 2.9729average G loss: 0.0064, average realD loss: 0.0781, average fakeD loss: 0.0683, 
[09/24 05:17:43][INFO] visual_prompt:  435: Inference (val):avg data time: 6.97e-05, avg batch time: 0.1200, average loss: 2.6749
[09/24 05:17:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.67	top5: 96.33	
[09/24 05:17:57][INFO] visual_prompt:  435: Inference (test):avg data time: 8.00e-05, avg batch time: 0.1272, average loss: 2.6735
[09/24 05:17:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.94	top5: 96.34	
[09/24 05:17:58][INFO] visual_prompt:  357: Best epoch 12: best metric: 0.737
[09/24 05:17:58][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 0.024969550628247805
[09/24 05:19:06][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 2.19e-02, avg batch time: 0.8054, average train loss: 2.5946average G loss: 0.0083, average realD loss: 0.0737, average fakeD loss: 0.0693, 
[09/24 05:19:09][INFO] visual_prompt:  435: Inference (val):avg data time: 6.06e-05, avg batch time: 0.1195, average loss: 2.4109
[09/24 05:19:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.67	top5: 97.67	
[09/24 05:19:22][INFO] visual_prompt:  435: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1275, average loss: 2.4168
[09/24 05:19:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.56	top5: 97.08	
[09/24 05:19:22][INFO] visual_prompt:  357: Best epoch 13: best metric: 0.747
[09/24 05:19:22][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 0.024931523692103417
[09/24 05:20:30][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.99e-02, avg batch time: 0.8037, average train loss: 2.4012average G loss: 0.0104, average realD loss: 0.0776, average fakeD loss: 0.0683, 
[09/24 05:20:33][INFO] visual_prompt:  435: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1201, average loss: 2.2772
[09/24 05:20:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.50	top5: 96.67	
[09/24 05:20:47][INFO] visual_prompt:  435: Inference (test):avg data time: 7.28e-05, avg batch time: 0.1276, average loss: 2.2686
[09/24 05:20:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.10	top5: 96.91	
[09/24 05:20:47][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 0.02487835085926963
[09/24 05:21:55][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.84e-02, avg batch time: 0.8029, average train loss: 2.2794average G loss: 0.0120, average realD loss: 0.0796, average fakeD loss: 0.0700, 
[09/24 05:21:57][INFO] visual_prompt:  435: Inference (val):avg data time: 6.18e-05, avg batch time: 0.1215, average loss: 2.1833
[09/24 05:21:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 97.67	
[09/24 05:22:11][INFO] visual_prompt:  435: Inference (test):avg data time: 7.74e-05, avg batch time: 0.1275, average loss: 2.1858
[09/24 05:22:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.32	top5: 97.51	
[09/24 05:22:11][INFO] visual_prompt:  357: Best epoch 15: best metric: 0.798
[09/24 05:22:11][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 0.024810096912652603
[09/24 05:23:19][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 2.02e-02, avg batch time: 0.8051, average train loss: 2.2144average G loss: 0.0131, average realD loss: 0.0778, average fakeD loss: 0.0708, 
[09/24 05:23:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1206, average loss: 2.1586
[09/24 05:23:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.00	top5: 97.50	
[09/24 05:23:35][INFO] visual_prompt:  435: Inference (test):avg data time: 6.45e-05, avg batch time: 0.1277, average loss: 2.1479
[09/24 05:23:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.80	top5: 97.67	
[09/24 05:23:35][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 0.024726845009172573
[09/24 05:24:44][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.85e-02, avg batch time: 0.8033, average train loss: 2.1832average G loss: 0.0139, average realD loss: 0.0750, average fakeD loss: 0.0684, 
[09/24 05:24:46][INFO] visual_prompt:  435: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1202, average loss: 2.1150
[09/24 05:24:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.17	top5: 97.67	
[09/24 05:25:00][INFO] visual_prompt:  435: Inference (test):avg data time: 8.06e-05, avg batch time: 0.1280, average loss: 2.1086
[09/24 05:25:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.55	top5: 97.76	
[09/24 05:25:00][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 0.024628696578449957
[09/24 05:26:08][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.90e-02, avg batch time: 0.8043, average train loss: 2.1478average G loss: 0.0142, average realD loss: 0.0741, average fakeD loss: 0.0698, 
[09/24 05:26:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.50e-05, avg batch time: 0.1212, average loss: 2.0953
[09/24 05:26:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 98.00	
[09/24 05:26:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1278, average loss: 2.0984
[09/24 05:26:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.51	top5: 97.84	
[09/24 05:26:24][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 0.024515771199228986
[09/24 05:27:33][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.97e-02, avg batch time: 0.8052, average train loss: 2.1355average G loss: 0.0144, average realD loss: 0.0762, average fakeD loss: 0.0729, 
[09/24 05:27:35][INFO] visual_prompt:  435: Inference (val):avg data time: 7.88e-05, avg batch time: 0.1212, average loss: 2.0854
[09/24 05:27:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 97.83	
[09/24 05:27:49][INFO] visual_prompt:  435: Inference (test):avg data time: 9.31e-05, avg batch time: 0.1275, average loss: 2.0850
[09/24 05:27:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.93	top5: 97.46	
[09/24 05:27:49][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 0.024388206453689422
[09/24 05:28:58][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.87e-02, avg batch time: 0.8044, average train loss: 2.1128average G loss: 0.0141, average realD loss: 0.0724, average fakeD loss: 0.0710, 
[09/24 05:29:00][INFO] visual_prompt:  435: Inference (val):avg data time: 8.82e-05, avg batch time: 0.1207, average loss: 2.0663
[09/24 05:29:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 98.00	
[09/24 05:29:14][INFO] visual_prompt:  435: Inference (test):avg data time: 8.41e-05, avg batch time: 0.1276, average loss: 2.0585
[09/24 05:29:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.93	top5: 97.50	
[09/24 05:29:14][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 0.024246157759823857
[09/24 05:30:23][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.88e-02, avg batch time: 0.8048, average train loss: 2.0919average G loss: 0.0140, average realD loss: 0.0729, average fakeD loss: 0.0720, 
[09/24 05:30:25][INFO] visual_prompt:  435: Inference (val):avg data time: 8.10e-05, avg batch time: 0.1199, average loss: 2.0377
[09/24 05:30:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 97.33	
[09/24 05:30:39][INFO] visual_prompt:  435: Inference (test):avg data time: 6.04e-05, avg batch time: 0.1279, average loss: 2.0301
[09/24 05:30:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.34	top5: 97.55	
[09/24 05:30:39][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 0.024089798182084843
[09/24 05:31:47][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.92e-02, avg batch time: 0.8051, average train loss: 2.0863average G loss: 0.0140, average realD loss: 0.0731, average fakeD loss: 0.0706, 
[09/24 05:31:50][INFO] visual_prompt:  435: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1203, average loss: 2.0601
[09/24 05:31:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 97.33	
[09/24 05:32:03][INFO] visual_prompt:  435: Inference (test):avg data time: 8.04e-05, avg batch time: 0.1282, average loss: 2.0496
[09/24 05:32:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.84	top5: 97.51	
[09/24 05:32:03][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 0.02391931822053251
[09/24 05:33:12][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.87e-02, avg batch time: 0.8047, average train loss: 2.0687average G loss: 0.0139, average realD loss: 0.0721, average fakeD loss: 0.0720, 
[09/24 05:33:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.70e-05, avg batch time: 0.1200, average loss: 2.0166
[09/24 05:33:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 98.33	
[09/24 05:33:28][INFO] visual_prompt:  435: Inference (test):avg data time: 8.60e-05, avg batch time: 0.1280, average loss: 2.0186
[09/24 05:33:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.77	top5: 97.81	
[09/24 05:33:28][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 0.023734925578739588
[09/24 05:34:36][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.89e-02, avg batch time: 0.8050, average train loss: 2.0651average G loss: 0.0135, average realD loss: 0.0727, average fakeD loss: 0.0714, 
[09/24 05:34:39][INFO] visual_prompt:  435: Inference (val):avg data time: 7.92e-05, avg batch time: 0.1212, average loss: 2.0289
[09/24 05:34:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.67	top5: 97.50	
[09/24 05:34:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1278, average loss: 2.0274
[09/24 05:34:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.74	top5: 97.38	
[09/24 05:34:52][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 0.023536844910736588
[09/24 05:36:01][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.82e-02, avg batch time: 0.8044, average train loss: 2.0588average G loss: 0.0135, average realD loss: 0.0696, average fakeD loss: 0.0716, 
[09/24 05:36:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.91e-05, avg batch time: 0.1203, average loss: 2.0367
[09/24 05:36:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 97.00	
[09/24 05:36:17][INFO] visual_prompt:  435: Inference (test):avg data time: 7.71e-05, avg batch time: 0.1280, average loss: 2.0279
[09/24 05:36:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.91	top5: 97.57	
[09/24 05:36:17][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 0.023325317547305487
[09/24 05:37:26][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.91e-02, avg batch time: 0.8054, average train loss: 2.0619average G loss: 0.0134, average realD loss: 0.0696, average fakeD loss: 0.0714, 
[09/24 05:37:28][INFO] visual_prompt:  435: Inference (val):avg data time: 4.99e-05, avg batch time: 0.1211, average loss: 2.0228
[09/24 05:37:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 97.50	
[09/24 05:37:41][INFO] visual_prompt:  435: Inference (test):avg data time: 7.69e-05, avg batch time: 0.1281, average loss: 2.0132
[09/24 05:37:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.99	top5: 97.72	
[09/24 05:37:42][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 0.023100601201955326
[09/24 05:38:50][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.91e-02, avg batch time: 0.8058, average train loss: 2.0492average G loss: 0.0131, average realD loss: 0.0698, average fakeD loss: 0.0735, 
[09/24 05:38:52][INFO] visual_prompt:  435: Inference (val):avg data time: 5.06e-05, avg batch time: 0.1215, average loss: 2.0025
[09/24 05:38:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 97.67	
[09/24 05:39:06][INFO] visual_prompt:  435: Inference (test):avg data time: 6.88e-05, avg batch time: 0.1281, average loss: 2.0078
[09/24 05:39:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.39	top5: 97.81	
[09/24 05:39:06][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 0.02286296965693802
[09/24 05:40:15][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.88e-02, avg batch time: 0.8057, average train loss: 2.0340average G loss: 0.0129, average realD loss: 0.0708, average fakeD loss: 0.0726, 
[09/24 05:40:17][INFO] visual_prompt:  435: Inference (val):avg data time: 5.56e-05, avg batch time: 0.1208, average loss: 2.0086
[09/24 05:40:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.00	top5: 97.67	
[09/24 05:40:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1279, average loss: 2.0094
[09/24 05:40:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.43	top5: 97.57	
[09/24 05:40:31][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 0.022612712429686845
[09/24 05:41:39][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.93e-02, avg batch time: 0.8061, average train loss: 2.0438average G loss: 0.0131, average realD loss: 0.0688, average fakeD loss: 0.0724, 
[09/24 05:41:42][INFO] visual_prompt:  435: Inference (val):avg data time: 6.49e-05, avg batch time: 0.1206, average loss: 2.0083
[09/24 05:41:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.17	
[09/24 05:41:55][INFO] visual_prompt:  435: Inference (test):avg data time: 7.51e-05, avg batch time: 0.1276, average loss: 2.0061
[09/24 05:41:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.48	top5: 97.50	
[09/24 05:41:55][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 0.022350134420084024
[09/24 05:43:04][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.83e-02, avg batch time: 0.8055, average train loss: 2.0344average G loss: 0.0129, average realD loss: 0.0709, average fakeD loss: 0.0711, 
[09/24 05:43:06][INFO] visual_prompt:  435: Inference (val):avg data time: 7.41e-05, avg batch time: 0.1212, average loss: 2.0034
[09/24 05:43:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.17	
[09/24 05:43:20][INFO] visual_prompt:  435: Inference (test):avg data time: 9.04e-05, avg batch time: 0.1279, average loss: 1.9936
[09/24 05:43:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.94	top5: 97.36	
[09/24 05:43:20][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 0.022075555538987227
[09/24 05:44:29][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 2.01e-02, avg batch time: 0.8073, average train loss: 2.0212average G loss: 0.0128, average realD loss: 0.0701, average fakeD loss: 0.0715, 
[09/24 05:44:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.29e-05, avg batch time: 0.1204, average loss: 2.0064
[09/24 05:44:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 97.67	
[09/24 05:44:45][INFO] visual_prompt:  435: Inference (test):avg data time: 6.79e-05, avg batch time: 0.1281, average loss: 1.9979
[09/24 05:44:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.58	top5: 97.38	
[09/24 05:44:45][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 0.02178931031846743
[09/24 05:45:54][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.88e-02, avg batch time: 0.8059, average train loss: 2.0249average G loss: 0.0129, average realD loss: 0.0676, average fakeD loss: 0.0747, 
[09/24 05:45:56][INFO] visual_prompt:  435: Inference (val):avg data time: 7.70e-05, avg batch time: 0.1210, average loss: 1.9962
[09/24 05:45:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.17	top5: 96.50	
[09/24 05:46:09][INFO] visual_prompt:  435: Inference (test):avg data time: 5.95e-05, avg batch time: 0.1291, average loss: 1.9765
[09/24 05:46:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.44	top5: 97.57	
[09/24 05:46:09][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 0.02149174750423314
[09/24 05:47:18][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.93e-02, avg batch time: 0.8063, average train loss: 2.0140average G loss: 0.0126, average realD loss: 0.0705, average fakeD loss: 0.0723, 
[09/24 05:47:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.03e-05, avg batch time: 0.1204, average loss: 2.0149
[09/24 05:47:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.50	top5: 96.83	
[09/24 05:47:34][INFO] visual_prompt:  435: Inference (test):avg data time: 6.27e-05, avg batch time: 0.1284, average loss: 1.9995
[09/24 05:47:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.06	top5: 97.86	
[09/24 05:47:34][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 0.021183229630737467
[09/24 05:48:42][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 2.03e-02, avg batch time: 0.8067, average train loss: 2.0157average G loss: 0.0127, average realD loss: 0.0719, average fakeD loss: 0.0735, 
[09/24 05:48:45][INFO] visual_prompt:  435: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1208, average loss: 1.9684
[09/24 05:48:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 97.67	
[09/24 05:48:59][INFO] visual_prompt:  435: Inference (test):avg data time: 8.84e-05, avg batch time: 0.1278, average loss: 1.9644
[09/24 05:48:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.65	top5: 97.58	
[09/24 05:48:59][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 0.02086413257948573
[09/24 05:50:07][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.87e-02, avg batch time: 0.8044, average train loss: 2.0196average G loss: 0.0126, average realD loss: 0.0725, average fakeD loss: 0.0765, 
[09/24 05:50:10][INFO] visual_prompt:  435: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1205, average loss: 1.9870
[09/24 05:50:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 97.83	
[09/24 05:50:23][INFO] visual_prompt:  435: Inference (test):avg data time: 8.30e-05, avg batch time: 0.1278, average loss: 1.9828
[09/24 05:50:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.24	top5: 97.57	
[09/24 05:50:24][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 0.02053484512108174
[09/24 05:51:32][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.93e-02, avg batch time: 0.8042, average train loss: 2.0054average G loss: 0.0126, average realD loss: 0.0716, average fakeD loss: 0.0754, 
[09/24 05:51:34][INFO] visual_prompt:  435: Inference (val):avg data time: 7.25e-05, avg batch time: 0.1210, average loss: 1.9769
[09/24 05:51:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 97.83	
[09/24 05:51:48][INFO] visual_prompt:  435: Inference (test):avg data time: 7.57e-05, avg batch time: 0.1279, average loss: 1.9783
[09/24 05:51:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.51	top5: 97.51	
[09/24 05:51:48][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 0.020195768441570727
[09/24 05:52:56][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.72e-02, avg batch time: 0.8020, average train loss: 1.9986average G loss: 0.0125, average realD loss: 0.0698, average fakeD loss: 0.0728, 
[09/24 05:52:59][INFO] visual_prompt:  435: Inference (val):avg data time: 5.61e-05, avg batch time: 0.1204, average loss: 1.9746
[09/24 05:52:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.00	top5: 97.00	
