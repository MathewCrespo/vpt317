[09/24 00:19:45][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/24 00:19:45][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/24 00:19:45][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/24 00:19:45][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/24 00:19:45][INFO] visual_prompt:  109: Training with config:
[09/24 00:19:45][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr0.0625_wd0.0001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 0.0625,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/24 00:19:45][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/24 00:19:45][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/24 00:19:45][INFO] visual_prompt:   77: Number of images: 5394
[09/24 00:19:45][INFO] visual_prompt:   78: Number of classes: 200
[09/24 00:19:45][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/24 00:19:45][INFO] visual_prompt:   73: Loading validation data...
[09/24 00:19:45][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/24 00:19:45][INFO] visual_prompt:   77: Number of images: 600
[09/24 00:19:45][INFO] visual_prompt:   78: Number of classes: 200
[09/24 00:19:45][INFO] visual_prompt:   76: Loading test data...
[09/24 00:19:45][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/24 00:19:45][INFO] visual_prompt:   77: Number of images: 5794
[09/24 00:19:45][INFO] visual_prompt:   78: Number of classes: 200
[09/24 00:19:45][INFO] visual_prompt:  103: Constructing models...
[09/24 00:19:50][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/24 00:19:50][INFO] visual_prompt:   55: tuned percent:0.143
[09/24 00:19:50][INFO] visual_prompt:   41: Device used for model: 0
[09/24 00:19:50][INFO] visual_prompt:  106: Setting up Evalutator...
[09/24 00:19:50][INFO] visual_prompt:  108: Setting up Trainer...
[09/24 00:19:50][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/24 00:19:50][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/24 00:20:58][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.82e-02, avg batch time: 0.8014, average train loss: 5.3310average G loss: 2.3669, average realD loss: 7.2607, average fakeD loss: 1.4625, 
[09/24 00:21:01][INFO] visual_prompt:  435: Inference (val):avg data time: 7.93e-05, avg batch time: 0.1201, average loss: 5.3317
[09/24 00:21:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.17	top5: 1.33	
[09/24 00:21:15][INFO] visual_prompt:  435: Inference (test):avg data time: 8.54e-05, avg batch time: 0.1275, average loss: 5.3301
[09/24 00:21:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.24	top5: 1.64	
[09/24 00:21:15][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.002
[09/24 00:21:15][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.00625
[09/24 00:22:23][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.92e-02, avg batch time: 0.8004, average train loss: 5.3193average G loss: 0.0233, average realD loss: 3.3151, average fakeD loss: 1.4262, 
[09/24 00:22:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1202, average loss: 5.3140
[09/24 00:22:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.17	
[09/24 00:22:39][INFO] visual_prompt:  435: Inference (test):avg data time: 9.38e-05, avg batch time: 0.1273, average loss: 5.3143
[09/24 00:22:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.54	top5: 2.49	
[09/24 00:22:39][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.005
[09/24 00:22:39][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.0125
[09/24 00:23:47][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.74e-02, avg batch time: 0.8005, average train loss: 5.3136average G loss: 0.0000, average realD loss: 1.4617, average fakeD loss: 0.9011, 
[09/24 00:23:49][INFO] visual_prompt:  435: Inference (val):avg data time: 5.35e-05, avg batch time: 0.1207, average loss: 5.3057
[09/24 00:23:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 1.67	
[09/24 00:24:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.83e-05, avg batch time: 0.1277, average loss: 5.3053
[09/24 00:24:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/24 00:24:03][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.01875
[09/24 00:25:12][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 2.03e-02, avg batch time: 0.8042, average train loss: 5.3083average G loss: 0.0000, average realD loss: 0.6876, average fakeD loss: 0.4843, 
[09/24 00:25:14][INFO] visual_prompt:  435: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1209, average loss: 5.2985
[09/24 00:25:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 2.50	
[09/24 00:25:27][INFO] visual_prompt:  435: Inference (test):avg data time: 6.94e-05, avg batch time: 0.1279, average loss: 5.2984
[09/24 00:25:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.71	top5: 2.97	
[09/24 00:25:28][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 0.025
[09/24 00:26:36][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.94e-02, avg batch time: 0.8041, average train loss: 5.3040average G loss: 0.0000, average realD loss: 0.3615, average fakeD loss: 0.2735, 
[09/24 00:26:38][INFO] visual_prompt:  435: Inference (val):avg data time: 5.21e-05, avg batch time: 0.1213, average loss: 5.2930
[09/24 00:26:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.67	
[09/24 00:26:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.52e-05, avg batch time: 0.1276, average loss: 5.2918
[09/24 00:26:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.83	top5: 3.90	
[09/24 00:26:52][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.007
[09/24 00:26:52][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 0.03125
[09/24 00:28:00][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 2.01e-02, avg batch time: 0.8026, average train loss: 5.2960average G loss: 0.0000, average realD loss: 0.2081, average fakeD loss: 0.2275, 
[09/24 00:28:03][INFO] visual_prompt:  435: Inference (val):avg data time: 4.94e-05, avg batch time: 0.1208, average loss: 5.2770
[09/24 00:28:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.50	top5: 4.50	
[09/24 00:28:16][INFO] visual_prompt:  435: Inference (test):avg data time: 6.60e-05, avg batch time: 0.1281, average loss: 5.2751
[09/24 00:28:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.26	top5: 4.78	
[09/24 00:28:16][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.015
[09/24 00:28:16][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 0.0375
[09/24 00:29:24][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.96e-02, avg batch time: 0.8010, average train loss: 5.2610average G loss: 0.0000, average realD loss: 0.1499, average fakeD loss: 0.1460, 
[09/24 00:29:26][INFO] visual_prompt:  435: Inference (val):avg data time: 5.66e-05, avg batch time: 0.1207, average loss: 5.1973
[09/24 00:29:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.67	top5: 6.50	
[09/24 00:29:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.85e-05, avg batch time: 0.1277, average loss: 5.1916
[09/24 00:29:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.64	top5: 6.23	
[09/24 00:29:41][INFO] visual_prompt:  357: Best epoch 7: best metric: 0.017
[09/24 00:29:41][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 0.04375
[09/24 00:30:49][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.90e-02, avg batch time: 0.8009, average train loss: 5.0270average G loss: 0.0000, average realD loss: 0.0932, average fakeD loss: 0.0935, 
[09/24 00:30:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.07e-05, avg batch time: 0.1201, average loss: 4.7063
[09/24 00:30:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 4.67	top5: 18.33	
[09/24 00:31:06][INFO] visual_prompt:  435: Inference (test):avg data time: 9.31e-05, avg batch time: 0.1275, average loss: 4.6919
[09/24 00:31:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 5.16	top5: 18.45	
[09/24 00:31:06][INFO] visual_prompt:  357: Best epoch 8: best metric: 0.047
[09/24 00:31:06][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 0.05
[09/24 00:32:14][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.86e-02, avg batch time: 0.7999, average train loss: 4.2434average G loss: 0.0003, average realD loss: 0.0780, average fakeD loss: 0.0982, 
[09/24 00:32:16][INFO] visual_prompt:  435: Inference (val):avg data time: 7.44e-05, avg batch time: 0.1214, average loss: 3.5729
[09/24 00:32:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 29.67	top5: 57.33	
[09/24 00:32:29][INFO] visual_prompt:  435: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1280, average loss: 3.5661
[09/24 00:32:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 28.82	top5: 57.08	
[09/24 00:32:29][INFO] visual_prompt:  357: Best epoch 9: best metric: 0.297
[09/24 00:32:29][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 0.05625
[09/24 00:33:38][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 2.04e-02, avg batch time: 0.8025, average train loss: 3.0221average G loss: 0.0012, average realD loss: 0.0517, average fakeD loss: 0.0754, 
[09/24 00:33:40][INFO] visual_prompt:  435: Inference (val):avg data time: 6.32e-05, avg batch time: 0.1203, average loss: 2.2974
[09/24 00:33:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 54.83	top5: 83.00	
[09/24 00:33:54][INFO] visual_prompt:  435: Inference (test):avg data time: 6.91e-05, avg batch time: 0.1274, average loss: 2.2752
[09/24 00:33:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 57.23	top5: 84.78	
[09/24 00:33:54][INFO] visual_prompt:  357: Best epoch 10: best metric: 0.548
[09/24 00:33:54][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 0.0625
[09/24 00:35:02][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.88e-02, avg batch time: 0.8008, average train loss: 1.8823average G loss: 0.0017, average realD loss: 0.0510, average fakeD loss: 0.0664, 
[09/24 00:35:05][INFO] visual_prompt:  435: Inference (val):avg data time: 5.74e-05, avg batch time: 0.1200, average loss: 1.4384
[09/24 00:35:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.67	top5: 95.33	
[09/24 00:35:18][INFO] visual_prompt:  435: Inference (test):avg data time: 8.09e-05, avg batch time: 0.1278, average loss: 1.4079
[09/24 00:35:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.61	top5: 94.79	
[09/24 00:35:18][INFO] visual_prompt:  357: Best epoch 11: best metric: 0.717
[09/24 00:35:18][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 0.062480963344346746
[09/24 00:36:27][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.91e-02, avg batch time: 0.8011, average train loss: 1.2203average G loss: 0.0020, average realD loss: 0.0473, average fakeD loss: 0.0611, 
[09/24 00:36:29][INFO] visual_prompt:  435: Inference (val):avg data time: 8.45e-05, avg batch time: 0.1202, average loss: 1.0332
[09/24 00:36:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 95.83	
[09/24 00:36:43][INFO] visual_prompt:  435: Inference (test):avg data time: 8.17e-05, avg batch time: 0.1274, average loss: 1.0156
[09/24 00:36:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.75	top5: 96.91	
[09/24 00:36:43][INFO] visual_prompt:  357: Best epoch 12: best metric: 0.777
[09/24 00:36:43][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 0.062423876570619506
[09/24 00:37:51][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.89e-02, avg batch time: 0.8011, average train loss: 0.9145average G loss: 0.0011, average realD loss: 0.0364, average fakeD loss: 0.0660, 
[09/24 00:37:54][INFO] visual_prompt:  435: Inference (val):avg data time: 5.67e-05, avg batch time: 0.1209, average loss: 0.8467
[09/24 00:37:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.33	
[09/24 00:38:07][INFO] visual_prompt:  435: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1277, average loss: 0.8324
[09/24 00:38:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.83	top5: 97.50	
[09/24 00:38:07][INFO] visual_prompt:  357: Best epoch 13: best metric: 0.810
[09/24 00:38:07][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 0.06232880923025854
[09/24 00:39:15][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.91e-02, avg batch time: 0.8010, average train loss: 0.7437average G loss: 0.0007, average realD loss: 0.0272, average fakeD loss: 0.0318, 
[09/24 00:39:18][INFO] visual_prompt:  435: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1207, average loss: 0.7454
[09/24 00:39:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 96.83	
[09/24 00:39:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.33e-05, avg batch time: 0.1279, average loss: 0.7282
[09/24 00:39:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.38	top5: 97.67	
[09/24 00:39:31][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 0.062195877148174074
[09/24 00:40:40][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.96e-02, avg batch time: 0.8016, average train loss: 0.6363average G loss: 0.0011, average realD loss: 0.0307, average fakeD loss: 0.0370, 
[09/24 00:40:42][INFO] visual_prompt:  435: Inference (val):avg data time: 5.73e-05, avg batch time: 0.1205, average loss: 0.6694
[09/24 00:40:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.00	top5: 97.50	
[09/24 00:40:56][INFO] visual_prompt:  435: Inference (test):avg data time: 8.19e-05, avg batch time: 0.1279, average loss: 0.6718
[09/24 00:40:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.00	top5: 97.69	
[09/24 00:40:56][INFO] visual_prompt:  357: Best epoch 15: best metric: 0.830
[09/24 00:40:56][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 0.062025242281631504
[09/24 00:42:04][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.87e-02, avg batch time: 0.8002, average train loss: 0.5728average G loss: 0.0008, average realD loss: 0.0355, average fakeD loss: 0.0440, 
[09/24 00:42:06][INFO] visual_prompt:  435: Inference (val):avg data time: 5.76e-05, avg batch time: 0.1196, average loss: 0.6259
[09/24 00:42:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 97.83	
[09/24 00:42:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1277, average loss: 0.6250
[09/24 00:42:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.30	top5: 97.89	
[09/24 00:42:20][INFO] visual_prompt:  357: Best epoch 16: best metric: 0.842
[09/24 00:42:20][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 0.06181711252293143
[09/24 00:43:28][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.92e-02, avg batch time: 0.8006, average train loss: 0.5136average G loss: 0.0007, average realD loss: 0.0208, average fakeD loss: 0.0468, 
[09/24 00:43:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.42e-05, avg batch time: 0.1209, average loss: 0.6056
[09/24 00:43:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.17	
[09/24 00:43:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1277, average loss: 0.6065
[09/24 00:43:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.40	top5: 97.91	
[09/24 00:43:44][INFO] visual_prompt:  357: Best epoch 17: best metric: 0.845
[09/24 00:43:44][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 0.061571741446124886
[09/24 00:44:53][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.94e-02, avg batch time: 0.8007, average train loss: 0.4802average G loss: 0.0006, average realD loss: 0.0280, average fakeD loss: 0.0419, 
[09/24 00:44:55][INFO] visual_prompt:  435: Inference (val):avg data time: 7.79e-05, avg batch time: 0.1206, average loss: 0.5783
[09/24 00:44:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.00	
[09/24 00:45:08][INFO] visual_prompt:  435: Inference (test):avg data time: 6.73e-05, avg batch time: 0.1281, average loss: 0.5786
[09/24 00:45:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.67	top5: 97.96	
[09/24 00:45:08][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 0.061289427998072465
[09/24 00:46:17][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.98e-02, avg batch time: 0.8008, average train loss: 0.4452average G loss: 0.0007, average realD loss: 0.0209, average fakeD loss: 0.0252, 
[09/24 00:46:19][INFO] visual_prompt:  435: Inference (val):avg data time: 6.50e-05, avg batch time: 0.1198, average loss: 0.5647
[09/24 00:46:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.33	
[09/24 00:46:32][INFO] visual_prompt:  435: Inference (test):avg data time: 7.09e-05, avg batch time: 0.1273, average loss: 0.5688
[09/24 00:46:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.99	top5: 97.96	
[09/24 00:46:32][INFO] visual_prompt:  357: Best epoch 19: best metric: 0.852
[09/24 00:46:32][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 0.06097051613422355
[09/24 00:47:40][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.82e-02, avg batch time: 0.7986, average train loss: 0.4112average G loss: 0.0004, average realD loss: 0.0199, average fakeD loss: 0.0622, 
[09/24 00:47:43][INFO] visual_prompt:  435: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1204, average loss: 0.5487
[09/24 00:47:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 97.67	
[09/24 00:47:56][INFO] visual_prompt:  435: Inference (test):avg data time: 7.01e-05, avg batch time: 0.1281, average loss: 0.5460
[09/24 00:47:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.52	top5: 97.93	
[09/24 00:47:56][INFO] visual_prompt:  357: Best epoch 20: best metric: 0.855
[09/24 00:47:56][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 0.06061539439955964
[09/24 00:49:04][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.74e-02, avg batch time: 0.7975, average train loss: 0.3866average G loss: 0.0007, average realD loss: 0.0222, average fakeD loss: 0.0494, 
[09/24 00:49:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.52e-05, avg batch time: 0.1205, average loss: 0.5209
[09/24 00:49:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.00	
[09/24 00:49:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1275, average loss: 0.5339
[09/24 00:49:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.69	top5: 97.96	
[09/24 00:49:20][INFO] visual_prompt:  357: Best epoch 21: best metric: 0.863
[09/24 00:49:20][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 0.06022449545521211
[09/24 00:50:28][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.87e-02, avg batch time: 0.7995, average train loss: 0.3695average G loss: 0.0004, average realD loss: 0.0187, average fakeD loss: 0.0258, 
[09/24 00:50:30][INFO] visual_prompt:  435: Inference (val):avg data time: 6.25e-05, avg batch time: 0.1205, average loss: 0.5288
[09/24 00:50:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/24 00:50:44][INFO] visual_prompt:  435: Inference (test):avg data time: 8.74e-05, avg batch time: 0.1278, average loss: 0.5316
[09/24 00:50:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.59	top5: 97.96	
[09/24 00:50:44][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 0.059798295551331274
[09/24 00:51:52][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.92e-02, avg batch time: 0.8000, average train loss: 0.3511average G loss: 0.0008, average realD loss: 0.0209, average fakeD loss: 0.0259, 
[09/24 00:51:54][INFO] visual_prompt:  435: Inference (val):avg data time: 7.80e-05, avg batch time: 0.1204, average loss: 0.5312
[09/24 00:51:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.00	
[09/24 00:52:07][INFO] visual_prompt:  435: Inference (test):avg data time: 7.04e-05, avg batch time: 0.1281, average loss: 0.5298
[09/24 00:52:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.19	top5: 97.95	
[09/24 00:52:07][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 0.05933731394684897
[09/24 00:53:15][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.82e-02, avg batch time: 0.7991, average train loss: 0.3257average G loss: 0.0006, average realD loss: 0.0128, average fakeD loss: 0.0465, 
[09/24 00:53:18][INFO] visual_prompt:  435: Inference (val):avg data time: 5.80e-05, avg batch time: 0.1202, average loss: 0.5147
[09/24 00:53:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.17	
[09/24 00:53:32][INFO] visual_prompt:  435: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1275, average loss: 0.5179
[09/24 00:53:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.54	top5: 97.98	
[09/24 00:53:32][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 0.05884211227684147
[09/24 00:54:40][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.95e-02, avg batch time: 0.8008, average train loss: 0.3105average G loss: 0.0004, average realD loss: 0.0169, average fakeD loss: 0.0334, 
[09/24 00:54:42][INFO] visual_prompt:  435: Inference (val):avg data time: 8.96e-05, avg batch time: 0.1201, average loss: 0.5062
[09/24 00:54:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.83	
[09/24 00:54:56][INFO] visual_prompt:  435: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1270, average loss: 0.5128
[09/24 00:54:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 98.03	
[09/24 00:54:56][INFO] visual_prompt:  357: Best epoch 25: best metric: 0.867
[09/24 00:54:56][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 0.05831329386826371
[09/24 00:56:04][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.79e-02, avg batch time: 0.7992, average train loss: 0.2960average G loss: 0.0005, average realD loss: 0.0216, average fakeD loss: 0.0262, 
[09/24 00:56:07][INFO] visual_prompt:  435: Inference (val):avg data time: 5.34e-05, avg batch time: 0.1204, average loss: 0.5013
[09/24 00:56:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.00	
[09/24 00:56:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.53e-05, avg batch time: 0.1278, average loss: 0.5125
[09/24 00:56:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.09	top5: 97.91	
[09/24 00:56:20][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 0.05775150300488831
[09/24 00:57:29][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.95e-02, avg batch time: 0.8011, average train loss: 0.2924average G loss: 0.0004, average realD loss: 0.0182, average fakeD loss: 0.0362, 
[09/24 00:57:31][INFO] visual_prompt:  435: Inference (val):avg data time: 7.03e-05, avg batch time: 0.1212, average loss: 0.4939
[09/24 00:57:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.17	
[09/24 00:57:44][INFO] visual_prompt:  435: Inference (test):avg data time: 7.40e-05, avg batch time: 0.1278, average loss: 0.5047
[09/24 00:57:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.18	top5: 97.98	
[09/24 00:57:44][INFO] visual_prompt:  357: Best epoch 27: best metric: 0.870
[09/24 00:57:44][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 0.05715742414234505
[09/24 00:58:52][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.91e-02, avg batch time: 0.8007, average train loss: 0.2757average G loss: 0.0005, average realD loss: 0.0174, average fakeD loss: 0.0269, 
[09/24 00:58:55][INFO] visual_prompt:  435: Inference (val):avg data time: 6.63e-05, avg batch time: 0.1205, average loss: 0.4970
[09/24 00:58:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.17	
[09/24 00:59:08][INFO] visual_prompt:  435: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1278, average loss: 0.5066
[09/24 00:59:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.16	top5: 97.91	
[09/24 00:59:08][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 0.05653178107421711
[09/24 01:00:16][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.71e-02, avg batch time: 0.7987, average train loss: 0.2644average G loss: 0.0008, average realD loss: 0.0145, average fakeD loss: 0.0178, 
[09/24 01:00:19][INFO] visual_prompt:  435: Inference (val):avg data time: 6.76e-05, avg batch time: 0.1213, average loss: 0.4994
[09/24 01:00:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.00	
[09/24 01:00:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.77e-05, avg batch time: 0.1277, average loss: 0.5046
[09/24 01:00:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.21	top5: 97.95	
[09/24 01:00:33][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 0.055875336050210056
[09/24 01:01:41][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.83e-02, avg batch time: 0.8004, average train loss: 0.2588average G loss: 0.0005, average realD loss: 0.0164, average fakeD loss: 0.0160, 
[09/24 01:01:43][INFO] visual_prompt:  435: Inference (val):avg data time: 4.72e-05, avg batch time: 0.1207, average loss: 0.4962
[09/24 01:01:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.17	
[09/24 01:01:57][INFO] visual_prompt:  435: Inference (test):avg data time: 1.24e-04, avg batch time: 0.1275, average loss: 0.4994
[09/24 01:01:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.56	top5: 97.93	
[09/24 01:01:57][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 0.05518888884746806
[09/24 01:03:05][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.75e-02, avg batch time: 0.7993, average train loss: 0.2506average G loss: 0.0006, average realD loss: 0.0105, average fakeD loss: 0.0201, 
[09/24 01:03:07][INFO] visual_prompt:  435: Inference (val):avg data time: 8.09e-05, avg batch time: 0.1207, average loss: 0.5046
[09/24 01:03:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 97.83	
[09/24 01:03:21][INFO] visual_prompt:  435: Inference (test):avg data time: 8.97e-05, avg batch time: 0.1275, average loss: 0.5014
[09/24 01:03:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.38	top5: 97.76	
[09/24 01:03:21][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 0.05447327579616857
[09/24 01:04:29][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.94e-02, avg batch time: 0.8012, average train loss: 0.2350average G loss: 0.0004, average realD loss: 0.0175, average fakeD loss: 0.0368, 
[09/24 01:04:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.81e-05, avg batch time: 0.1198, average loss: 0.4909
[09/24 01:04:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.17	
[09/24 01:04:45][INFO] visual_prompt:  435: Inference (test):avg data time: 6.97e-05, avg batch time: 0.1277, average loss: 0.4937
[09/24 01:04:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.38	top5: 98.05	
[09/24 01:04:45][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 0.053729368760582846
[09/24 01:05:53][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.92e-02, avg batch time: 0.8013, average train loss: 0.2306average G loss: 0.0005, average realD loss: 0.0118, average fakeD loss: 0.0368, 
[09/24 01:05:56][INFO] visual_prompt:  435: Inference (val):avg data time: 6.03e-05, avg batch time: 0.1203, average loss: 0.4948
[09/24 01:05:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.00	
[09/24 01:06:10][INFO] visual_prompt:  435: Inference (test):avg data time: 8.60e-05, avg batch time: 0.1271, average loss: 0.4972
[09/24 01:06:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 98.00	
[09/24 01:06:10][INFO] visual_prompt:  357: Best epoch 33: best metric: 0.875
[09/24 01:06:10][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 0.052958074076843664
[09/24 01:07:18][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.75e-02, avg batch time: 0.8000, average train loss: 0.2220average G loss: 0.0004, average realD loss: 0.0248, average fakeD loss: 0.0268, 
[09/24 01:07:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.73e-05, avg batch time: 0.1204, average loss: 0.5040
[09/24 01:07:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.00	
[09/24 01:07:33][INFO] visual_prompt:  435: Inference (test):avg data time: 6.24e-05, avg batch time: 0.1284, average loss: 0.5055
[09/24 01:07:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.23	top5: 97.88	
[09/24 01:07:33][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 0.05216033144871432
[09/24 01:08:42][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.92e-02, avg batch time: 0.8017, average train loss: 0.2186average G loss: 0.0004, average realD loss: 0.0137, average fakeD loss: 0.0228, 
[09/24 01:08:44][INFO] visual_prompt:  435: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1206, average loss: 0.4847
[09/24 01:08:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.33	
[09/24 01:08:57][INFO] visual_prompt:  435: Inference (test):avg data time: 7.59e-05, avg batch time: 0.1279, average loss: 0.4966
[09/24 01:08:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.28	top5: 98.05	
[09/24 01:08:58][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 0.05133711280270435
[09/24 01:10:06][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.80e-02, avg batch time: 0.8005, average train loss: 0.2059average G loss: 0.0003, average realD loss: 0.0129, average fakeD loss: 0.0195, 
[09/24 01:10:08][INFO] visual_prompt:  435: Inference (val):avg data time: 7.45e-05, avg batch time: 0.1200, average loss: 0.4781
[09/24 01:10:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.17	
[09/24 01:10:22][INFO] visual_prompt:  435: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1277, average loss: 0.4944
[09/24 01:10:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.12	top5: 98.12	
[09/24 01:10:22][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 0.05048942110392682
[09/24 01:11:30][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 2.01e-02, avg batch time: 0.8024, average train loss: 0.1985average G loss: 0.0007, average realD loss: 0.0164, average fakeD loss: 0.0158, 
[09/24 01:11:33][INFO] visual_prompt:  435: Inference (val):avg data time: 9.15e-05, avg batch time: 0.1207, average loss: 0.4735
[09/24 01:11:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.83	top5: 98.33	
[09/24 01:11:46][INFO] visual_prompt:  435: Inference (test):avg data time: 1.06e-04, avg batch time: 0.1276, average loss: 0.4868
[09/24 01:11:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.90	top5: 98.03	
[09/24 01:11:46][INFO] visual_prompt:  357: Best epoch 37: best metric: 0.878
[09/24 01:11:46][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 0.049618289134139786
[09/24 01:12:54][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.81e-02, avg batch time: 0.8000, average train loss: 0.1976average G loss: 0.0003, average realD loss: 0.0141, average fakeD loss: 0.0160, 
[09/24 01:12:57][INFO] visual_prompt:  435: Inference (val):avg data time: 8.24e-05, avg batch time: 0.1212, average loss: 0.5033
[09/24 01:12:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.00	
[09/24 01:13:10][INFO] visual_prompt:  435: Inference (test):avg data time: 8.08e-05, avg batch time: 0.1282, average loss: 0.5069
[09/24 01:13:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.89	
[09/24 01:13:10][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 0.04872477823346084
[09/24 01:14:18][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 1.92e-02, avg batch time: 0.8015, average train loss: 0.1916average G loss: 0.0004, average realD loss: 0.0140, average fakeD loss: 0.0205, 
[09/24 01:14:21][INFO] visual_prompt:  435: Inference (val):avg data time: 5.71e-05, avg batch time: 0.1205, average loss: 0.4934
[09/24 01:14:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.00	
[09/24 01:14:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1278, average loss: 0.4978
[09/24 01:14:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.49	top5: 97.84	
[09/24 01:14:34][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 0.04780997700728765
[09/24 01:15:42][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.85e-02, avg batch time: 0.8008, average train loss: 0.1843average G loss: 0.0004, average realD loss: 0.0076, average fakeD loss: 0.0177, 
[09/24 01:15:45][INFO] visual_prompt:  435: Inference (val):avg data time: 5.74e-05, avg batch time: 0.1199, average loss: 0.5020
[09/24 01:15:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 97.83	
[09/24 01:15:58][INFO] visual_prompt:  435: Inference (test):avg data time: 6.39e-05, avg batch time: 0.1282, average loss: 0.5033
[09/24 01:15:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.21	top5: 97.86	
[09/24 01:15:58][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 0.046875
[09/24 01:17:06][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.83e-02, avg batch time: 0.8006, average train loss: 0.1827average G loss: 0.0004, average realD loss: 0.0133, average fakeD loss: 0.0153, 
[09/24 01:17:09][INFO] visual_prompt:  435: Inference (val):avg data time: 6.15e-05, avg batch time: 0.1219, average loss: 0.4881
[09/24 01:17:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.67	
[09/24 01:17:22][INFO] visual_prompt:  435: Inference (test):avg data time: 7.96e-05, avg batch time: 0.1282, average loss: 0.4942
[09/24 01:17:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.12	top5: 98.03	
[09/24 01:17:22][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 0.045920986337059086
[09/24 01:18:30][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 1.89e-02, avg batch time: 0.8013, average train loss: 0.1776average G loss: 0.0004, average realD loss: 0.0127, average fakeD loss: 0.0297, 
[09/24 01:18:33][INFO] visual_prompt:  435: Inference (val):avg data time: 5.13e-05, avg batch time: 0.1218, average loss: 0.4912
[09/24 01:18:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.67	
[09/24 01:18:46][INFO] visual_prompt:  435: Inference (test):avg data time: 8.58e-05, avg batch time: 0.1277, average loss: 0.4953
[09/24 01:18:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.88	top5: 98.02	
[09/24 01:18:46][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 0.04494909833715867
[09/24 01:19:54][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.75e-02, avg batch time: 0.8000, average train loss: 0.1773average G loss: 0.0005, average realD loss: 0.0128, average fakeD loss: 0.0343, 
[09/24 01:19:57][INFO] visual_prompt:  435: Inference (val):avg data time: 5.28e-05, avg batch time: 0.1199, average loss: 0.4875
[09/24 01:19:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.50	
[09/24 01:20:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.85e-05, avg batch time: 0.1276, average loss: 0.4951
[09/24 01:20:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.63	top5: 97.91	
[09/24 01:20:10][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 0.04396052009611876
[09/24 01:21:18][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 1.85e-02, avg batch time: 0.8008, average train loss: 0.1638average G loss: 0.0004, average realD loss: 0.0156, average fakeD loss: 0.0187, 
[09/24 01:21:21][INFO] visual_prompt:  435: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1208, average loss: 0.4856
[09/24 01:21:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.00	
[09/24 01:21:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.51e-05, avg batch time: 0.1277, average loss: 0.4986
[09/24 01:21:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.19	top5: 97.84	
[09/24 01:21:34][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 0.042956456044247256
[09/24 01:22:42][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.80e-02, avg batch time: 0.8002, average train loss: 0.1655average G loss: 0.0004, average realD loss: 0.0112, average fakeD loss: 0.0137, 
[09/24 01:22:45][INFO] visual_prompt:  435: Inference (val):avg data time: 5.28e-05, avg batch time: 0.1212, average loss: 0.4954
[09/24 01:22:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 97.67	
[09/24 01:22:59][INFO] visual_prompt:  435: Inference (test):avg data time: 6.66e-05, avg batch time: 0.1273, average loss: 0.4963
[09/24 01:22:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.38	top5: 97.88	
[09/24 01:22:59][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 0.04193812947892715
[09/24 01:24:07][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 1.80e-02, avg batch time: 0.8006, average train loss: 0.1657average G loss: 0.0006, average realD loss: 0.0116, average fakeD loss: 0.0203, 
[09/24 01:24:09][INFO] visual_prompt:  435: Inference (val):avg data time: 5.61e-05, avg batch time: 0.1200, average loss: 0.4799
[09/24 01:24:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.00	
[09/24 01:24:23][INFO] visual_prompt:  435: Inference (test):avg data time: 7.74e-05, avg batch time: 0.1277, average loss: 0.4987
[09/24 01:24:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.11	top5: 97.84	
[09/24 01:24:23][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 0.04090678107421711
[09/24 01:25:31][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 1.73e-02, avg batch time: 0.8001, average train loss: 0.1591average G loss: 0.0003, average realD loss: 0.0152, average fakeD loss: 0.0392, 
[09/24 01:25:33][INFO] visual_prompt:  435: Inference (val):avg data time: 8.04e-05, avg batch time: 0.1205, average loss: 0.4839
[09/24 01:25:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.83	top5: 97.83	
[09/24 01:25:47][INFO] visual_prompt:  435: Inference (test):avg data time: 8.63e-05, avg batch time: 0.1283, average loss: 0.4995
[09/24 01:25:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.35	top5: 97.76	
[09/24 01:25:47][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 0.03986366736928122
[09/24 01:26:55][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.84e-02, avg batch time: 0.8012, average train loss: 0.1582average G loss: 0.0004, average realD loss: 0.0092, average fakeD loss: 0.0273, 
[09/24 01:26:57][INFO] visual_prompt:  435: Inference (val):avg data time: 5.77e-05, avg batch time: 0.1204, average loss: 0.4903
[09/24 01:26:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.00	
[09/24 01:27:11][INFO] visual_prompt:  435: Inference (test):avg data time: 9.77e-05, avg batch time: 0.1281, average loss: 0.5019
[09/24 01:27:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.93	top5: 97.81	
[09/24 01:27:11][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 0.03881005923748961
[09/24 01:28:20][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 1.84e-02, avg batch time: 0.8011, average train loss: 0.1578average G loss: 0.0004, average realD loss: 0.0143, average fakeD loss: 0.0376, 
[09/24 01:28:22][INFO] visual_prompt:  435: Inference (val):avg data time: 8.29e-05, avg batch time: 0.1201, average loss: 0.4918
[09/24 01:28:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 97.83	
[09/24 01:28:36][INFO] visual_prompt:  435: Inference (test):avg data time: 9.17e-05, avg batch time: 0.1279, average loss: 0.4984
[09/24 01:28:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.21	top5: 97.84	
[09/24 01:28:36][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 0.037747240338054974
[09/24 01:29:44][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 1.91e-02, avg batch time: 0.8018, average train loss: 0.1520average G loss: 0.0004, average realD loss: 0.0102, average fakeD loss: 0.0192, 
[09/24 01:29:46][INFO] visual_prompt:  435: Inference (val):avg data time: 7.11e-05, avg batch time: 0.1213, average loss: 0.4909
[09/24 01:29:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.33	
[09/24 01:30:00][INFO] visual_prompt:  435: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1276, average loss: 0.4993
[09/24 01:30:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.25	top5: 97.74	
[09/24 01:30:00][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 0.03667650555209158
[09/24 01:31:08][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.83e-02, avg batch time: 0.8013, average train loss: 0.1499average G loss: 0.0004, average realD loss: 0.0109, average fakeD loss: 0.0356, 
[09/24 01:31:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.74e-05, avg batch time: 0.1207, average loss: 0.4992
[09/24 01:31:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.83	
[09/24 01:31:24][INFO] visual_prompt:  435: Inference (test):avg data time: 7.84e-05, avg batch time: 0.1281, average loss: 0.5047
[09/24 01:31:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.91	
[09/24 01:31:24][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 0.035599159405002044
[09/24 01:32:32][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.91e-02, avg batch time: 0.8021, average train loss: 0.1449average G loss: 0.0004, average realD loss: 0.0126, average fakeD loss: 0.0106, 
[09/24 01:32:35][INFO] visual_prompt:  435: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1205, average loss: 0.4905
[09/24 01:32:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.17	
[09/24 01:32:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.30e-05, avg batch time: 0.1282, average loss: 0.5029
[09/24 01:32:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.21	top5: 97.76	
[09/24 01:32:48][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 0.03451651447711417
[09/24 01:33:56][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 1.93e-02, avg batch time: 0.8024, average train loss: 0.1404average G loss: 0.0003, average realD loss: 0.0077, average fakeD loss: 0.0206, 
[09/24 01:33:59][INFO] visual_prompt:  435: Inference (val):avg data time: 7.68e-05, avg batch time: 0.1212, average loss: 0.4867
[09/24 01:33:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.00	
[09/24 01:34:12][INFO] visual_prompt:  435: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1279, average loss: 0.5026
[09/24 01:34:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.97	top5: 97.95	
[09/24 01:34:12][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 0.03342988980450391
[09/24 01:35:21][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.96e-02, avg batch time: 0.8029, average train loss: 0.1395average G loss: 0.0004, average realD loss: 0.0094, average fakeD loss: 0.0342, 
[09/24 01:35:23][INFO] visual_prompt:  435: Inference (val):avg data time: 6.60e-05, avg batch time: 0.1201, average loss: 0.5045
[09/24 01:35:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 97.83	
[09/24 01:35:37][INFO] visual_prompt:  435: Inference (test):avg data time: 8.60e-05, avg batch time: 0.1278, average loss: 0.5074
[09/24 01:35:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.00	top5: 97.69	
[09/24 01:35:37][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 0.03234060927195316
[09/24 01:36:45][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.84e-02, avg batch time: 0.8016, average train loss: 0.1391average G loss: 0.0004, average realD loss: 0.0125, average fakeD loss: 0.0131, 
[09/24 01:36:48][INFO] visual_prompt:  435: Inference (val):avg data time: 5.22e-05, avg batch time: 0.1204, average loss: 0.5011
[09/24 01:36:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.33	
[09/24 01:37:01][INFO] visual_prompt:  435: Inference (test):avg data time: 7.44e-05, avg batch time: 0.1281, average loss: 0.5033
[09/24 01:37:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.26	top5: 97.79	
[09/24 01:37:01][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 0.03125
[09/24 01:38:10][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 1.87e-02, avg batch time: 0.8018, average train loss: 0.1338average G loss: 0.0003, average realD loss: 0.0126, average fakeD loss: 0.0171, 
[09/24 01:38:12][INFO] visual_prompt:  435: Inference (val):avg data time: 7.55e-05, avg batch time: 0.1215, average loss: 0.4949
[09/24 01:38:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.83	
[09/24 01:38:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.40e-05, avg batch time: 0.1276, average loss: 0.5012
[09/24 01:38:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.88	
[09/24 01:38:26][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 0.030159390728046853
[09/24 01:39:34][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.86e-02, avg batch time: 0.8019, average train loss: 0.1349average G loss: 0.0004, average realD loss: 0.0126, average fakeD loss: 0.0100, 
[09/24 01:39:36][INFO] visual_prompt:  435: Inference (val):avg data time: 5.94e-05, avg batch time: 0.1205, average loss: 0.4897
[09/24 01:39:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.00	
[09/24 01:39:50][INFO] visual_prompt:  435: Inference (test):avg data time: 7.72e-05, avg batch time: 0.1278, average loss: 0.4955
[09/24 01:39:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.21	top5: 97.83	
[09/24 01:39:50][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 0.029070110195496084
[09/24 01:40:58][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 1.87e-02, avg batch time: 0.8020, average train loss: 0.1334average G loss: 0.0003, average realD loss: 0.0076, average fakeD loss: 0.0225, 
[09/24 01:41:01][INFO] visual_prompt:  435: Inference (val):avg data time: 5.93e-05, avg batch time: 0.1206, average loss: 0.5021
[09/24 01:41:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 88.00	top5: 97.83	
[09/24 01:41:14][INFO] visual_prompt:  435: Inference (test):avg data time: 7.04e-05, avg batch time: 0.1282, average loss: 0.5010
[09/24 01:41:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.77	
[09/24 01:41:14][INFO] visual_prompt:  357: Best epoch 58: best metric: 0.880
[09/24 01:41:14][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 0.027983485522885834
[09/24 01:42:22][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.79e-02, avg batch time: 0.8013, average train loss: 0.1335average G loss: 0.0004, average realD loss: 0.0121, average fakeD loss: 0.0154, 
[09/24 01:42:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.59e-05, avg batch time: 0.1203, average loss: 0.5032
[09/24 01:42:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 97.83	
[09/24 01:42:39][INFO] visual_prompt:  435: Inference (test):avg data time: 9.74e-05, avg batch time: 0.1278, average loss: 0.5061
[09/24 01:42:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.18	top5: 97.65	
[09/24 01:42:39][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 0.026900840594997963
[09/24 01:43:47][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 1.84e-02, avg batch time: 0.8022, average train loss: 0.1277average G loss: 0.0002, average realD loss: 0.0099, average fakeD loss: 0.0127, 
[09/24 01:43:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.92e-05, avg batch time: 0.1203, average loss: 0.5095
[09/24 01:43:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.83	
[09/24 01:44:03][INFO] visual_prompt:  435: Inference (test):avg data time: 7.44e-05, avg batch time: 0.1278, average loss: 0.5049
[09/24 01:44:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.67	
[09/24 01:44:03][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 0.025823494447908428
[09/24 01:45:11][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.88e-02, avg batch time: 0.8026, average train loss: 0.1244average G loss: 0.0005, average realD loss: 0.0100, average fakeD loss: 0.0139, 
[09/24 01:45:13][INFO] visual_prompt:  435: Inference (val):avg data time: 6.15e-05, avg batch time: 0.1213, average loss: 0.4990
[09/24 01:45:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 97.67	
[09/24 01:45:27][INFO] visual_prompt:  435: Inference (test):avg data time: 7.01e-05, avg batch time: 0.1277, average loss: 0.5067
[09/24 01:45:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.02	top5: 97.67	
[09/24 01:45:27][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 0.024752759661945026
[09/24 01:46:35][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.94e-02, avg batch time: 0.8029, average train loss: 0.1264average G loss: 0.0004, average realD loss: 0.0088, average fakeD loss: 0.0141, 
[09/24 01:46:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1204, average loss: 0.4924
[09/24 01:46:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 97.67	
[09/24 01:46:51][INFO] visual_prompt:  435: Inference (test):avg data time: 7.74e-05, avg batch time: 0.1282, average loss: 0.5017
[09/24 01:46:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.04	top5: 97.76	
[09/24 01:46:51][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 0.023689940762510388
[09/24 01:48:00][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 2.10e-02, avg batch time: 0.8051, average train loss: 0.1270average G loss: 0.0002, average realD loss: 0.0084, average fakeD loss: 0.0325, 
[09/24 01:48:02][INFO] visual_prompt:  435: Inference (val):avg data time: 5.01e-05, avg batch time: 0.1215, average loss: 0.4893
[09/24 01:48:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.00	
[09/24 01:48:16][INFO] visual_prompt:  435: Inference (test):avg data time: 8.38e-05, avg batch time: 0.1280, average loss: 0.4979
[09/24 01:48:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.16	top5: 97.91	
[09/24 01:48:16][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 0.022636332630718778
[09/24 01:49:24][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.85e-02, avg batch time: 0.8023, average train loss: 0.1169average G loss: 0.0005, average realD loss: 0.0140, average fakeD loss: 0.0292, 
[09/24 01:49:26][INFO] visual_prompt:  435: Inference (val):avg data time: 9.00e-05, avg batch time: 0.1206, average loss: 0.5001
[09/24 01:49:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.67	
[09/24 01:49:40][INFO] visual_prompt:  435: Inference (test):avg data time: 7.47e-05, avg batch time: 0.1279, average loss: 0.5027
[09/24 01:49:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.88	top5: 97.70	
[09/24 01:49:40][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 0.021593218925782896
[09/24 01:50:48][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.98e-02, avg batch time: 0.8035, average train loss: 0.1269average G loss: 0.0004, average realD loss: 0.0094, average fakeD loss: 0.0124, 
[09/24 01:50:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.65e-05, avg batch time: 0.1207, average loss: 0.4973
[09/24 01:50:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.00	
[09/24 01:51:04][INFO] visual_prompt:  435: Inference (test):avg data time: 6.80e-05, avg batch time: 0.1278, average loss: 0.5022
[09/24 01:51:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.97	top5: 97.72	
[09/24 01:51:04][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 0.020561870521072854
[09/24 01:52:13][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 2.01e-02, avg batch time: 0.8039, average train loss: 0.1205average G loss: 0.0003, average realD loss: 0.0098, average fakeD loss: 0.0305, 
[09/24 01:52:15][INFO] visual_prompt:  435: Inference (val):avg data time: 6.01e-05, avg batch time: 0.1208, average loss: 0.5032
[09/24 01:52:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.83	
[09/24 01:52:29][INFO] visual_prompt:  435: Inference (test):avg data time: 5.44e-05, avg batch time: 0.1280, average loss: 0.5095
[09/24 01:52:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.97	top5: 97.64	
[09/24 01:52:29][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 0.019543543955752748
[09/24 01:53:37][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.88e-02, avg batch time: 0.8028, average train loss: 0.1229average G loss: 0.0003, average realD loss: 0.0109, average fakeD loss: 0.0188, 
[09/24 01:53:39][INFO] visual_prompt:  435: Inference (val):avg data time: 7.61e-05, avg batch time: 0.1206, average loss: 0.4941
[09/24 01:53:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.00	
[09/24 01:53:53][INFO] visual_prompt:  435: Inference (test):avg data time: 6.19e-05, avg batch time: 0.1282, average loss: 0.5019
[09/24 01:53:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.25	top5: 97.83	
[09/24 01:53:53][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 0.01853947990388125
[09/24 01:55:01][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.78e-02, avg batch time: 0.8017, average train loss: 0.1133average G loss: 0.0006, average realD loss: 0.0108, average fakeD loss: 0.0117, 
[09/24 01:55:03][INFO] visual_prompt:  435: Inference (val):avg data time: 6.59e-05, avg batch time: 0.1208, average loss: 0.4969
[09/24 01:55:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.67	
[09/24 01:55:17][INFO] visual_prompt:  435: Inference (test):avg data time: 6.13e-05, avg batch time: 0.1282, average loss: 0.5004
[09/24 01:55:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.11	top5: 97.67	
[09/24 01:55:17][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 0.017550901662841328
[09/24 01:56:25][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 1.87e-02, avg batch time: 0.8026, average train loss: 0.1228average G loss: 0.0004, average realD loss: 0.0090, average fakeD loss: 0.0121, 
[09/24 01:56:28][INFO] visual_prompt:  435: Inference (val):avg data time: 5.63e-05, avg batch time: 0.1207, average loss: 0.4902
[09/24 01:56:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.00	
[09/24 01:56:41][INFO] visual_prompt:  435: Inference (test):avg data time: 7.55e-05, avg batch time: 0.1282, average loss: 0.5018
[09/24 01:56:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.83	
[09/24 01:56:41][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 0.01657901366294092
[09/24 01:57:50][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.72e-02, avg batch time: 0.8015, average train loss: 0.1166average G loss: 0.0003, average realD loss: 0.0107, average fakeD loss: 0.0182, 
[09/24 01:57:52][INFO] visual_prompt:  435: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1204, average loss: 0.5100
[09/24 01:57:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.33	
[09/24 01:58:05][INFO] visual_prompt:  435: Inference (test):avg data time: 7.50e-05, avg batch time: 0.1285, average loss: 0.5070
[09/24 01:58:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.67	
[09/24 01:58:05][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 0.015625000000000007
[09/24 01:59:14][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 1.77e-02, avg batch time: 0.8019, average train loss: 0.1111average G loss: 0.0006, average realD loss: 0.0090, average fakeD loss: 0.0148, 
[09/24 01:59:16][INFO] visual_prompt:  435: Inference (val):avg data time: 9.10e-05, avg batch time: 0.1205, average loss: 0.5061
[09/24 01:59:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.67	
[09/24 01:59:30][INFO] visual_prompt:  435: Inference (test):avg data time: 9.65e-05, avg batch time: 0.1278, average loss: 0.5106
[09/24 01:59:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.85	top5: 97.69	
[09/24 01:59:30][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 0.01469002299271235
[09/24 02:00:38][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.77e-02, avg batch time: 0.8017, average train loss: 0.1114average G loss: 0.0002, average realD loss: 0.0083, average fakeD loss: 0.0238, 
[09/24 02:00:40][INFO] visual_prompt:  435: Inference (val):avg data time: 5.26e-05, avg batch time: 0.1218, average loss: 0.5022
[09/24 02:00:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 97.83	
[09/24 02:00:54][INFO] visual_prompt:  435: Inference (test):avg data time: 1.31e-04, avg batch time: 0.1276, average loss: 0.5054
[09/24 02:00:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.86	
[09/24 02:00:54][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 0.013775221766539166
[09/24 02:02:03][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 1.95e-02, avg batch time: 0.8035, average train loss: 0.1092average G loss: 0.0003, average realD loss: 0.0092, average fakeD loss: 0.0110, 
[09/24 02:02:05][INFO] visual_prompt:  435: Inference (val):avg data time: 6.67e-05, avg batch time: 0.1211, average loss: 0.5076
[09/24 02:02:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.50	
[09/24 02:02:18][INFO] visual_prompt:  435: Inference (test):avg data time: 6.31e-05, avg batch time: 0.1281, average loss: 0.5050
[09/24 02:02:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.76	top5: 97.77	
[09/24 02:02:18][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 0.012881710865860218
[09/24 02:03:27][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.93e-02, avg batch time: 0.8035, average train loss: 0.1146average G loss: 0.0003, average realD loss: 0.0074, average fakeD loss: 0.0136, 
[09/24 02:03:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.78e-05, avg batch time: 0.1213, average loss: 0.5004
[09/24 02:03:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 97.67	
[09/24 02:03:43][INFO] visual_prompt:  435: Inference (test):avg data time: 6.49e-05, avg batch time: 0.1276, average loss: 0.5046
[09/24 02:03:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.84	
[09/24 02:03:43][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 0.012010578896073178
[09/24 02:04:51][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.73e-02, avg batch time: 0.8018, average train loss: 0.1125average G loss: 0.0003, average realD loss: 0.0112, average fakeD loss: 0.0144, 
[09/24 02:04:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.13e-05, avg batch time: 0.1207, average loss: 0.4977
[09/24 02:04:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.83	
[09/24 02:05:07][INFO] visual_prompt:  435: Inference (test):avg data time: 8.65e-05, avg batch time: 0.1282, average loss: 0.5012
[09/24 02:05:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.80	top5: 97.77	
[09/24 02:05:07][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 0.011162887197295645
[09/24 02:06:16][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.92e-02, avg batch time: 0.8033, average train loss: 0.1043average G loss: 0.0003, average realD loss: 0.0110, average fakeD loss: 0.0143, 
[09/24 02:06:18][INFO] visual_prompt:  435: Inference (val):avg data time: 4.22e-05, avg batch time: 0.1217, average loss: 0.4998
[09/24 02:06:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.67	
[09/24 02:06:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1282, average loss: 0.5017
[09/24 02:06:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.12	top5: 97.76	
[09/24 02:06:32][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 0.01033966855128569
[09/24 02:07:40][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 1.89e-02, avg batch time: 0.8031, average train loss: 0.1051average G loss: 0.0003, average realD loss: 0.0075, average fakeD loss: 0.0156, 
[09/24 02:07:42][INFO] visual_prompt:  435: Inference (val):avg data time: 5.72e-05, avg batch time: 0.1208, average loss: 0.4997
[09/24 02:07:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 97.50	
[09/24 02:07:56][INFO] visual_prompt:  435: Inference (test):avg data time: 8.71e-05, avg batch time: 0.1280, average loss: 0.5038
[09/24 02:07:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.72	
[09/24 02:07:56][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.009541925923156332
[09/24 02:09:04][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 1.85e-02, avg batch time: 0.8027, average train loss: 0.1061average G loss: 0.0004, average realD loss: 0.0079, average fakeD loss: 0.0110, 
[09/24 02:09:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.07e-05, avg batch time: 0.1203, average loss: 0.5054
[09/24 02:09:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 97.67	
[09/24 02:09:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.35e-05, avg batch time: 0.1280, average loss: 0.5044
[09/24 02:09:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.77	
[09/24 02:09:20][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.008770631239417157
[09/24 02:10:29][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 1.85e-02, avg batch time: 0.8029, average train loss: 0.1015average G loss: 0.0004, average realD loss: 0.0100, average fakeD loss: 0.0316, 
[09/24 02:10:31][INFO] visual_prompt:  435: Inference (val):avg data time: 7.09e-05, avg batch time: 0.1202, average loss: 0.5036
[09/24 02:10:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.67	
[09/24 02:10:45][INFO] visual_prompt:  435: Inference (test):avg data time: 7.40e-05, avg batch time: 0.1278, average loss: 0.5042
[09/24 02:10:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.76	
[09/24 02:10:45][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.008026724203831426
[09/24 02:11:53][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 1.83e-02, avg batch time: 0.8025, average train loss: 0.1084average G loss: 0.0005, average realD loss: 0.0105, average fakeD loss: 0.0100, 
[09/24 02:11:55][INFO] visual_prompt:  435: Inference (val):avg data time: 5.75e-05, avg batch time: 0.1201, average loss: 0.5005
[09/24 02:11:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.67	
[09/24 02:12:09][INFO] visual_prompt:  435: Inference (test):avg data time: 7.46e-05, avg batch time: 0.1279, average loss: 0.5025
[09/24 02:12:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.92	top5: 97.76	
[09/24 02:12:09][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.0073111111525319405
[09/24 02:13:18][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.82e-02, avg batch time: 0.8025, average train loss: 0.1086average G loss: 0.0003, average realD loss: 0.0092, average fakeD loss: 0.0275, 
[09/24 02:13:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1205, average loss: 0.4992
[09/24 02:13:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.67	
[09/24 02:13:33][INFO] visual_prompt:  435: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1286, average loss: 0.5041
[09/24 02:13:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.77	
[09/24 02:13:33][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.0066246639497899405
[09/24 02:14:42][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.90e-02, avg batch time: 0.8033, average train loss: 0.1076average G loss: 0.0003, average realD loss: 0.0119, average fakeD loss: 0.0135, 
[09/24 02:14:44][INFO] visual_prompt:  435: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1210, average loss: 0.5063
[09/24 02:14:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.50	
[09/24 02:14:57][INFO] visual_prompt:  435: Inference (test):avg data time: 6.50e-05, avg batch time: 0.1286, average loss: 0.5080
[09/24 02:14:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.78	top5: 97.79	
[09/24 02:14:57][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.005968218925782896
[09/24 02:16:06][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.84e-02, avg batch time: 0.8029, average train loss: 0.1023average G loss: 0.0003, average realD loss: 0.0082, average fakeD loss: 0.0156, 
[09/24 02:16:08][INFO] visual_prompt:  435: Inference (val):avg data time: 6.51e-05, avg batch time: 0.1212, average loss: 0.4942
[09/24 02:16:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.67	
[09/24 02:16:22][INFO] visual_prompt:  435: Inference (test):avg data time: 6.94e-05, avg batch time: 0.1281, average loss: 0.5024
[09/24 02:16:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.77	
[09/24 02:16:22][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.005342575857654949
[09/24 02:17:30][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.85e-02, avg batch time: 0.8030, average train loss: 0.1053average G loss: 0.0003, average realD loss: 0.0112, average fakeD loss: 0.0142, 
[09/24 02:17:32][INFO] visual_prompt:  435: Inference (val):avg data time: 4.91e-05, avg batch time: 0.1217, average loss: 0.4985
[09/24 02:17:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.67	
[09/24 02:17:46][INFO] visual_prompt:  435: Inference (test):avg data time: 6.33e-05, avg batch time: 0.1278, average loss: 0.5044
[09/24 02:17:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.74	
[09/24 02:17:46][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.004748496995111689
[09/24 02:18:54][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.90e-02, avg batch time: 0.8033, average train loss: 0.1051average G loss: 0.0002, average realD loss: 0.0073, average fakeD loss: 0.0148, 
[09/24 02:18:57][INFO] visual_prompt:  435: Inference (val):avg data time: 6.16e-05, avg batch time: 0.1208, average loss: 0.4988
[09/24 02:18:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.67	
[09/24 02:19:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.09e-05, avg batch time: 0.1280, average loss: 0.5044
[09/24 02:19:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.72	
[09/24 02:19:10][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.00418670613173629
[09/24 02:20:19][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.93e-02, avg batch time: 0.8040, average train loss: 0.1023average G loss: 0.0003, average realD loss: 0.0067, average fakeD loss: 0.0104, 
[09/24 02:20:21][INFO] visual_prompt:  435: Inference (val):avg data time: 5.92e-05, avg batch time: 0.1203, average loss: 0.4999
[09/24 02:20:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 97.67	
[09/24 02:20:35][INFO] visual_prompt:  435: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1278, average loss: 0.5043
[09/24 02:20:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.71	top5: 97.72	
[09/24 02:20:35][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.0036578877231585316
[09/24 02:21:43][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.83e-02, avg batch time: 0.8029, average train loss: 0.1044average G loss: 0.0003, average realD loss: 0.0087, average fakeD loss: 0.0148, 
[09/24 02:21:45][INFO] visual_prompt:  435: Inference (val):avg data time: 5.93e-05, avg batch time: 0.1205, average loss: 0.5016
[09/24 02:21:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.67	
[09/24 02:21:59][INFO] visual_prompt:  435: Inference (test):avg data time: 8.86e-05, avg batch time: 0.1278, average loss: 0.5040
[09/24 02:21:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.85	top5: 97.76	
[09/24 02:21:59][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.003162686053151037
[09/24 02:23:08][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.84e-02, avg batch time: 0.8032, average train loss: 0.0995average G loss: 0.0004, average realD loss: 0.0086, average fakeD loss: 0.0105, 
[09/24 02:23:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1208, average loss: 0.4986
[09/24 02:23:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 97.67	
[09/24 02:23:23][INFO] visual_prompt:  435: Inference (test):avg data time: 6.97e-05, avg batch time: 0.1284, average loss: 0.5051
[09/24 02:23:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.76	top5: 97.76	
[09/24 02:23:24][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.0027017044486687194
[09/24 02:24:32][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.89e-02, avg batch time: 0.8038, average train loss: 0.1009average G loss: 0.0004, average realD loss: 0.0095, average fakeD loss: 0.0103, 
[09/24 02:24:34][INFO] visual_prompt:  435: Inference (val):avg data time: 1.04e-04, avg batch time: 0.1203, average loss: 0.4988
[09/24 02:24:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.67	
[09/24 02:24:48][INFO] visual_prompt:  435: Inference (test):avg data time: 8.34e-05, avg batch time: 0.1281, average loss: 0.5050
[09/24 02:24:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.66	top5: 97.74	
[09/24 02:24:48][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.0022755045447878965
[09/24 02:25:56][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.85e-02, avg batch time: 0.8029, average train loss: 0.1004average G loss: 0.0004, average realD loss: 0.0124, average fakeD loss: 0.0288, 
[09/24 02:25:59][INFO] visual_prompt:  435: Inference (val):avg data time: 9.60e-05, avg batch time: 0.1216, average loss: 0.4994
[09/24 02:25:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 97.67	
[09/24 02:26:12][INFO] visual_prompt:  435: Inference (test):avg data time: 8.08e-05, avg batch time: 0.1287, average loss: 0.5056
[09/24 02:26:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.76	
[09/24 02:26:12][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.001884605600440365
[09/24 02:27:20][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.84e-02, avg batch time: 0.8030, average train loss: 0.1002average G loss: 0.0003, average realD loss: 0.0076, average fakeD loss: 0.0122, 
[09/24 02:27:22][INFO] visual_prompt:  435: Inference (val):avg data time: 5.42e-05, avg batch time: 0.1208, average loss: 0.4989
[09/24 02:27:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.67	
[09/24 02:27:36][INFO] visual_prompt:  435: Inference (test):avg data time: 7.96e-05, avg batch time: 0.1279, average loss: 0.5052
[09/24 02:27:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.76	top5: 97.74	
[09/24 02:27:36][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.0015294838657764522
[09/24 02:28:44][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.77e-02, avg batch time: 0.8025, average train loss: 0.0973average G loss: 0.0002, average realD loss: 0.0118, average fakeD loss: 0.0080, 
[09/24 02:28:47][INFO] visual_prompt:  435: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1208, average loss: 0.4986
[09/24 02:28:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.67	
[09/24 02:29:00][INFO] visual_prompt:  435: Inference (test):avg data time: 6.63e-05, avg batch time: 0.1280, average loss: 0.5045
[09/24 02:29:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.78	top5: 97.70	
[09/24 02:29:00][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.0012105720019275346
[09/24 02:30:09][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.82e-02, avg batch time: 0.8027, average train loss: 0.0962average G loss: 0.0005, average realD loss: 0.0090, average fakeD loss: 0.0127, 
[09/24 02:30:11][INFO] visual_prompt:  435: Inference (val):avg data time: 7.15e-05, avg batch time: 0.1209, average loss: 0.4988
[09/24 02:30:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 97.67	
[09/24 02:30:25][INFO] visual_prompt:  435: Inference (test):avg data time: 8.10e-05, avg batch time: 0.1280, average loss: 0.5048
[09/24 02:30:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.88	top5: 97.74	
[09/24 02:30:25][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.0009282585538751102
[09/24 02:31:33][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.91e-02, avg batch time: 0.8034, average train loss: 0.0998average G loss: 0.0002, average realD loss: 0.0068, average fakeD loss: 0.0113, 
[09/24 02:31:36][INFO] visual_prompt:  435: Inference (val):avg data time: 5.64e-05, avg batch time: 0.1209, average loss: 0.4996
[09/24 02:31:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 97.67	
[09/24 02:31:49][INFO] visual_prompt:  435: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1279, average loss: 0.5053
[09/24 02:31:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.74	
[09/24 02:31:50][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.0006828874770685722
[09/24 02:32:58][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 1.95e-02, avg batch time: 0.8039, average train loss: 0.1034average G loss: 0.0002, average realD loss: 0.0082, average fakeD loss: 0.0172, 
[09/24 02:33:00][INFO] visual_prompt:  435: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1205, average loss: 0.4986
[09/24 02:33:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.67	
[09/24 02:33:14][INFO] visual_prompt:  435: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1280, average loss: 0.5048
[09/24 02:33:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.88	top5: 97.76	
[09/24 02:33:14][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.00047475771836849937
[09/24 02:34:22][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 1.98e-02, avg batch time: 0.8043, average train loss: 0.0982average G loss: 0.0006, average realD loss: 0.0107, average fakeD loss: 0.0291, 
[09/24 02:34:25][INFO] visual_prompt:  435: Inference (val):avg data time: 4.97e-05, avg batch time: 0.1218, average loss: 0.4983
[09/24 02:34:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 97.67	
[09/24 02:34:38][INFO] visual_prompt:  435: Inference (test):avg data time: 9.49e-05, avg batch time: 0.1282, average loss: 0.5046
[09/24 02:34:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.76	
[09/24 02:34:38][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.0003041228518259262
[09/24 02:35:46][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 1.86e-02, avg batch time: 0.8027, average train loss: 0.0994average G loss: 0.0002, average realD loss: 0.0078, average fakeD loss: 0.0127, 
[09/24 02:35:48][INFO] visual_prompt:  435: Inference (val):avg data time: 8.44e-05, avg batch time: 0.1206, average loss: 0.4987
[09/24 02:35:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.67	
[09/24 02:36:02][INFO] visual_prompt:  435: Inference (test):avg data time: 8.51e-05, avg batch time: 0.1277, average loss: 0.5046
[09/24 02:36:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.87	top5: 97.76	
[09/24 02:36:02][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.0001711907697414597
[09/24 02:37:11][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 1.93e-02, avg batch time: 0.8026, average train loss: 0.0986average G loss: 0.0003, average realD loss: 0.0120, average fakeD loss: 0.0149, 
[09/24 02:37:13][INFO] visual_prompt:  435: Inference (val):avg data time: 4.82e-05, avg batch time: 0.1218, average loss: 0.4986
[09/24 02:37:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.67	
[09/24 02:37:27][INFO] visual_prompt:  435: Inference (test):avg data time: 6.27e-05, avg batch time: 0.1278, average loss: 0.5047
[09/24 02:37:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.74	
[09/24 02:37:27][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 7.612342938049382e-05
[09/24 02:38:35][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.81e-02, avg batch time: 0.8009, average train loss: 0.1053average G loss: 0.0003, average realD loss: 0.0095, average fakeD loss: 0.0303, 
[09/24 02:38:37][INFO] visual_prompt:  435: Inference (val):avg data time: 5.24e-05, avg batch time: 0.1209, average loss: 0.4988
[09/24 02:38:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.67	
[09/24 02:38:51][INFO] visual_prompt:  435: Inference (test):avg data time: 6.87e-05, avg batch time: 0.1276, average loss: 0.5047
[09/24 02:38:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.85	top5: 97.74	
[09/24 02:38:51][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 1.9036655653257434e-05
[09/24 02:39:59][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.75e-02, avg batch time: 0.7998, average train loss: 0.1012average G loss: 0.0003, average realD loss: 0.0091, average fakeD loss: 0.0154, 
[09/24 02:40:01][INFO] visual_prompt:  435: Inference (val):avg data time: 4.48e-05, avg batch time: 0.1204, average loss: 0.4988
[09/24 02:40:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 97.67	
[09/24 02:40:15][INFO] visual_prompt:  435: Inference (test):avg data time: 7.54e-05, avg batch time: 0.1278, average loss: 0.5047
[09/24 02:40:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.85	top5: 97.74	
