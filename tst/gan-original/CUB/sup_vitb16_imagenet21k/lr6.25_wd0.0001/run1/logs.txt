[09/22 20:05:05][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/22 20:05:05][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/22 20:05:05][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/gan-original', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/22 20:05:05][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/22 20:05:05][INFO] visual_prompt:  109: Training with config:
[09/22 20:05:05][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/gan-original/CUB/sup_vitb16_imagenet21k/lr6.25_wd0.0001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 6.25,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/22 20:05:05][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/22 20:05:05][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/22 20:05:05][INFO] visual_prompt:   77: Number of images: 5394
[09/22 20:05:05][INFO] visual_prompt:   78: Number of classes: 200
[09/22 20:05:05][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/22 20:05:05][INFO] visual_prompt:   73: Loading validation data...
[09/22 20:05:05][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/22 20:05:05][INFO] visual_prompt:   77: Number of images: 600
[09/22 20:05:05][INFO] visual_prompt:   78: Number of classes: 200
[09/22 20:05:05][INFO] visual_prompt:   76: Loading test data...
[09/22 20:05:05][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/22 20:05:05][INFO] visual_prompt:   77: Number of images: 5794
[09/22 20:05:05][INFO] visual_prompt:   78: Number of classes: 200
[09/22 20:05:05][INFO] visual_prompt:  103: Constructing models...
[09/22 20:05:10][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/22 20:05:10][INFO] visual_prompt:   55: tuned percent:0.143
[09/22 20:05:10][INFO] visual_prompt:   41: Device used for model: 0
[09/22 20:05:10][INFO] visual_prompt:  106: Setting up Evalutator...
[09/22 20:05:10][INFO] visual_prompt:  108: Setting up Trainer...
[09/22 20:05:10][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/22 20:05:10][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/22 20:06:19][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.87e-02, avg batch time: 0.8075, average train loss: 5.3271average G loss: 4.8391, average realD loss: 11.1847, average fakeD loss: 0.5552, 
[09/22 20:06:21][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1210, average loss: 5.3305
[09/22 20:06:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 1.67	
[09/22 20:06:35][INFO] visual_prompt:  435: Inference (test):avg data time: 6.09e-05, avg batch time: 0.1290, average loss: 5.3229
[09/22 20:06:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.45	top5: 2.59	
[09/22 20:06:35][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.003
[09/22 20:06:35][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.625
[09/22 20:07:44][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.91e-02, avg batch time: 0.8061, average train loss: 5.4122average G loss: 0.0000, average realD loss: 0.1300, average fakeD loss: 97.9110, 
[09/22 20:07:46][INFO] visual_prompt:  435: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1220, average loss: 5.3660
[09/22 20:07:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.83	
[09/22 20:08:00][INFO] visual_prompt:  435: Inference (test):avg data time: 8.01e-05, avg batch time: 0.1294, average loss: 5.3663
[09/22 20:08:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.87	
[09/22 20:08:00][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.007
[09/22 20:08:00][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 1.25
[09/22 20:09:08][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.89e-02, avg batch time: 0.8062, average train loss: 5.4192average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:09:11][INFO] visual_prompt:  435: Inference (val):avg data time: 7.92e-05, avg batch time: 0.1207, average loss: 5.0778
[09/22 20:09:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 2.50	top5: 7.83	
[09/22 20:09:24][INFO] visual_prompt:  435: Inference (test):avg data time: 5.94e-05, avg batch time: 0.1294, average loss: 5.0797
[09/22 20:09:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 2.28	top5: 7.77	
[09/22 20:09:25][INFO] visual_prompt:  357: Best epoch 3: best metric: 0.025
[09/22 20:09:25][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 1.875
[09/22 20:10:33][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.93e-02, avg batch time: 0.8069, average train loss: 4.9912average G loss: 0.0009, average realD loss: 0.0011, average fakeD loss: 100.0000, 
[09/22 20:10:35][INFO] visual_prompt:  435: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1216, average loss: 3.6905
[09/22 20:10:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 17.50	top5: 42.00	
[09/22 20:10:50][INFO] visual_prompt:  435: Inference (test):avg data time: 9.57e-05, avg batch time: 0.1285, average loss: 3.6739
[09/22 20:10:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 17.76	top5: 41.91	
[09/22 20:10:50][INFO] visual_prompt:  357: Best epoch 4: best metric: 0.175
[09/22 20:10:50][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 2.5
[09/22 20:11:58][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 2.08e-02, avg batch time: 0.8079, average train loss: 2.7775average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:12:01][INFO] visual_prompt:  435: Inference (val):avg data time: 6.67e-05, avg batch time: 0.1209, average loss: 1.8002
[09/22 20:12:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 56.17	top5: 85.00	
[09/22 20:12:14][INFO] visual_prompt:  435: Inference (test):avg data time: 6.68e-05, avg batch time: 0.1293, average loss: 1.7719
[09/22 20:12:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 57.87	top5: 85.69	
[09/22 20:12:14][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.562
[09/22 20:12:14][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 3.125
[09/22 20:13:23][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.92e-02, avg batch time: 0.8066, average train loss: 1.6603average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:13:25][INFO] visual_prompt:  435: Inference (val):avg data time: 6.47e-05, avg batch time: 0.1227, average loss: 1.8247
[09/22 20:13:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.50	top5: 84.83	
[09/22 20:13:39][INFO] visual_prompt:  435: Inference (test):avg data time: 5.55e-05, avg batch time: 0.1293, average loss: 1.8498
[09/22 20:13:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.05	top5: 86.49	
[09/22 20:13:39][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.655
[09/22 20:13:39][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 3.75
[09/22 20:14:48][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.90e-02, avg batch time: 0.8061, average train loss: 1.5970average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:14:50][INFO] visual_prompt:  435: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1216, average loss: 2.2380
[09/22 20:14:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.00	top5: 85.00	
[09/22 20:15:04][INFO] visual_prompt:  435: Inference (test):avg data time: 6.25e-05, avg batch time: 0.1289, average loss: 2.1744
[09/22 20:15:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.64	top5: 86.50	
[09/22 20:15:04][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 4.375
[09/22 20:16:12][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.88e-02, avg batch time: 0.8059, average train loss: 1.6460average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:16:15][INFO] visual_prompt:  435: Inference (val):avg data time: 4.56e-05, avg batch time: 0.1217, average loss: 1.9134
[09/22 20:16:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.33	top5: 87.67	
[09/22 20:16:28][INFO] visual_prompt:  435: Inference (test):avg data time: 5.93e-05, avg batch time: 0.1292, average loss: 1.9227
[09/22 20:16:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.09	top5: 88.83	
[09/22 20:16:28][INFO] visual_prompt:  357: Best epoch 8: best metric: 0.673
[09/22 20:16:28][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 5.0
[09/22 20:17:37][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.96e-02, avg batch time: 0.8069, average train loss: 1.3312average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:17:39][INFO] visual_prompt:  435: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1212, average loss: 1.2584
[09/22 20:17:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.50	top5: 93.00	
[09/22 20:17:53][INFO] visual_prompt:  435: Inference (test):avg data time: 6.72e-05, avg batch time: 0.1292, average loss: 1.4138
[09/22 20:17:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.80	top5: 91.68	
[09/22 20:17:53][INFO] visual_prompt:  357: Best epoch 9: best metric: 0.715
[09/22 20:17:53][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 5.625
[09/22 20:19:02][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.94e-02, avg batch time: 0.8068, average train loss: 1.5110average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:19:04][INFO] visual_prompt:  435: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1213, average loss: 1.4093
[09/22 20:19:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.17	top5: 90.50	
[09/22 20:19:17][INFO] visual_prompt:  435: Inference (test):avg data time: 7.04e-05, avg batch time: 0.1300, average loss: 1.3844
[09/22 20:19:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.63	top5: 91.84	
[09/22 20:19:18][INFO] visual_prompt:  357: Best epoch 10: best metric: 0.722
[09/22 20:19:18][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 6.25
[09/22 20:20:26][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.91e-02, avg batch time: 0.8064, average train loss: 1.9763average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:20:29][INFO] visual_prompt:  435: Inference (val):avg data time: 4.71e-05, avg batch time: 0.1213, average loss: 2.0865
[09/22 20:20:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.67	top5: 88.67	
[09/22 20:20:42][INFO] visual_prompt:  435: Inference (test):avg data time: 6.58e-05, avg batch time: 0.1287, average loss: 2.1234
[09/22 20:20:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.22	top5: 88.61	
[09/22 20:20:42][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 6.248096334434675
[09/22 20:21:51][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.88e-02, avg batch time: 0.8062, average train loss: 1.8753average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:21:53][INFO] visual_prompt:  435: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1223, average loss: 2.4029
[09/22 20:21:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 59.00	top5: 82.83	
[09/22 20:22:07][INFO] visual_prompt:  435: Inference (test):avg data time: 6.29e-05, avg batch time: 0.1293, average loss: 2.2636
[09/22 20:22:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 61.29	top5: 84.47	
[09/22 20:22:07][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 6.2423876570619505
[09/22 20:23:16][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.90e-02, avg batch time: 0.8063, average train loss: 1.9801average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:23:18][INFO] visual_prompt:  435: Inference (val):avg data time: 4.96e-05, avg batch time: 0.1214, average loss: 1.6661
[09/22 20:23:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.67	top5: 89.67	
[09/22 20:23:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.04e-05, avg batch time: 0.1295, average loss: 1.5941
[09/22 20:23:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.71	top5: 90.35	
[09/22 20:23:31][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 6.232880923025854
[09/22 20:24:40][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 2.00e-02, avg batch time: 0.8076, average train loss: 1.7187average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:24:43][INFO] visual_prompt:  435: Inference (val):avg data time: 6.72e-05, avg batch time: 0.1210, average loss: 2.2741
[09/22 20:24:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.83	top5: 89.17	
[09/22 20:24:56][INFO] visual_prompt:  435: Inference (test):avg data time: 6.54e-05, avg batch time: 0.1291, average loss: 2.1011
[09/22 20:24:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.19	top5: 89.21	
[09/22 20:24:56][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 6.219587714817408
[09/22 20:26:05][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.88e-02, avg batch time: 0.8063, average train loss: 2.0966average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:26:07][INFO] visual_prompt:  435: Inference (val):avg data time: 5.04e-05, avg batch time: 0.1222, average loss: 2.2063
[09/22 20:26:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.33	top5: 83.50	
[09/22 20:26:21][INFO] visual_prompt:  435: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1295, average loss: 2.1855
[09/22 20:26:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 63.50	top5: 84.64	
[09/22 20:26:21][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 6.20252422816315
[09/22 20:27:30][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 2.02e-02, avg batch time: 0.8079, average train loss: 2.8539average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:27:32][INFO] visual_prompt:  435: Inference (val):avg data time: 4.72e-05, avg batch time: 0.1220, average loss: 3.7710
[09/22 20:27:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 48.33	top5: 69.67	
[09/22 20:27:46][INFO] visual_prompt:  435: Inference (test):avg data time: 8.57e-05, avg batch time: 0.1290, average loss: 3.7099
[09/22 20:27:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 49.31	top5: 69.11	
[09/22 20:27:46][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 6.181711252293143
[09/22 20:28:54][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.85e-02, avg batch time: 0.8061, average train loss: 2.3971average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:28:57][INFO] visual_prompt:  435: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1219, average loss: 2.3118
[09/22 20:28:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.67	top5: 85.17	
[09/22 20:29:10][INFO] visual_prompt:  435: Inference (test):avg data time: 7.70e-05, avg batch time: 0.1295, average loss: 2.3130
[09/22 20:29:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.58	top5: 85.73	
[09/22 20:29:10][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 6.157174144612489
[09/22 20:30:19][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.84e-02, avg batch time: 0.8061, average train loss: 1.9735average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:30:21][INFO] visual_prompt:  435: Inference (val):avg data time: 4.37e-05, avg batch time: 0.1220, average loss: 1.9651
[09/22 20:30:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.67	top5: 86.50	
[09/22 20:30:34][INFO] visual_prompt:  435: Inference (test):avg data time: 8.28e-05, avg batch time: 0.1296, average loss: 2.0019
[09/22 20:30:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.83	top5: 86.54	
[09/22 20:30:35][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 6.1289427998072465
[09/22 20:31:43][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 2.00e-02, avg batch time: 0.8074, average train loss: 1.5935average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:31:46][INFO] visual_prompt:  435: Inference (val):avg data time: 8.24e-05, avg batch time: 0.1218, average loss: 2.4173
[09/22 20:31:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.67	top5: 83.17	
[09/22 20:31:59][INFO] visual_prompt:  435: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1292, average loss: 2.2786
[09/22 20:31:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 64.96	top5: 83.97	
[09/22 20:31:59][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 6.097051613422355
[09/22 20:33:08][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 2.00e-02, avg batch time: 0.8075, average train loss: 1.8564average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:33:10][INFO] visual_prompt:  435: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1223, average loss: 1.8058
[09/22 20:33:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.17	top5: 86.67	
[09/22 20:33:24][INFO] visual_prompt:  435: Inference (test):avg data time: 8.68e-05, avg batch time: 0.1290, average loss: 1.7609
[09/22 20:33:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.31	top5: 87.78	
[09/22 20:33:24][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 6.061539439955964
[09/22 20:34:33][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.97e-02, avg batch time: 0.8071, average train loss: 2.1136average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:34:35][INFO] visual_prompt:  435: Inference (val):avg data time: 9.03e-05, avg batch time: 0.1219, average loss: 5.5205
[09/22 20:34:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 7.50	top5: 21.33	
[09/22 20:34:48][INFO] visual_prompt:  435: Inference (test):avg data time: 1.10e-04, avg batch time: 0.1292, average loss: 5.4866
[09/22 20:34:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 7.99	top5: 21.00	
[09/22 20:34:49][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 6.02244954552121
[09/22 20:35:57][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.96e-02, avg batch time: 0.8068, average train loss: 2.8179average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:36:00][INFO] visual_prompt:  435: Inference (val):avg data time: 5.57e-05, avg batch time: 0.1216, average loss: 1.6490
[09/22 20:36:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.33	top5: 88.83	
[09/22 20:36:13][INFO] visual_prompt:  435: Inference (test):avg data time: 6.81e-05, avg batch time: 0.1295, average loss: 1.5770
[09/22 20:36:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.21	top5: 89.73	
[09/22 20:36:13][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 5.9798295551331275
[09/22 20:37:22][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.94e-02, avg batch time: 0.8067, average train loss: 1.5641average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:37:24][INFO] visual_prompt:  435: Inference (val):avg data time: 7.17e-05, avg batch time: 0.1220, average loss: 1.7214
[09/22 20:37:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.50	top5: 89.00	
[09/22 20:37:38][INFO] visual_prompt:  435: Inference (test):avg data time: 5.77e-05, avg batch time: 0.1291, average loss: 1.6890
[09/22 20:37:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.59	top5: 88.33	
[09/22 20:37:38][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 5.933731394684897
[09/22 20:38:47][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.98e-02, avg batch time: 0.8065, average train loss: 1.7680average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:38:49][INFO] visual_prompt:  435: Inference (val):avg data time: 6.44e-05, avg batch time: 0.1218, average loss: 1.8352
[09/22 20:38:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.50	top5: 89.83	
[09/22 20:39:03][INFO] visual_prompt:  435: Inference (test):avg data time: 5.87e-05, avg batch time: 0.1294, average loss: 1.6825
[09/22 20:39:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.37	top5: 90.42	
[09/22 20:39:03][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 5.884211227684147
[09/22 20:40:11][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 2.03e-02, avg batch time: 0.8074, average train loss: 2.0559average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:40:14][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1217, average loss: 2.0414
[09/22 20:40:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 59.33	top5: 82.50	
[09/22 20:40:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.72e-05, avg batch time: 0.1292, average loss: 2.0501
[09/22 20:40:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 59.86	top5: 82.67	
[09/22 20:40:28][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 5.831329386826371
[09/22 20:41:37][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 2.01e-02, avg batch time: 0.8073, average train loss: 1.8121average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:41:39][INFO] visual_prompt:  435: Inference (val):avg data time: 4.89e-05, avg batch time: 0.1212, average loss: 1.8341
[09/22 20:41:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.50	top5: 89.83	
[09/22 20:41:52][INFO] visual_prompt:  435: Inference (test):avg data time: 9.28e-05, avg batch time: 0.1296, average loss: 1.8101
[09/22 20:41:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.16	top5: 89.99	
[09/22 20:41:53][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 5.775150300488831
[09/22 20:43:01][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.85e-02, avg batch time: 0.8059, average train loss: 1.9492average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:43:03][INFO] visual_prompt:  435: Inference (val):avg data time: 5.91e-05, avg batch time: 0.1225, average loss: 2.1377
[09/22 20:43:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 88.50	
[09/22 20:43:17][INFO] visual_prompt:  435: Inference (test):avg data time: 6.68e-05, avg batch time: 0.1296, average loss: 2.3008
[09/22 20:43:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.98	top5: 87.75	
[09/22 20:43:17][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 5.715742414234505
[09/22 20:44:26][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 1.88e-02, avg batch time: 0.8061, average train loss: 1.7941average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:44:28][INFO] visual_prompt:  435: Inference (val):avg data time: 7.66e-05, avg batch time: 0.1216, average loss: 1.9265
[09/22 20:44:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.83	top5: 90.50	
[09/22 20:44:41][INFO] visual_prompt:  435: Inference (test):avg data time: 8.21e-05, avg batch time: 0.1295, average loss: 1.9353
[09/22 20:44:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.54	top5: 89.92	
[09/22 20:44:41][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 5.653178107421711
[09/22 20:45:50][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.92e-02, avg batch time: 0.8062, average train loss: 1.5896average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:45:52][INFO] visual_prompt:  435: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1215, average loss: 1.7031
[09/22 20:45:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.50	top5: 88.67	
[09/22 20:46:06][INFO] visual_prompt:  435: Inference (test):avg data time: 5.76e-05, avg batch time: 0.1295, average loss: 1.6465
[09/22 20:46:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.49	top5: 89.82	
[09/22 20:46:06][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 5.587533605021005
[09/22 20:47:15][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.90e-02, avg batch time: 0.8064, average train loss: 1.6120average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:47:17][INFO] visual_prompt:  435: Inference (val):avg data time: 7.01e-05, avg batch time: 0.1231, average loss: 1.7177
[09/22 20:47:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.50	top5: 89.50	
[09/22 20:47:31][INFO] visual_prompt:  435: Inference (test):avg data time: 6.76e-05, avg batch time: 0.1291, average loss: 1.7139
[09/22 20:47:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.18	top5: 89.01	
[09/22 20:47:31][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 5.518888884746806
[09/22 20:48:39][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.91e-02, avg batch time: 0.8062, average train loss: 1.4434average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:48:42][INFO] visual_prompt:  435: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1219, average loss: 1.4445
[09/22 20:48:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.83	top5: 91.50	
[09/22 20:48:55][INFO] visual_prompt:  435: Inference (test):avg data time: 9.21e-05, avg batch time: 0.1290, average loss: 1.5188
[09/22 20:48:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.16	top5: 91.03	
[09/22 20:48:55][INFO] visual_prompt:  357: Best epoch 31: best metric: 0.728
[09/22 20:48:55][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 5.447327579616857
[09/22 20:50:04][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.83e-02, avg batch time: 0.8057, average train loss: 1.7759average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:50:06][INFO] visual_prompt:  435: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1224, average loss: 1.6894
[09/22 20:50:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.83	top5: 92.67	
[09/22 20:50:20][INFO] visual_prompt:  435: Inference (test):avg data time: 6.04e-05, avg batch time: 0.1292, average loss: 1.7421
[09/22 20:50:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.95	top5: 90.68	
[09/22 20:50:20][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 5.372936876058285
[09/22 20:51:29][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.81e-02, avg batch time: 0.8054, average train loss: 1.4664average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:51:31][INFO] visual_prompt:  435: Inference (val):avg data time: 9.49e-05, avg batch time: 0.1226, average loss: 1.6863
[09/22 20:51:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.00	top5: 90.67	
[09/22 20:51:44][INFO] visual_prompt:  435: Inference (test):avg data time: 6.42e-05, avg batch time: 0.1295, average loss: 1.6848
[09/22 20:51:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.73	top5: 89.49	
[09/22 20:51:45][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 5.295807407684366
[09/22 20:52:53][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.92e-02, avg batch time: 0.8065, average train loss: 1.5578average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:52:55][INFO] visual_prompt:  435: Inference (val):avg data time: 4.94e-05, avg batch time: 0.1224, average loss: 1.6766
[09/22 20:52:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.83	top5: 87.33	
[09/22 20:53:09][INFO] visual_prompt:  435: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1296, average loss: 1.6657
[09/22 20:53:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.92	top5: 87.95	
[09/22 20:53:09][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 5.216033144871432
[09/22 20:54:18][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.95e-02, avg batch time: 0.8067, average train loss: 1.2715average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:54:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.26e-05, avg batch time: 0.1220, average loss: 1.5312
[09/22 20:54:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.50	top5: 92.67	
[09/22 20:54:33][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1293, average loss: 1.5006
[09/22 20:54:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.09	top5: 90.92	
[09/22 20:54:33][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 5.133711280270435
[09/22 20:55:42][INFO] visual_prompt:  321: Epoch 36 / 100: avg data time: 1.79e-02, avg batch time: 0.8049, average train loss: 1.3695average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:55:44][INFO] visual_prompt:  435: Inference (val):avg data time: 6.26e-05, avg batch time: 0.1228, average loss: 1.7732
[09/22 20:55:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.50	top5: 85.67	
[09/22 20:55:58][INFO] visual_prompt:  435: Inference (test):avg data time: 6.33e-05, avg batch time: 0.1293, average loss: 1.6559
[09/22 20:55:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.07	top5: 88.06	
[09/22 20:55:58][INFO] visual_prompt:  253: Training 37 / 100 epoch, with learning rate 5.048942110392682
[09/22 20:57:07][INFO] visual_prompt:  321: Epoch 37 / 100: avg data time: 1.99e-02, avg batch time: 0.8067, average train loss: 1.3366average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:57:09][INFO] visual_prompt:  435: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1222, average loss: 1.4916
[09/22 20:57:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.17	top5: 91.50	
[09/22 20:57:23][INFO] visual_prompt:  435: Inference (test):avg data time: 5.81e-05, avg batch time: 0.1287, average loss: 1.5216
[09/22 20:57:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.09	top5: 91.56	
[09/22 20:57:23][INFO] visual_prompt:  253: Training 38 / 100 epoch, with learning rate 4.961828913413979
[09/22 20:58:32][INFO] visual_prompt:  321: Epoch 38 / 100: avg data time: 1.99e-02, avg batch time: 0.8065, average train loss: 1.4264average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:58:34][INFO] visual_prompt:  435: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1218, average loss: 1.6378
[09/22 20:58:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.33	top5: 89.33	
[09/22 20:58:47][INFO] visual_prompt:  435: Inference (test):avg data time: 6.74e-05, avg batch time: 0.1293, average loss: 1.6141
[09/22 20:58:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.37	top5: 89.23	
[09/22 20:58:47][INFO] visual_prompt:  253: Training 39 / 100 epoch, with learning rate 4.872477823346084
[09/22 20:59:56][INFO] visual_prompt:  321: Epoch 39 / 100: avg data time: 2.14e-02, avg batch time: 0.8081, average train loss: 1.3288average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 20:59:59][INFO] visual_prompt:  435: Inference (val):avg data time: 5.35e-05, avg batch time: 0.1213, average loss: 1.4632
[09/22 20:59:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.67	top5: 88.67	
[09/22 21:00:12][INFO] visual_prompt:  435: Inference (test):avg data time: 6.68e-05, avg batch time: 0.1290, average loss: 1.4659
[09/22 21:00:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.11	top5: 89.42	
[09/22 21:00:12][INFO] visual_prompt:  253: Training 40 / 100 epoch, with learning rate 4.780997700728765
[09/22 21:01:21][INFO] visual_prompt:  321: Epoch 40 / 100: avg data time: 1.97e-02, avg batch time: 0.8066, average train loss: 1.2179average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:01:23][INFO] visual_prompt:  435: Inference (val):avg data time: 8.43e-05, avg batch time: 0.1223, average loss: 1.8554
[09/22 21:01:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.17	top5: 89.00	
[09/22 21:01:36][INFO] visual_prompt:  435: Inference (test):avg data time: 7.72e-05, avg batch time: 0.1304, average loss: 1.7686
[09/22 21:01:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.57	top5: 89.23	
[09/22 21:01:36][INFO] visual_prompt:  253: Training 41 / 100 epoch, with learning rate 4.6875
[09/22 21:02:45][INFO] visual_prompt:  321: Epoch 41 / 100: avg data time: 1.88e-02, avg batch time: 0.8057, average train loss: 1.2327average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:02:47][INFO] visual_prompt:  435: Inference (val):avg data time: 5.19e-05, avg batch time: 0.1220, average loss: 1.7989
[09/22 21:02:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 65.50	top5: 85.50	
[09/22 21:03:01][INFO] visual_prompt:  435: Inference (test):avg data time: 6.80e-05, avg batch time: 0.1287, average loss: 1.7115
[09/22 21:03:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.69	top5: 86.64	
[09/22 21:03:01][INFO] visual_prompt:  253: Training 42 / 100 epoch, with learning rate 4.592098633705908
[09/22 21:04:10][INFO] visual_prompt:  321: Epoch 42 / 100: avg data time: 2.01e-02, avg batch time: 0.8068, average train loss: 1.2188average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:04:12][INFO] visual_prompt:  435: Inference (val):avg data time: 6.80e-05, avg batch time: 0.1216, average loss: 1.3710
[09/22 21:04:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.17	top5: 92.17	
[09/22 21:04:26][INFO] visual_prompt:  435: Inference (test):avg data time: 6.70e-05, avg batch time: 0.1293, average loss: 1.3280
[09/22 21:04:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.89	top5: 92.30	
[09/22 21:04:26][INFO] visual_prompt:  357: Best epoch 42: best metric: 0.732
[09/22 21:04:26][INFO] visual_prompt:  253: Training 43 / 100 epoch, with learning rate 4.494909833715867
[09/22 21:05:34][INFO] visual_prompt:  321: Epoch 43 / 100: avg data time: 1.92e-02, avg batch time: 0.8054, average train loss: 1.2177average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:05:37][INFO] visual_prompt:  435: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1212, average loss: 1.3908
[09/22 21:05:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.50	top5: 91.83	
[09/22 21:05:51][INFO] visual_prompt:  435: Inference (test):avg data time: 5.66e-05, avg batch time: 0.1289, average loss: 1.3504
[09/22 21:05:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.37	top5: 92.29	
[09/22 21:05:51][INFO] visual_prompt:  357: Best epoch 43: best metric: 0.735
[09/22 21:05:51][INFO] visual_prompt:  253: Training 44 / 100 epoch, with learning rate 4.396052009611876
[09/22 21:06:59][INFO] visual_prompt:  321: Epoch 44 / 100: avg data time: 2.03e-02, avg batch time: 0.8066, average train loss: 1.0821average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:07:02][INFO] visual_prompt:  435: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1216, average loss: 1.2472
[09/22 21:07:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.33	top5: 91.50	
[09/22 21:07:15][INFO] visual_prompt:  435: Inference (test):avg data time: 9.95e-05, avg batch time: 0.1293, average loss: 1.2891
[09/22 21:07:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.61	top5: 91.49	
[09/22 21:07:15][INFO] visual_prompt:  253: Training 45 / 100 epoch, with learning rate 4.295645604424726
[09/22 21:08:24][INFO] visual_prompt:  321: Epoch 45 / 100: avg data time: 1.80e-02, avg batch time: 0.8044, average train loss: 1.0943average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:08:26][INFO] visual_prompt:  435: Inference (val):avg data time: 6.60e-05, avg batch time: 0.1202, average loss: 1.2782
[09/22 21:08:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.67	top5: 91.17	
[09/22 21:08:40][INFO] visual_prompt:  435: Inference (test):avg data time: 7.00e-05, avg batch time: 0.1291, average loss: 1.2853
[09/22 21:08:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.16	top5: 91.40	
[09/22 21:08:40][INFO] visual_prompt:  357: Best epoch 45: best metric: 0.737
[09/22 21:08:40][INFO] visual_prompt:  253: Training 46 / 100 epoch, with learning rate 4.193812947892715
[09/22 21:09:48][INFO] visual_prompt:  321: Epoch 46 / 100: avg data time: 1.94e-02, avg batch time: 0.8057, average train loss: 1.0461average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:09:51][INFO] visual_prompt:  435: Inference (val):avg data time: 6.81e-05, avg batch time: 0.1215, average loss: 1.3313
[09/22 21:09:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.17	top5: 90.33	
[09/22 21:10:04][INFO] visual_prompt:  435: Inference (test):avg data time: 8.18e-05, avg batch time: 0.1290, average loss: 1.3572
[09/22 21:10:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 71.87	top5: 91.04	
[09/22 21:10:05][INFO] visual_prompt:  253: Training 47 / 100 epoch, with learning rate 4.090678107421711
[09/22 21:11:13][INFO] visual_prompt:  321: Epoch 47 / 100: avg data time: 1.89e-02, avg batch time: 0.8053, average train loss: 0.9800average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:11:16][INFO] visual_prompt:  435: Inference (val):avg data time: 1.24e-04, avg batch time: 0.1209, average loss: 1.3834
[09/22 21:11:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.00	top5: 89.17	
[09/22 21:11:29][INFO] visual_prompt:  435: Inference (test):avg data time: 7.90e-05, avg batch time: 0.1291, average loss: 1.2971
[09/22 21:11:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.85	top5: 90.84	
[09/22 21:11:29][INFO] visual_prompt:  253: Training 48 / 100 epoch, with learning rate 3.9863667369281224
[09/22 21:12:38][INFO] visual_prompt:  321: Epoch 48 / 100: avg data time: 1.91e-02, avg batch time: 0.8054, average train loss: 1.0343average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:12:40][INFO] visual_prompt:  435: Inference (val):avg data time: 4.48e-05, avg batch time: 0.1223, average loss: 1.2796
[09/22 21:12:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.67	top5: 91.83	
[09/22 21:12:54][INFO] visual_prompt:  435: Inference (test):avg data time: 6.57e-05, avg batch time: 0.1288, average loss: 1.2334
[09/22 21:12:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.42	top5: 93.08	
[09/22 21:12:54][INFO] visual_prompt:  357: Best epoch 48: best metric: 0.747
[09/22 21:12:54][INFO] visual_prompt:  253: Training 49 / 100 epoch, with learning rate 3.8810059237489614
[09/22 21:14:03][INFO] visual_prompt:  321: Epoch 49 / 100: avg data time: 2.07e-02, avg batch time: 0.8068, average train loss: 0.9139average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:14:05][INFO] visual_prompt:  435: Inference (val):avg data time: 6.21e-05, avg batch time: 0.1211, average loss: 1.3101
[09/22 21:14:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 71.33	top5: 91.33	
[09/22 21:14:19][INFO] visual_prompt:  435: Inference (test):avg data time: 6.10e-05, avg batch time: 0.1289, average loss: 1.3233
[09/22 21:14:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 72.83	top5: 90.66	
[09/22 21:14:19][INFO] visual_prompt:  253: Training 50 / 100 epoch, with learning rate 3.7747240338054975
[09/22 21:15:28][INFO] visual_prompt:  321: Epoch 50 / 100: avg data time: 2.05e-02, avg batch time: 0.8072, average train loss: 0.8551average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:15:30][INFO] visual_prompt:  435: Inference (val):avg data time: 8.07e-05, avg batch time: 0.1220, average loss: 1.3675
[09/22 21:15:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.33	top5: 90.33	
[09/22 21:15:44][INFO] visual_prompt:  435: Inference (test):avg data time: 8.02e-05, avg batch time: 0.1286, average loss: 1.3224
[09/22 21:15:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.18	top5: 91.23	
[09/22 21:15:44][INFO] visual_prompt:  253: Training 51 / 100 epoch, with learning rate 3.667650555209158
[09/22 21:16:52][INFO] visual_prompt:  321: Epoch 51 / 100: avg data time: 1.85e-02, avg batch time: 0.8050, average train loss: 0.8340average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:16:55][INFO] visual_prompt:  435: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1205, average loss: 0.9901
[09/22 21:16:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 95.33	
[09/22 21:17:09][INFO] visual_prompt:  435: Inference (test):avg data time: 5.81e-05, avg batch time: 0.1291, average loss: 1.0095
[09/22 21:17:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.46	top5: 94.34	
[09/22 21:17:09][INFO] visual_prompt:  357: Best epoch 51: best metric: 0.763
[09/22 21:17:09][INFO] visual_prompt:  253: Training 52 / 100 epoch, with learning rate 3.5599159405002045
[09/22 21:18:17][INFO] visual_prompt:  321: Epoch 52 / 100: avg data time: 1.85e-02, avg batch time: 0.8049, average train loss: 0.7990average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:18:20][INFO] visual_prompt:  435: Inference (val):avg data time: 6.39e-05, avg batch time: 0.1215, average loss: 1.1589
[09/22 21:18:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.33	top5: 94.50	
[09/22 21:18:33][INFO] visual_prompt:  435: Inference (test):avg data time: 6.81e-05, avg batch time: 0.1293, average loss: 1.2101
[09/22 21:18:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.84	top5: 93.70	
[09/22 21:18:33][INFO] visual_prompt:  253: Training 53 / 100 epoch, with learning rate 3.4516514477114173
[09/22 21:19:42][INFO] visual_prompt:  321: Epoch 53 / 100: avg data time: 2.00e-02, avg batch time: 0.8065, average train loss: 0.7506average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:19:44][INFO] visual_prompt:  435: Inference (val):avg data time: 5.64e-05, avg batch time: 0.1207, average loss: 1.0080
[09/22 21:19:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.33	top5: 95.17	
[09/22 21:19:57][INFO] visual_prompt:  435: Inference (test):avg data time: 6.71e-05, avg batch time: 0.1297, average loss: 1.0348
[09/22 21:19:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.84	top5: 94.22	
[09/22 21:19:58][INFO] visual_prompt:  357: Best epoch 53: best metric: 0.773
[09/22 21:19:58][INFO] visual_prompt:  253: Training 54 / 100 epoch, with learning rate 3.342988980450391
[09/22 21:21:06][INFO] visual_prompt:  321: Epoch 54 / 100: avg data time: 1.87e-02, avg batch time: 0.8049, average train loss: 0.9081average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:21:08][INFO] visual_prompt:  435: Inference (val):avg data time: 6.17e-05, avg batch time: 0.1218, average loss: 1.2795
[09/22 21:21:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.00	top5: 92.33	
[09/22 21:21:22][INFO] visual_prompt:  435: Inference (test):avg data time: 6.09e-05, avg batch time: 0.1291, average loss: 1.2432
[09/22 21:21:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.41	top5: 92.23	
[09/22 21:21:22][INFO] visual_prompt:  253: Training 55 / 100 epoch, with learning rate 3.234060927195316
[09/22 21:22:30][INFO] visual_prompt:  321: Epoch 55 / 100: avg data time: 1.88e-02, avg batch time: 0.8051, average train loss: 0.8998average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:22:33][INFO] visual_prompt:  435: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1218, average loss: 1.1110
[09/22 21:22:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.83	top5: 93.33	
[09/22 21:22:47][INFO] visual_prompt:  435: Inference (test):avg data time: 8.14e-05, avg batch time: 0.1286, average loss: 1.0876
[09/22 21:22:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.73	top5: 93.23	
[09/22 21:22:47][INFO] visual_prompt:  253: Training 56 / 100 epoch, with learning rate 3.125
[09/22 21:23:55][INFO] visual_prompt:  321: Epoch 56 / 100: avg data time: 2.07e-02, avg batch time: 0.8071, average train loss: 0.6429average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:23:58][INFO] visual_prompt:  435: Inference (val):avg data time: 7.02e-05, avg batch time: 0.1222, average loss: 1.0473
[09/22 21:23:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.50	top5: 95.00	
[09/22 21:24:11][INFO] visual_prompt:  435: Inference (test):avg data time: 9.78e-05, avg batch time: 0.1290, average loss: 1.0747
[09/22 21:24:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.17	top5: 93.82	
[09/22 21:24:11][INFO] visual_prompt:  253: Training 57 / 100 epoch, with learning rate 3.0159390728046853
[09/22 21:25:20][INFO] visual_prompt:  321: Epoch 57 / 100: avg data time: 1.74e-02, avg batch time: 0.8042, average train loss: 0.6618average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:25:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.02e-05, avg batch time: 0.1219, average loss: 1.1903
[09/22 21:25:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 72.50	top5: 93.17	
[09/22 21:25:36][INFO] visual_prompt:  435: Inference (test):avg data time: 8.39e-05, avg batch time: 0.1297, average loss: 1.1070
[09/22 21:25:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.15	top5: 92.85	
[09/22 21:25:36][INFO] visual_prompt:  253: Training 58 / 100 epoch, with learning rate 2.9070110195496084
[09/22 21:26:44][INFO] visual_prompt:  321: Epoch 58 / 100: avg data time: 1.85e-02, avg batch time: 0.8051, average train loss: 0.6824average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:26:47][INFO] visual_prompt:  435: Inference (val):avg data time: 4.27e-05, avg batch time: 0.1221, average loss: 0.9751
[09/22 21:26:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.17	top5: 94.67	
[09/22 21:27:00][INFO] visual_prompt:  435: Inference (test):avg data time: 5.85e-05, avg batch time: 0.1298, average loss: 0.9251
[09/22 21:27:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.87	top5: 95.05	
[09/22 21:27:00][INFO] visual_prompt:  253: Training 59 / 100 epoch, with learning rate 2.7983485522885836
[09/22 21:28:08][INFO] visual_prompt:  321: Epoch 59 / 100: avg data time: 1.85e-02, avg batch time: 0.8049, average train loss: 0.5528average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:28:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.86e-05, avg batch time: 0.1232, average loss: 0.9801
[09/22 21:28:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 94.00	
[09/22 21:28:25][INFO] visual_prompt:  435: Inference (test):avg data time: 7.62e-05, avg batch time: 0.1286, average loss: 1.0141
[09/22 21:28:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.60	top5: 93.79	
[09/22 21:28:25][INFO] visual_prompt:  253: Training 60 / 100 epoch, with learning rate 2.6900840594997963
[09/22 21:29:34][INFO] visual_prompt:  321: Epoch 60 / 100: avg data time: 1.97e-02, avg batch time: 0.8057, average train loss: 0.5246average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:29:36][INFO] visual_prompt:  435: Inference (val):avg data time: 6.54e-05, avg batch time: 0.1210, average loss: 0.9233
[09/22 21:29:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 94.83	
[09/22 21:29:50][INFO] visual_prompt:  435: Inference (test):avg data time: 8.72e-05, avg batch time: 0.1285, average loss: 0.9074
[09/22 21:29:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.44	top5: 94.74	
[09/22 21:29:50][INFO] visual_prompt:  357: Best epoch 60: best metric: 0.777
[09/22 21:29:50][INFO] visual_prompt:  253: Training 61 / 100 epoch, with learning rate 2.5823494447908426
[09/22 21:30:59][INFO] visual_prompt:  321: Epoch 61 / 100: avg data time: 1.95e-02, avg batch time: 0.8056, average train loss: 0.5003average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:31:01][INFO] visual_prompt:  435: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1226, average loss: 0.9307
[09/22 21:31:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 94.17	
[09/22 21:31:16][INFO] visual_prompt:  435: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1283, average loss: 0.9070
[09/22 21:31:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.00	top5: 94.30	
[09/22 21:31:16][INFO] visual_prompt:  253: Training 62 / 100 epoch, with learning rate 2.4752759661945025
[09/22 21:32:24][INFO] visual_prompt:  321: Epoch 62 / 100: avg data time: 1.82e-02, avg batch time: 0.8042, average train loss: 0.5120average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:32:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1208, average loss: 1.0802
[09/22 21:32:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 93.83	
[09/22 21:32:41][INFO] visual_prompt:  435: Inference (test):avg data time: 5.53e-05, avg batch time: 0.1282, average loss: 1.0826
[09/22 21:32:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.96	top5: 92.84	
[09/22 21:32:41][INFO] visual_prompt:  357: Best epoch 62: best metric: 0.793
[09/22 21:32:41][INFO] visual_prompt:  253: Training 63 / 100 epoch, with learning rate 2.3689940762510386
[09/22 21:33:50][INFO] visual_prompt:  321: Epoch 63 / 100: avg data time: 2.07e-02, avg batch time: 0.8065, average train loss: 0.4594average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:33:52][INFO] visual_prompt:  435: Inference (val):avg data time: 6.53e-05, avg batch time: 0.1209, average loss: 0.7941
[09/22 21:33:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 96.83	
[09/22 21:34:06][INFO] visual_prompt:  435: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1291, average loss: 0.8139
[09/22 21:34:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.58	top5: 95.88	
[09/22 21:34:06][INFO] visual_prompt:  253: Training 64 / 100 epoch, with learning rate 2.2636332630718776
[09/22 21:35:14][INFO] visual_prompt:  321: Epoch 64 / 100: avg data time: 1.88e-02, avg batch time: 0.8048, average train loss: 0.4250average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:35:17][INFO] visual_prompt:  435: Inference (val):avg data time: 6.47e-05, avg batch time: 0.1212, average loss: 0.9284
[09/22 21:35:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.17	top5: 95.50	
[09/22 21:35:31][INFO] visual_prompt:  435: Inference (test):avg data time: 6.80e-05, avg batch time: 0.1284, average loss: 0.9127
[09/22 21:35:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.12	top5: 94.93	
[09/22 21:35:31][INFO] visual_prompt:  253: Training 65 / 100 epoch, with learning rate 2.1593218925782898
[09/22 21:36:39][INFO] visual_prompt:  321: Epoch 65 / 100: avg data time: 1.86e-02, avg batch time: 0.8046, average train loss: 0.3939average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:36:42][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1221, average loss: 0.7645
[09/22 21:36:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 95.67	
[09/22 21:36:55][INFO] visual_prompt:  435: Inference (test):avg data time: 6.51e-05, avg batch time: 0.1289, average loss: 0.8149
[09/22 21:36:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.74	top5: 95.12	
[09/22 21:36:55][INFO] visual_prompt:  357: Best epoch 65: best metric: 0.820
[09/22 21:36:55][INFO] visual_prompt:  253: Training 66 / 100 epoch, with learning rate 2.0561870521072856
[09/22 21:38:04][INFO] visual_prompt:  321: Epoch 66 / 100: avg data time: 1.83e-02, avg batch time: 0.8045, average train loss: 0.3505average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:38:06][INFO] visual_prompt:  435: Inference (val):avg data time: 8.41e-05, avg batch time: 0.1222, average loss: 0.7876
[09/22 21:38:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 95.00	
[09/22 21:38:20][INFO] visual_prompt:  435: Inference (test):avg data time: 7.71e-05, avg batch time: 0.1286, average loss: 0.7851
[09/22 21:38:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.43	top5: 95.65	
[09/22 21:38:20][INFO] visual_prompt:  253: Training 67 / 100 epoch, with learning rate 1.9543543955752747
[09/22 21:39:29][INFO] visual_prompt:  321: Epoch 67 / 100: avg data time: 1.86e-02, avg batch time: 0.8047, average train loss: 0.2916average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:39:31][INFO] visual_prompt:  435: Inference (val):avg data time: 9.84e-05, avg batch time: 0.1216, average loss: 0.8099
[09/22 21:39:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 96.00	
[09/22 21:39:45][INFO] visual_prompt:  435: Inference (test):avg data time: 7.50e-05, avg batch time: 0.1288, average loss: 0.8185
[09/22 21:39:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.17	top5: 96.12	
[09/22 21:39:45][INFO] visual_prompt:  253: Training 68 / 100 epoch, with learning rate 1.8539479903881249
[09/22 21:40:53][INFO] visual_prompt:  321: Epoch 68 / 100: avg data time: 1.88e-02, avg batch time: 0.8046, average train loss: 0.3156average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:40:56][INFO] visual_prompt:  435: Inference (val):avg data time: 4.10e-05, avg batch time: 0.1206, average loss: 0.8101
[09/22 21:40:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 95.83	
[09/22 21:41:09][INFO] visual_prompt:  435: Inference (test):avg data time: 5.44e-05, avg batch time: 0.1288, average loss: 0.7824
[09/22 21:41:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.93	top5: 95.81	
[09/22 21:41:09][INFO] visual_prompt:  253: Training 69 / 100 epoch, with learning rate 1.7550901662841327
[09/22 21:42:18][INFO] visual_prompt:  321: Epoch 69 / 100: avg data time: 1.89e-02, avg batch time: 0.8047, average train loss: 0.2650average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:42:20][INFO] visual_prompt:  435: Inference (val):avg data time: 5.41e-05, avg batch time: 0.1213, average loss: 0.6897
[09/22 21:42:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 96.83	
[09/22 21:42:34][INFO] visual_prompt:  435: Inference (test):avg data time: 6.87e-05, avg batch time: 0.1290, average loss: 0.7040
[09/22 21:42:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.62	top5: 96.82	
[09/22 21:42:34][INFO] visual_prompt:  357: Best epoch 69: best metric: 0.822
[09/22 21:42:34][INFO] visual_prompt:  253: Training 70 / 100 epoch, with learning rate 1.657901366294092
[09/22 21:43:42][INFO] visual_prompt:  321: Epoch 70 / 100: avg data time: 1.81e-02, avg batch time: 0.8041, average train loss: 0.2612average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:43:45][INFO] visual_prompt:  435: Inference (val):avg data time: 4.51e-05, avg batch time: 0.1205, average loss: 0.7530
[09/22 21:43:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 96.33	
[09/22 21:43:59][INFO] visual_prompt:  435: Inference (test):avg data time: 7.45e-05, avg batch time: 0.1286, average loss: 0.7235
[09/22 21:43:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.79	top5: 96.51	
[09/22 21:43:59][INFO] visual_prompt:  253: Training 71 / 100 epoch, with learning rate 1.5625000000000007
[09/22 21:45:07][INFO] visual_prompt:  321: Epoch 71 / 100: avg data time: 2.00e-02, avg batch time: 0.8061, average train loss: 0.2751average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:45:10][INFO] visual_prompt:  435: Inference (val):avg data time: 5.13e-05, avg batch time: 0.1215, average loss: 0.6412
[09/22 21:45:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 97.83	
[09/22 21:45:24][INFO] visual_prompt:  435: Inference (test):avg data time: 8.97e-05, avg batch time: 0.1286, average loss: 0.6453
[09/22 21:45:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.40	top5: 97.03	
[09/22 21:45:24][INFO] visual_prompt:  357: Best epoch 71: best metric: 0.823
[09/22 21:45:24][INFO] visual_prompt:  253: Training 72 / 100 epoch, with learning rate 1.469002299271235
[09/22 21:46:32][INFO] visual_prompt:  321: Epoch 72 / 100: avg data time: 1.89e-02, avg batch time: 0.8047, average train loss: 0.2188average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:46:35][INFO] visual_prompt:  435: Inference (val):avg data time: 4.65e-05, avg batch time: 0.1224, average loss: 0.6078
[09/22 21:46:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 98.17	
[09/22 21:46:48][INFO] visual_prompt:  435: Inference (test):avg data time: 6.03e-05, avg batch time: 0.1297, average loss: 0.6415
[09/22 21:46:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.15	top5: 97.01	
[09/22 21:46:48][INFO] visual_prompt:  357: Best epoch 72: best metric: 0.833
[09/22 21:46:48][INFO] visual_prompt:  253: Training 73 / 100 epoch, with learning rate 1.3775221766539165
[09/22 21:47:57][INFO] visual_prompt:  321: Epoch 73 / 100: avg data time: 1.98e-02, avg batch time: 0.8060, average train loss: 0.2093average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:47:59][INFO] visual_prompt:  435: Inference (val):avg data time: 5.79e-05, avg batch time: 0.1213, average loss: 0.6219
[09/22 21:47:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.17	
[09/22 21:48:13][INFO] visual_prompt:  435: Inference (test):avg data time: 7.23e-05, avg batch time: 0.1286, average loss: 0.6211
[09/22 21:48:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.28	top5: 97.12	
[09/22 21:48:13][INFO] visual_prompt:  253: Training 74 / 100 epoch, with learning rate 1.2881710865860219
[09/22 21:49:22][INFO] visual_prompt:  321: Epoch 74 / 100: avg data time: 1.84e-02, avg batch time: 0.8047, average train loss: 0.2163average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:49:24][INFO] visual_prompt:  435: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1216, average loss: 0.6088
[09/22 21:49:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.33	
[09/22 21:49:38][INFO] visual_prompt:  435: Inference (test):avg data time: 6.91e-05, avg batch time: 0.1292, average loss: 0.5989
[09/22 21:49:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.73	top5: 97.32	
[09/22 21:49:38][INFO] visual_prompt:  357: Best epoch 74: best metric: 0.847
[09/22 21:49:38][INFO] visual_prompt:  253: Training 75 / 100 epoch, with learning rate 1.2010578896073179
[09/22 21:50:46][INFO] visual_prompt:  321: Epoch 75 / 100: avg data time: 1.96e-02, avg batch time: 0.8060, average train loss: 0.2370average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:50:49][INFO] visual_prompt:  435: Inference (val):avg data time: 9.51e-05, avg batch time: 0.1215, average loss: 0.6136
[09/22 21:50:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.00	
[09/22 21:51:02][INFO] visual_prompt:  435: Inference (test):avg data time: 9.29e-05, avg batch time: 0.1290, average loss: 0.6112
[09/22 21:51:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.02	top5: 97.26	
[09/22 21:51:02][INFO] visual_prompt:  253: Training 76 / 100 epoch, with learning rate 1.1162887197295646
[09/22 21:52:11][INFO] visual_prompt:  321: Epoch 76 / 100: avg data time: 1.98e-02, avg batch time: 0.8061, average train loss: 0.1820average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:52:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.43e-05, avg batch time: 0.1217, average loss: 0.6111
[09/22 21:52:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 98.33	
[09/22 21:52:27][INFO] visual_prompt:  435: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1290, average loss: 0.6058
[09/22 21:52:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.17	top5: 97.45	
[09/22 21:52:27][INFO] visual_prompt:  253: Training 77 / 100 epoch, with learning rate 1.033966855128569
[09/22 21:53:35][INFO] visual_prompt:  321: Epoch 77 / 100: avg data time: 1.77e-02, avg batch time: 0.8040, average train loss: 0.1597average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:53:38][INFO] visual_prompt:  435: Inference (val):avg data time: 6.04e-05, avg batch time: 0.1213, average loss: 0.5457
[09/22 21:53:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.67	
[09/22 21:53:51][INFO] visual_prompt:  435: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1295, average loss: 0.5495
[09/22 21:53:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.90	top5: 97.34	
[09/22 21:53:51][INFO] visual_prompt:  253: Training 78 / 100 epoch, with learning rate 0.9541925923156332
[09/22 21:55:00][INFO] visual_prompt:  321: Epoch 78 / 100: avg data time: 2.00e-02, avg batch time: 0.8062, average train loss: 0.1587average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:55:02][INFO] visual_prompt:  435: Inference (val):avg data time: 7.58e-05, avg batch time: 0.1212, average loss: 0.5847
[09/22 21:55:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 98.17	
[09/22 21:55:16][INFO] visual_prompt:  435: Inference (test):avg data time: 6.64e-05, avg batch time: 0.1286, average loss: 0.5723
[09/22 21:55:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.59	top5: 97.41	
[09/22 21:55:16][INFO] visual_prompt:  253: Training 79 / 100 epoch, with learning rate 0.8770631239417157
[09/22 21:56:25][INFO] visual_prompt:  321: Epoch 79 / 100: avg data time: 2.02e-02, avg batch time: 0.8064, average train loss: 0.1455average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:56:27][INFO] visual_prompt:  435: Inference (val):avg data time: 5.64e-05, avg batch time: 0.1205, average loss: 0.5675
[09/22 21:56:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 97.50	
[09/22 21:56:41][INFO] visual_prompt:  435: Inference (test):avg data time: 6.15e-05, avg batch time: 0.1286, average loss: 0.5611
[09/22 21:56:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.81	top5: 97.50	
[09/22 21:56:41][INFO] visual_prompt:  253: Training 80 / 100 epoch, with learning rate 0.8026724203831427
[09/22 21:57:49][INFO] visual_prompt:  321: Epoch 80 / 100: avg data time: 1.94e-02, avg batch time: 0.8058, average train loss: 0.1472average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:57:52][INFO] visual_prompt:  435: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1209, average loss: 0.5523
[09/22 21:57:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.17	
[09/22 21:58:05][INFO] visual_prompt:  435: Inference (test):avg data time: 9.73e-05, avg batch time: 0.1291, average loss: 0.5492
[09/22 21:58:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.95	top5: 97.62	
[09/22 21:58:06][INFO] visual_prompt:  253: Training 81 / 100 epoch, with learning rate 0.731111115253194
[09/22 21:59:14][INFO] visual_prompt:  321: Epoch 81 / 100: avg data time: 1.96e-02, avg batch time: 0.8059, average train loss: 0.1378average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 21:59:16][INFO] visual_prompt:  435: Inference (val):avg data time: 5.32e-05, avg batch time: 0.1209, average loss: 0.5188
[09/22 21:59:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.33	
[09/22 21:59:30][INFO] visual_prompt:  435: Inference (test):avg data time: 1.08e-04, avg batch time: 0.1289, average loss: 0.5345
[09/22 21:59:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.90	top5: 97.69	
[09/22 21:59:30][INFO] visual_prompt:  357: Best epoch 81: best metric: 0.863
[09/22 21:59:30][INFO] visual_prompt:  253: Training 82 / 100 epoch, with learning rate 0.6624663949789941
[09/22 22:00:39][INFO] visual_prompt:  321: Epoch 82 / 100: avg data time: 1.80e-02, avg batch time: 0.8041, average train loss: 0.1328average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:00:41][INFO] visual_prompt:  435: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1212, average loss: 0.5234
[09/22 22:00:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.67	
[09/22 22:00:55][INFO] visual_prompt:  435: Inference (test):avg data time: 9.03e-05, avg batch time: 0.1291, average loss: 0.5343
[09/22 22:00:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.16	top5: 97.58	
[09/22 22:00:55][INFO] visual_prompt:  357: Best epoch 82: best metric: 0.865
[09/22 22:00:55][INFO] visual_prompt:  253: Training 83 / 100 epoch, with learning rate 0.5968218925782895
[09/22 22:02:03][INFO] visual_prompt:  321: Epoch 83 / 100: avg data time: 1.82e-02, avg batch time: 0.8048, average train loss: 0.1315average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:02:06][INFO] visual_prompt:  435: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1217, average loss: 0.5260
[09/22 22:02:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.17	
[09/22 22:02:19][INFO] visual_prompt:  435: Inference (test):avg data time: 9.05e-05, avg batch time: 0.1291, average loss: 0.5370
[09/22 22:02:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.99	top5: 97.57	
[09/22 22:02:20][INFO] visual_prompt:  253: Training 84 / 100 epoch, with learning rate 0.534257585765495
[09/22 22:03:28][INFO] visual_prompt:  321: Epoch 84 / 100: avg data time: 1.97e-02, avg batch time: 0.8061, average train loss: 0.1288average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:03:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1206, average loss: 0.5119
[09/22 22:03:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.50	
[09/22 22:03:44][INFO] visual_prompt:  435: Inference (test):avg data time: 9.07e-05, avg batch time: 0.1289, average loss: 0.5175
[09/22 22:03:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.04	top5: 97.79	
[09/22 22:03:44][INFO] visual_prompt:  253: Training 85 / 100 epoch, with learning rate 0.4748496995111689
[09/22 22:04:53][INFO] visual_prompt:  321: Epoch 85 / 100: avg data time: 1.85e-02, avg batch time: 0.8046, average train loss: 0.1222average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:04:55][INFO] visual_prompt:  435: Inference (val):avg data time: 5.95e-05, avg batch time: 0.1216, average loss: 0.4812
[09/22 22:04:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.50	
[09/22 22:05:09][INFO] visual_prompt:  435: Inference (test):avg data time: 5.88e-05, avg batch time: 0.1284, average loss: 0.5002
[09/22 22:05:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.52	top5: 97.76	
[09/22 22:05:09][INFO] visual_prompt:  253: Training 86 / 100 epoch, with learning rate 0.418670613173629
[09/22 22:06:18][INFO] visual_prompt:  321: Epoch 86 / 100: avg data time: 1.93e-02, avg batch time: 0.8058, average train loss: 0.1154average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:06:20][INFO] visual_prompt:  435: Inference (val):avg data time: 7.24e-05, avg batch time: 0.1213, average loss: 0.4943
[09/22 22:06:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.50	
[09/22 22:06:34][INFO] visual_prompt:  435: Inference (test):avg data time: 7.14e-05, avg batch time: 0.1290, average loss: 0.5014
[09/22 22:06:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.56	top5: 97.91	
[09/22 22:06:34][INFO] visual_prompt:  357: Best epoch 86: best metric: 0.867
[09/22 22:06:34][INFO] visual_prompt:  253: Training 87 / 100 epoch, with learning rate 0.36578877231585316
[09/22 22:07:42][INFO] visual_prompt:  321: Epoch 87 / 100: avg data time: 1.81e-02, avg batch time: 0.8043, average train loss: 0.1103average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:07:45][INFO] visual_prompt:  435: Inference (val):avg data time: 5.17e-05, avg batch time: 0.1217, average loss: 0.5176
[09/22 22:07:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.33	
[09/22 22:07:58][INFO] visual_prompt:  435: Inference (test):avg data time: 7.53e-05, avg batch time: 0.1288, average loss: 0.5260
[09/22 22:07:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.09	top5: 97.55	
[09/22 22:07:58][INFO] visual_prompt:  253: Training 88 / 100 epoch, with learning rate 0.3162686053151037
[09/22 22:09:07][INFO] visual_prompt:  321: Epoch 88 / 100: avg data time: 1.94e-02, avg batch time: 0.8056, average train loss: 0.1049average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:09:09][INFO] visual_prompt:  435: Inference (val):avg data time: 4.78e-05, avg batch time: 0.1209, average loss: 0.5309
[09/22 22:09:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.50	
[09/22 22:09:23][INFO] visual_prompt:  435: Inference (test):avg data time: 6.40e-05, avg batch time: 0.1286, average loss: 0.5238
[09/22 22:09:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.38	top5: 97.79	
[09/22 22:09:23][INFO] visual_prompt:  253: Training 89 / 100 epoch, with learning rate 0.2701704448668719
[09/22 22:10:31][INFO] visual_prompt:  321: Epoch 89 / 100: avg data time: 1.87e-02, avg batch time: 0.8049, average train loss: 0.1051average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:10:34][INFO] visual_prompt:  435: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1209, average loss: 0.4887
[09/22 22:10:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.67	
[09/22 22:10:47][INFO] visual_prompt:  435: Inference (test):avg data time: 6.92e-05, avg batch time: 0.1291, average loss: 0.4934
[09/22 22:10:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.75	top5: 97.83	
[09/22 22:10:48][INFO] visual_prompt:  253: Training 90 / 100 epoch, with learning rate 0.22755045447878963
[09/22 22:11:56][INFO] visual_prompt:  321: Epoch 90 / 100: avg data time: 1.90e-02, avg batch time: 0.8051, average train loss: 0.0985average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:11:58][INFO] visual_prompt:  435: Inference (val):avg data time: 5.44e-05, avg batch time: 0.1222, average loss: 0.4925
[09/22 22:11:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.33	
[09/22 22:12:12][INFO] visual_prompt:  435: Inference (test):avg data time: 7.80e-05, avg batch time: 0.1290, average loss: 0.4984
[09/22 22:12:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.94	top5: 97.93	
[09/22 22:12:12][INFO] visual_prompt:  357: Best epoch 90: best metric: 0.872
[09/22 22:12:12][INFO] visual_prompt:  253: Training 91 / 100 epoch, with learning rate 0.1884605600440365
[09/22 22:13:21][INFO] visual_prompt:  321: Epoch 91 / 100: avg data time: 1.76e-02, avg batch time: 0.8041, average train loss: 0.0979average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:13:23][INFO] visual_prompt:  435: Inference (val):avg data time: 5.66e-05, avg batch time: 0.1220, average loss: 0.4991
[09/22 22:13:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.50	
[09/22 22:13:36][INFO] visual_prompt:  435: Inference (test):avg data time: 9.57e-05, avg batch time: 0.1289, average loss: 0.5002
[09/22 22:13:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.75	top5: 97.77	
[09/22 22:13:37][INFO] visual_prompt:  253: Training 92 / 100 epoch, with learning rate 0.1529483865776452
[09/22 22:14:45][INFO] visual_prompt:  321: Epoch 92 / 100: avg data time: 1.97e-02, avg batch time: 0.8060, average train loss: 0.0927average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:14:48][INFO] visual_prompt:  435: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1223, average loss: 0.4870
[09/22 22:14:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 98.67	
[09/22 22:15:01][INFO] visual_prompt:  435: Inference (test):avg data time: 6.90e-05, avg batch time: 0.1293, average loss: 0.4926
[09/22 22:15:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.04	top5: 97.83	
[09/22 22:15:01][INFO] visual_prompt:  357: Best epoch 92: best metric: 0.877
[09/22 22:15:01][INFO] visual_prompt:  253: Training 93 / 100 epoch, with learning rate 0.12105720019275346
[09/22 22:16:09][INFO] visual_prompt:  321: Epoch 93 / 100: avg data time: 1.89e-02, avg batch time: 0.8050, average train loss: 0.0908average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:16:12][INFO] visual_prompt:  435: Inference (val):avg data time: 5.07e-05, avg batch time: 0.1211, average loss: 0.4945
[09/22 22:16:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 99.00	
[09/22 22:16:26][INFO] visual_prompt:  435: Inference (test):avg data time: 8.44e-05, avg batch time: 0.1283, average loss: 0.5005
[09/22 22:16:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.02	top5: 97.81	
[09/22 22:16:26][INFO] visual_prompt:  253: Training 94 / 100 epoch, with learning rate 0.09282585538751102
[09/22 22:17:35][INFO] visual_prompt:  321: Epoch 94 / 100: avg data time: 1.94e-02, avg batch time: 0.8057, average train loss: 0.0929average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:17:37][INFO] visual_prompt:  435: Inference (val):avg data time: 5.13e-05, avg batch time: 0.1215, average loss: 0.4897
[09/22 22:17:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.50	
[09/22 22:17:51][INFO] visual_prompt:  435: Inference (test):avg data time: 9.60e-05, avg batch time: 0.1291, average loss: 0.4958
[09/22 22:17:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.04	top5: 97.89	
[09/22 22:17:51][INFO] visual_prompt:  253: Training 95 / 100 epoch, with learning rate 0.06828874770685722
[09/22 22:18:59][INFO] visual_prompt:  321: Epoch 95 / 100: avg data time: 2.23e-02, avg batch time: 0.8085, average train loss: 0.0876average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:19:02][INFO] visual_prompt:  435: Inference (val):avg data time: 5.57e-05, avg batch time: 0.1216, average loss: 0.4931
[09/22 22:19:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.67	
[09/22 22:19:16][INFO] visual_prompt:  435: Inference (test):avg data time: 8.78e-05, avg batch time: 0.1284, average loss: 0.4944
[09/22 22:19:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.97	top5: 97.86	
[09/22 22:19:16][INFO] visual_prompt:  253: Training 96 / 100 epoch, with learning rate 0.047475771836849937
[09/22 22:20:24][INFO] visual_prompt:  321: Epoch 96 / 100: avg data time: 2.00e-02, avg batch time: 0.8060, average train loss: 0.0836average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:20:27][INFO] visual_prompt:  435: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1216, average loss: 0.4850
[09/22 22:20:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.67	
[09/22 22:20:40][INFO] visual_prompt:  435: Inference (test):avg data time: 6.64e-05, avg batch time: 0.1289, average loss: 0.4911
[09/22 22:20:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.97	top5: 97.88	
[09/22 22:20:41][INFO] visual_prompt:  253: Training 97 / 100 epoch, with learning rate 0.03041228518259262
[09/22 22:21:49][INFO] visual_prompt:  321: Epoch 97 / 100: avg data time: 2.12e-02, avg batch time: 0.8072, average train loss: 0.0858average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:21:51][INFO] visual_prompt:  435: Inference (val):avg data time: 8.25e-05, avg batch time: 0.1211, average loss: 0.4840
[09/22 22:21:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.50	
[09/22 22:22:05][INFO] visual_prompt:  435: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1286, average loss: 0.4912
[09/22 22:22:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.99	top5: 97.84	
[09/22 22:22:05][INFO] visual_prompt:  253: Training 98 / 100 epoch, with learning rate 0.01711907697414597
[09/22 22:23:14][INFO] visual_prompt:  321: Epoch 98 / 100: avg data time: 1.95e-02, avg batch time: 0.8056, average train loss: 0.0823average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:23:16][INFO] visual_prompt:  435: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1221, average loss: 0.4815
[09/22 22:23:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.67	
[09/22 22:23:30][INFO] visual_prompt:  435: Inference (test):avg data time: 9.11e-05, avg batch time: 0.1286, average loss: 0.4882
[09/22 22:23:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.18	top5: 97.86	
[09/22 22:23:30][INFO] visual_prompt:  253: Training 99 / 100 epoch, with learning rate 0.007612342938049382
[09/22 22:24:39][INFO] visual_prompt:  321: Epoch 99 / 100: avg data time: 1.96e-02, avg batch time: 0.8057, average train loss: 0.0840average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:24:41][INFO] visual_prompt:  435: Inference (val):avg data time: 5.74e-05, avg batch time: 0.1226, average loss: 0.4815
[09/22 22:24:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.50	
[09/22 22:24:55][INFO] visual_prompt:  435: Inference (test):avg data time: 6.89e-05, avg batch time: 0.1290, average loss: 0.4889
[09/22 22:24:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.09	top5: 97.86	
[09/22 22:24:55][INFO] visual_prompt:  253: Training 100 / 100 epoch, with learning rate 0.0019036655653257434
[09/22 22:26:03][INFO] visual_prompt:  321: Epoch 100 / 100: avg data time: 1.93e-02, avg batch time: 0.8053, average train loss: 0.0833average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/22 22:26:06][INFO] visual_prompt:  435: Inference (val):avg data time: 7.60e-05, avg batch time: 0.1219, average loss: 0.4816
[09/22 22:26:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.50	
[09/22 22:26:19][INFO] visual_prompt:  435: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1288, average loss: 0.4888
[09/22 22:26:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.09	top5: 97.86	
