[09/20 14:15:27][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/20 14:15:27][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              6
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/20 14:15:27][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/debug_ratio2', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/20 14:15:27][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/20 14:15:27][INFO] visual_prompt:  109: Training with config:
[09/20 14:15:27][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/debug_ratio2/CUB/sup_vitb16_imagenet21k/lr0.1_wd0.01/run4',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 0.1,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.01,
            'WEIGHT_DECAY_BIAS': 0}}
[09/20 14:15:27][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/20 14:15:27][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/20 14:15:27][INFO] visual_prompt:   77: Number of images: 5394
[09/20 14:15:27][INFO] visual_prompt:   78: Number of classes: 200
[09/20 14:15:27][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/20 14:15:27][INFO] visual_prompt:   73: Loading validation data...
[09/20 14:15:27][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/20 14:15:27][INFO] visual_prompt:   77: Number of images: 600
[09/20 14:15:27][INFO] visual_prompt:   78: Number of classes: 200
[09/20 14:15:27][INFO] visual_prompt:   76: Loading test data...
[09/20 14:15:27][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/20 14:15:27][INFO] visual_prompt:   77: Number of images: 5794
[09/20 14:15:27][INFO] visual_prompt:   78: Number of classes: 200
[09/20 14:15:27][INFO] visual_prompt:  103: Constructing models...
[09/20 14:15:32][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/20 14:15:32][INFO] visual_prompt:   55: tuned percent:0.143
[09/20 14:15:35][INFO] visual_prompt:   41: Device used for model: 0
[09/20 14:15:35][INFO] visual_prompt:  106: Setting up Evalutator...
[09/20 14:15:35][INFO] visual_prompt:  108: Setting up Trainer...
[09/20 14:15:35][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/20 14:15:35][INFO] visual_prompt:  253: Training 1 / 100 epoch, with learning rate 0.0
[09/20 14:16:44][INFO] visual_prompt:  321: Epoch 1 / 100: avg data time: 1.78e-02, avg batch time: 0.8078, average train loss: 5.3263average G loss: 5.8162, average realD loss: 12.0324, average fakeD loss: 0.5539, 
[09/20 14:16:46][INFO] visual_prompt:  435: Inference (val):avg data time: 8.53e-05, avg batch time: 0.1190, average loss: 5.3320
[09/20 14:16:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 1.00	
[09/20 14:17:00][INFO] visual_prompt:  435: Inference (test):avg data time: 7.35e-05, avg batch time: 0.1265, average loss: 5.3306
[09/20 14:17:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.36	top5: 1.79	
[09/20 14:17:00][INFO] visual_prompt:  357: Best epoch 1: best metric: 0.005
[09/20 14:17:00][INFO] visual_prompt:  253: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/20 14:18:07][INFO] visual_prompt:  321: Epoch 2 / 100: avg data time: 1.75e-02, avg batch time: 0.7930, average train loss: 5.3161average G loss: 0.0616, average realD loss: 2.6984, average fakeD loss: 1.1666, 
[09/20 14:18:10][INFO] visual_prompt:  435: Inference (val):avg data time: 7.98e-05, avg batch time: 0.1198, average loss: 5.3063
[09/20 14:18:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 2.00	
[09/20 14:18:24][INFO] visual_prompt:  435: Inference (test):avg data time: 6.46e-05, avg batch time: 0.1271, average loss: 5.3054
[09/20 14:18:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.40	top5: 2.28	
[09/20 14:18:24][INFO] visual_prompt:  357: Best epoch 2: best metric: 0.007
[09/20 14:18:24][INFO] visual_prompt:  253: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/20 14:19:32][INFO] visual_prompt:  321: Epoch 3 / 100: avg data time: 1.85e-02, avg batch time: 0.7966, average train loss: 5.3062average G loss: 0.0000, average realD loss: 0.8191, average fakeD loss: 0.5240, 
[09/20 14:19:34][INFO] visual_prompt:  435: Inference (val):avg data time: 7.11e-05, avg batch time: 0.1198, average loss: 5.2956
[09/20 14:19:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 2.33	
[09/20 14:19:47][INFO] visual_prompt:  435: Inference (test):avg data time: 6.25e-05, avg batch time: 0.1280, average loss: 5.2953
[09/20 14:19:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.55	top5: 2.99	
[09/20 14:19:47][INFO] visual_prompt:  357: Best epoch 3: best metric: 0.008
[09/20 14:19:47][INFO] visual_prompt:  253: Training 4 / 100 epoch, with learning rate 0.03
[09/20 14:20:56][INFO] visual_prompt:  321: Epoch 4 / 100: avg data time: 1.92e-02, avg batch time: 0.8012, average train loss: 5.2952average G loss: 0.0000, average realD loss: 0.2555, average fakeD loss: 0.1981, 
[09/20 14:20:58][INFO] visual_prompt:  435: Inference (val):avg data time: 4.00e-05, avg batch time: 0.1212, average loss: 5.2363
[09/20 14:20:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.50	top5: 7.83	
[09/20 14:21:11][INFO] visual_prompt:  435: Inference (test):avg data time: 4.86e-05, avg batch time: 0.1283, average loss: 5.2374
[09/20 14:21:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.86	top5: 6.42	
[09/20 14:21:11][INFO] visual_prompt:  357: Best epoch 4: best metric: 0.015
[09/20 14:21:11][INFO] visual_prompt:  253: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/20 14:22:19][INFO] visual_prompt:  321: Epoch 5 / 100: avg data time: 1.69e-02, avg batch time: 0.8008, average train loss: 4.8174average G loss: 0.0016, average realD loss: 0.1119, average fakeD loss: 0.1015, 
[09/20 14:22:22][INFO] visual_prompt:  435: Inference (val):avg data time: 6.25e-05, avg batch time: 0.1199, average loss: 4.1973
[09/20 14:22:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 44.17	top5: 74.33	
[09/20 14:22:36][INFO] visual_prompt:  435: Inference (test):avg data time: 6.24e-05, avg batch time: 0.1275, average loss: 4.1842
[09/20 14:22:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 44.75	top5: 74.94	
[09/20 14:22:36][INFO] visual_prompt:  357: Best epoch 5: best metric: 0.442
[09/20 14:22:36][INFO] visual_prompt:  253: Training 6 / 100 epoch, with learning rate 0.05
[09/20 14:23:44][INFO] visual_prompt:  321: Epoch 6 / 100: avg data time: 1.83e-02, avg batch time: 0.8036, average train loss: 3.6135average G loss: 0.0051, average realD loss: 0.0790, average fakeD loss: 0.0771, 
[09/20 14:23:47][INFO] visual_prompt:  435: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1208, average loss: 3.0220
[09/20 14:23:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.00	top5: 93.00	
[09/20 14:24:00][INFO] visual_prompt:  435: Inference (test):avg data time: 6.75e-05, avg batch time: 0.1278, average loss: 3.0204
[09/20 14:24:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.66	top5: 93.27	
[09/20 14:24:00][INFO] visual_prompt:  357: Best epoch 6: best metric: 0.670
[09/20 14:24:00][INFO] visual_prompt:  253: Training 7 / 100 epoch, with learning rate 0.06
[09/20 14:25:09][INFO] visual_prompt:  321: Epoch 7 / 100: avg data time: 1.88e-02, avg batch time: 0.8041, average train loss: 2.7319average G loss: 0.0092, average realD loss: 0.0720, average fakeD loss: 0.0685, 
[09/20 14:25:11][INFO] visual_prompt:  435: Inference (val):avg data time: 5.15e-05, avg batch time: 0.1204, average loss: 2.4041
[09/20 14:25:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.50	top5: 95.33	
[09/20 14:25:24][INFO] visual_prompt:  435: Inference (test):avg data time: 6.14e-05, avg batch time: 0.1282, average loss: 2.4030
[09/20 14:25:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.04	top5: 95.51	
[09/20 14:25:25][INFO] visual_prompt:  357: Best epoch 7: best metric: 0.685
[09/20 14:25:25][INFO] visual_prompt:  253: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/20 14:26:33][INFO] visual_prompt:  321: Epoch 8 / 100: avg data time: 1.81e-02, avg batch time: 0.8033, average train loss: 2.4139average G loss: 0.0142, average realD loss: 0.0765, average fakeD loss: 0.0710, 
[09/20 14:26:35][INFO] visual_prompt:  435: Inference (val):avg data time: 4.78e-05, avg batch time: 0.1201, average loss: 2.2859
[09/20 14:26:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.83	top5: 97.00	
[09/20 14:26:49][INFO] visual_prompt:  435: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1273, average loss: 2.2862
[09/20 14:26:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.38	top5: 96.06	
[09/20 14:26:49][INFO] visual_prompt:  357: Best epoch 8: best metric: 0.708
[09/20 14:26:49][INFO] visual_prompt:  253: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/20 14:27:58][INFO] visual_prompt:  321: Epoch 9 / 100: avg data time: 1.85e-02, avg batch time: 0.8037, average train loss: 2.3281average G loss: 0.0162, average realD loss: 0.0763, average fakeD loss: 0.0753, 
[09/20 14:28:00][INFO] visual_prompt:  435: Inference (val):avg data time: 4.68e-05, avg batch time: 0.1201, average loss: 2.3590
[09/20 14:28:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.83	top5: 93.67	
[09/20 14:28:14][INFO] visual_prompt:  435: Inference (test):avg data time: 7.31e-05, avg batch time: 0.1277, average loss: 2.3416
[09/20 14:28:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.98	top5: 94.55	
[09/20 14:28:14][INFO] visual_prompt:  253: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/20 14:29:22][INFO] visual_prompt:  321: Epoch 10 / 100: avg data time: 1.87e-02, avg batch time: 0.8036, average train loss: 2.3470average G loss: 0.0170, average realD loss: 0.0775, average fakeD loss: 0.0759, 
[09/20 14:29:25][INFO] visual_prompt:  435: Inference (val):avg data time: 5.44e-05, avg batch time: 0.1207, average loss: 2.2407
[09/20 14:29:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.17	top5: 95.00	
[09/20 14:29:38][INFO] visual_prompt:  435: Inference (test):avg data time: 5.84e-05, avg batch time: 0.1277, average loss: 2.2450
[09/20 14:29:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.31	top5: 96.15	
[09/20 14:29:38][INFO] visual_prompt:  253: Training 11 / 100 epoch, with learning rate 0.1
[09/20 14:30:47][INFO] visual_prompt:  321: Epoch 11 / 100: avg data time: 1.78e-02, avg batch time: 0.8026, average train loss: 2.3402average G loss: 0.0168, average realD loss: 0.0762, average fakeD loss: 0.0772, 
[09/20 14:30:49][INFO] visual_prompt:  435: Inference (val):avg data time: 5.18e-05, avg batch time: 0.1207, average loss: 2.2166
[09/20 14:30:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.17	top5: 95.67	
[09/20 14:31:02][INFO] visual_prompt:  435: Inference (test):avg data time: 6.03e-05, avg batch time: 0.1280, average loss: 2.2034
[09/20 14:31:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.22	top5: 95.58	
[09/20 14:31:02][INFO] visual_prompt:  253: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/20 14:32:11][INFO] visual_prompt:  321: Epoch 12 / 100: avg data time: 1.88e-02, avg batch time: 0.8037, average train loss: 2.3411average G loss: 0.0164, average realD loss: 0.0715, average fakeD loss: 0.0756, 
[09/20 14:32:13][INFO] visual_prompt:  435: Inference (val):avg data time: 5.57e-05, avg batch time: 0.1202, average loss: 2.2594
[09/20 14:32:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.50	top5: 95.00	
[09/20 14:32:27][INFO] visual_prompt:  435: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1281, average loss: 2.2625
[09/20 14:32:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.22	top5: 95.84	
[09/20 14:32:27][INFO] visual_prompt:  253: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/20 14:33:35][INFO] visual_prompt:  321: Epoch 13 / 100: avg data time: 1.95e-02, avg batch time: 0.8042, average train loss: 2.3253average G loss: 0.0160, average realD loss: 0.0719, average fakeD loss: 0.0777, 
[09/20 14:33:38][INFO] visual_prompt:  435: Inference (val):avg data time: 5.60e-05, avg batch time: 0.1198, average loss: 2.2510
[09/20 14:33:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.67	top5: 94.00	
[09/20 14:33:51][INFO] visual_prompt:  435: Inference (test):avg data time: 6.07e-05, avg batch time: 0.1280, average loss: 2.2518
[09/20 14:33:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.09	top5: 94.30	
[09/20 14:33:51][INFO] visual_prompt:  253: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/20 14:35:00][INFO] visual_prompt:  321: Epoch 14 / 100: avg data time: 1.92e-02, avg batch time: 0.8041, average train loss: 2.3308average G loss: 0.0163, average realD loss: 0.0738, average fakeD loss: 0.0752, 
[09/20 14:35:02][INFO] visual_prompt:  435: Inference (val):avg data time: 7.71e-05, avg batch time: 0.1206, average loss: 2.2344
[09/20 14:35:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.50	top5: 94.50	
[09/20 14:35:15][INFO] visual_prompt:  435: Inference (test):avg data time: 8.71e-05, avg batch time: 0.1279, average loss: 2.2250
[09/20 14:35:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.69	top5: 95.08	
[09/20 14:35:16][INFO] visual_prompt:  253: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/20 14:36:24][INFO] visual_prompt:  321: Epoch 15 / 100: avg data time: 1.84e-02, avg batch time: 0.8030, average train loss: 2.3413average G loss: 0.0162, average realD loss: 0.0717, average fakeD loss: 0.0784, 
[09/20 14:36:26][INFO] visual_prompt:  435: Inference (val):avg data time: 6.29e-05, avg batch time: 0.1205, average loss: 2.2291
[09/20 14:36:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.17	top5: 94.67	
[09/20 14:36:40][INFO] visual_prompt:  435: Inference (test):avg data time: 6.63e-05, avg batch time: 0.1281, average loss: 2.2309
[09/20 14:36:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.47	top5: 94.24	
[09/20 14:36:40][INFO] visual_prompt:  253: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/20 14:37:48][INFO] visual_prompt:  321: Epoch 16 / 100: avg data time: 1.97e-02, avg batch time: 0.8046, average train loss: 2.3238average G loss: 0.0156, average realD loss: 0.0715, average fakeD loss: 0.0767, 
[09/20 14:37:51][INFO] visual_prompt:  435: Inference (val):avg data time: 7.27e-05, avg batch time: 0.1199, average loss: 2.2310
[09/20 14:37:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 62.17	top5: 93.50	
[09/20 14:38:04][INFO] visual_prompt:  435: Inference (test):avg data time: 5.28e-05, avg batch time: 0.1286, average loss: 2.2261
[09/20 14:38:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.98	top5: 93.70	
[09/20 14:38:04][INFO] visual_prompt:  253: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/20 14:39:12][INFO] visual_prompt:  321: Epoch 17 / 100: avg data time: 1.77e-02, avg batch time: 0.8026, average train loss: 2.3141average G loss: 0.0154, average realD loss: 0.0737, average fakeD loss: 0.0798, 
[09/20 14:39:14][INFO] visual_prompt:  435: Inference (val):avg data time: 4.46e-05, avg batch time: 0.1218, average loss: 2.2359
[09/20 14:39:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.17	top5: 97.33	
[09/20 14:39:28][INFO] visual_prompt:  435: Inference (test):avg data time: 4.99e-05, avg batch time: 0.1286, average loss: 2.2319
[09/20 14:39:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.97	top5: 95.53	
[09/20 14:39:28][INFO] visual_prompt:  253: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/20 14:40:36][INFO] visual_prompt:  321: Epoch 18 / 100: avg data time: 1.78e-02, avg batch time: 0.8026, average train loss: 2.3340average G loss: 0.0158, average realD loss: 0.0697, average fakeD loss: 0.0755, 
[09/20 14:40:38][INFO] visual_prompt:  435: Inference (val):avg data time: 5.46e-05, avg batch time: 0.1210, average loss: 2.1878
[09/20 14:40:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.67	top5: 95.67	
[09/20 14:40:52][INFO] visual_prompt:  435: Inference (test):avg data time: 7.08e-05, avg batch time: 0.1279, average loss: 2.1888
[09/20 14:40:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.42	top5: 95.74	
[09/20 14:40:52][INFO] visual_prompt:  253: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/20 14:42:00][INFO] visual_prompt:  321: Epoch 19 / 100: avg data time: 1.87e-02, avg batch time: 0.8032, average train loss: 2.3383average G loss: 0.0167, average realD loss: 0.0752, average fakeD loss: 0.0767, 
[09/20 14:42:03][INFO] visual_prompt:  435: Inference (val):avg data time: 5.17e-05, avg batch time: 0.1198, average loss: 2.2066
[09/20 14:42:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 64.83	top5: 96.67	
[09/20 14:42:16][INFO] visual_prompt:  435: Inference (test):avg data time: 5.50e-05, avg batch time: 0.1282, average loss: 2.2058
[09/20 14:42:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.77	top5: 96.08	
[09/20 14:42:16][INFO] visual_prompt:  253: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/20 14:43:24][INFO] visual_prompt:  321: Epoch 20 / 100: avg data time: 1.86e-02, avg batch time: 0.8033, average train loss: 2.3229average G loss: 0.0162, average realD loss: 0.0723, average fakeD loss: 0.0773, 
[09/20 14:43:26][INFO] visual_prompt:  435: Inference (val):avg data time: 4.99e-05, avg batch time: 0.1197, average loss: 2.2280
[09/20 14:43:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.83	top5: 94.33	
[09/20 14:43:40][INFO] visual_prompt:  435: Inference (test):avg data time: 5.98e-05, avg batch time: 0.1283, average loss: 2.2348
[09/20 14:43:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.62	top5: 94.87	
[09/20 14:43:40][INFO] visual_prompt:  253: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/20 14:44:48][INFO] visual_prompt:  321: Epoch 21 / 100: avg data time: 1.85e-02, avg batch time: 0.8031, average train loss: 2.3274average G loss: 0.0156, average realD loss: 0.0732, average fakeD loss: 0.0766, 
[09/20 14:44:50][INFO] visual_prompt:  435: Inference (val):avg data time: 5.71e-05, avg batch time: 0.1218, average loss: 2.2287
[09/20 14:44:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.17	top5: 95.00	
[09/20 14:45:04][INFO] visual_prompt:  435: Inference (test):avg data time: 5.64e-05, avg batch time: 0.1284, average loss: 2.2235
[09/20 14:45:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.73	top5: 94.87	
[09/20 14:45:04][INFO] visual_prompt:  253: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/20 14:46:12][INFO] visual_prompt:  321: Epoch 22 / 100: avg data time: 1.96e-02, avg batch time: 0.8043, average train loss: 2.3524average G loss: 0.0164, average realD loss: 0.0707, average fakeD loss: 0.0786, 
[09/20 14:46:14][INFO] visual_prompt:  435: Inference (val):avg data time: 5.11e-05, avg batch time: 0.1215, average loss: 2.2758
[09/20 14:46:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.50	top5: 95.17	
[09/20 14:46:28][INFO] visual_prompt:  435: Inference (test):avg data time: 6.10e-05, avg batch time: 0.1280, average loss: 2.2722
[09/20 14:46:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.88	top5: 95.17	
[09/20 14:46:28][INFO] visual_prompt:  253: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/20 14:47:37][INFO] visual_prompt:  321: Epoch 23 / 100: avg data time: 1.84e-02, avg batch time: 0.8033, average train loss: 2.3197average G loss: 0.0158, average realD loss: 0.0717, average fakeD loss: 0.0755, 
[09/20 14:47:39][INFO] visual_prompt:  435: Inference (val):avg data time: 5.36e-05, avg batch time: 0.1202, average loss: 2.2387
[09/20 14:47:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.17	top5: 95.00	
[09/20 14:47:52][INFO] visual_prompt:  435: Inference (test):avg data time: 6.00e-05, avg batch time: 0.1278, average loss: 2.2401
[09/20 14:47:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.95	top5: 94.60	
[09/20 14:47:52][INFO] visual_prompt:  253: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/20 14:49:01][INFO] visual_prompt:  321: Epoch 24 / 100: avg data time: 1.86e-02, avg batch time: 0.8034, average train loss: 2.3293average G loss: 0.0157, average realD loss: 0.0745, average fakeD loss: 0.0795, 
[09/20 14:49:03][INFO] visual_prompt:  435: Inference (val):avg data time: 5.16e-05, avg batch time: 0.1210, average loss: 2.1957
[09/20 14:49:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.17	top5: 96.00	
[09/20 14:49:16][INFO] visual_prompt:  435: Inference (test):avg data time: 4.89e-05, avg batch time: 0.1282, average loss: 2.1854
[09/20 14:49:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.76	top5: 95.56	
[09/20 14:49:16][INFO] visual_prompt:  253: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/20 14:50:25][INFO] visual_prompt:  321: Epoch 25 / 100: avg data time: 1.86e-02, avg batch time: 0.8033, average train loss: 2.3250average G loss: 0.0160, average realD loss: 0.0709, average fakeD loss: 0.0798, 
[09/20 14:50:27][INFO] visual_prompt:  435: Inference (val):avg data time: 5.72e-05, avg batch time: 0.1204, average loss: 2.2251
[09/20 14:50:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.50	top5: 95.17	
[09/20 14:50:41][INFO] visual_prompt:  435: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1276, average loss: 2.2268
[09/20 14:50:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.26	top5: 95.58	
[09/20 14:50:41][INFO] visual_prompt:  253: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/20 14:51:49][INFO] visual_prompt:  321: Epoch 26 / 100: avg data time: 1.75e-02, avg batch time: 0.8024, average train loss: 2.3117average G loss: 0.0159, average realD loss: 0.0748, average fakeD loss: 0.0776, 
[09/20 14:51:51][INFO] visual_prompt:  435: Inference (val):avg data time: 5.38e-05, avg batch time: 0.1204, average loss: 2.2786
[09/20 14:51:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.17	top5: 94.17	
[09/20 14:52:05][INFO] visual_prompt:  435: Inference (test):avg data time: 4.95e-05, avg batch time: 0.1288, average loss: 2.2952
[09/20 14:52:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 66.26	top5: 94.49	
[09/20 14:52:05][INFO] visual_prompt:  253: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/20 14:53:13][INFO] visual_prompt:  321: Epoch 27 / 100: avg data time: 1.71e-02, avg batch time: 0.8021, average train loss: 2.3039average G loss: 0.0160, average realD loss: 0.0704, average fakeD loss: 0.0758, 
[09/20 14:53:15][INFO] visual_prompt:  435: Inference (val):avg data time: 5.22e-05, avg batch time: 0.1205, average loss: 2.1856
[09/20 14:53:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.67	top5: 95.17	
[09/20 14:53:29][INFO] visual_prompt:  435: Inference (test):avg data time: 6.04e-05, avg batch time: 0.1278, average loss: 2.1954
[09/20 14:53:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.62	top5: 94.30	
[09/20 14:53:29][INFO] visual_prompt:  253: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/20 14:54:38][INFO] visual_prompt:  321: Epoch 28 / 100: avg data time: 2.05e-02, avg batch time: 0.8055, average train loss: 2.3438average G loss: 0.0159, average realD loss: 0.0726, average fakeD loss: 0.0806, 
[09/20 14:54:40][INFO] visual_prompt:  435: Inference (val):avg data time: 5.91e-05, avg batch time: 0.1208, average loss: 2.3648
[09/20 14:54:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 63.83	top5: 93.67	
[09/20 14:54:54][INFO] visual_prompt:  435: Inference (test):avg data time: 7.40e-05, avg batch time: 0.1279, average loss: 2.3574
[09/20 14:54:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 65.31	top5: 93.49	
[09/20 14:54:54][INFO] visual_prompt:  253: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/20 14:56:02][INFO] visual_prompt:  321: Epoch 29 / 100: avg data time: 1.76e-02, avg batch time: 0.8027, average train loss: 2.3499average G loss: 0.0160, average realD loss: 0.0730, average fakeD loss: 0.0792, 
[09/20 14:56:05][INFO] visual_prompt:  435: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1202, average loss: 2.1958
[09/20 14:56:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.00	top5: 96.17	
[09/20 14:56:18][INFO] visual_prompt:  435: Inference (test):avg data time: 6.67e-05, avg batch time: 0.1275, average loss: 2.1884
[09/20 14:56:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.74	top5: 96.32	
[09/20 14:56:18][INFO] visual_prompt:  253: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/20 14:57:27][INFO] visual_prompt:  321: Epoch 30 / 100: avg data time: 1.86e-02, avg batch time: 0.8035, average train loss: 2.3015average G loss: 0.0158, average realD loss: 0.0723, average fakeD loss: 0.0777, 
[09/20 14:57:29][INFO] visual_prompt:  435: Inference (val):avg data time: 6.09e-05, avg batch time: 0.1208, average loss: 2.2177
[09/20 14:57:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.67	top5: 94.83	
[09/20 14:57:43][INFO] visual_prompt:  435: Inference (test):avg data time: 6.99e-05, avg batch time: 0.1277, average loss: 2.2144
[09/20 14:57:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.05	top5: 95.03	
[09/20 14:57:43][INFO] visual_prompt:  253: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/20 14:58:51][INFO] visual_prompt:  321: Epoch 31 / 100: avg data time: 1.77e-02, avg batch time: 0.8026, average train loss: 2.2907average G loss: 0.0154, average realD loss: 0.0708, average fakeD loss: 0.0795, 
[09/20 14:58:53][INFO] visual_prompt:  435: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1211, average loss: 2.1899
[09/20 14:58:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.67	top5: 95.67	
[09/20 14:59:07][INFO] visual_prompt:  435: Inference (test):avg data time: 6.53e-05, avg batch time: 0.1280, average loss: 2.1810
[09/20 14:59:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.59	top5: 95.63	
[09/20 14:59:07][INFO] visual_prompt:  253: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/20 15:00:15][INFO] visual_prompt:  321: Epoch 32 / 100: avg data time: 1.80e-02, avg batch time: 0.8033, average train loss: 2.3104average G loss: 0.0173, average realD loss: 0.0713, average fakeD loss: 0.0781, 
[09/20 15:00:18][INFO] visual_prompt:  435: Inference (val):avg data time: 6.02e-05, avg batch time: 0.1197, average loss: 2.3395
[09/20 15:00:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.17	top5: 95.33	
[09/20 15:00:31][INFO] visual_prompt:  435: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1279, average loss: 2.3312
[09/20 15:00:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.00	top5: 95.62	
[09/20 15:00:31][INFO] visual_prompt:  253: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/20 15:01:40][INFO] visual_prompt:  321: Epoch 33 / 100: avg data time: 1.95e-02, avg batch time: 0.8048, average train loss: 2.2996average G loss: 0.0156, average realD loss: 0.0709, average fakeD loss: 0.0776, 
[09/20 15:01:42][INFO] visual_prompt:  435: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1196, average loss: 2.1750
[09/20 15:01:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 67.00	top5: 94.50	
[09/20 15:01:56][INFO] visual_prompt:  435: Inference (test):avg data time: 6.64e-05, avg batch time: 0.1279, average loss: 2.1835
[09/20 15:01:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 68.09	top5: 95.17	
[09/20 15:01:56][INFO] visual_prompt:  253: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/20 15:03:04][INFO] visual_prompt:  321: Epoch 34 / 100: avg data time: 1.78e-02, avg batch time: 0.8028, average train loss: 2.2931average G loss: 0.0158, average realD loss: 0.0735, average fakeD loss: 0.0771, 
[09/20 15:03:06][INFO] visual_prompt:  435: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1199, average loss: 2.2025
[09/20 15:03:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.83	top5: 94.33	
[09/20 15:03:20][INFO] visual_prompt:  435: Inference (test):avg data time: 6.73e-05, avg batch time: 0.1285, average loss: 2.1936
[09/20 15:03:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.92	top5: 94.67	
[09/20 15:03:20][INFO] visual_prompt:  253: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/20 15:04:28][INFO] visual_prompt:  321: Epoch 35 / 100: avg data time: 1.77e-02, avg batch time: 0.8028, average train loss: 2.2871average G loss: 0.0157, average realD loss: 0.0723, average fakeD loss: 0.0784, 
[09/20 15:04:31][INFO] visual_prompt:  435: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1205, average loss: 2.1870
[09/20 15:04:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 68.00	top5: 95.67	
[09/20 15:04:44][INFO] visual_prompt:  435: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1282, average loss: 2.1802
[09/20 15:04:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 69.49	top5: 95.12	
[09/20 15:04:44][INFO] visual_prompt:  253: Training 36 / 100 epoch, with learning rate 0.08213938048432697
