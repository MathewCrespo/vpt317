[09/23 16:02:51][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 16:02:51][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 16:02:51][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/1fake_epoch200', 'MODEL.TRANSFER_TYPE', 'prompt+gan', 'SOLVER.TOTAL_EPOCH', '200'], train_type='prompt')
[09/23 16:02:51][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 16:02:51][INFO] visual_prompt:  109: Training with config:
[09/23 16:02:51][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/1fake_epoch200/CUB/sup_vitb16_imagenet21k/lr0.625_wd0.001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 0.625,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 200,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 16:02:51][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 16:02:51][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 16:02:51][INFO] visual_prompt:   77: Number of images: 5394
[09/23 16:02:51][INFO] visual_prompt:   78: Number of classes: 200
[09/23 16:02:51][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 16:02:51][INFO] visual_prompt:   73: Loading validation data...
[09/23 16:02:51][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 16:02:51][INFO] visual_prompt:   77: Number of images: 600
[09/23 16:02:51][INFO] visual_prompt:   78: Number of classes: 200
[09/23 16:02:51][INFO] visual_prompt:   76: Loading test data...
[09/23 16:02:51][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 16:02:51][INFO] visual_prompt:   77: Number of images: 5794
[09/23 16:02:51][INFO] visual_prompt:   78: Number of classes: 200
[09/23 16:02:51][INFO] visual_prompt:  103: Constructing models...
[09/23 16:02:56][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 16:02:56][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 16:02:57][INFO] visual_prompt:   41: Device used for model: 0
[09/23 16:02:57][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 16:02:57][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 16:02:57][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 16:02:57][INFO] visual_prompt:  259: Training 1 / 200 epoch, with learning rate 0.0
[09/23 16:04:13][INFO] visual_prompt:  327: Epoch 1 / 200: avg data time: 1.93e-02, avg batch time: 0.8948, average train loss: 5.3302average G loss: 3.3659, average realD loss: 4.3546, average fakeD loss: 0.2079, 
[09/23 16:04:15][INFO] visual_prompt:  441: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1170, average loss: 5.3349
[09/23 16:04:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 3.33	
[09/23 16:04:30][INFO] visual_prompt:  441: Inference (test):avg data time: 7.69e-05, avg batch time: 0.1235, average loss: 5.3289
[09/23 16:04:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.81	top5: 3.16	
[09/23 16:04:30][INFO] visual_prompt:  363: Best epoch 1: best metric: 0.007
[09/23 16:04:30][INFO] visual_prompt:  259: Training 2 / 200 epoch, with learning rate 0.0625
[09/23 16:05:46][INFO] visual_prompt:  327: Epoch 2 / 200: avg data time: 1.99e-02, avg batch time: 0.8928, average train loss: 5.3219average G loss: 0.0346, average realD loss: 0.3543, average fakeD loss: 98.7859, 
[09/23 16:05:48][INFO] visual_prompt:  441: Inference (val):avg data time: 6.33e-05, avg batch time: 0.1171, average loss: 5.2986
[09/23 16:05:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:06:03][INFO] visual_prompt:  441: Inference (test):avg data time: 7.72e-05, avg batch time: 0.1239, average loss: 5.2981
[09/23 16:06:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.71	top5: 2.35	
[09/23 16:06:03][INFO] visual_prompt:  259: Training 3 / 200 epoch, with learning rate 0.125
[09/23 16:07:19][INFO] visual_prompt:  327: Epoch 3 / 200: avg data time: 1.93e-02, avg batch time: 0.8929, average train loss: 5.3262average G loss: 0.0000, average realD loss: 0.0125, average fakeD loss: 100.0000, 
[09/23 16:07:21][INFO] visual_prompt:  441: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1177, average loss: 5.2997
[09/23 16:07:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 16:07:35][INFO] visual_prompt:  441: Inference (test):avg data time: 8.74e-05, avg batch time: 0.1238, average loss: 5.2986
[09/23 16:07:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.95	
[09/23 16:07:35][INFO] visual_prompt:  259: Training 4 / 200 epoch, with learning rate 0.1875
[09/23 16:08:51][INFO] visual_prompt:  327: Epoch 4 / 200: avg data time: 1.97e-02, avg batch time: 0.8930, average train loss: 5.3306average G loss: 0.0000, average realD loss: 0.0025, average fakeD loss: 100.0000, 
[09/23 16:08:54][INFO] visual_prompt:  441: Inference (val):avg data time: 6.11e-05, avg batch time: 0.1171, average loss: 5.2810
[09/23 16:08:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 3.83	
[09/23 16:09:08][INFO] visual_prompt:  441: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1239, average loss: 5.2801
[09/23 16:09:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.93	top5: 4.21	
[09/23 16:09:08][INFO] visual_prompt:  363: Best epoch 4: best metric: 0.008
[09/23 16:09:08][INFO] visual_prompt:  259: Training 5 / 200 epoch, with learning rate 0.25
[09/23 16:10:24][INFO] visual_prompt:  327: Epoch 5 / 200: avg data time: 1.84e-02, avg batch time: 0.8935, average train loss: 5.3515average G loss: 5.0318, average realD loss: 1.8863, average fakeD loss: 48.9981, 
[09/23 16:10:26][INFO] visual_prompt:  441: Inference (val):avg data time: 5.87e-05, avg batch time: 0.1169, average loss: 5.3899
[09/23 16:10:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:10:39][INFO] visual_prompt:  441: Inference (test):avg data time: 6.68e-05, avg batch time: 0.1239, average loss: 5.3887
[09/23 16:10:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.55	
[09/23 16:10:40][INFO] visual_prompt:  259: Training 6 / 200 epoch, with learning rate 0.3125
[09/23 16:11:56][INFO] visual_prompt:  327: Epoch 6 / 200: avg data time: 1.88e-02, avg batch time: 0.8928, average train loss: 5.4908average G loss: 0.1476, average realD loss: 1.8427, average fakeD loss: 89.4248, 
[09/23 16:11:58][INFO] visual_prompt:  441: Inference (val):avg data time: 5.79e-05, avg batch time: 0.1167, average loss: 5.3575
[09/23 16:11:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.67	
[09/23 16:12:12][INFO] visual_prompt:  441: Inference (test):avg data time: 8.42e-05, avg batch time: 0.1237, average loss: 5.3579
[09/23 16:12:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.76	
[09/23 16:12:12][INFO] visual_prompt:  259: Training 7 / 200 epoch, with learning rate 0.375
[09/23 16:13:28][INFO] visual_prompt:  327: Epoch 7 / 200: avg data time: 1.89e-02, avg batch time: 0.8920, average train loss: 5.3874average G loss: 0.0027, average realD loss: 0.1860, average fakeD loss: 97.5216, 
[09/23 16:13:30][INFO] visual_prompt:  441: Inference (val):avg data time: 7.64e-05, avg batch time: 0.1168, average loss: 5.3566
[09/23 16:13:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/23 16:13:44][INFO] visual_prompt:  441: Inference (test):avg data time: 8.90e-05, avg batch time: 0.1234, average loss: 5.3575
[09/23 16:13:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.92	
[09/23 16:13:44][INFO] visual_prompt:  259: Training 8 / 200 epoch, with learning rate 0.4375
[09/23 16:15:00][INFO] visual_prompt:  327: Epoch 8 / 200: avg data time: 1.99e-02, avg batch time: 0.8933, average train loss: 5.3791average G loss: 0.0018, average realD loss: 0.0169, average fakeD loss: 94.4645, 
[09/23 16:15:02][INFO] visual_prompt:  441: Inference (val):avg data time: 7.33e-05, avg batch time: 0.1170, average loss: 5.3413
[09/23 16:15:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:15:17][INFO] visual_prompt:  441: Inference (test):avg data time: 8.86e-05, avg batch time: 0.1237, average loss: 5.3423
[09/23 16:15:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.43	
[09/23 16:15:17][INFO] visual_prompt:  259: Training 9 / 200 epoch, with learning rate 0.5
[09/23 16:16:33][INFO] visual_prompt:  327: Epoch 9 / 200: avg data time: 1.85e-02, avg batch time: 0.8947, average train loss: 5.4043average G loss: 40.6805, average realD loss: 1.0497, average fakeD loss: 11.4941, 
[09/23 16:16:35][INFO] visual_prompt:  441: Inference (val):avg data time: 6.20e-05, avg batch time: 0.1176, average loss: 5.3728
[09/23 16:16:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:16:50][INFO] visual_prompt:  441: Inference (test):avg data time: 7.79e-05, avg batch time: 0.1237, average loss: 5.3723
[09/23 16:16:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 16:16:50][INFO] visual_prompt:  259: Training 10 / 200 epoch, with learning rate 0.5625
[09/23 16:18:06][INFO] visual_prompt:  327: Epoch 10 / 200: avg data time: 1.89e-02, avg batch time: 0.8949, average train loss: 5.4521average G loss: 28.2932, average realD loss: 0.6367, average fakeD loss: 21.7600, 
[09/23 16:18:09][INFO] visual_prompt:  441: Inference (val):avg data time: 7.65e-05, avg batch time: 0.1170, average loss: 5.6697
[09/23 16:18:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:18:23][INFO] visual_prompt:  441: Inference (test):avg data time: 9.13e-05, avg batch time: 0.1237, average loss: 5.6686
[09/23 16:18:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.52	
[09/23 16:18:23][INFO] visual_prompt:  259: Training 11 / 200 epoch, with learning rate 0.625
[09/23 16:19:39][INFO] visual_prompt:  327: Epoch 11 / 200: avg data time: 1.98e-02, avg batch time: 0.8929, average train loss: 5.4934average G loss: 0.0531, average realD loss: 0.4432, average fakeD loss: 90.4996, 
[09/23 16:19:42][INFO] visual_prompt:  441: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1174, average loss: 5.3750
[09/23 16:19:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/23 16:19:56][INFO] visual_prompt:  441: Inference (test):avg data time: 5.34e-05, avg batch time: 0.1237, average loss: 5.3736
[09/23 16:19:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.85	
[09/23 16:19:56][INFO] visual_prompt:  259: Training 12 / 200 epoch, with learning rate 0.6249572828101466
[09/23 16:21:12][INFO] visual_prompt:  327: Epoch 12 / 200: avg data time: 1.80e-02, avg batch time: 0.8922, average train loss: 5.6844average G loss: 0.8217, average realD loss: 1.4825, average fakeD loss: 84.7086, 
[09/23 16:21:14][INFO] visual_prompt:  441: Inference (val):avg data time: 7.43e-05, avg batch time: 0.1167, average loss: 5.4460
[09/23 16:21:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/23 16:21:29][INFO] visual_prompt:  441: Inference (test):avg data time: 6.62e-05, avg batch time: 0.1235, average loss: 5.4530
[09/23 16:21:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.38	top5: 2.69	
[09/23 16:21:29][INFO] visual_prompt:  259: Training 13 / 200 epoch, with learning rate 0.6248291429190393
[09/23 16:22:45][INFO] visual_prompt:  327: Epoch 13 / 200: avg data time: 2.01e-02, avg batch time: 0.8937, average train loss: 5.6023average G loss: 0.0814, average realD loss: 0.7773, average fakeD loss: 91.9459, 
[09/23 16:22:47][INFO] visual_prompt:  441: Inference (val):avg data time: 1.03e-04, avg batch time: 0.1168, average loss: 5.4058
[09/23 16:22:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/23 16:23:01][INFO] visual_prompt:  441: Inference (test):avg data time: 1.09e-04, avg batch time: 0.1238, average loss: 5.4048
[09/23 16:23:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.43	
[09/23 16:23:01][INFO] visual_prompt:  259: Training 14 / 200 epoch, with learning rate 0.6246156153588452
[09/23 16:24:18][INFO] visual_prompt:  327: Epoch 14 / 200: avg data time: 2.15e-02, avg batch time: 0.8959, average train loss: 5.6020average G loss: 0.7300, average realD loss: 1.6134, average fakeD loss: 80.7048, 
[09/23 16:24:20][INFO] visual_prompt:  441: Inference (val):avg data time: 6.38e-05, avg batch time: 0.1168, average loss: 6.0467
[09/23 16:24:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:24:34][INFO] visual_prompt:  441: Inference (test):avg data time: 9.53e-05, avg batch time: 0.1239, average loss: 6.0373
[09/23 16:24:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.47	top5: 2.54	
[09/23 16:24:34][INFO] visual_prompt:  259: Training 15 / 200 epoch, with learning rate 0.6243167585058671
[09/23 16:25:51][INFO] visual_prompt:  327: Epoch 15 / 200: avg data time: 2.15e-02, avg batch time: 0.8946, average train loss: 5.6287average G loss: 0.0727, average realD loss: 0.2064, average fakeD loss: 98.8827, 
[09/23 16:25:53][INFO] visual_prompt:  441: Inference (val):avg data time: 8.68e-05, avg batch time: 0.1169, average loss: 5.3763
[09/23 16:25:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:26:07][INFO] visual_prompt:  441: Inference (test):avg data time: 1.22e-04, avg batch time: 0.1239, average loss: 5.3735
[09/23 16:26:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 16:26:07][INFO] visual_prompt:  259: Training 16 / 200 epoch, with learning rate 0.6239326540645843
[09/23 16:27:23][INFO] visual_prompt:  327: Epoch 16 / 200: avg data time: 1.75e-02, avg batch time: 0.8927, average train loss: 5.4481average G loss: 31.0016, average realD loss: 1.1218, average fakeD loss: 42.5690, 
[09/23 16:27:25][INFO] visual_prompt:  441: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1169, average loss: 5.3735
[09/23 16:27:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:27:38][INFO] visual_prompt:  441: Inference (test):avg data time: 8.85e-05, avg batch time: 0.1241, average loss: 5.3730
[09/23 16:27:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 16:27:38][INFO] visual_prompt:  259: Training 17 / 200 epoch, with learning rate 0.6234634070453161
[09/23 16:28:55][INFO] visual_prompt:  327: Epoch 17 / 200: avg data time: 1.86e-02, avg batch time: 0.8949, average train loss: 5.4260average G loss: 32.5797, average realD loss: 0.5030, average fakeD loss: 18.7367, 
[09/23 16:28:57][INFO] visual_prompt:  441: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1167, average loss: 5.5630
[09/23 16:28:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:29:12][INFO] visual_prompt:  441: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1239, average loss: 5.5562
[09/23 16:29:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.35	
[09/23 16:29:12][INFO] visual_prompt:  259: Training 18 / 200 epoch, with learning rate 0.6229091457355119
[09/23 16:30:27][INFO] visual_prompt:  327: Epoch 18 / 200: avg data time: 1.85e-02, avg batch time: 0.8914, average train loss: 5.5736average G loss: 0.1010, average realD loss: 0.1687, average fakeD loss: 96.2690, 
[09/23 16:30:30][INFO] visual_prompt:  441: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1170, average loss: 5.3839
[09/23 16:30:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:30:44][INFO] visual_prompt:  441: Inference (test):avg data time: 7.52e-05, avg batch time: 0.1237, average loss: 5.3856
[09/23 16:30:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.49	
[09/23 16:30:44][INFO] visual_prompt:  259: Training 19 / 200 epoch, with learning rate 0.6222700216646797
[09/23 16:32:00][INFO] visual_prompt:  327: Epoch 19 / 200: avg data time: 1.90e-02, avg batch time: 0.8917, average train loss: 5.4237average G loss: 0.2095, average realD loss: 0.3037, average fakeD loss: 95.2461, 
[09/23 16:32:03][INFO] visual_prompt:  441: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1166, average loss: 5.3977
[09/23 16:32:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:32:17][INFO] visual_prompt:  441: Inference (test):avg data time: 7.03e-05, avg batch time: 0.1236, average loss: 5.3921
[09/23 16:32:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.61	
[09/23 16:32:17][INFO] visual_prompt:  259: Training 20 / 200 epoch, with learning rate 0.6215462095629589
[09/23 16:33:32][INFO] visual_prompt:  327: Epoch 20 / 200: avg data time: 1.75e-02, avg batch time: 0.8912, average train loss: 5.4953average G loss: 0.7031, average realD loss: 0.7565, average fakeD loss: 85.5361, 
[09/23 16:33:35][INFO] visual_prompt:  441: Inference (val):avg data time: 6.80e-05, avg batch time: 0.1168, average loss: 5.6948
[09/23 16:33:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:33:49][INFO] visual_prompt:  441: Inference (test):avg data time: 7.26e-05, avg batch time: 0.1238, average loss: 5.6857
[09/23 16:33:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 16:33:49][INFO] visual_prompt:  259: Training 21 / 200 epoch, with learning rate 0.6207379073133508
[09/23 16:35:05][INFO] visual_prompt:  327: Epoch 21 / 200: avg data time: 1.75e-02, avg batch time: 0.8910, average train loss: 5.6345average G loss: 0.4028, average realD loss: 0.9955, average fakeD loss: 91.2604, 
[09/23 16:35:07][INFO] visual_prompt:  441: Inference (val):avg data time: 7.27e-05, avg batch time: 0.1167, average loss: 5.5950
[09/23 16:35:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.17	
[09/23 16:35:21][INFO] visual_prompt:  441: Inference (test):avg data time: 1.09e-04, avg batch time: 0.1239, average loss: 5.6016
[09/23 16:35:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.19	top5: 3.00	
[09/23 16:35:21][INFO] visual_prompt:  259: Training 22 / 200 epoch, with learning rate 0.6198453358976195
[09/23 16:36:37][INFO] visual_prompt:  327: Epoch 22 / 200: avg data time: 1.93e-02, avg batch time: 0.8923, average train loss: 5.4493average G loss: 0.1272, average realD loss: 0.3244, average fakeD loss: 92.9892, 
[09/23 16:36:39][INFO] visual_prompt:  441: Inference (val):avg data time: 6.91e-05, avg batch time: 0.1175, average loss: 5.4274
[09/23 16:36:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:36:53][INFO] visual_prompt:  441: Inference (test):avg data time: 7.04e-05, avg batch time: 0.1238, average loss: 5.4223
[09/23 16:36:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 16:36:53][INFO] visual_prompt:  259: Training 23 / 200 epoch, with learning rate 0.6188687393358779
[09/23 16:38:09][INFO] visual_prompt:  327: Epoch 23 / 200: avg data time: 1.84e-02, avg batch time: 0.8921, average train loss: 5.5289average G loss: 0.6198, average realD loss: 1.6428, average fakeD loss: 84.6819, 
[09/23 16:38:11][INFO] visual_prompt:  441: Inference (val):avg data time: 7.67e-05, avg batch time: 0.1168, average loss: 5.4138
[09/23 16:38:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.17	
[09/23 16:38:25][INFO] visual_prompt:  441: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1239, average loss: 5.4158
[09/23 16:38:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.48	top5: 3.00	
[09/23 16:38:25][INFO] visual_prompt:  259: Training 24 / 200 epoch, with learning rate 0.6178083846198748
[09/23 16:39:41][INFO] visual_prompt:  327: Epoch 24 / 200: avg data time: 2.11e-02, avg batch time: 0.8968, average train loss: 5.4600average G loss: 30.3435, average realD loss: 0.6499, average fakeD loss: 32.3208, 
[09/23 16:39:43][INFO] visual_prompt:  441: Inference (val):avg data time: 6.39e-05, avg batch time: 0.1167, average loss: 5.3821
[09/23 16:39:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:39:58][INFO] visual_prompt:  441: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1236, average loss: 5.3769
[09/23 16:39:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 16:39:58][INFO] visual_prompt:  259: Training 25 / 200 epoch, with learning rate 0.6166645616400018
[09/23 16:41:14][INFO] visual_prompt:  327: Epoch 25 / 200: avg data time: 1.96e-02, avg batch time: 0.8950, average train loss: 5.5351average G loss: 16.3786, average realD loss: 1.2818, average fakeD loss: 44.4833, 
[09/23 16:41:16][INFO] visual_prompt:  441: Inference (val):avg data time: 7.16e-05, avg batch time: 0.1168, average loss: 5.6888
[09/23 16:41:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/23 16:41:31][INFO] visual_prompt:  441: Inference (test):avg data time: 8.13e-05, avg batch time: 0.1237, average loss: 5.6883
[09/23 16:41:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.64	
[09/23 16:41:31][INFO] visual_prompt:  259: Training 26 / 200 epoch, with learning rate 0.6154375831060408
[09/23 16:42:47][INFO] visual_prompt:  327: Epoch 26 / 200: avg data time: 1.94e-02, avg batch time: 0.8933, average train loss: 5.5685average G loss: 0.1980, average realD loss: 0.9700, average fakeD loss: 85.2663, 
[09/23 16:42:49][INFO] visual_prompt:  441: Inference (val):avg data time: 6.72e-05, avg batch time: 0.1170, average loss: 5.8182
[09/23 16:42:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:43:03][INFO] visual_prompt:  441: Inference (test):avg data time: 7.30e-05, avg batch time: 0.1237, average loss: 5.8135
[09/23 16:43:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.59	
[09/23 16:43:03][INFO] visual_prompt:  259: Training 27 / 200 epoch, with learning rate 0.6141277844616715
[09/23 16:44:19][INFO] visual_prompt:  327: Epoch 27 / 200: avg data time: 1.84e-02, avg batch time: 0.8915, average train loss: 5.7010average G loss: 0.0999, average realD loss: 0.6464, average fakeD loss: 93.5265, 
[09/23 16:44:21][INFO] visual_prompt:  441: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1167, average loss: 5.4966
[09/23 16:44:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:44:35][INFO] visual_prompt:  441: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1237, average loss: 5.4951
[09/23 16:44:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.59	
[09/23 16:44:35][INFO] visual_prompt:  259: Training 28 / 200 epoch, with learning rate 0.6127355237927651
[09/23 16:45:51][INFO] visual_prompt:  327: Epoch 28 / 200: avg data time: 1.83e-02, avg batch time: 0.8918, average train loss: 5.4776average G loss: 0.4868, average realD loss: 0.7103, average fakeD loss: 84.4631, 
[09/23 16:45:53][INFO] visual_prompt:  441: Inference (val):avg data time: 6.51e-05, avg batch time: 0.1173, average loss: 5.6351
[09/23 16:45:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 2.33	
[09/23 16:46:08][INFO] visual_prompt:  441: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1238, average loss: 5.6348
[09/23 16:46:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.55	top5: 2.99	
[09/23 16:46:08][INFO] visual_prompt:  259: Training 29 / 200 epoch, with learning rate 0.6112611817294867
[09/23 16:47:24][INFO] visual_prompt:  327: Epoch 29 / 200: avg data time: 1.95e-02, avg batch time: 0.8931, average train loss: 5.6017average G loss: 0.3629, average realD loss: 1.4229, average fakeD loss: 85.3941, 
[09/23 16:47:26][INFO] visual_prompt:  441: Inference (val):avg data time: 6.97e-05, avg batch time: 0.1168, average loss: 5.4532
[09/23 16:47:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:47:40][INFO] visual_prompt:  441: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1236, average loss: 5.4501
[09/23 16:47:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.55	
[09/23 16:47:40][INFO] visual_prompt:  259: Training 30 / 200 epoch, with learning rate 0.6097051613422355
[09/23 16:48:57][INFO] visual_prompt:  327: Epoch 30 / 200: avg data time: 2.09e-02, avg batch time: 0.8941, average train loss: 5.5149average G loss: 0.0912, average realD loss: 0.3899, average fakeD loss: 95.2153, 
[09/23 16:48:59][INFO] visual_prompt:  441: Inference (val):avg data time: 6.93e-05, avg batch time: 0.1168, average loss: 5.3994
[09/23 16:48:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/23 16:49:13][INFO] visual_prompt:  441: Inference (test):avg data time: 6.96e-05, avg batch time: 0.1236, average loss: 5.4040
[09/23 16:49:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.81	
[09/23 16:49:14][INFO] visual_prompt:  259: Training 31 / 200 epoch, with learning rate 0.6080678880314483
[09/23 16:50:30][INFO] visual_prompt:  327: Epoch 31 / 200: avg data time: 2.02e-02, avg batch time: 0.8936, average train loss: 5.4914average G loss: 0.4760, average realD loss: 0.6792, average fakeD loss: 89.4655, 
[09/23 16:50:32][INFO] visual_prompt:  441: Inference (val):avg data time: 7.52e-05, avg batch time: 0.1168, average loss: 5.4352
[09/23 16:50:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/23 16:50:45][INFO] visual_prompt:  441: Inference (test):avg data time: 8.57e-05, avg batch time: 0.1240, average loss: 5.4352
[09/23 16:50:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 3.07	
[09/23 16:50:46][INFO] visual_prompt:  259: Training 32 / 200 epoch, with learning rate 0.6063498094113005
[09/23 16:52:02][INFO] visual_prompt:  327: Epoch 32 / 200: avg data time: 1.86e-02, avg batch time: 0.8922, average train loss: 5.5757average G loss: 0.2525, average realD loss: 1.1114, average fakeD loss: 87.5030, 
[09/23 16:52:04][INFO] visual_prompt:  441: Inference (val):avg data time: 7.24e-05, avg batch time: 0.1168, average loss: 5.4836
[09/23 16:52:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:52:19][INFO] visual_prompt:  441: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1236, average loss: 5.4836
[09/23 16:52:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.87	
[09/23 16:52:19][INFO] visual_prompt:  259: Training 33 / 200 epoch, with learning rate 0.6045513951873315
[09/23 16:53:35][INFO] visual_prompt:  327: Epoch 33 / 200: avg data time: 1.93e-02, avg batch time: 0.8929, average train loss: 5.6092average G loss: 0.4140, average realD loss: 1.1220, average fakeD loss: 85.6163, 
[09/23 16:53:37][INFO] visual_prompt:  441: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1169, average loss: 6.0781
[09/23 16:53:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.83	
[09/23 16:53:52][INFO] visual_prompt:  441: Inference (test):avg data time: 7.34e-05, avg batch time: 0.1238, average loss: 6.0739
[09/23 16:53:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.59	
[09/23 16:53:52][INFO] visual_prompt:  259: Training 34 / 200 epoch, with learning rate 0.6026731370280335
[09/23 16:55:08][INFO] visual_prompt:  327: Epoch 34 / 200: avg data time: 1.95e-02, avg batch time: 0.8928, average train loss: 5.7999average G loss: 0.0567, average realD loss: 0.5224, average fakeD loss: 93.3272, 
[09/23 16:55:10][INFO] visual_prompt:  441: Inference (val):avg data time: 6.67e-05, avg batch time: 0.1173, average loss: 5.7692
[09/23 16:55:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:55:24][INFO] visual_prompt:  441: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1237, average loss: 5.7699
[09/23 16:55:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.33	
[09/23 16:55:24][INFO] visual_prompt:  259: Training 35 / 200 epoch, with learning rate 0.6007155484304327
[09/23 16:56:40][INFO] visual_prompt:  327: Epoch 35 / 200: avg data time: 1.97e-02, avg batch time: 0.8934, average train loss: 5.5154average G loss: 0.4649, average realD loss: 1.4059, average fakeD loss: 85.2539, 
[09/23 16:56:43][INFO] visual_prompt:  441: Inference (val):avg data time: 7.11e-05, avg batch time: 0.1170, average loss: 5.7820
[09/23 16:56:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 16:56:57][INFO] visual_prompt:  441: Inference (test):avg data time: 7.54e-05, avg batch time: 0.1237, average loss: 5.7846
[09/23 16:56:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.69	
[09/23 16:56:57][INFO] visual_prompt:  259: Training 36 / 200 epoch, with learning rate 0.5986791645797054
[09/23 16:58:13][INFO] visual_prompt:  327: Epoch 36 / 200: avg data time: 1.89e-02, avg batch time: 0.8925, average train loss: 5.6675average G loss: 0.2715, average realD loss: 0.9682, average fakeD loss: 87.6689, 
[09/23 16:58:15][INFO] visual_prompt:  441: Inference (val):avg data time: 6.93e-05, avg batch time: 0.1171, average loss: 5.8055
[09/23 16:58:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 2.50	
[09/23 16:58:29][INFO] visual_prompt:  441: Inference (test):avg data time: 1.03e-04, avg batch time: 0.1240, average loss: 5.8094
[09/23 16:58:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.72	top5: 2.57	
[09/23 16:58:29][INFO] visual_prompt:  259: Training 37 / 200 epoch, with learning rate 0.5965645422028633
[09/23 16:59:45][INFO] visual_prompt:  327: Epoch 37 / 200: avg data time: 2.08e-02, avg batch time: 0.8940, average train loss: 5.8361average G loss: 0.1036, average realD loss: 0.4066, average fakeD loss: 96.0756, 
[09/23 16:59:48][INFO] visual_prompt:  441: Inference (val):avg data time: 7.70e-05, avg batch time: 0.1169, average loss: 5.7162
[09/23 16:59:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 3.00	
[09/23 17:00:02][INFO] visual_prompt:  441: Inference (test):avg data time: 8.01e-05, avg batch time: 0.1239, average loss: 5.7181
[09/23 17:00:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.81	top5: 3.02	
[09/23 17:00:02][INFO] visual_prompt:  259: Training 38 / 200 epoch, with learning rate 0.5943722594165497
[09/23 17:01:18][INFO] visual_prompt:  327: Epoch 38 / 200: avg data time: 1.97e-02, avg batch time: 0.8928, average train loss: 3.7653average G loss: 0.0558, average realD loss: 0.3521, average fakeD loss: 91.9279, 
[09/23 17:01:20][INFO] visual_prompt:  441: Inference (val):avg data time: 8.37e-05, avg batch time: 0.1169, average loss: 1.5212
[09/23 17:01:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 66.67	top5: 91.17	
[09/23 17:01:34][INFO] visual_prompt:  441: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1240, average loss: 1.4907
[09/23 17:01:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.90	top5: 92.39	
[09/23 17:01:34][INFO] visual_prompt:  363: Best epoch 38: best metric: 0.667
[09/23 17:01:34][INFO] visual_prompt:  259: Training 39 / 200 epoch, with learning rate 0.5921029155689885
[09/23 17:02:50][INFO] visual_prompt:  327: Epoch 39 / 200: avg data time: 2.00e-02, avg batch time: 0.8937, average train loss: 1.2596average G loss: 0.0630, average realD loss: 0.4423, average fakeD loss: 88.8438, 
[09/23 17:02:53][INFO] visual_prompt:  441: Inference (val):avg data time: 5.03e-05, avg batch time: 0.1171, average loss: 0.9916
[09/23 17:02:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.50	top5: 95.00	
[09/23 17:03:06][INFO] visual_prompt:  441: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1236, average loss: 0.9982
[09/23 17:03:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.96	top5: 96.19	
[09/23 17:03:07][INFO] visual_prompt:  363: Best epoch 39: best metric: 0.765
[09/23 17:03:07][INFO] visual_prompt:  259: Training 40 / 200 epoch, with learning rate 0.5897571310761287
[09/23 17:04:23][INFO] visual_prompt:  327: Epoch 40 / 200: avg data time: 1.95e-02, avg batch time: 0.8934, average train loss: 1.1163average G loss: 0.0509, average realD loss: 0.5797, average fakeD loss: 85.7007, 
[09/23 17:04:25][INFO] visual_prompt:  441: Inference (val):avg data time: 5.19e-05, avg batch time: 0.1167, average loss: 1.1133
[09/23 17:04:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.50	top5: 95.17	
[09/23 17:04:39][INFO] visual_prompt:  441: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1237, average loss: 1.0881
[09/23 17:04:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.94	top5: 95.67	
[09/23 17:04:39][INFO] visual_prompt:  259: Training 41 / 200 epoch, with learning rate 0.5873355472520279
[09/23 17:05:55][INFO] visual_prompt:  327: Epoch 41 / 200: avg data time: 2.02e-02, avg batch time: 0.8939, average train loss: 1.0839average G loss: 0.0517, average realD loss: 0.5434, average fakeD loss: 85.6224, 
[09/23 17:05:57][INFO] visual_prompt:  441: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1169, average loss: 1.0424
[09/23 17:05:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.17	top5: 96.00	
[09/23 17:06:11][INFO] visual_prompt:  441: Inference (test):avg data time: 6.17e-05, avg batch time: 0.1236, average loss: 1.0446
[09/23 17:06:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.70	top5: 96.60	
[09/23 17:06:11][INFO] visual_prompt:  259: Training 42 / 200 epoch, with learning rate 0.5848388261335241
[09/23 17:07:27][INFO] visual_prompt:  327: Epoch 42 / 200: avg data time: 1.88e-02, avg batch time: 0.8927, average train loss: 1.1107average G loss: 0.0575, average realD loss: 0.6407, average fakeD loss: 83.6657, 
[09/23 17:07:30][INFO] visual_prompt:  441: Inference (val):avg data time: 6.37e-05, avg batch time: 0.1166, average loss: 1.0670
[09/23 17:07:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.00	top5: 96.83	
[09/23 17:07:43][INFO] visual_prompt:  441: Inference (test):avg data time: 7.41e-05, avg batch time: 0.1235, average loss: 1.0467
[09/23 17:07:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.75	top5: 96.76	
[09/23 17:07:43][INFO] visual_prompt:  259: Training 43 / 200 epoch, with learning rate 0.5822676502992419
[09/23 17:08:59][INFO] visual_prompt:  327: Epoch 43 / 200: avg data time: 1.91e-02, avg batch time: 0.8929, average train loss: 1.0866average G loss: 0.0523, average realD loss: 0.5914, average fakeD loss: 83.6727, 
[09/23 17:09:02][INFO] visual_prompt:  441: Inference (val):avg data time: 5.58e-05, avg batch time: 0.1168, average loss: 1.2893
[09/23 17:09:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.50	top5: 94.83	
[09/23 17:09:15][INFO] visual_prompt:  441: Inference (test):avg data time: 6.13e-05, avg batch time: 0.1239, average loss: 1.2488
[09/23 17:09:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 74.99	top5: 94.87	
[09/23 17:09:15][INFO] visual_prompt:  259: Training 44 / 200 epoch, with learning rate 0.579622722682981
[09/23 17:10:31][INFO] visual_prompt:  327: Epoch 44 / 200: avg data time: 1.76e-02, avg batch time: 0.8913, average train loss: 1.0618average G loss: 0.0504, average realD loss: 0.4143, average fakeD loss: 87.3784, 
[09/23 17:10:34][INFO] visual_prompt:  441: Inference (val):avg data time: 6.13e-05, avg batch time: 0.1168, average loss: 0.9617
[09/23 17:10:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 97.00	
[09/23 17:10:48][INFO] visual_prompt:  441: Inference (test):avg data time: 6.81e-05, avg batch time: 0.1236, average loss: 0.9552
[09/23 17:10:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.15	top5: 96.89	
[09/23 17:10:48][INFO] visual_prompt:  363: Best epoch 44: best metric: 0.780
[09/23 17:10:48][INFO] visual_prompt:  259: Training 45 / 200 epoch, with learning rate 0.5769047663815423
[09/23 17:12:04][INFO] visual_prompt:  327: Epoch 45 / 200: avg data time: 1.89e-02, avg batch time: 0.8926, average train loss: 1.0599average G loss: 0.0491, average realD loss: 0.5228, average fakeD loss: 85.6152, 
[09/23 17:12:06][INFO] visual_prompt:  441: Inference (val):avg data time: 6.55e-05, avg batch time: 0.1168, average loss: 1.0043
[09/23 17:12:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.33	top5: 96.50	
[09/23 17:12:20][INFO] visual_prompt:  441: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1238, average loss: 0.9977
[09/23 17:12:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.98	top5: 96.13	
[09/23 17:12:21][INFO] visual_prompt:  259: Training 46 / 200 epoch, with learning rate 0.5741145244570401
[09/23 17:13:37][INFO] visual_prompt:  327: Epoch 46 / 200: avg data time: 2.00e-02, avg batch time: 0.8935, average train loss: 1.1008average G loss: 0.0525, average realD loss: 0.4169, average fakeD loss: 87.9049, 
[09/23 17:13:39][INFO] visual_prompt:  441: Inference (val):avg data time: 5.37e-05, avg batch time: 0.1167, average loss: 0.9634
[09/23 17:13:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.17	top5: 96.50	
[09/23 17:13:53][INFO] visual_prompt:  441: Inference (test):avg data time: 8.59e-05, avg batch time: 0.1237, average loss: 0.9763
[09/23 17:13:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.55	top5: 96.32	
[09/23 17:13:53][INFO] visual_prompt:  259: Training 47 / 200 epoch, with learning rate 0.5712527597337562
[09/23 17:15:09][INFO] visual_prompt:  327: Epoch 47 / 200: avg data time: 1.95e-02, avg batch time: 0.8933, average train loss: 1.0150average G loss: 0.0470, average realD loss: 0.5386, average fakeD loss: 84.4187, 
[09/23 17:15:12][INFO] visual_prompt:  441: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1167, average loss: 1.0747
[09/23 17:15:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.50	top5: 95.50	
[09/23 17:15:25][INFO] visual_prompt:  441: Inference (test):avg data time: 8.56e-05, avg batch time: 0.1237, average loss: 1.0710
[09/23 17:15:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.42	top5: 95.69	
[09/23 17:15:25][INFO] visual_prompt:  259: Training 48 / 200 epoch, with learning rate 0.5683202545895915
[09/23 17:16:41][INFO] visual_prompt:  327: Epoch 48 / 200: avg data time: 1.91e-02, avg batch time: 0.8932, average train loss: 1.0134average G loss: 0.0330, average realD loss: 0.7050, average fakeD loss: 84.1505, 
[09/23 17:16:44][INFO] visual_prompt:  441: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1166, average loss: 0.9451
[09/23 17:16:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.67	top5: 96.67	
[09/23 17:16:59][INFO] visual_prompt:  441: Inference (test):avg data time: 9.22e-05, avg batch time: 0.1238, average loss: 0.9305
[09/23 17:16:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.89	top5: 97.07	
[09/23 17:16:59][INFO] visual_prompt:  259: Training 49 / 200 epoch, with learning rate 0.565317810742171
[09/23 17:18:15][INFO] visual_prompt:  327: Epoch 49 / 200: avg data time: 1.65e-02, avg batch time: 0.8904, average train loss: 1.0479average G loss: 0.0446, average realD loss: 0.6703, average fakeD loss: 83.5165, 
[09/23 17:18:17][INFO] visual_prompt:  441: Inference (val):avg data time: 5.46e-05, avg batch time: 0.1170, average loss: 1.0644
[09/23 17:18:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.33	top5: 96.83	
[09/23 17:18:31][INFO] visual_prompt:  441: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1240, average loss: 1.0506
[09/23 17:18:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.39	top5: 96.20	
[09/23 17:18:31][INFO] visual_prompt:  259: Training 50 / 200 epoch, with learning rate 0.562246249029664
[09/23 17:19:47][INFO] visual_prompt:  327: Epoch 50 / 200: avg data time: 1.98e-02, avg batch time: 0.8936, average train loss: 1.2452average G loss: 0.0761, average realD loss: 0.6324, average fakeD loss: 83.7885, 
[09/23 17:19:50][INFO] visual_prompt:  441: Inference (val):avg data time: 6.65e-05, avg batch time: 0.1170, average loss: 1.0044
[09/23 17:19:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 95.83	
[09/23 17:20:04][INFO] visual_prompt:  441: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1238, average loss: 0.9946
[09/23 17:20:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.54	top5: 96.48	
[09/23 17:20:04][INFO] visual_prompt:  259: Training 51 / 200 epoch, with learning rate 0.559106409186373
[09/23 17:21:20][INFO] visual_prompt:  327: Epoch 51 / 200: avg data time: 2.00e-02, avg batch time: 0.8935, average train loss: 1.0257average G loss: 0.0521, average realD loss: 0.3685, average fakeD loss: 88.5136, 
[09/23 17:21:23][INFO] visual_prompt:  441: Inference (val):avg data time: 7.60e-05, avg batch time: 0.1173, average loss: 0.9716
[09/23 17:21:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 95.83	
[09/23 17:21:36][INFO] visual_prompt:  441: Inference (test):avg data time: 7.98e-05, avg batch time: 0.1237, average loss: 0.9691
[09/23 17:21:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.98	top5: 96.41	
[09/23 17:21:37][INFO] visual_prompt:  363: Best epoch 51: best metric: 0.783
[09/23 17:21:37][INFO] visual_prompt:  259: Training 52 / 200 epoch, with learning rate 0.5558991496131602
[09/23 17:22:52][INFO] visual_prompt:  327: Epoch 52 / 200: avg data time: 1.85e-02, avg batch time: 0.8920, average train loss: 1.0371average G loss: 0.0423, average realD loss: 0.5323, average fakeD loss: 87.7280, 
[09/23 17:22:55][INFO] visual_prompt:  441: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1172, average loss: 1.0163
[09/23 17:22:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.50	top5: 97.17	
[09/23 17:23:08][INFO] visual_prompt:  441: Inference (test):avg data time: 8.63e-05, avg batch time: 0.1239, average loss: 0.9978
[09/23 17:23:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.06	top5: 96.50	
[09/23 17:23:09][INFO] visual_prompt:  259: Training 53 / 200 epoch, with learning rate 0.5526253471427685
[09/23 17:24:24][INFO] visual_prompt:  327: Epoch 53 / 200: avg data time: 1.82e-02, avg batch time: 0.8921, average train loss: 1.0305average G loss: 0.0379, average realD loss: 0.5794, average fakeD loss: 85.3001, 
[09/23 17:24:27][INFO] visual_prompt:  441: Inference (val):avg data time: 8.39e-05, avg batch time: 0.1171, average loss: 1.0005
[09/23 17:24:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.50	top5: 96.00	
[09/23 17:24:40][INFO] visual_prompt:  441: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1240, average loss: 1.0110
[09/23 17:24:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.23	top5: 95.79	
[09/23 17:24:40][INFO] visual_prompt:  259: Training 54 / 200 epoch, with learning rate 0.5492858968001046
[09/23 17:25:56][INFO] visual_prompt:  327: Epoch 54 / 200: avg data time: 1.87e-02, avg batch time: 0.8923, average train loss: 1.0982average G loss: 0.0592, average realD loss: 0.5982, average fakeD loss: 83.3588, 
[09/23 17:25:58][INFO] visual_prompt:  441: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1170, average loss: 1.1281
[09/23 17:25:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.33	top5: 95.67	
[09/23 17:26:12][INFO] visual_prompt:  441: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1237, average loss: 1.1162
[09/23 17:26:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.91	top5: 95.46	
[09/23 17:26:12][INFO] visual_prompt:  259: Training 55 / 200 epoch, with learning rate 0.545881711557548
[09/23 17:27:28][INFO] visual_prompt:  327: Epoch 55 / 200: avg data time: 1.82e-02, avg batch time: 0.8919, average train loss: 0.9752average G loss: 0.0408, average realD loss: 0.6594, average fakeD loss: 82.4150, 
[09/23 17:27:30][INFO] visual_prompt:  441: Inference (val):avg data time: 8.45e-05, avg batch time: 0.1170, average loss: 1.0196
[09/23 17:27:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.33	top5: 96.50	
[09/23 17:27:44][INFO] visual_prompt:  441: Inference (test):avg data time: 7.80e-05, avg batch time: 0.1237, average loss: 1.0046
[09/23 17:27:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.77	top5: 96.70	
[09/23 17:27:44][INFO] visual_prompt:  259: Training 56 / 200 epoch, with learning rate 0.5424137220853537
[09/23 17:29:00][INFO] visual_prompt:  327: Epoch 56 / 200: avg data time: 2.03e-02, avg batch time: 0.8935, average train loss: 1.0208average G loss: 0.0437, average realD loss: 0.7527, average fakeD loss: 81.7793, 
[09/23 17:29:02][INFO] visual_prompt:  441: Inference (val):avg data time: 6.09e-05, avg batch time: 0.1177, average loss: 0.9760
[09/23 17:29:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.67	top5: 97.00	
[09/23 17:29:16][INFO] visual_prompt:  441: Inference (test):avg data time: 6.69e-05, avg batch time: 0.1237, average loss: 0.9543
[09/23 17:29:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.89	top5: 97.03	
[09/23 17:29:16][INFO] visual_prompt:  259: Training 57 / 200 epoch, with learning rate 0.5388828764972153
[09/23 17:30:32][INFO] visual_prompt:  327: Epoch 57 / 200: avg data time: 1.86e-02, avg batch time: 0.8917, average train loss: 1.0635average G loss: 0.0609, average realD loss: 0.5369, average fakeD loss: 84.5775, 
[09/23 17:30:34][INFO] visual_prompt:  441: Inference (val):avg data time: 7.07e-05, avg batch time: 0.1173, average loss: 1.2333
[09/23 17:30:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.83	top5: 96.17	
[09/23 17:30:47][INFO] visual_prompt:  441: Inference (test):avg data time: 6.74e-05, avg batch time: 0.1238, average loss: 1.1946
[09/23 17:30:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.34	top5: 96.20	
[09/23 17:30:47][INFO] visual_prompt:  259: Training 58 / 200 epoch, with learning rate 0.5352901400910616
[09/23 17:32:03][INFO] visual_prompt:  327: Epoch 58 / 200: avg data time: 2.13e-02, avg batch time: 0.8941, average train loss: 0.9910average G loss: 0.0347, average realD loss: 0.4320, average fakeD loss: 88.7320, 
[09/23 17:32:06][INFO] visual_prompt:  441: Inference (val):avg data time: 5.82e-05, avg batch time: 0.1171, average loss: 0.9298
[09/23 17:32:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.83	top5: 97.00	
[09/23 17:32:19][INFO] visual_prompt:  441: Inference (test):avg data time: 8.38e-05, avg batch time: 0.1240, average loss: 0.8924
[09/23 17:32:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.41	top5: 97.05	
[09/23 17:32:19][INFO] visual_prompt:  259: Training 59 / 200 epoch, with learning rate 0.5316364950851526
[09/23 17:33:35][INFO] visual_prompt:  327: Epoch 59 / 200: avg data time: 1.73e-02, avg batch time: 0.8908, average train loss: 1.0622average G loss: 0.0584, average realD loss: 0.6889, average fakeD loss: 82.3080, 
[09/23 17:33:37][INFO] visual_prompt:  441: Inference (val):avg data time: 6.67e-05, avg batch time: 0.1169, average loss: 0.9886
[09/23 17:33:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.83	top5: 95.67	
[09/23 17:33:51][INFO] visual_prompt:  441: Inference (test):avg data time: 7.74e-05, avg batch time: 0.1238, average loss: 0.9743
[09/23 17:33:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.68	top5: 96.34	
[09/23 17:33:51][INFO] visual_prompt:  259: Training 60 / 200 epoch, with learning rate 0.5279229403495518
[09/23 17:35:07][INFO] visual_prompt:  327: Epoch 60 / 200: avg data time: 1.78e-02, avg batch time: 0.8908, average train loss: 1.1251average G loss: 0.0583, average realD loss: 0.4000, average fakeD loss: 87.8111, 
[09/23 17:35:09][INFO] visual_prompt:  441: Inference (val):avg data time: 6.60e-05, avg batch time: 0.1170, average loss: 1.0003
[09/23 17:35:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.00	top5: 96.83	
[09/23 17:35:23][INFO] visual_prompt:  441: Inference (test):avg data time: 8.20e-05, avg batch time: 0.1241, average loss: 0.9935
[09/23 17:35:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.96	top5: 96.77	
[09/23 17:35:23][INFO] visual_prompt:  259: Training 61 / 200 epoch, with learning rate 0.5241504911330441
[09/23 17:36:39][INFO] visual_prompt:  327: Epoch 61 / 200: avg data time: 1.95e-02, avg batch time: 0.8926, average train loss: 1.0666average G loss: 0.0533, average realD loss: 0.5118, average fakeD loss: 86.1219, 
[09/23 17:36:42][INFO] visual_prompt:  441: Inference (val):avg data time: 6.50e-05, avg batch time: 0.1167, average loss: 1.0044
[09/23 17:36:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 96.50	
[09/23 17:36:55][INFO] visual_prompt:  441: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1236, average loss: 1.0014
[09/23 17:36:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.75	top5: 96.82	
[09/23 17:36:55][INFO] visual_prompt:  363: Best epoch 61: best metric: 0.787
[09/23 17:36:55][INFO] visual_prompt:  259: Training 62 / 200 epoch, with learning rate 0.5203201787855776
[09/23 17:38:11][INFO] visual_prompt:  327: Epoch 62 / 200: avg data time: 1.86e-02, avg batch time: 0.8920, average train loss: 0.9921average G loss: 0.0394, average realD loss: 0.6203, average fakeD loss: 83.5849, 
[09/23 17:38:13][INFO] visual_prompt:  441: Inference (val):avg data time: 6.55e-05, avg batch time: 0.1170, average loss: 0.9516
[09/23 17:38:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 96.83	
[09/23 17:38:27][INFO] visual_prompt:  441: Inference (test):avg data time: 7.40e-05, avg batch time: 0.1236, average loss: 0.9177
[09/23 17:38:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.81	top5: 97.41	
[09/23 17:38:27][INFO] visual_prompt:  259: Training 63 / 200 epoch, with learning rate 0.5164330504763027
[09/23 17:39:43][INFO] visual_prompt:  327: Epoch 63 / 200: avg data time: 2.01e-02, avg batch time: 0.8935, average train loss: 1.0500average G loss: 0.0415, average realD loss: 0.4271, average fakeD loss: 88.1477, 
[09/23 17:39:46][INFO] visual_prompt:  441: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1169, average loss: 1.0326
[09/23 17:39:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.00	top5: 97.17	
[09/23 17:40:00][INFO] visual_prompt:  441: Inference (test):avg data time: 8.40e-05, avg batch time: 0.1238, average loss: 1.0137
[09/23 17:40:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.32	top5: 96.19	
[09/23 17:40:00][INFO] visual_prompt:  259: Training 64 / 200 epoch, with learning rate 0.5124901689072865
[09/23 17:41:16][INFO] visual_prompt:  327: Epoch 64 / 200: avg data time: 1.84e-02, avg batch time: 0.8921, average train loss: 0.9984average G loss: 0.0403, average realD loss: 0.7122, average fakeD loss: 84.5426, 
[09/23 17:41:19][INFO] visual_prompt:  441: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1170, average loss: 0.9958
[09/23 17:41:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.50	top5: 96.83	
[09/23 17:41:32][INFO] visual_prompt:  441: Inference (test):avg data time: 8.72e-05, avg batch time: 0.1237, average loss: 0.9842
[09/23 17:41:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.84	top5: 97.01	
[09/23 17:41:33][INFO] visual_prompt:  259: Training 65 / 200 epoch, with learning rate 0.5084926120229804
[09/23 17:42:49][INFO] visual_prompt:  327: Epoch 65 / 200: avg data time: 1.93e-02, avg batch time: 0.8931, average train loss: 1.0738average G loss: 0.0664, average realD loss: 0.6250, average fakeD loss: 82.9946, 
[09/23 17:42:51][INFO] visual_prompt:  441: Inference (val):avg data time: 5.77e-05, avg batch time: 0.1169, average loss: 1.0950
[09/23 17:42:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.50	top5: 96.17	
[09/23 17:43:05][INFO] visual_prompt:  441: Inference (test):avg data time: 7.84e-05, avg batch time: 0.1238, average loss: 1.0875
[09/23 17:43:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.73	top5: 96.31	
[09/23 17:43:05][INFO] visual_prompt:  259: Training 66 / 200 epoch, with learning rate 0.5044414727155212
[09/23 17:44:21][INFO] visual_prompt:  327: Epoch 66 / 200: avg data time: 2.03e-02, avg batch time: 0.8942, average train loss: 0.9942average G loss: 0.0419, average realD loss: 0.5671, average fakeD loss: 84.1224, 
[09/23 17:44:24][INFO] visual_prompt:  441: Inference (val):avg data time: 7.79e-05, avg batch time: 0.1170, average loss: 1.2573
[09/23 17:44:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.00	top5: 95.17	
[09/23 17:44:37][INFO] visual_prompt:  441: Inference (test):avg data time: 7.71e-05, avg batch time: 0.1239, average loss: 1.2536
[09/23 17:44:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.23	top5: 95.72	
[09/23 17:44:38][INFO] visual_prompt:  259: Training 67 / 200 epoch, with learning rate 0.5003378585259454
[09/23 17:45:53][INFO] visual_prompt:  327: Epoch 67 / 200: avg data time: 1.80e-02, avg batch time: 0.8919, average train loss: 1.0428average G loss: 0.0512, average realD loss: 0.6120, average fakeD loss: 84.2438, 
[09/23 17:45:56][INFO] visual_prompt:  441: Inference (val):avg data time: 8.81e-05, avg batch time: 0.1169, average loss: 0.9275
[09/23 17:45:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.83	
[09/23 17:46:09][INFO] visual_prompt:  441: Inference (test):avg data time: 7.43e-05, avg batch time: 0.1237, average loss: 0.9303
[09/23 17:46:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.77	top5: 97.39	
[09/23 17:46:10][INFO] visual_prompt:  363: Best epoch 67: best metric: 0.818
[09/23 17:46:10][INFO] visual_prompt:  259: Training 68 / 200 epoch, with learning rate 0.49618289134139787
[09/23 17:47:26][INFO] visual_prompt:  327: Epoch 68 / 200: avg data time: 2.05e-02, avg batch time: 0.8945, average train loss: 1.0311average G loss: 0.0563, average realD loss: 0.6553, average fakeD loss: 82.8581, 
[09/23 17:47:28][INFO] visual_prompt:  441: Inference (val):avg data time: 7.64e-05, avg batch time: 0.1167, average loss: 1.0043
[09/23 17:47:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 76.83	top5: 96.50	
[09/23 17:47:42][INFO] visual_prompt:  441: Inference (test):avg data time: 8.72e-05, avg batch time: 0.1239, average loss: 0.9837
[09/23 17:47:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.24	top5: 96.65	
[09/23 17:47:42][INFO] visual_prompt:  259: Training 69 / 200 epoch, with learning rate 0.49197770708841987
[09/23 17:48:58][INFO] visual_prompt:  327: Epoch 69 / 200: avg data time: 2.03e-02, avg batch time: 0.8939, average train loss: 0.9990average G loss: 0.0421, average realD loss: 0.5611, average fakeD loss: 85.0326, 
[09/23 17:49:01][INFO] visual_prompt:  441: Inference (val):avg data time: 8.50e-05, avg batch time: 0.1168, average loss: 1.7662
[09/23 17:49:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 69.00	top5: 92.50	
[09/23 17:49:15][INFO] visual_prompt:  441: Inference (test):avg data time: 7.36e-05, avg batch time: 0.1237, average loss: 1.8095
[09/23 17:49:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 67.24	top5: 91.11	
[09/23 17:49:15][INFO] visual_prompt:  259: Training 70 / 200 epoch, with learning rate 0.48772345542239776
[09/23 17:50:31][INFO] visual_prompt:  327: Epoch 70 / 200: avg data time: 1.87e-02, avg batch time: 0.8924, average train loss: 1.0808average G loss: 0.0659, average realD loss: 0.5486, average fakeD loss: 84.6496, 
[09/23 17:50:33][INFO] visual_prompt:  441: Inference (val):avg data time: 6.98e-05, avg batch time: 0.1171, average loss: 1.2033
[09/23 17:50:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.33	top5: 95.33	
[09/23 17:50:46][INFO] visual_prompt:  441: Inference (test):avg data time: 6.85e-05, avg batch time: 0.1240, average loss: 1.1815
[09/23 17:50:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.37	top5: 96.43	
[09/23 17:50:47][INFO] visual_prompt:  259: Training 71 / 200 epoch, with learning rate 0.4834212994132585
[09/23 17:52:03][INFO] visual_prompt:  327: Epoch 71 / 200: avg data time: 2.00e-02, avg batch time: 0.8934, average train loss: 1.0575average G loss: 0.0546, average realD loss: 0.6334, average fakeD loss: 82.6719, 
[09/23 17:52:05][INFO] visual_prompt:  441: Inference (val):avg data time: 6.57e-05, avg batch time: 0.1171, average loss: 1.1138
[09/23 17:52:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.67	top5: 96.50	
[09/23 17:52:18][INFO] visual_prompt:  441: Inference (test):avg data time: 9.36e-05, avg batch time: 0.1241, average loss: 1.1077
[09/23 17:52:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.16	top5: 96.74	
[09/23 17:52:18][INFO] visual_prompt:  259: Training 72 / 200 epoch, with learning rate 0.47907241522749805
[09/23 17:53:34][INFO] visual_prompt:  327: Epoch 72 / 200: avg data time: 2.09e-02, avg batch time: 0.8944, average train loss: 1.0357average G loss: 0.0571, average realD loss: 0.5127, average fakeD loss: 84.6327, 
[09/23 17:53:37][INFO] visual_prompt:  441: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1167, average loss: 0.9504
[09/23 17:53:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 97.00	
[09/23 17:53:51][INFO] visual_prompt:  441: Inference (test):avg data time: 7.52e-05, avg batch time: 0.1237, average loss: 0.9417
[09/23 17:53:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.44	top5: 96.88	
[09/23 17:53:51][INFO] visual_prompt:  259: Training 73 / 200 epoch, with learning rate 0.47467799180662973
[09/23 17:55:07][INFO] visual_prompt:  327: Epoch 73 / 200: avg data time: 1.80e-02, avg batch time: 0.8914, average train loss: 0.9759average G loss: 0.0503, average realD loss: 0.6975, average fakeD loss: 84.6475, 
[09/23 17:55:09][INFO] visual_prompt:  441: Inference (val):avg data time: 6.79e-05, avg batch time: 0.1175, average loss: 1.1574
[09/23 17:55:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 74.17	top5: 95.50	
[09/23 17:55:23][INFO] visual_prompt:  441: Inference (test):avg data time: 8.71e-05, avg batch time: 0.1238, average loss: 1.1321
[09/23 17:55:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.04	top5: 96.43	
[09/23 17:55:23][INFO] visual_prompt:  259: Training 74 / 200 epoch, with learning rate 0.47023923054213873
[09/23 17:56:39][INFO] visual_prompt:  327: Epoch 74 / 200: avg data time: 1.85e-02, avg batch time: 0.8922, average train loss: 1.0312average G loss: 0.0523, average realD loss: 0.7975, average fakeD loss: 80.7018, 
[09/23 17:56:41][INFO] visual_prompt:  441: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1168, average loss: 0.8999
[09/23 17:56:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 97.00	
[09/23 17:56:55][INFO] visual_prompt:  441: Inference (test):avg data time: 8.78e-05, avg batch time: 0.1239, average loss: 0.8972
[09/23 17:56:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.20	top5: 96.93	
[09/23 17:56:55][INFO] visual_prompt:  259: Training 75 / 200 epoch, with learning rate 0.4657573449470338
[09/23 17:58:11][INFO] visual_prompt:  327: Epoch 75 / 200: avg data time: 1.82e-02, avg batch time: 0.8915, average train loss: 0.9696average G loss: 0.0409, average realD loss: 0.4557, average fakeD loss: 86.1595, 
[09/23 17:58:13][INFO] visual_prompt:  441: Inference (val):avg data time: 7.04e-05, avg batch time: 0.1172, average loss: 1.1083
[09/23 17:58:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 96.67	
[09/23 17:58:27][INFO] visual_prompt:  441: Inference (test):avg data time: 9.31e-05, avg batch time: 0.1239, average loss: 1.1076
[09/23 17:58:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.08	top5: 96.39	
[09/23 17:58:27][INFO] visual_prompt:  259: Training 76 / 200 epoch, with learning rate 0.4612335603240855
[09/23 17:59:43][INFO] visual_prompt:  327: Epoch 76 / 200: avg data time: 1.97e-02, avg batch time: 0.8931, average train loss: 0.9679average G loss: 0.0383, average realD loss: 0.4172, average fakeD loss: 88.5298, 
[09/23 17:59:45][INFO] visual_prompt:  441: Inference (val):avg data time: 6.89e-05, avg batch time: 0.1173, average loss: 0.9783
[09/23 17:59:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 96.83	
[09/23 18:00:00][INFO] visual_prompt:  441: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1234, average loss: 0.9837
[09/23 18:00:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.77	top5: 96.72	
[09/23 18:00:00][INFO] visual_prompt:  259: Training 77 / 200 epoch, with learning rate 0.45666911343083993
[09/23 18:01:16][INFO] visual_prompt:  327: Epoch 77 / 200: avg data time: 2.00e-02, avg batch time: 0.8937, average train loss: 1.0907average G loss: 0.0638, average realD loss: 0.7114, average fakeD loss: 83.0734, 
[09/23 18:01:18][INFO] visual_prompt:  441: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1169, average loss: 0.9676
[09/23 18:01:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 96.83	
[09/23 18:01:32][INFO] visual_prompt:  441: Inference (test):avg data time: 1.05e-04, avg batch time: 0.1237, average loss: 0.9589
[09/23 18:01:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.10	top5: 96.84	
[09/23 18:01:32][INFO] visual_prompt:  259: Training 78 / 200 epoch, with learning rate 0.45206525214150206
[09/23 18:02:48][INFO] visual_prompt:  327: Epoch 78 / 200: avg data time: 1.85e-02, avg batch time: 0.8919, average train loss: 0.9726average G loss: 0.0422, average realD loss: 0.5736, average fakeD loss: 84.6424, 
[09/23 18:02:50][INFO] visual_prompt:  441: Inference (val):avg data time: 7.82e-05, avg batch time: 0.1166, average loss: 1.0747
[09/23 18:02:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 96.83	
[09/23 18:03:05][INFO] visual_prompt:  441: Inference (test):avg data time: 7.79e-05, avg batch time: 0.1236, average loss: 1.0639
[09/23 18:03:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.20	top5: 97.08	
[09/23 18:03:05][INFO] visual_prompt:  259: Training 79 / 200 epoch, with learning rate 0.44742323510577897
[09/23 18:04:21][INFO] visual_prompt:  327: Epoch 79 / 200: avg data time: 1.77e-02, avg batch time: 0.8913, average train loss: 1.0001average G loss: 0.0549, average realD loss: 0.7309, average fakeD loss: 80.2482, 
[09/23 18:04:23][INFO] visual_prompt:  441: Inference (val):avg data time: 5.51e-05, avg batch time: 0.1168, average loss: 0.9037
[09/23 18:04:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 97.33	
[09/23 18:04:37][INFO] visual_prompt:  441: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1237, average loss: 0.8961
[09/23 18:04:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.03	top5: 97.57	
[09/23 18:04:37][INFO] visual_prompt:  259: Training 80 / 200 epoch, with learning rate 0.44274433140477826
[09/23 18:05:54][INFO] visual_prompt:  327: Epoch 80 / 200: avg data time: 2.09e-02, avg batch time: 0.8940, average train loss: 0.9444average G loss: 0.0348, average realD loss: 0.4162, average fakeD loss: 89.0003, 
[09/23 18:05:56][INFO] visual_prompt:  441: Inference (val):avg data time: 1.04e-04, avg batch time: 0.1169, average loss: 0.9735
[09/23 18:05:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 97.50	
[09/23 18:06:10][INFO] visual_prompt:  441: Inference (test):avg data time: 7.04e-05, avg batch time: 0.1236, average loss: 0.9559
[09/23 18:06:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.91	top5: 97.00	
[09/23 18:06:10][INFO] visual_prompt:  259: Training 81 / 200 epoch, with learning rate 0.438029820204053
[09/23 18:07:27][INFO] visual_prompt:  327: Epoch 81 / 200: avg data time: 2.00e-02, avg batch time: 0.8936, average train loss: 0.9733average G loss: 0.0407, average realD loss: 0.6768, average fakeD loss: 82.1927, 
[09/23 18:07:29][INFO] visual_prompt:  441: Inference (val):avg data time: 5.69e-05, avg batch time: 0.1171, average loss: 1.1572
[09/23 18:07:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.33	top5: 96.50	
[09/23 18:07:42][INFO] visual_prompt:  441: Inference (test):avg data time: 8.94e-05, avg batch time: 0.1238, average loss: 1.1375
[09/23 18:07:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.05	top5: 96.41	
[09/23 18:07:42][INFO] visual_prompt:  259: Training 82 / 200 epoch, with learning rate 0.43328099040389134
[09/23 18:08:58][INFO] visual_prompt:  327: Epoch 82 / 200: avg data time: 2.07e-02, avg batch time: 0.8943, average train loss: 0.9731average G loss: 0.0422, average realD loss: 0.7388, average fakeD loss: 81.5584, 
[09/23 18:09:01][INFO] visual_prompt:  441: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1173, average loss: 1.0035
[09/23 18:09:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.83	top5: 97.17	
[09/23 18:09:14][INFO] visual_prompt:  441: Inference (test):avg data time: 6.79e-05, avg batch time: 0.1237, average loss: 0.9949
[09/23 18:09:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.80	top5: 97.08	
[09/23 18:09:14][INFO] visual_prompt:  259: Training 83 / 200 epoch, with learning rate 0.42849914028694397
[09/23 18:10:30][INFO] visual_prompt:  327: Epoch 83 / 200: avg data time: 1.89e-02, avg batch time: 0.8925, average train loss: 0.9486average G loss: 0.0351, average realD loss: 0.6710, average fakeD loss: 81.6681, 
[09/23 18:10:32][INFO] visual_prompt:  441: Inference (val):avg data time: 9.02e-05, avg batch time: 0.1172, average loss: 1.0457
[09/23 18:10:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.50	top5: 96.50	
[09/23 18:10:46][INFO] visual_prompt:  441: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1239, average loss: 1.0426
[09/23 18:10:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.58	top5: 96.69	
[09/23 18:10:46][INFO] visual_prompt:  259: Training 84 / 200 epoch, with learning rate 0.4236855771632864
[09/23 18:12:02][INFO] visual_prompt:  327: Epoch 84 / 200: avg data time: 1.72e-02, avg batch time: 0.8911, average train loss: 1.0115average G loss: 0.0450, average realD loss: 0.8125, average fakeD loss: 80.1959, 
[09/23 18:12:04][INFO] visual_prompt:  441: Inference (val):avg data time: 7.10e-05, avg batch time: 0.1170, average loss: 0.8279
[09/23 18:12:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 98.00	
[09/23 18:12:18][INFO] visual_prompt:  441: Inference (test):avg data time: 8.40e-05, avg batch time: 0.1238, average loss: 0.8358
[09/23 18:12:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.86	top5: 97.62	
[09/23 18:12:18][INFO] visual_prompt:  259: Training 85 / 200 epoch, with learning rate 0.4188416170130135
[09/23 18:13:34][INFO] visual_prompt:  327: Epoch 85 / 200: avg data time: 2.00e-02, avg batch time: 0.8935, average train loss: 0.9288average G loss: 0.0426, average realD loss: 0.6189, average fakeD loss: 83.3829, 
[09/23 18:13:36][INFO] visual_prompt:  441: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1172, average loss: 0.9185
[09/23 18:13:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 96.67	
[09/23 18:13:51][INFO] visual_prompt:  441: Inference (test):avg data time: 7.96e-05, avg batch time: 0.1236, average loss: 0.9000
[09/23 18:13:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.05	top5: 96.93	
[09/23 18:13:51][INFO] visual_prompt:  259: Training 86 / 200 epoch, with learning rate 0.41396858412646365
[09/23 18:15:07][INFO] visual_prompt:  327: Epoch 86 / 200: avg data time: 1.85e-02, avg batch time: 0.8924, average train loss: 0.9569average G loss: 0.0572, average realD loss: 0.7290, average fakeD loss: 80.0164, 
[09/23 18:15:09][INFO] visual_prompt:  441: Inference (val):avg data time: 5.85e-05, avg batch time: 0.1167, average loss: 1.0498
[09/23 18:15:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 98.00	
[09/23 18:15:22][INFO] visual_prompt:  441: Inference (test):avg data time: 8.11e-05, avg batch time: 0.1239, average loss: 1.0237
[09/23 18:15:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.45	top5: 97.10	
[09/23 18:15:22][INFO] visual_prompt:  259: Training 87 / 200 epoch, with learning rate 0.4090678107421711
[09/23 18:16:38][INFO] visual_prompt:  327: Epoch 87 / 200: avg data time: 1.92e-02, avg batch time: 0.8926, average train loss: 0.9210average G loss: 0.0360, average realD loss: 0.4458, average fakeD loss: 88.7514, 
[09/23 18:16:41][INFO] visual_prompt:  441: Inference (val):avg data time: 8.09e-05, avg batch time: 0.1166, average loss: 1.1107
[09/23 18:16:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 96.83	
[09/23 18:16:55][INFO] visual_prompt:  441: Inference (test):avg data time: 9.11e-05, avg batch time: 0.1237, average loss: 1.0924
[09/23 18:16:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.22	top5: 96.32	
[09/23 18:16:55][INFO] visual_prompt:  259: Training 88 / 200 epoch, with learning rate 0.40414063668264527
[09/23 18:18:11][INFO] visual_prompt:  327: Epoch 88 / 200: avg data time: 1.90e-02, avg batch time: 0.8929, average train loss: 1.0604average G loss: 0.0570, average realD loss: 0.7684, average fakeD loss: 81.6407, 
[09/23 18:18:13][INFO] visual_prompt:  441: Inference (val):avg data time: 5.67e-05, avg batch time: 0.1170, average loss: 0.8194
[09/23 18:18:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 97.33	
[09/23 18:18:28][INFO] visual_prompt:  441: Inference (test):avg data time: 8.24e-05, avg batch time: 0.1237, average loss: 0.8239
[09/23 18:18:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.96	top5: 97.46	
[09/23 18:18:28][INFO] visual_prompt:  259: Training 89 / 200 epoch, with learning rate 0.39918840898807645
[09/23 18:19:44][INFO] visual_prompt:  327: Epoch 89 / 200: avg data time: 2.14e-02, avg batch time: 0.8955, average train loss: 0.9108average G loss: 0.0303, average realD loss: 0.8196, average fakeD loss: 78.0079, 
[09/23 18:19:46][INFO] visual_prompt:  441: Inference (val):avg data time: 1.07e-04, avg batch time: 0.1169, average loss: 1.0259
[09/23 18:19:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.67	top5: 96.83	
[09/23 18:20:01][INFO] visual_prompt:  441: Inference (test):avg data time: 1.00e-04, avg batch time: 0.1239, average loss: 1.0168
[09/23 18:20:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.94	top5: 97.13	
[09/23 18:20:01][INFO] visual_prompt:  259: Training 90 / 200 epoch, with learning rate 0.39421248154806865
[09/23 18:21:17][INFO] visual_prompt:  327: Epoch 90 / 200: avg data time: 1.90e-02, avg batch time: 0.8927, average train loss: 0.9589average G loss: 0.0439, average realD loss: 0.6235, average fakeD loss: 82.2626, 
[09/23 18:21:19][INFO] visual_prompt:  441: Inference (val):avg data time: 7.48e-05, avg batch time: 0.1166, average loss: 1.0089
[09/23 18:21:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 96.17	
[09/23 18:21:33][INFO] visual_prompt:  441: Inference (test):avg data time: 9.85e-05, avg batch time: 0.1237, average loss: 0.9978
[09/23 18:21:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.62	top5: 96.88	
[09/23 18:21:33][INFO] visual_prompt:  259: Training 91 / 200 epoch, with learning rate 0.38921421473149975
[09/23 18:22:49][INFO] visual_prompt:  327: Epoch 91 / 200: avg data time: 1.70e-02, avg batch time: 0.8905, average train loss: 0.9905average G loss: 0.0585, average realD loss: 0.6927, average fakeD loss: 84.4979, 
[09/23 18:22:51][INFO] visual_prompt:  441: Inference (val):avg data time: 7.89e-05, avg batch time: 0.1171, average loss: 1.2184
[09/23 18:22:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.00	top5: 96.17	
[09/23 18:23:06][INFO] visual_prompt:  441: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1237, average loss: 1.2166
[09/23 18:23:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.05	top5: 96.27	
[09/23 18:23:06][INFO] visual_prompt:  259: Training 92 / 200 epoch, with learning rate 0.38419497501460986
[09/23 18:24:22][INFO] visual_prompt:  327: Epoch 92 / 200: avg data time: 1.95e-02, avg batch time: 0.8930, average train loss: 0.9730average G loss: 0.0478, average realD loss: 0.8477, average fakeD loss: 79.6185, 
[09/23 18:24:24][INFO] visual_prompt:  441: Inference (val):avg data time: 8.11e-05, avg batch time: 0.1168, average loss: 0.9275
[09/23 18:24:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.50	top5: 96.33	
[09/23 18:24:39][INFO] visual_prompt:  441: Inference (test):avg data time: 8.33e-05, avg batch time: 0.1240, average loss: 0.9214
[09/23 18:24:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.55	top5: 96.82	
[09/23 18:24:39][INFO] visual_prompt:  259: Training 93 / 200 epoch, with learning rate 0.3791561346074209
[09/23 18:25:55][INFO] visual_prompt:  327: Epoch 93 / 200: avg data time: 2.00e-02, avg batch time: 0.8936, average train loss: 1.0211average G loss: 0.0622, average realD loss: 0.5535, average fakeD loss: 83.8680, 
[09/23 18:25:57][INFO] visual_prompt:  441: Inference (val):avg data time: 6.22e-05, avg batch time: 0.1175, average loss: 1.1006
[09/23 18:25:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.00	top5: 96.67	
[09/23 18:26:11][INFO] visual_prompt:  441: Inference (test):avg data time: 9.04e-05, avg batch time: 0.1240, average loss: 1.0910
[09/23 18:26:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.94	top5: 97.10	
[09/23 18:26:11][INFO] visual_prompt:  259: Training 94 / 200 epoch, with learning rate 0.37409907107858753
[09/23 18:27:27][INFO] visual_prompt:  327: Epoch 94 / 200: avg data time: 1.78e-02, avg batch time: 0.8912, average train loss: 0.9222average G loss: 0.0396, average realD loss: 0.6478, average fakeD loss: 84.6397, 
[09/23 18:27:29][INFO] visual_prompt:  441: Inference (val):avg data time: 1.03e-04, avg batch time: 0.1169, average loss: 1.3628
[09/23 18:27:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.50	top5: 96.00	
[09/23 18:27:43][INFO] visual_prompt:  441: Inference (test):avg data time: 8.70e-05, avg batch time: 0.1236, average loss: 1.3204
[09/23 18:27:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.79	top5: 96.70	
[09/23 18:27:43][INFO] visual_prompt:  259: Training 95 / 200 epoch, with learning rate 0.3690251669787844
[09/23 18:28:59][INFO] visual_prompt:  327: Epoch 95 / 200: avg data time: 1.97e-02, avg batch time: 0.8936, average train loss: 1.0012average G loss: 0.0545, average realD loss: 0.8995, average fakeD loss: 77.9381, 
[09/23 18:29:01][INFO] visual_prompt:  441: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1166, average loss: 0.9517
[09/23 18:29:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 96.67	
[09/23 18:29:16][INFO] visual_prompt:  441: Inference (test):avg data time: 7.69e-05, avg batch time: 0.1237, average loss: 0.9526
[09/23 18:29:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.58	top5: 97.36	
[09/23 18:29:16][INFO] visual_prompt:  259: Training 96 / 200 epoch, with learning rate 0.36393580946272935
[09/23 18:30:32][INFO] visual_prompt:  327: Epoch 96 / 200: avg data time: 2.08e-02, avg batch time: 0.8939, average train loss: 0.9451average G loss: 0.0367, average realD loss: 0.3661, average fakeD loss: 89.0964, 
[09/23 18:30:34][INFO] visual_prompt:  441: Inference (val):avg data time: 6.14e-05, avg batch time: 0.1170, average loss: 0.9442
[09/23 18:30:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 97.67	
[09/23 18:30:49][INFO] visual_prompt:  441: Inference (test):avg data time: 1.03e-04, avg batch time: 0.1237, average loss: 0.9285
[09/23 18:30:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.24	top5: 97.51	
[09/23 18:30:49][INFO] visual_prompt:  259: Training 97 / 200 epoch, with learning rate 0.3588323899099506
[09/23 18:32:05][INFO] visual_prompt:  327: Epoch 97 / 200: avg data time: 1.84e-02, avg batch time: 0.8924, average train loss: 1.0018average G loss: 0.0519, average realD loss: 0.7730, average fakeD loss: 80.7804, 
[09/23 18:32:07][INFO] visual_prompt:  441: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1176, average loss: 1.0320
[09/23 18:32:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.17	top5: 97.17	
[09/23 18:32:21][INFO] visual_prompt:  441: Inference (test):avg data time: 7.90e-05, avg batch time: 0.1236, average loss: 1.0074
[09/23 18:32:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.89	top5: 97.22	
[09/23 18:32:22][INFO] visual_prompt:  259: Training 98 / 200 epoch, with learning rate 0.3537163035443966
[09/23 18:33:38][INFO] visual_prompt:  327: Epoch 98 / 200: avg data time: 2.04e-02, avg batch time: 0.8942, average train loss: 0.9624average G loss: 0.0504, average realD loss: 0.9484, average fakeD loss: 77.6999, 
[09/23 18:33:40][INFO] visual_prompt:  441: Inference (val):avg data time: 6.23e-05, avg batch time: 0.1173, average loss: 1.0471
[09/23 18:33:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 97.50	
[09/23 18:33:54][INFO] visual_prompt:  441: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1236, average loss: 1.0070
[09/23 18:33:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.77	top5: 97.53	
[09/23 18:33:54][INFO] visual_prompt:  259: Training 99 / 200 epoch, with learning rate 0.34858894905299576
[09/23 18:35:10][INFO] visual_prompt:  327: Epoch 99 / 200: avg data time: 1.85e-02, avg batch time: 0.8915, average train loss: 0.8486average G loss: 0.0231, average realD loss: 0.3626, average fakeD loss: 88.7886, 
[09/23 18:35:12][INFO] visual_prompt:  441: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1169, average loss: 0.8189
[09/23 18:35:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.00	
[09/23 18:35:26][INFO] visual_prompt:  441: Inference (test):avg data time: 6.29e-05, avg batch time: 0.1237, average loss: 0.8179
[09/23 18:35:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.88	top5: 97.70	
[09/23 18:35:26][INFO] visual_prompt:  363: Best epoch 99: best metric: 0.827
[09/23 18:35:26][INFO] visual_prompt:  259: Training 100 / 200 epoch, with learning rate 0.34345172820326964
[09/23 18:36:42][INFO] visual_prompt:  327: Epoch 100 / 200: avg data time: 1.99e-02, avg batch time: 0.8936, average train loss: 0.8834average G loss: 0.0360, average realD loss: 1.1487, average fakeD loss: 74.7195, 
[09/23 18:36:44][INFO] visual_prompt:  441: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1171, average loss: 0.8430
[09/23 18:36:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.17	
[09/23 18:36:58][INFO] visual_prompt:  441: Inference (test):avg data time: 7.02e-05, avg batch time: 0.1236, average loss: 0.8195
[09/23 18:36:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.96	top5: 97.76	
[09/23 18:36:58][INFO] visual_prompt:  259: Training 101 / 200 epoch, with learning rate 0.3383060454601039
[09/23 18:38:14][INFO] visual_prompt:  327: Epoch 101 / 200: avg data time: 1.84e-02, avg batch time: 0.8923, average train loss: 0.9475average G loss: 0.0542, average realD loss: 1.0405, average fakeD loss: 76.5225, 
[09/23 18:38:17][INFO] visual_prompt:  441: Inference (val):avg data time: 6.93e-05, avg batch time: 0.1168, average loss: 1.0645
[09/23 18:38:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.17	top5: 96.33	
[09/23 18:38:31][INFO] visual_prompt:  441: Inference (test):avg data time: 7.40e-05, avg batch time: 0.1237, average loss: 1.0684
[09/23 18:38:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.53	top5: 96.57	
[09/23 18:38:31][INFO] visual_prompt:  259: Training 102 / 200 epoch, with learning rate 0.3331533076017811
[09/23 18:39:47][INFO] visual_prompt:  327: Epoch 102 / 200: avg data time: 1.80e-02, avg batch time: 0.8915, average train loss: 0.8954average G loss: 0.0293, average realD loss: 0.6059, average fakeD loss: 83.8007, 
[09/23 18:39:49][INFO] visual_prompt:  441: Inference (val):avg data time: 5.82e-05, avg batch time: 0.1170, average loss: 1.3304
[09/23 18:39:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.17	top5: 95.67	
[09/23 18:40:02][INFO] visual_prompt:  441: Inference (test):avg data time: 7.65e-05, avg batch time: 0.1238, average loss: 1.3189
[09/23 18:40:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 77.13	top5: 95.70	
[09/23 18:40:03][INFO] visual_prompt:  259: Training 103 / 200 epoch, with learning rate 0.32799492333538194
[09/23 18:41:19][INFO] visual_prompt:  327: Epoch 103 / 200: avg data time: 1.89e-02, avg batch time: 0.8922, average train loss: 0.9970average G loss: 0.0451, average realD loss: 1.0342, average fakeD loss: 77.8596, 
[09/23 18:41:21][INFO] visual_prompt:  441: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1165, average loss: 0.8229
[09/23 18:41:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 98.83	
[09/23 18:41:35][INFO] visual_prompt:  441: Inference (test):avg data time: 8.96e-05, avg batch time: 0.1237, average loss: 0.8304
[09/23 18:41:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.97	top5: 97.96	
[09/23 18:41:35][INFO] visual_prompt:  259: Training 104 / 200 epoch, with learning rate 0.32283230291165876
[09/23 18:42:51][INFO] visual_prompt:  327: Epoch 104 / 200: avg data time: 2.01e-02, avg batch time: 0.8933, average train loss: 0.8608average G loss: 0.0321, average realD loss: 0.5699, average fakeD loss: 82.9860, 
[09/23 18:42:54][INFO] visual_prompt:  441: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1168, average loss: 0.9037
[09/23 18:42:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 98.00	
[09/23 18:43:07][INFO] visual_prompt:  441: Inference (test):avg data time: 9.02e-05, avg batch time: 0.1239, average loss: 0.9149
[09/23 18:43:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.60	top5: 97.55	
[09/23 18:43:07][INFO] visual_prompt:  363: Best epoch 104: best metric: 0.828
[09/23 18:43:07][INFO] visual_prompt:  259: Training 105 / 200 epoch, with learning rate 0.31766685773948705
[09/23 18:44:23][INFO] visual_prompt:  327: Epoch 105 / 200: avg data time: 1.80e-02, avg batch time: 0.8915, average train loss: 1.2874average G loss: 0.1058, average realD loss: 0.8831, average fakeD loss: 80.1253, 
[09/23 18:44:26][INFO] visual_prompt:  441: Inference (val):avg data time: 5.53e-05, avg batch time: 0.1168, average loss: 0.8575
[09/23 18:44:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.67	
[09/23 18:44:39][INFO] visual_prompt:  441: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1238, average loss: 0.8490
[09/23 18:44:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.33	top5: 97.51	
[09/23 18:44:39][INFO] visual_prompt:  259: Training 106 / 200 epoch, with learning rate 0.3125
[09/23 18:45:55][INFO] visual_prompt:  327: Epoch 106 / 200: avg data time: 2.03e-02, avg batch time: 0.8936, average train loss: 0.9294average G loss: 0.0410, average realD loss: 0.6294, average fakeD loss: 83.9490, 
[09/23 18:45:58][INFO] visual_prompt:  441: Inference (val):avg data time: 5.56e-05, avg batch time: 0.1168, average loss: 0.9097
[09/23 18:45:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 98.33	
[09/23 18:46:11][INFO] visual_prompt:  441: Inference (test):avg data time: 8.83e-05, avg batch time: 0.1238, average loss: 0.9052
[09/23 18:46:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.34	top5: 97.79	
[09/23 18:46:11][INFO] visual_prompt:  259: Training 107 / 200 epoch, with learning rate 0.30733314226051295
[09/23 18:47:27][INFO] visual_prompt:  327: Epoch 107 / 200: avg data time: 1.85e-02, avg batch time: 0.8923, average train loss: 0.9303average G loss: 0.0474, average realD loss: 0.8488, average fakeD loss: 79.0137, 
[09/23 18:47:29][INFO] visual_prompt:  441: Inference (val):avg data time: 6.73e-05, avg batch time: 0.1168, average loss: 0.9725
[09/23 18:47:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 97.50	
[09/23 18:47:44][INFO] visual_prompt:  441: Inference (test):avg data time: 7.72e-05, avg batch time: 0.1236, average loss: 0.9620
[09/23 18:47:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.53	top5: 97.19	
[09/23 18:47:44][INFO] visual_prompt:  259: Training 108 / 200 epoch, with learning rate 0.3021676970883412
[09/23 18:49:00][INFO] visual_prompt:  327: Epoch 108 / 200: avg data time: 1.85e-02, avg batch time: 0.8925, average train loss: 0.9059average G loss: 0.0339, average realD loss: 1.0755, average fakeD loss: 74.6155, 
[09/23 18:49:02][INFO] visual_prompt:  441: Inference (val):avg data time: 6.08e-05, avg batch time: 0.1171, average loss: 0.9378
[09/23 18:49:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 97.50	
[09/23 18:49:16][INFO] visual_prompt:  441: Inference (test):avg data time: 8.93e-05, avg batch time: 0.1238, average loss: 0.9248
[09/23 18:49:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.00	top5: 97.72	
[09/23 18:49:16][INFO] visual_prompt:  259: Training 109 / 200 epoch, with learning rate 0.297005076664618
[09/23 18:50:32][INFO] visual_prompt:  327: Epoch 109 / 200: avg data time: 1.95e-02, avg batch time: 0.8927, average train loss: 0.8875average G loss: 0.0312, average realD loss: 0.5565, average fakeD loss: 84.5641, 
[09/23 18:50:34][INFO] visual_prompt:  441: Inference (val):avg data time: 9.43e-05, avg batch time: 0.1169, average loss: 0.8649
[09/23 18:50:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.83	
[09/23 18:50:47][INFO] visual_prompt:  441: Inference (test):avg data time: 7.95e-05, avg batch time: 0.1238, average loss: 0.8529
[09/23 18:50:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.88	top5: 98.00	
[09/23 18:50:47][INFO] visual_prompt:  259: Training 110 / 200 epoch, with learning rate 0.2918466923982189
[09/23 18:52:03][INFO] visual_prompt:  327: Epoch 110 / 200: avg data time: 2.01e-02, avg batch time: 0.8938, average train loss: 0.9097average G loss: 0.0495, average realD loss: 1.0487, average fakeD loss: 77.9485, 
[09/23 18:52:06][INFO] visual_prompt:  441: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1168, average loss: 0.9432
[09/23 18:52:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.50	
[09/23 18:52:20][INFO] visual_prompt:  441: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1237, average loss: 0.9492
[09/23 18:52:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.34	top5: 97.39	
[09/23 18:52:20][INFO] visual_prompt:  259: Training 111 / 200 epoch, with learning rate 0.28669395453989616
[09/23 18:53:36][INFO] visual_prompt:  327: Epoch 111 / 200: avg data time: 1.76e-02, avg batch time: 0.8916, average train loss: 0.9583average G loss: 0.0489, average realD loss: 1.3211, average fakeD loss: 71.7746, 
[09/23 18:53:38][INFO] visual_prompt:  441: Inference (val):avg data time: 6.85e-05, avg batch time: 0.1170, average loss: 1.0234
[09/23 18:53:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.17	top5: 97.50	
[09/23 18:53:52][INFO] visual_prompt:  441: Inference (test):avg data time: 8.11e-05, avg batch time: 0.1241, average loss: 1.0207
[09/23 18:53:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.41	top5: 97.26	
[09/23 18:53:52][INFO] visual_prompt:  259: Training 112 / 200 epoch, with learning rate 0.2815482717967304
[09/23 18:55:08][INFO] visual_prompt:  327: Epoch 112 / 200: avg data time: 1.89e-02, avg batch time: 0.8919, average train loss: 0.8512average G loss: 0.0266, average realD loss: 0.4349, average fakeD loss: 89.0233, 
[09/23 18:55:10][INFO] visual_prompt:  441: Inference (val):avg data time: 8.56e-05, avg batch time: 0.1168, average loss: 0.7595
[09/23 18:55:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.83	
[09/23 18:55:24][INFO] visual_prompt:  441: Inference (test):avg data time: 7.58e-05, avg batch time: 0.1236, average loss: 0.7744
[09/23 18:55:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.34	top5: 97.93	
[09/23 18:55:24][INFO] visual_prompt:  363: Best epoch 112: best metric: 0.847
[09/23 18:55:24][INFO] visual_prompt:  259: Training 113 / 200 epoch, with learning rate 0.27641105094700436
[09/23 18:56:40][INFO] visual_prompt:  327: Epoch 113 / 200: avg data time: 2.06e-02, avg batch time: 0.8946, average train loss: 0.8909average G loss: 0.0446, average realD loss: 1.0660, average fakeD loss: 72.2928, 
[09/23 18:56:43][INFO] visual_prompt:  441: Inference (val):avg data time: 8.16e-05, avg batch time: 0.1168, average loss: 1.1510
[09/23 18:56:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.83	top5: 96.67	
[09/23 18:56:57][INFO] visual_prompt:  441: Inference (test):avg data time: 9.02e-05, avg batch time: 0.1240, average loss: 1.1513
[09/23 18:56:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.70	top5: 96.46	
[09/23 18:56:57][INFO] visual_prompt:  259: Training 114 / 200 epoch, with learning rate 0.27128369645560346
[09/23 18:58:13][INFO] visual_prompt:  327: Epoch 114 / 200: avg data time: 1.92e-02, avg batch time: 0.8927, average train loss: 0.8972average G loss: 0.0346, average realD loss: 0.9806, average fakeD loss: 78.7800, 
[09/23 18:58:15][INFO] visual_prompt:  441: Inference (val):avg data time: 8.50e-05, avg batch time: 0.1168, average loss: 0.9654
[09/23 18:58:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 97.00	
[09/23 18:58:30][INFO] visual_prompt:  441: Inference (test):avg data time: 9.10e-05, avg batch time: 0.1239, average loss: 0.9581
[09/23 18:58:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.48	top5: 97.43	
[09/23 18:58:30][INFO] visual_prompt:  259: Training 115 / 200 epoch, with learning rate 0.26616761009004936
[09/23 18:59:46][INFO] visual_prompt:  327: Epoch 115 / 200: avg data time: 2.03e-02, avg batch time: 0.8945, average train loss: 0.9085average G loss: 0.0429, average realD loss: 1.3048, average fakeD loss: 70.4171, 
[09/23 18:59:48][INFO] visual_prompt:  441: Inference (val):avg data time: 6.52e-05, avg batch time: 0.1174, average loss: 0.8345
[09/23 18:59:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.50	
[09/23 19:00:02][INFO] visual_prompt:  441: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1238, average loss: 0.8392
[09/23 19:00:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.52	top5: 97.77	
[09/23 19:00:02][INFO] visual_prompt:  259: Training 116 / 200 epoch, with learning rate 0.2610641905372706
[09/23 19:01:18][INFO] visual_prompt:  327: Epoch 116 / 200: avg data time: 1.91e-02, avg batch time: 0.8926, average train loss: 0.8149average G loss: 0.0298, average realD loss: 0.7912, average fakeD loss: 77.8975, 
[09/23 19:01:20][INFO] visual_prompt:  441: Inference (val):avg data time: 8.03e-05, avg batch time: 0.1168, average loss: 1.0182
[09/23 19:01:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.83	
[09/23 19:01:33][INFO] visual_prompt:  441: Inference (test):avg data time: 7.02e-05, avg batch time: 0.1238, average loss: 1.0085
[09/23 19:01:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.08	top5: 97.67	
[09/23 19:01:34][INFO] visual_prompt:  259: Training 117 / 200 epoch, with learning rate 0.25597483302121576
[09/23 19:02:49][INFO] visual_prompt:  327: Epoch 117 / 200: avg data time: 1.71e-02, avg batch time: 0.8907, average train loss: 0.8947average G loss: 0.0396, average realD loss: 1.5258, average fakeD loss: 75.9987, 
[09/23 19:02:52][INFO] visual_prompt:  441: Inference (val):avg data time: 9.14e-05, avg batch time: 0.1172, average loss: 0.7767
[09/23 19:02:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.67	
[09/23 19:03:05][INFO] visual_prompt:  441: Inference (test):avg data time: 6.48e-05, avg batch time: 0.1236, average loss: 0.7789
[09/23 19:03:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.02	top5: 97.98	
[09/23 19:03:06][INFO] visual_prompt:  259: Training 118 / 200 epoch, with learning rate 0.25090092892141247
[09/23 19:04:22][INFO] visual_prompt:  327: Epoch 118 / 200: avg data time: 2.06e-02, avg batch time: 0.8948, average train loss: 0.8958average G loss: 0.0383, average realD loss: 1.6458, average fakeD loss: 71.0614, 
[09/23 19:04:24][INFO] visual_prompt:  441: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1167, average loss: 1.5328
[09/23 19:04:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.33	top5: 96.33	
[09/23 19:04:38][INFO] visual_prompt:  441: Inference (test):avg data time: 9.21e-05, avg batch time: 0.1240, average loss: 1.5269
[09/23 19:04:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.37	top5: 95.46	
[09/23 19:04:38][INFO] visual_prompt:  259: Training 119 / 200 epoch, with learning rate 0.24584386539257916
[09/23 19:05:54][INFO] visual_prompt:  327: Epoch 119 / 200: avg data time: 1.95e-02, avg batch time: 0.8927, average train loss: 0.8666average G loss: 0.0298, average realD loss: 0.5587, average fakeD loss: 85.5949, 
[09/23 19:05:56][INFO] visual_prompt:  441: Inference (val):avg data time: 6.05e-05, avg batch time: 0.1170, average loss: 0.7989
[09/23 19:05:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.50	
[09/23 19:06:10][INFO] visual_prompt:  441: Inference (test):avg data time: 7.87e-05, avg batch time: 0.1238, average loss: 0.7743
[09/23 19:06:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.52	top5: 98.02	
[09/23 19:06:10][INFO] visual_prompt:  259: Training 120 / 200 epoch, with learning rate 0.24080502498539016
[09/23 19:07:26][INFO] visual_prompt:  327: Epoch 120 / 200: avg data time: 1.77e-02, avg batch time: 0.8921, average train loss: 0.9459average G loss: 0.0453, average realD loss: 1.3136, average fakeD loss: 70.8776, 
[09/23 19:07:28][INFO] visual_prompt:  441: Inference (val):avg data time: 7.57e-05, avg batch time: 0.1174, average loss: 0.9671
[09/23 19:07:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.67	
[09/23 19:07:42][INFO] visual_prompt:  441: Inference (test):avg data time: 8.24e-05, avg batch time: 0.1238, average loss: 0.9481
[09/23 19:07:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.39	top5: 97.34	
[09/23 19:07:42][INFO] visual_prompt:  259: Training 121 / 200 epoch, with learning rate 0.23578578526850028
[09/23 19:08:58][INFO] visual_prompt:  327: Epoch 121 / 200: avg data time: 1.91e-02, avg batch time: 0.8931, average train loss: 0.9040average G loss: 0.0459, average realD loss: 1.6349, average fakeD loss: 68.3553, 
[09/23 19:09:00][INFO] visual_prompt:  441: Inference (val):avg data time: 6.04e-05, avg batch time: 0.1172, average loss: 1.0009
[09/23 19:09:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 98.33	
[09/23 19:09:14][INFO] visual_prompt:  441: Inference (test):avg data time: 7.83e-05, avg batch time: 0.1238, average loss: 0.9944
[09/23 19:09:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.29	top5: 97.62	
[09/23 19:09:14][INFO] visual_prompt:  259: Training 122 / 200 epoch, with learning rate 0.23078751845193132
[09/23 19:10:30][INFO] visual_prompt:  327: Epoch 122 / 200: avg data time: 2.02e-02, avg batch time: 0.8935, average train loss: 0.8275average G loss: 0.0277, average realD loss: 0.7941, average fakeD loss: 82.2010, 
[09/23 19:10:32][INFO] visual_prompt:  441: Inference (val):avg data time: 7.27e-05, avg batch time: 0.1167, average loss: 0.7384
[09/23 19:10:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.33	
[09/23 19:10:46][INFO] visual_prompt:  441: Inference (test):avg data time: 7.67e-05, avg batch time: 0.1237, average loss: 0.7399
[09/23 19:10:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.78	top5: 97.74	
[09/23 19:10:46][INFO] visual_prompt:  363: Best epoch 122: best metric: 0.867
[09/23 19:10:46][INFO] visual_prompt:  259: Training 123 / 200 epoch, with learning rate 0.22581159101192363
[09/23 19:12:02][INFO] visual_prompt:  327: Epoch 123 / 200: avg data time: 1.80e-02, avg batch time: 0.8921, average train loss: 0.8554average G loss: 0.0443, average realD loss: 1.2855, average fakeD loss: 70.8885, 
[09/23 19:12:04][INFO] visual_prompt:  441: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1177, average loss: 0.9862
[09/23 19:12:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.67	
[09/23 19:12:18][INFO] visual_prompt:  441: Inference (test):avg data time: 9.73e-05, avg batch time: 0.1239, average loss: 0.9744
[09/23 19:12:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.81	top5: 97.74	
[09/23 19:12:18][INFO] visual_prompt:  259: Training 124 / 200 epoch, with learning rate 0.22085936331735478
[09/23 19:13:34][INFO] visual_prompt:  327: Epoch 124 / 200: avg data time: 1.87e-02, avg batch time: 0.8924, average train loss: 0.8604average G loss: 0.0337, average realD loss: 1.3909, average fakeD loss: 70.3878, 
[09/23 19:13:36][INFO] visual_prompt:  441: Inference (val):avg data time: 4.84e-05, avg batch time: 0.1173, average loss: 0.7859
[09/23 19:13:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.00	
[09/23 19:13:50][INFO] visual_prompt:  441: Inference (test):avg data time: 8.30e-05, avg batch time: 0.1236, average loss: 0.7871
[09/23 19:13:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.88	top5: 97.98	
[09/23 19:13:50][INFO] visual_prompt:  259: Training 125 / 200 epoch, with learning rate 0.21593218925782895
[09/23 19:15:06][INFO] visual_prompt:  327: Epoch 125 / 200: avg data time: 1.83e-02, avg batch time: 0.8927, average train loss: 0.8434average G loss: 0.0353, average realD loss: 1.6721, average fakeD loss: 66.1006, 
[09/23 19:15:08][INFO] visual_prompt:  441: Inference (val):avg data time: 5.95e-05, avg batch time: 0.1171, average loss: 0.7598
[09/23 19:15:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.00	
[09/23 19:15:22][INFO] visual_prompt:  441: Inference (test):avg data time: 7.52e-05, avg batch time: 0.1236, average loss: 0.7586
[09/23 19:15:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.90	top5: 98.12	
[09/23 19:15:22][INFO] visual_prompt:  259: Training 126 / 200 epoch, with learning rate 0.21103141587353644
[09/23 19:16:38][INFO] visual_prompt:  327: Epoch 126 / 200: avg data time: 1.86e-02, avg batch time: 0.8923, average train loss: 0.8066average G loss: 0.0323, average realD loss: 1.2273, average fakeD loss: 72.5677, 
[09/23 19:16:40][INFO] visual_prompt:  441: Inference (val):avg data time: 5.81e-05, avg batch time: 0.1170, average loss: 0.8779
[09/23 19:16:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 98.00	
[09/23 19:16:54][INFO] visual_prompt:  441: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1237, average loss: 0.8648
[09/23 19:16:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.62	top5: 97.79	
[09/23 19:16:54][INFO] visual_prompt:  259: Training 127 / 200 epoch, with learning rate 0.20615838298698652
[09/23 19:18:10][INFO] visual_prompt:  327: Epoch 127 / 200: avg data time: 1.92e-02, avg batch time: 0.8932, average train loss: 0.8432average G loss: 0.0362, average realD loss: 1.5047, average fakeD loss: 72.2242, 
[09/23 19:18:12][INFO] visual_prompt:  441: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1170, average loss: 0.8827
[09/23 19:18:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.67	
[09/23 19:18:25][INFO] visual_prompt:  441: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1239, average loss: 0.8803
[09/23 19:18:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.50	top5: 97.88	
[09/23 19:18:26][INFO] visual_prompt:  259: Training 128 / 200 epoch, with learning rate 0.20131442283671358
[09/23 19:19:41][INFO] visual_prompt:  327: Epoch 128 / 200: avg data time: 1.78e-02, avg batch time: 0.8915, average train loss: 0.8251average G loss: 0.0334, average realD loss: 0.9224, average fakeD loss: 74.7045, 
[09/23 19:19:44][INFO] visual_prompt:  441: Inference (val):avg data time: 5.58e-05, avg batch time: 0.1173, average loss: 1.1566
[09/23 19:19:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 98.00	
[09/23 19:19:58][INFO] visual_prompt:  441: Inference (test):avg data time: 6.59e-05, avg batch time: 0.1235, average loss: 1.1611
[09/23 19:19:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.19	top5: 97.55	
[09/23 19:19:58][INFO] visual_prompt:  259: Training 129 / 200 epoch, with learning rate 0.19650085971305598
[09/23 19:21:14][INFO] visual_prompt:  327: Epoch 129 / 200: avg data time: 2.01e-02, avg batch time: 0.8938, average train loss: 0.8741average G loss: 0.0337, average realD loss: 1.6966, average fakeD loss: 73.5365, 
[09/23 19:21:16][INFO] visual_prompt:  441: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1168, average loss: 0.8705
[09/23 19:21:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.33	
[09/23 19:21:30][INFO] visual_prompt:  441: Inference (test):avg data time: 8.26e-05, avg batch time: 0.1238, average loss: 0.8473
[09/23 19:21:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.33	top5: 97.84	
[09/23 19:21:30][INFO] visual_prompt:  259: Training 130 / 200 epoch, with learning rate 0.19171900959610877
[09/23 19:22:46][INFO] visual_prompt:  327: Epoch 130 / 200: avg data time: 1.97e-02, avg batch time: 0.8936, average train loss: 0.8413average G loss: 0.0443, average realD loss: 0.9720, average fakeD loss: 73.7373, 
[09/23 19:22:48][INFO] visual_prompt:  441: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1167, average loss: 1.3766
[09/23 19:22:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 97.50	
[09/23 19:23:02][INFO] visual_prompt:  441: Inference (test):avg data time: 9.96e-05, avg batch time: 0.1241, average loss: 1.3778
[09/23 19:23:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.22	top5: 97.48	
[09/23 19:23:02][INFO] visual_prompt:  259: Training 131 / 200 epoch, with learning rate 0.1869701797959471
[09/23 19:24:18][INFO] visual_prompt:  327: Epoch 131 / 200: avg data time: 1.85e-02, avg batch time: 0.8922, average train loss: 0.8873average G loss: 0.0407, average realD loss: 1.9809, average fakeD loss: 70.8671, 
[09/23 19:24:20][INFO] visual_prompt:  441: Inference (val):avg data time: 6.16e-05, avg batch time: 0.1173, average loss: 0.8196
[09/23 19:24:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.67	
[09/23 19:24:34][INFO] visual_prompt:  441: Inference (test):avg data time: 6.99e-05, avg batch time: 0.1236, average loss: 0.8230
[09/23 19:24:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.52	top5: 97.77	
[09/23 19:24:34][INFO] visual_prompt:  259: Training 132 / 200 epoch, with learning rate 0.1822556685952218
[09/23 19:25:50][INFO] visual_prompt:  327: Epoch 132 / 200: avg data time: 1.92e-02, avg batch time: 0.8932, average train loss: 1.0056average G loss: 0.0694, average realD loss: 1.8193, average fakeD loss: 64.0521, 
[09/23 19:25:52][INFO] visual_prompt:  441: Inference (val):avg data time: 8.02e-05, avg batch time: 0.1171, average loss: 1.1121
[09/23 19:25:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.00	
[09/23 19:26:05][INFO] visual_prompt:  441: Inference (test):avg data time: 8.20e-05, avg batch time: 0.1239, average loss: 1.0947
[09/23 19:26:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.27	top5: 97.67	
[09/23 19:26:05][INFO] visual_prompt:  259: Training 133 / 200 epoch, with learning rate 0.177576764894221
[09/23 19:27:21][INFO] visual_prompt:  327: Epoch 133 / 200: avg data time: 1.79e-02, avg batch time: 0.8911, average train loss: 0.8860average G loss: 0.0444, average realD loss: 1.1257, average fakeD loss: 80.1828, 
[09/23 19:27:24][INFO] visual_prompt:  441: Inference (val):avg data time: 9.29e-05, avg batch time: 0.1166, average loss: 0.8362
[09/23 19:27:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.67	
[09/23 19:27:37][INFO] visual_prompt:  441: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1240, average loss: 0.8357
[09/23 19:27:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.81	top5: 97.95	
[09/23 19:27:37][INFO] visual_prompt:  259: Training 134 / 200 epoch, with learning rate 0.172934747858498
[09/23 19:28:53][INFO] visual_prompt:  327: Epoch 134 / 200: avg data time: 2.01e-02, avg batch time: 0.8945, average train loss: 0.8800average G loss: 0.0408, average realD loss: 2.8636, average fakeD loss: 59.0210, 
[09/23 19:28:56][INFO] visual_prompt:  441: Inference (val):avg data time: 7.00e-05, avg batch time: 0.1171, average loss: 0.9507
[09/23 19:28:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 97.50	
[09/23 19:29:10][INFO] visual_prompt:  441: Inference (test):avg data time: 7.89e-05, avg batch time: 0.1235, average loss: 0.9197
[09/23 19:29:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.50	top5: 97.70	
[09/23 19:29:10][INFO] visual_prompt:  259: Training 135 / 200 epoch, with learning rate 0.16833088656916012
[09/23 19:30:26][INFO] visual_prompt:  327: Epoch 135 / 200: avg data time: 1.94e-02, avg batch time: 0.8921, average train loss: 0.7765average G loss: 0.0191, average realD loss: 0.4788, average fakeD loss: 89.3026, 
[09/23 19:30:28][INFO] visual_prompt:  441: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1169, average loss: 0.8025
[09/23 19:30:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 98.00	
[09/23 19:30:41][INFO] visual_prompt:  441: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1236, average loss: 0.7960
[09/23 19:30:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.69	top5: 97.91	
[09/23 19:30:42][INFO] visual_prompt:  259: Training 136 / 200 epoch, with learning rate 0.1637664396759145
[09/23 19:31:58][INFO] visual_prompt:  327: Epoch 136 / 200: avg data time: 2.09e-02, avg batch time: 0.8942, average train loss: 0.8394average G loss: 0.0429, average realD loss: 0.8250, average fakeD loss: 76.3592, 
[09/23 19:32:00][INFO] visual_prompt:  441: Inference (val):avg data time: 5.52e-05, avg batch time: 0.1168, average loss: 1.1415
[09/23 19:32:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 98.17	
[09/23 19:32:14][INFO] visual_prompt:  441: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1238, average loss: 1.1325
[09/23 19:32:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.57	top5: 97.83	
[09/23 19:32:14][INFO] visual_prompt:  259: Training 137 / 200 epoch, with learning rate 0.1592426550529663
[09/23 19:33:30][INFO] visual_prompt:  327: Epoch 137 / 200: avg data time: 1.93e-02, avg batch time: 0.8934, average train loss: 0.9029average G loss: 0.0457, average realD loss: 2.3898, average fakeD loss: 61.0159, 
[09/23 19:33:32][INFO] visual_prompt:  441: Inference (val):avg data time: 5.26e-05, avg batch time: 0.1167, average loss: 0.7657
[09/23 19:33:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.50	
[09/23 19:33:46][INFO] visual_prompt:  441: Inference (test):avg data time: 8.49e-05, avg batch time: 0.1237, average loss: 0.7469
[09/23 19:33:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.35	top5: 98.21	
[09/23 19:33:46][INFO] visual_prompt:  259: Training 138 / 200 epoch, with learning rate 0.15476076945786144
[09/23 19:35:02][INFO] visual_prompt:  327: Epoch 138 / 200: avg data time: 1.81e-02, avg batch time: 0.8913, average train loss: 0.7676average G loss: 0.0303, average realD loss: 0.8161, average fakeD loss: 79.6915, 
[09/23 19:35:04][INFO] visual_prompt:  441: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1171, average loss: 0.9451
[09/23 19:35:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 97.50	
[09/23 19:35:18][INFO] visual_prompt:  441: Inference (test):avg data time: 7.39e-05, avg batch time: 0.1238, average loss: 0.9231
[09/23 19:35:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.99	top5: 98.14	
[09/23 19:35:18][INFO] visual_prompt:  259: Training 139 / 200 epoch, with learning rate 0.15032200819337035
[09/23 19:36:34][INFO] visual_prompt:  327: Epoch 139 / 200: avg data time: 1.75e-02, avg batch time: 0.8921, average train loss: 0.9280average G loss: 0.0530, average realD loss: 2.8960, average fakeD loss: 52.1776, 
[09/23 19:36:36][INFO] visual_prompt:  441: Inference (val):avg data time: 7.72e-05, avg batch time: 0.1167, average loss: 0.7855
[09/23 19:36:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 98.50	
[09/23 19:36:49][INFO] visual_prompt:  441: Inference (test):avg data time: 8.97e-05, avg batch time: 0.1236, average loss: 0.7803
[09/23 19:36:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.60	top5: 98.17	
[09/23 19:36:50][INFO] visual_prompt:  259: Training 140 / 200 epoch, with learning rate 0.145927584772502
[09/23 19:38:06][INFO] visual_prompt:  327: Epoch 140 / 200: avg data time: 1.90e-02, avg batch time: 0.8927, average train loss: 0.7537average G loss: 0.0217, average realD loss: 1.2085, average fakeD loss: 68.6273, 
[09/23 19:38:08][INFO] visual_prompt:  441: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1167, average loss: 0.8935
[09/23 19:38:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.17	
[09/23 19:38:21][INFO] visual_prompt:  441: Inference (test):avg data time: 7.37e-05, avg batch time: 0.1237, average loss: 0.8857
[09/23 19:38:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.83	top5: 97.93	
[09/23 19:38:21][INFO] visual_prompt:  259: Training 141 / 200 epoch, with learning rate 0.14157870058674166
[09/23 19:39:37][INFO] visual_prompt:  327: Epoch 141 / 200: avg data time: 1.79e-02, avg batch time: 0.8925, average train loss: 0.8350average G loss: 0.0358, average realD loss: 3.6280, average fakeD loss: 51.5029, 
[09/23 19:39:39][INFO] visual_prompt:  441: Inference (val):avg data time: 5.54e-05, avg batch time: 0.1169, average loss: 0.8000
[09/23 19:39:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.67	
[09/23 19:39:53][INFO] visual_prompt:  441: Inference (test):avg data time: 8.09e-05, avg batch time: 0.1238, average loss: 0.7940
[09/23 19:39:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.93	top5: 98.10	
[09/23 19:39:53][INFO] visual_prompt:  259: Training 142 / 200 epoch, with learning rate 0.1372765445776023
[09/23 19:41:09][INFO] visual_prompt:  327: Epoch 142 / 200: avg data time: 1.85e-02, avg batch time: 0.8933, average train loss: 0.8677average G loss: 0.0541, average realD loss: 3.9056, average fakeD loss: 47.8860, 
[09/23 19:41:11][INFO] visual_prompt:  441: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1169, average loss: 0.9527
[09/23 19:41:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 98.17	
[09/23 19:41:25][INFO] visual_prompt:  441: Inference (test):avg data time: 7.78e-05, avg batch time: 0.1237, average loss: 0.9322
[09/23 19:41:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.43	top5: 98.10	
[09/23 19:41:25][INFO] visual_prompt:  259: Training 143 / 200 epoch, with learning rate 0.13302229291158013
[09/23 19:42:40][INFO] visual_prompt:  327: Epoch 143 / 200: avg data time: 1.76e-02, avg batch time: 0.8912, average train loss: 0.7732average G loss: 0.0213, average realD loss: 1.4180, average fakeD loss: 75.4246, 
[09/23 19:42:43][INFO] visual_prompt:  441: Inference (val):avg data time: 5.93e-05, avg batch time: 0.1170, average loss: 0.7934
[09/23 19:42:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.33	
[09/23 19:42:57][INFO] visual_prompt:  441: Inference (test):avg data time: 8.05e-05, avg batch time: 0.1236, average loss: 0.7995
[09/23 19:42:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.12	top5: 98.03	
[09/23 19:42:57][INFO] visual_prompt:  259: Training 144 / 200 epoch, with learning rate 0.1288171086586022
[09/23 19:44:13][INFO] visual_prompt:  327: Epoch 144 / 200: avg data time: 1.94e-02, avg batch time: 0.8943, average train loss: 0.8554average G loss: 0.0422, average realD loss: 3.6637, average fakeD loss: 46.9384, 
[09/23 19:44:15][INFO] visual_prompt:  441: Inference (val):avg data time: 6.29e-05, avg batch time: 0.1167, average loss: 0.9246
[09/23 19:44:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.50	
[09/23 19:44:29][INFO] visual_prompt:  441: Inference (test):avg data time: 6.52e-05, avg batch time: 0.1238, average loss: 0.9103
[09/23 19:44:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.07	top5: 97.98	
[09/23 19:44:29][INFO] visual_prompt:  259: Training 145 / 200 epoch, with learning rate 0.12466214147405466
[09/23 19:45:45][INFO] visual_prompt:  327: Epoch 145 / 200: avg data time: 1.75e-02, avg batch time: 0.8914, average train loss: 0.7595average G loss: 0.0277, average realD loss: 1.6308, average fakeD loss: 69.4662, 
[09/23 19:45:47][INFO] visual_prompt:  441: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1169, average loss: 0.7825
[09/23 19:45:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 98.50	
[09/23 19:46:01][INFO] visual_prompt:  441: Inference (test):avg data time: 6.65e-05, avg batch time: 0.1235, average loss: 0.7640
[09/23 19:46:01][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.97	top5: 98.19	
[09/23 19:46:01][INFO] visual_prompt:  259: Training 146 / 200 epoch, with learning rate 0.1205585272844788
[09/23 19:47:17][INFO] visual_prompt:  327: Epoch 146 / 200: avg data time: 1.83e-02, avg batch time: 0.8933, average train loss: 0.9081average G loss: 0.0526, average realD loss: 3.3822, average fakeD loss: 45.1273, 
[09/23 19:47:20][INFO] visual_prompt:  441: Inference (val):avg data time: 1.00e-04, avg batch time: 0.1167, average loss: 0.7866
[09/23 19:47:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.17	
[09/23 19:47:33][INFO] visual_prompt:  441: Inference (test):avg data time: 7.72e-05, avg batch time: 0.1235, average loss: 0.7712
[09/23 19:47:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.04	top5: 98.12	
[09/23 19:47:34][INFO] visual_prompt:  259: Training 147 / 200 epoch, with learning rate 0.11650738797701968
[09/23 19:48:50][INFO] visual_prompt:  327: Epoch 147 / 200: avg data time: 1.84e-02, avg batch time: 0.8922, average train loss: 0.7542average G loss: 0.0245, average realD loss: 1.3651, average fakeD loss: 69.1075, 
[09/23 19:48:52][INFO] visual_prompt:  441: Inference (val):avg data time: 4.73e-05, avg batch time: 0.1168, average loss: 0.7987
[09/23 19:48:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.67	
[09/23 19:49:05][INFO] visual_prompt:  441: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1239, average loss: 0.7896
[09/23 19:49:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.92	top5: 98.22	
[09/23 19:49:05][INFO] visual_prompt:  259: Training 148 / 200 epoch, with learning rate 0.11250983109271355
[09/23 19:50:22][INFO] visual_prompt:  327: Epoch 148 / 200: avg data time: 1.96e-02, avg batch time: 0.8948, average train loss: 0.8386average G loss: 0.0410, average realD loss: 3.7715, average fakeD loss: 43.7770, 
[09/23 19:50:24][INFO] visual_prompt:  441: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1167, average loss: 0.8881
[09/23 19:50:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.17	
[09/23 19:50:38][INFO] visual_prompt:  441: Inference (test):avg data time: 8.02e-05, avg batch time: 0.1237, average loss: 0.8762
[09/23 19:50:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.71	top5: 98.10	
[09/23 19:50:38][INFO] visual_prompt:  259: Training 149 / 200 epoch, with learning rate 0.10856694952369728
[09/23 19:51:54][INFO] visual_prompt:  327: Epoch 149 / 200: avg data time: 2.13e-02, avg batch time: 0.8949, average train loss: 0.7054average G loss: 0.0202, average realD loss: 0.8507, average fakeD loss: 78.5862, 
[09/23 19:51:56][INFO] visual_prompt:  441: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1169, average loss: 0.8313
[09/23 19:51:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.17	
[09/23 19:52:11][INFO] visual_prompt:  441: Inference (test):avg data time: 9.39e-05, avg batch time: 0.1239, average loss: 0.8460
[09/23 19:52:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.00	top5: 97.81	
[09/23 19:52:11][INFO] visual_prompt:  259: Training 150 / 200 epoch, with learning rate 0.10467982121442239
[09/23 19:53:27][INFO] visual_prompt:  327: Epoch 150 / 200: avg data time: 2.06e-02, avg batch time: 0.8964, average train loss: 0.9552average G loss: 0.0657, average realD loss: 4.7794, average fakeD loss: 31.3316, 
[09/23 19:53:29][INFO] visual_prompt:  441: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1169, average loss: 0.8251
[09/23 19:53:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.17	
[09/23 19:53:43][INFO] visual_prompt:  441: Inference (test):avg data time: 8.39e-05, avg batch time: 0.1237, average loss: 0.8197
[09/23 19:53:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.12	top5: 98.02	
[09/23 19:53:43][INFO] visual_prompt:  259: Training 151 / 200 epoch, with learning rate 0.10084950886695598
[09/23 19:54:59][INFO] visual_prompt:  327: Epoch 151 / 200: avg data time: 1.79e-02, avg batch time: 0.8932, average train loss: 0.7701average G loss: 0.0283, average realD loss: 3.6286, average fakeD loss: 43.5548, 
[09/23 19:55:01][INFO] visual_prompt:  441: Inference (val):avg data time: 2.65e-04, avg batch time: 0.1173, average loss: 0.9257
[09/23 19:55:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.33	
[09/23 19:55:15][INFO] visual_prompt:  441: Inference (test):avg data time: 9.25e-05, avg batch time: 0.1237, average loss: 0.9262
[09/23 19:55:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.97	top5: 97.91	
[09/23 19:55:15][INFO] visual_prompt:  259: Training 152 / 200 epoch, with learning rate 0.09707705965044819
[09/23 19:56:31][INFO] visual_prompt:  327: Epoch 152 / 200: avg data time: 1.70e-02, avg batch time: 0.8929, average train loss: 0.8151average G loss: 0.0362, average realD loss: 4.7541, average fakeD loss: 39.3800, 
[09/23 19:56:33][INFO] visual_prompt:  441: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1170, average loss: 0.8322
[09/23 19:56:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.83	
[09/23 19:56:46][INFO] visual_prompt:  441: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1238, average loss: 0.8238
[09/23 19:56:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.19	top5: 98.27	
[09/23 19:56:46][INFO] visual_prompt:  259: Training 153 / 200 epoch, with learning rate 0.09336350491484732
[09/23 19:58:03][INFO] visual_prompt:  327: Epoch 153 / 200: avg data time: 1.98e-02, avg batch time: 0.8961, average train loss: 0.8302average G loss: 0.0364, average realD loss: 5.9785, average fakeD loss: 27.9567, 
[09/23 19:58:05][INFO] visual_prompt:  441: Inference (val):avg data time: 5.71e-05, avg batch time: 0.1167, average loss: 0.7372
[09/23 19:58:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.33	
[09/23 19:58:18][INFO] visual_prompt:  441: Inference (test):avg data time: 8.64e-05, avg batch time: 0.1239, average loss: 0.7464
[09/23 19:58:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.86	top5: 98.21	
[09/23 19:58:18][INFO] visual_prompt:  363: Best epoch 153: best metric: 0.875
[09/23 19:58:18][INFO] visual_prompt:  259: Training 154 / 200 epoch, with learning rate 0.08970985990893843
[09/23 19:59:34][INFO] visual_prompt:  327: Epoch 154 / 200: avg data time: 1.76e-02, avg batch time: 0.8933, average train loss: 0.7784average G loss: 0.0302, average realD loss: 5.2235, average fakeD loss: 31.8556, 
[09/23 19:59:36][INFO] visual_prompt:  441: Inference (val):avg data time: 7.14e-05, avg batch time: 0.1169, average loss: 0.8818
[09/23 19:59:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.33	
[09/23 19:59:50][INFO] visual_prompt:  441: Inference (test):avg data time: 8.20e-05, avg batch time: 0.1241, average loss: 0.8692
[09/23 19:59:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.30	top5: 98.26	
[09/23 19:59:50][INFO] visual_prompt:  259: Training 155 / 200 epoch, with learning rate 0.08611712350278469
[09/23 20:01:06][INFO] visual_prompt:  327: Epoch 155 / 200: avg data time: 1.86e-02, avg batch time: 0.8946, average train loss: 0.8070average G loss: 0.0385, average realD loss: 6.6615, average fakeD loss: 24.3612, 
[09/23 20:01:09][INFO] visual_prompt:  441: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1170, average loss: 0.9066
[09/23 20:01:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.83	
[09/23 20:01:23][INFO] visual_prompt:  441: Inference (test):avg data time: 9.58e-05, avg batch time: 0.1239, average loss: 0.8956
[09/23 20:01:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.85	top5: 98.02	
[09/23 20:01:23][INFO] visual_prompt:  259: Training 156 / 200 epoch, with learning rate 0.08258627791464637
[09/23 20:02:39][INFO] visual_prompt:  327: Epoch 156 / 200: avg data time: 1.93e-02, avg batch time: 0.8955, average train loss: 0.8478average G loss: 0.0403, average realD loss: 6.7474, average fakeD loss: 21.3371, 
[09/23 20:02:41][INFO] visual_prompt:  441: Inference (val):avg data time: 7.27e-05, avg batch time: 0.1168, average loss: 0.8630
[09/23 20:02:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.83	
[09/23 20:02:55][INFO] visual_prompt:  441: Inference (test):avg data time: 7.83e-05, avg batch time: 0.1237, average loss: 0.8542
[09/23 20:02:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.37	top5: 98.15	
[09/23 20:02:55][INFO] visual_prompt:  259: Training 157 / 200 epoch, with learning rate 0.079118288442452
[09/23 20:04:11][INFO] visual_prompt:  327: Epoch 157 / 200: avg data time: 1.84e-02, avg batch time: 0.8946, average train loss: 0.8192average G loss: 0.0376, average realD loss: 7.0756, average fakeD loss: 21.9337, 
[09/23 20:04:14][INFO] visual_prompt:  441: Inference (val):avg data time: 9.31e-05, avg batch time: 0.1170, average loss: 1.0901
[09/23 20:04:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 99.00	
[09/23 20:04:27][INFO] visual_prompt:  441: Inference (test):avg data time: 8.11e-05, avg batch time: 0.1239, average loss: 1.0948
[09/23 20:04:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.07	top5: 97.98	
[09/23 20:04:27][INFO] visual_prompt:  259: Training 158 / 200 epoch, with learning rate 0.07571410319989547
[09/23 20:05:43][INFO] visual_prompt:  327: Epoch 158 / 200: avg data time: 1.94e-02, avg batch time: 0.8958, average train loss: 0.8394average G loss: 0.0422, average realD loss: 8.0596, average fakeD loss: 18.0558, 
[09/23 20:05:46][INFO] visual_prompt:  441: Inference (val):avg data time: 5.77e-05, avg batch time: 0.1168, average loss: 0.9554
[09/23 20:05:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.17	
[09/23 20:06:00][INFO] visual_prompt:  441: Inference (test):avg data time: 7.57e-05, avg batch time: 0.1238, average loss: 0.9498
[09/23 20:06:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.99	top5: 98.24	
[09/23 20:06:00][INFO] visual_prompt:  259: Training 159 / 200 epoch, with learning rate 0.07237465285723163
[09/23 20:07:16][INFO] visual_prompt:  327: Epoch 159 / 200: avg data time: 1.88e-02, avg batch time: 0.8950, average train loss: 0.8238average G loss: 0.0375, average realD loss: 7.5192, average fakeD loss: 19.8587, 
[09/23 20:07:19][INFO] visual_prompt:  441: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1172, average loss: 0.9273
[09/23 20:07:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.33	
[09/23 20:07:32][INFO] visual_prompt:  441: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1238, average loss: 0.9118
[09/23 20:07:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.73	top5: 98.24	
[09/23 20:07:32][INFO] visual_prompt:  259: Training 160 / 200 epoch, with learning rate 0.0691008503868399
[09/23 20:08:49][INFO] visual_prompt:  327: Epoch 160 / 200: avg data time: 1.99e-02, avg batch time: 0.8962, average train loss: 0.8791average G loss: 0.0445, average realD loss: 9.3480, average fakeD loss: 11.8481, 
[09/23 20:08:51][INFO] visual_prompt:  441: Inference (val):avg data time: 6.54e-05, avg batch time: 0.1169, average loss: 0.8727
[09/23 20:08:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.33	
[09/23 20:09:05][INFO] visual_prompt:  441: Inference (test):avg data time: 1.05e-04, avg batch time: 0.1239, average loss: 0.8653
[09/23 20:09:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.81	top5: 98.14	
[09/23 20:09:05][INFO] visual_prompt:  259: Training 161 / 200 epoch, with learning rate 0.06589359081362704
[09/23 20:10:22][INFO] visual_prompt:  327: Epoch 161 / 200: avg data time: 1.72e-02, avg batch time: 0.8935, average train loss: 0.8706average G loss: 0.0500, average realD loss: 9.7599, average fakeD loss: 12.3321, 
[09/23 20:10:24][INFO] visual_prompt:  441: Inference (val):avg data time: 8.08e-05, avg batch time: 0.1173, average loss: 1.0397
[09/23 20:10:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 97.83	
[09/23 20:10:37][INFO] visual_prompt:  441: Inference (test):avg data time: 7.78e-05, avg batch time: 0.1239, average loss: 1.0249
[09/23 20:10:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.97	top5: 98.05	
[09/23 20:10:38][INFO] visual_prompt:  259: Training 162 / 200 epoch, with learning rate 0.06275375097033603
[09/23 20:11:54][INFO] visual_prompt:  327: Epoch 162 / 200: avg data time: 1.88e-02, avg batch time: 0.8952, average train loss: 0.8664average G loss: 0.0459, average realD loss: 9.4818, average fakeD loss: 13.2420, 
[09/23 20:11:56][INFO] visual_prompt:  441: Inference (val):avg data time: 6.68e-05, avg batch time: 0.1170, average loss: 0.9883
[09/23 20:11:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 97.67	
[09/23 20:12:10][INFO] visual_prompt:  441: Inference (test):avg data time: 7.11e-05, avg batch time: 0.1240, average loss: 0.9773
[09/23 20:12:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.30	top5: 98.21	
[09/23 20:12:10][INFO] visual_prompt:  259: Training 163 / 200 epoch, with learning rate 0.059682189257828956
[09/23 20:13:26][INFO] visual_prompt:  327: Epoch 163 / 200: avg data time: 1.81e-02, avg batch time: 0.8942, average train loss: 0.8708average G loss: 0.0469, average realD loss: 10.4677, average fakeD loss: 10.8388, 
[09/23 20:13:28][INFO] visual_prompt:  441: Inference (val):avg data time: 5.66e-05, avg batch time: 0.1166, average loss: 1.0134
[09/23 20:13:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.33	
[09/23 20:13:42][INFO] visual_prompt:  441: Inference (test):avg data time: 8.09e-05, avg batch time: 0.1239, average loss: 0.9974
[09/23 20:13:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.80	top5: 98.24	
[09/23 20:13:42][INFO] visual_prompt:  259: Training 164 / 200 epoch, with learning rate 0.05667974541040864
[09/23 20:14:58][INFO] visual_prompt:  327: Epoch 164 / 200: avg data time: 1.83e-02, avg batch time: 0.8940, average train loss: 0.9252average G loss: 0.0576, average realD loss: 11.2176, average fakeD loss: 11.8876, 
[09/23 20:15:00][INFO] visual_prompt:  441: Inference (val):avg data time: 7.77e-05, avg batch time: 0.1173, average loss: 0.9752
[09/23 20:15:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.67	
[09/23 20:15:14][INFO] visual_prompt:  441: Inference (test):avg data time: 9.76e-05, avg batch time: 0.1237, average loss: 0.9756
[09/23 20:15:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.26	top5: 98.07	
[09/23 20:15:14][INFO] visual_prompt:  259: Training 165 / 200 epoch, with learning rate 0.05374724026624374
[09/23 20:16:30][INFO] visual_prompt:  327: Epoch 165 / 200: avg data time: 1.85e-02, avg batch time: 0.8945, average train loss: 0.9426average G loss: 0.0639, average realD loss: 11.3300, average fakeD loss: 8.0108, 
[09/23 20:16:33][INFO] visual_prompt:  441: Inference (val):avg data time: 7.54e-05, avg batch time: 0.1168, average loss: 1.1056
[09/23 20:16:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.33	
[09/23 20:16:46][INFO] visual_prompt:  441: Inference (test):avg data time: 7.66e-05, avg batch time: 0.1236, average loss: 1.0911
[09/23 20:16:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.36	top5: 98.19	
[09/23 20:16:46][INFO] visual_prompt:  259: Training 166 / 200 epoch, with learning rate 0.05088547554295983
[09/23 20:18:03][INFO] visual_prompt:  327: Epoch 166 / 200: avg data time: 1.93e-02, avg batch time: 0.8952, average train loss: 0.9405average G loss: 0.0661, average realD loss: 12.1590, average fakeD loss: 8.1002, 
[09/23 20:18:05][INFO] visual_prompt:  441: Inference (val):avg data time: 8.00e-05, avg batch time: 0.1166, average loss: 1.0916
[09/23 20:18:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.50	
[09/23 20:18:19][INFO] visual_prompt:  441: Inference (test):avg data time: 9.88e-05, avg batch time: 0.1238, average loss: 1.0852
[09/23 20:18:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.98	top5: 98.00	
[09/23 20:18:19][INFO] visual_prompt:  259: Training 167 / 200 epoch, with learning rate 0.04809523361845765
[09/23 20:19:36][INFO] visual_prompt:  327: Epoch 167 / 200: avg data time: 2.00e-02, avg batch time: 0.8960, average train loss: 1.0221average G loss: 0.0780, average realD loss: 13.5940, average fakeD loss: 7.3731, 
[09/23 20:19:38][INFO] visual_prompt:  441: Inference (val):avg data time: 7.50e-05, avg batch time: 0.1168, average loss: 1.2592
[09/23 20:19:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 98.17	
[09/23 20:19:52][INFO] visual_prompt:  441: Inference (test):avg data time: 7.41e-05, avg batch time: 0.1235, average loss: 1.2478
[09/23 20:19:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.28	top5: 98.00	
[09/23 20:19:52][INFO] visual_prompt:  259: Training 168 / 200 epoch, with learning rate 0.04537727731701902
[09/23 20:21:08][INFO] visual_prompt:  327: Epoch 168 / 200: avg data time: 1.74e-02, avg batch time: 0.8933, average train loss: 1.1020average G loss: 0.0984, average realD loss: 14.3038, average fakeD loss: 6.3509, 
[09/23 20:21:10][INFO] visual_prompt:  441: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1170, average loss: 1.3499
[09/23 20:21:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 97.50	
[09/23 20:21:23][INFO] visual_prompt:  441: Inference (test):avg data time: 7.90e-05, avg batch time: 0.1238, average loss: 1.3461
[09/23 20:21:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.09	top5: 97.79	
[09/23 20:21:23][INFO] visual_prompt:  259: Training 169 / 200 epoch, with learning rate 0.042732349700758156
[09/23 20:22:40][INFO] visual_prompt:  327: Epoch 169 / 200: avg data time: 2.01e-02, avg batch time: 0.8963, average train loss: 1.1529average G loss: 0.1148, average realD loss: 14.7223, average fakeD loss: 6.3311, 
[09/23 20:22:42][INFO] visual_prompt:  441: Inference (val):avg data time: 5.90e-05, avg batch time: 0.1169, average loss: 1.1980
[09/23 20:22:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 98.17	
[09/23 20:22:56][INFO] visual_prompt:  441: Inference (test):avg data time: 7.51e-05, avg batch time: 0.1238, average loss: 1.1850
[09/23 20:22:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.24	top5: 97.93	
[09/23 20:22:56][INFO] visual_prompt:  259: Training 170 / 200 epoch, with learning rate 0.040161173866475816
[09/23 20:24:13][INFO] visual_prompt:  327: Epoch 170 / 200: avg data time: 1.85e-02, avg batch time: 0.8948, average train loss: 1.2205average G loss: 0.1351, average realD loss: 15.8082, average fakeD loss: 5.8699, 
[09/23 20:24:15][INFO] visual_prompt:  441: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1171, average loss: 1.4636
[09/23 20:24:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.00	
[09/23 20:24:29][INFO] visual_prompt:  441: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1238, average loss: 1.4510
[09/23 20:24:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.98	top5: 97.76	
[09/23 20:24:29][INFO] visual_prompt:  259: Training 171 / 200 epoch, with learning rate 0.0376644527479722
[09/23 20:25:45][INFO] visual_prompt:  327: Epoch 171 / 200: avg data time: 1.95e-02, avg batch time: 0.8957, average train loss: 1.4286average G loss: 0.1930, average realD loss: 16.8526, average fakeD loss: 5.0211, 
[09/23 20:25:48][INFO] visual_prompt:  441: Inference (val):avg data time: 8.41e-05, avg batch time: 0.1168, average loss: 1.4792
[09/23 20:25:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 97.67	
[09/23 20:26:02][INFO] visual_prompt:  441: Inference (test):avg data time: 1.05e-04, avg batch time: 0.1238, average loss: 1.4671
[09/23 20:26:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.83	top5: 97.79	
[09/23 20:26:02][INFO] visual_prompt:  259: Training 172 / 200 epoch, with learning rate 0.03524286892387131
[09/23 20:27:18][INFO] visual_prompt:  327: Epoch 172 / 200: avg data time: 1.85e-02, avg batch time: 0.8947, average train loss: 1.5462average G loss: 0.2397, average realD loss: 17.7107, average fakeD loss: 4.6261, 
[09/23 20:27:20][INFO] visual_prompt:  441: Inference (val):avg data time: 6.91e-05, avg batch time: 0.1171, average loss: 1.8603
[09/23 20:27:20][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 97.00	
[09/23 20:27:34][INFO] visual_prompt:  441: Inference (test):avg data time: 7.24e-05, avg batch time: 0.1237, average loss: 1.8480
[09/23 20:27:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.34	top5: 97.19	
[09/23 20:27:34][INFO] visual_prompt:  259: Training 173 / 200 epoch, with learning rate 0.032897084431011414
[09/23 20:28:50][INFO] visual_prompt:  327: Epoch 173 / 200: avg data time: 1.84e-02, avg batch time: 0.8945, average train loss: 1.7978average G loss: 0.3137, average realD loss: 18.6301, average fakeD loss: 4.0923, 
[09/23 20:28:53][INFO] visual_prompt:  441: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1169, average loss: 2.1207
[09/23 20:28:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.33	
[09/23 20:29:06][INFO] visual_prompt:  441: Inference (test):avg data time: 6.94e-05, avg batch time: 0.1236, average loss: 2.1081
[09/23 20:29:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.07	top5: 97.27	
[09/23 20:29:06][INFO] visual_prompt:  259: Training 174 / 200 epoch, with learning rate 0.030627740583450344
[09/23 20:30:23][INFO] visual_prompt:  327: Epoch 174 / 200: avg data time: 1.94e-02, avg batch time: 0.8956, average train loss: 2.1683average G loss: 0.4889, average realD loss: 18.1277, average fakeD loss: 3.1266, 
[09/23 20:30:25][INFO] visual_prompt:  441: Inference (val):avg data time: 1.13e-04, avg batch time: 0.1174, average loss: 2.3919
[09/23 20:30:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.83	top5: 96.33	
[09/23 20:30:38][INFO] visual_prompt:  441: Inference (test):avg data time: 6.57e-05, avg batch time: 0.1238, average loss: 2.3802
[09/23 20:30:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 76.94	top5: 96.39	
[09/23 20:30:39][INFO] visual_prompt:  259: Training 175 / 200 epoch, with learning rate 0.028435457797136715
[09/23 20:31:55][INFO] visual_prompt:  327: Epoch 175 / 200: avg data time: 1.71e-02, avg batch time: 0.8932, average train loss: 2.1646average G loss: 0.5093, average realD loss: 15.6678, average fakeD loss: 2.7860, 
[09/23 20:31:57][INFO] visual_prompt:  441: Inference (val):avg data time: 6.21e-05, avg batch time: 0.1168, average loss: 1.9353
[09/23 20:31:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 96.50	
[09/23 20:32:10][INFO] visual_prompt:  441: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1239, average loss: 1.9118
[09/23 20:32:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.79	top5: 96.89	
[09/23 20:32:10][INFO] visual_prompt:  259: Training 176 / 200 epoch, with learning rate 0.02632083542029453
[09/23 20:33:26][INFO] visual_prompt:  327: Epoch 176 / 200: avg data time: 1.81e-02, avg batch time: 0.8942, average train loss: 1.8146average G loss: 0.3762, average realD loss: 13.2709, average fakeD loss: 3.1242, 
[09/23 20:33:29][INFO] visual_prompt:  441: Inference (val):avg data time: 5.81e-05, avg batch time: 0.1170, average loss: 1.7722
[09/23 20:33:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 98.17	
[09/23 20:33:42][INFO] visual_prompt:  441: Inference (test):avg data time: 8.72e-05, avg batch time: 0.1237, average loss: 1.7681
[09/23 20:33:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.91	top5: 97.20	
[09/23 20:33:42][INFO] visual_prompt:  259: Training 177 / 200 epoch, with learning rate 0.024284451569567267
[09/23 20:34:58][INFO] visual_prompt:  327: Epoch 177 / 200: avg data time: 1.75e-02, avg batch time: 0.8936, average train loss: 1.4399average G loss: 0.2764, average realD loss: 11.1427, average fakeD loss: 3.2477, 
[09/23 20:35:00][INFO] visual_prompt:  441: Inference (val):avg data time: 6.94e-05, avg batch time: 0.1171, average loss: 1.5353
[09/23 20:35:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.67	
[09/23 20:35:14][INFO] visual_prompt:  441: Inference (test):avg data time: 8.48e-05, avg batch time: 0.1238, average loss: 1.5260
[09/23 20:35:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.26	top5: 97.22	
[09/23 20:35:14][INFO] visual_prompt:  259: Training 178 / 200 epoch, with learning rate 0.022326862971966573
[09/23 20:36:30][INFO] visual_prompt:  327: Epoch 178 / 200: avg data time: 1.74e-02, avg batch time: 0.8934, average train loss: 1.2721average G loss: 0.2066, average realD loss: 9.6725, average fakeD loss: 3.6584, 
[09/23 20:36:32][INFO] visual_prompt:  441: Inference (val):avg data time: 7.12e-05, avg batch time: 0.1171, average loss: 1.3073
[09/23 20:36:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.67	
[09/23 20:36:46][INFO] visual_prompt:  441: Inference (test):avg data time: 7.71e-05, avg batch time: 0.1238, average loss: 1.3088
[09/23 20:36:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.41	top5: 97.77	
[09/23 20:36:46][INFO] visual_prompt:  259: Training 179 / 200 epoch, with learning rate 0.020448604812668518
[09/23 20:38:02][INFO] visual_prompt:  327: Epoch 179 / 200: avg data time: 1.89e-02, avg batch time: 0.8950, average train loss: 1.1639average G loss: 0.1915, average realD loss: 8.1956, average fakeD loss: 3.6694, 
[09/23 20:38:05][INFO] visual_prompt:  441: Inference (val):avg data time: 7.14e-05, avg batch time: 0.1170, average loss: 1.2557
[09/23 20:38:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.67	
[09/23 20:38:18][INFO] visual_prompt:  441: Inference (test):avg data time: 7.46e-05, avg batch time: 0.1238, average loss: 1.2475
[09/23 20:38:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.50	top5: 97.86	
[09/23 20:38:18][INFO] visual_prompt:  259: Training 180 / 200 epoch, with learning rate 0.018650190588699635
[09/23 20:39:35][INFO] visual_prompt:  327: Epoch 180 / 200: avg data time: 1.92e-02, avg batch time: 0.8958, average train loss: 1.0666average G loss: 0.1508, average realD loss: 7.0932, average fakeD loss: 3.9122, 
[09/23 20:39:37][INFO] visual_prompt:  441: Inference (val):avg data time: 6.75e-05, avg batch time: 0.1166, average loss: 1.1921
[09/23 20:39:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.67	
[09/23 20:39:51][INFO] visual_prompt:  441: Inference (test):avg data time: 9.43e-05, avg batch time: 0.1238, average loss: 1.1894
[09/23 20:39:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.88	top5: 97.76	
[09/23 20:39:51][INFO] visual_prompt:  259: Training 181 / 200 epoch, with learning rate 0.016932111968551676
[09/23 20:41:07][INFO] visual_prompt:  327: Epoch 181 / 200: avg data time: 1.97e-02, avg batch time: 0.8960, average train loss: 1.0848average G loss: 0.1774, average realD loss: 7.0646, average fakeD loss: 3.5173, 
[09/23 20:41:09][INFO] visual_prompt:  441: Inference (val):avg data time: 5.25e-05, avg batch time: 0.1168, average loss: 1.2449
[09/23 20:41:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 98.00	
[09/23 20:41:23][INFO] visual_prompt:  441: Inference (test):avg data time: 7.14e-05, avg batch time: 0.1238, average loss: 1.2378
[09/23 20:41:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.12	top5: 97.72	
[09/23 20:41:23][INFO] visual_prompt:  259: Training 182 / 200 epoch, with learning rate 0.015294838657764522
[09/23 20:42:39][INFO] visual_prompt:  327: Epoch 182 / 200: avg data time: 1.89e-02, avg batch time: 0.8952, average train loss: 1.0890average G loss: 0.1836, average realD loss: 6.4257, average fakeD loss: 3.0334, 
[09/23 20:42:41][INFO] visual_prompt:  441: Inference (val):avg data time: 8.07e-05, avg batch time: 0.1172, average loss: 1.1674
[09/23 20:42:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 98.17	
[09/23 20:42:55][INFO] visual_prompt:  441: Inference (test):avg data time: 8.37e-05, avg batch time: 0.1238, average loss: 1.1698
[09/23 20:42:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.86	top5: 97.93	
[09/23 20:42:55][INFO] visual_prompt:  259: Training 183 / 200 epoch, with learning rate 0.013738818270513237
[09/23 20:44:11][INFO] visual_prompt:  327: Epoch 183 / 200: avg data time: 1.87e-02, avg batch time: 0.8947, average train loss: 1.0696average G loss: 0.2069, average realD loss: 5.7442, average fakeD loss: 2.8230, 
[09/23 20:44:14][INFO] visual_prompt:  441: Inference (val):avg data time: 5.94e-05, avg batch time: 0.1174, average loss: 1.1785
[09/23 20:44:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 97.67	
[09/23 20:44:27][INFO] visual_prompt:  441: Inference (test):avg data time: 1.02e-04, avg batch time: 0.1239, average loss: 1.1581
[09/23 20:44:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.19	top5: 97.96	
[09/23 20:44:27][INFO] visual_prompt:  259: Training 184 / 200 epoch, with learning rate 0.012264476207234955
[09/23 20:45:43][INFO] visual_prompt:  327: Epoch 184 / 200: avg data time: 1.91e-02, avg batch time: 0.8953, average train loss: 1.0032average G loss: 0.1987, average realD loss: 4.3652, average fakeD loss: 2.6869, 
[09/23 20:45:46][INFO] visual_prompt:  441: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1167, average loss: 1.1641
[09/23 20:45:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.00	
[09/23 20:45:59][INFO] visual_prompt:  441: Inference (test):avg data time: 8.21e-05, avg batch time: 0.1238, average loss: 1.1636
[09/23 20:46:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.24	top5: 98.10	
[09/23 20:46:00][INFO] visual_prompt:  259: Training 185 / 200 epoch, with learning rate 0.010872215538328574
[09/23 20:47:16][INFO] visual_prompt:  327: Epoch 185 / 200: avg data time: 1.80e-02, avg batch time: 0.8943, average train loss: 1.0425average G loss: 0.2219, average realD loss: 4.7378, average fakeD loss: 2.4120, 
[09/23 20:47:18][INFO] visual_prompt:  441: Inference (val):avg data time: 6.64e-05, avg batch time: 0.1168, average loss: 1.1952
[09/23 20:47:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.17	
[09/23 20:47:32][INFO] visual_prompt:  441: Inference (test):avg data time: 8.33e-05, avg batch time: 0.1237, average loss: 1.1887
[09/23 20:47:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.93	top5: 97.93	
[09/23 20:47:32][INFO] visual_prompt:  259: Training 186 / 200 epoch, with learning rate 0.009562416893959258
[09/23 20:48:48][INFO] visual_prompt:  327: Epoch 186 / 200: avg data time: 1.86e-02, avg batch time: 0.8948, average train loss: 1.0858average G loss: 0.2452, average realD loss: 4.3319, average fakeD loss: 2.1249, 
[09/23 20:48:51][INFO] visual_prompt:  441: Inference (val):avg data time: 8.13e-05, avg batch time: 0.1168, average loss: 1.1795
[09/23 20:48:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.17	
[09/23 20:49:04][INFO] visual_prompt:  441: Inference (test):avg data time: 7.82e-05, avg batch time: 0.1237, average loss: 1.1747
[09/23 20:49:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.55	top5: 98.05	
[09/23 20:49:05][INFO] visual_prompt:  259: Training 187 / 200 epoch, with learning rate 0.008335438359998205
[09/23 20:50:21][INFO] visual_prompt:  327: Epoch 187 / 200: avg data time: 1.95e-02, avg batch time: 0.8958, average train loss: 1.0387average G loss: 0.2529, average realD loss: 3.7357, average fakeD loss: 2.0202, 
[09/23 20:50:23][INFO] visual_prompt:  441: Inference (val):avg data time: 5.99e-05, avg batch time: 0.1170, average loss: 1.1648
[09/23 20:50:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 97.50	
[09/23 20:50:37][INFO] visual_prompt:  441: Inference (test):avg data time: 7.84e-05, avg batch time: 0.1237, average loss: 1.1631
[09/23 20:50:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.16	top5: 97.88	
[09/23 20:50:37][INFO] visual_prompt:  259: Training 188 / 200 epoch, with learning rate 0.007191615380125228
[09/23 20:51:53][INFO] visual_prompt:  327: Epoch 188 / 200: avg data time: 1.77e-02, avg batch time: 0.8938, average train loss: 1.0015average G loss: 0.2485, average realD loss: 3.4074, average fakeD loss: 1.9244, 
[09/23 20:51:55][INFO] visual_prompt:  441: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1170, average loss: 1.1412
[09/23 20:51:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 97.50	
[09/23 20:52:09][INFO] visual_prompt:  441: Inference (test):avg data time: 8.28e-05, avg batch time: 0.1237, average loss: 1.1327
[09/23 20:52:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.62	top5: 98.03	
[09/23 20:52:09][INFO] visual_prompt:  259: Training 189 / 200 epoch, with learning rate 0.006131260664122076
[09/23 20:53:25][INFO] visual_prompt:  327: Epoch 189 / 200: avg data time: 1.91e-02, avg batch time: 0.8953, average train loss: 1.0094average G loss: 0.2662, average realD loss: 3.2296, average fakeD loss: 1.7655, 
[09/23 20:53:27][INFO] visual_prompt:  441: Inference (val):avg data time: 7.03e-05, avg batch time: 0.1167, average loss: 1.1466
[09/23 20:53:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.67	
[09/23 20:53:40][INFO] visual_prompt:  441: Inference (test):avg data time: 7.73e-05, avg batch time: 0.1239, average loss: 1.1448
[09/23 20:53:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.52	top5: 98.15	
[09/23 20:53:40][INFO] visual_prompt:  259: Training 190 / 200 epoch, with learning rate 0.00515466410238051
[09/23 20:54:57][INFO] visual_prompt:  327: Epoch 190 / 200: avg data time: 1.87e-02, avg batch time: 0.8951, average train loss: 1.0228average G loss: 0.2807, average realD loss: 3.0626, average fakeD loss: 1.6324, 
[09/23 20:54:59][INFO] visual_prompt:  441: Inference (val):avg data time: 8.23e-05, avg batch time: 0.1168, average loss: 1.1494
[09/23 20:54:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.67	
[09/23 20:55:12][INFO] visual_prompt:  441: Inference (test):avg data time: 8.22e-05, avg batch time: 0.1239, average loss: 1.1485
[09/23 20:55:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.04	top5: 98.08	
[09/23 20:55:13][INFO] visual_prompt:  259: Training 191 / 200 epoch, with learning rate 0.004262092686649274
[09/23 20:56:29][INFO] visual_prompt:  327: Epoch 191 / 200: avg data time: 1.97e-02, avg batch time: 0.8956, average train loss: 0.9962average G loss: 0.2829, average realD loss: 2.8716, average fakeD loss: 1.5796, 
[09/23 20:56:31][INFO] visual_prompt:  441: Inference (val):avg data time: 6.10e-05, avg batch time: 0.1167, average loss: 1.1214
[09/23 20:56:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.17	
[09/23 20:56:45][INFO] visual_prompt:  441: Inference (test):avg data time: 8.49e-05, avg batch time: 0.1236, average loss: 1.1180
[09/23 20:56:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.04	top5: 98.05	
[09/23 20:56:45][INFO] visual_prompt:  259: Training 192 / 200 epoch, with learning rate 0.003453790437041096
[09/23 20:58:02][INFO] visual_prompt:  327: Epoch 192 / 200: avg data time: 1.90e-02, avg batch time: 0.8949, average train loss: 1.0143average G loss: 0.2946, average realD loss: 2.9429, average fakeD loss: 1.5121, 
[09/23 20:58:04][INFO] visual_prompt:  441: Inference (val):avg data time: 7.33e-05, avg batch time: 0.1167, average loss: 1.1586
[09/23 20:58:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.83	
[09/23 20:58:17][INFO] visual_prompt:  441: Inference (test):avg data time: 8.80e-05, avg batch time: 0.1237, average loss: 1.1548
[09/23 20:58:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.33	top5: 98.00	
[09/23 20:58:18][INFO] visual_prompt:  259: Training 193 / 200 epoch, with learning rate 0.0027299783353202517
[09/23 20:59:34][INFO] visual_prompt:  327: Epoch 193 / 200: avg data time: 1.73e-02, avg batch time: 0.8933, average train loss: 1.0051average G loss: 0.2998, average realD loss: 2.8317, average fakeD loss: 1.4866, 
[09/23 20:59:36][INFO] visual_prompt:  441: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1169, average loss: 1.1452
[09/23 20:59:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.67	
[09/23 20:59:50][INFO] visual_prompt:  441: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1238, average loss: 1.1395
[09/23 20:59:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.26	top5: 98.07	
[09/23 20:59:50][INFO] visual_prompt:  259: Training 194 / 200 epoch, with learning rate 0.0020908542644880804
[09/23 21:01:06][INFO] visual_prompt:  327: Epoch 194 / 200: avg data time: 1.90e-02, avg batch time: 0.8950, average train loss: 1.0013average G loss: 0.2953, average realD loss: 2.7188, average fakeD loss: 1.5025, 
[09/23 21:01:08][INFO] visual_prompt:  441: Inference (val):avg data time: 5.68e-05, avg batch time: 0.1167, average loss: 1.1374
[09/23 21:01:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.00	
[09/23 21:01:21][INFO] visual_prompt:  441: Inference (test):avg data time: 6.64e-05, avg batch time: 0.1238, average loss: 1.1294
[09/23 21:01:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.38	top5: 98.14	
[09/23 21:01:21][INFO] visual_prompt:  259: Training 195 / 200 epoch, with learning rate 0.0015365929546839324
[09/23 21:02:37][INFO] visual_prompt:  327: Epoch 195 / 200: avg data time: 1.79e-02, avg batch time: 0.8940, average train loss: 0.9804average G loss: 0.2906, average realD loss: 2.6581, average fakeD loss: 1.5106, 
[09/23 21:02:40][INFO] visual_prompt:  441: Inference (val):avg data time: 7.10e-05, avg batch time: 0.1168, average loss: 1.1298
[09/23 21:02:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.17	
[09/23 21:02:53][INFO] visual_prompt:  441: Inference (test):avg data time: 9.23e-05, avg batch time: 0.1239, average loss: 1.1214
[09/23 21:02:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.54	top5: 98.14	
[09/23 21:02:53][INFO] visual_prompt:  259: Training 196 / 200 epoch, with learning rate 0.0010673459354156728
[09/23 21:04:09][INFO] visual_prompt:  327: Epoch 196 / 200: avg data time: 1.86e-02, avg batch time: 0.8947, average train loss: 0.9735average G loss: 0.3017, average realD loss: 2.6101, average fakeD loss: 1.4709, 
[09/23 21:04:12][INFO] visual_prompt:  441: Inference (val):avg data time: 4.70e-05, avg batch time: 0.1168, average loss: 1.1297
[09/23 21:04:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.00	
[09/23 21:04:26][INFO] visual_prompt:  441: Inference (test):avg data time: 7.18e-05, avg batch time: 0.1234, average loss: 1.1220
[09/23 21:04:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.50	top5: 98.21	
[09/23 21:04:26][INFO] visual_prompt:  259: Training 197 / 200 epoch, with learning rate 0.0006832414941329579
[09/23 21:05:42][INFO] visual_prompt:  327: Epoch 197 / 200: avg data time: 1.80e-02, avg batch time: 0.8942, average train loss: 0.9778average G loss: 0.3026, average realD loss: 2.6580, average fakeD loss: 1.4646, 
[09/23 21:05:44][INFO] visual_prompt:  441: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1175, average loss: 1.1255
[09/23 21:05:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.00	
[09/23 21:05:57][INFO] visual_prompt:  441: Inference (test):avg data time: 8.29e-05, avg batch time: 0.1238, average loss: 1.1186
[09/23 21:05:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.49	top5: 98.24	
[09/23 21:05:57][INFO] visual_prompt:  259: Training 198 / 200 epoch, with learning rate 0.00038438464115476967
[09/23 21:07:13][INFO] visual_prompt:  327: Epoch 198 / 200: avg data time: 1.68e-02, avg batch time: 0.8934, average train loss: 0.9717average G loss: 0.3009, average realD loss: 2.6384, average fakeD loss: 1.4680, 
[09/23 21:07:16][INFO] visual_prompt:  441: Inference (val):avg data time: 6.83e-05, avg batch time: 0.1172, average loss: 1.1239
[09/23 21:07:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.17	
[09/23 21:07:30][INFO] visual_prompt:  441: Inference (test):avg data time: 7.77e-05, avg batch time: 0.1236, average loss: 1.1173
[09/23 21:07:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.49	top5: 98.24	
[09/23 21:07:30][INFO] visual_prompt:  259: Training 199 / 200 epoch, with learning rate 0.0001708570809606097
[09/23 21:08:46][INFO] visual_prompt:  327: Epoch 199 / 200: avg data time: 1.87e-02, avg batch time: 0.8953, average train loss: 0.9738average G loss: 0.2995, average realD loss: 2.5619, average fakeD loss: 1.4696, 
[09/23 21:08:48][INFO] visual_prompt:  441: Inference (val):avg data time: 6.67e-05, avg batch time: 0.1170, average loss: 1.1229
[09/23 21:08:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.17	
[09/23 21:09:02][INFO] visual_prompt:  441: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1238, average loss: 1.1165
[09/23 21:09:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.50	top5: 98.26	
[09/23 21:09:02][INFO] visual_prompt:  259: Training 200 / 200 epoch, with learning rate 4.27171898534362e-05
[09/23 21:10:18][INFO] visual_prompt:  327: Epoch 200 / 200: avg data time: 1.92e-02, avg batch time: 0.8958, average train loss: 0.9776average G loss: 0.3004, average realD loss: 2.6005, average fakeD loss: 1.4665, 
[09/23 21:10:21][INFO] visual_prompt:  441: Inference (val):avg data time: 8.06e-05, avg batch time: 0.1171, average loss: 1.1227
[09/23 21:10:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.17	
[09/23 21:10:34][INFO] visual_prompt:  441: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1239, average loss: 1.1163
[09/23 21:10:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.52	top5: 98.26	
