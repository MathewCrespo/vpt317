[09/23 00:37:29][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/23 00:37:29][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/23 00:37:29][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', './tst/1fake_epoch200', 'MODEL.TRANSFER_TYPE', 'prompt+gan', 'SOLVER.TOTAL_EPOCH', '200'], train_type='prompt')
[09/23 00:37:29][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/23 00:37:29][INFO] visual_prompt:  109: Training with config:
[09/23 00:37:29][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': './tst/1fake_epoch200/CUB/sup_vitb16_imagenet21k/lr1.25_wd0.0001/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 1.25,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 200,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/23 00:37:29][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/23 00:37:29][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/23 00:37:29][INFO] visual_prompt:   77: Number of images: 5394
[09/23 00:37:29][INFO] visual_prompt:   78: Number of classes: 200
[09/23 00:37:29][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/23 00:37:29][INFO] visual_prompt:   73: Loading validation data...
[09/23 00:37:29][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/23 00:37:29][INFO] visual_prompt:   77: Number of images: 600
[09/23 00:37:29][INFO] visual_prompt:   78: Number of classes: 200
[09/23 00:37:29][INFO] visual_prompt:   76: Loading test data...
[09/23 00:37:29][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/23 00:37:29][INFO] visual_prompt:   77: Number of images: 5794
[09/23 00:37:29][INFO] visual_prompt:   78: Number of classes: 200
[09/23 00:37:29][INFO] visual_prompt:  103: Constructing models...
[09/23 00:37:35][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/23 00:37:35][INFO] visual_prompt:   55: tuned percent:0.143
[09/23 00:37:35][INFO] visual_prompt:   41: Device used for model: 0
[09/23 00:37:35][INFO] visual_prompt:  106: Setting up Evalutator...
[09/23 00:37:35][INFO] visual_prompt:  108: Setting up Trainer...
[09/23 00:37:35][INFO] visual_prompt:   57: 	Setting up the optimizer...
[09/23 00:37:35][INFO] visual_prompt:  259: Training 1 / 200 epoch, with learning rate 0.0
[09/23 00:38:51][INFO] visual_prompt:  327: Epoch 1 / 200: avg data time: 1.83e-02, avg batch time: 0.8992, average train loss: 5.3311average G loss: 6.6223, average realD loss: 7.9482, average fakeD loss: 0.0052, 
[09/23 00:38:54][INFO] visual_prompt:  441: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1188, average loss: 5.3394
[09/23 00:38:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.00	top5: 1.83	
[09/23 00:39:07][INFO] visual_prompt:  441: Inference (test):avg data time: 7.06e-05, avg batch time: 0.1247, average loss: 5.3344
[09/23 00:39:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.26	top5: 2.00	
[09/23 00:39:07][INFO] visual_prompt:  259: Training 2 / 200 epoch, with learning rate 0.125
[09/23 00:40:23][INFO] visual_prompt:  327: Epoch 2 / 200: avg data time: 1.84e-02, avg batch time: 0.8969, average train loss: 5.3338average G loss: 0.0642, average realD loss: 0.2807, average fakeD loss: 98.8135, 
[09/23 00:40:26][INFO] visual_prompt:  441: Inference (val):avg data time: 4.91e-05, avg batch time: 0.1177, average loss: 5.3045
[09/23 00:40:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.33	
[09/23 00:40:39][INFO] visual_prompt:  441: Inference (test):avg data time: 6.59e-05, avg batch time: 0.1246, average loss: 5.3039
[09/23 00:40:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.73	
[09/23 00:40:39][INFO] visual_prompt:  363: Best epoch 2: best metric: 0.005
[09/23 00:40:39][INFO] visual_prompt:  259: Training 3 / 200 epoch, with learning rate 0.25
[09/23 00:41:55][INFO] visual_prompt:  327: Epoch 3 / 200: avg data time: 1.81e-02, avg batch time: 0.8965, average train loss: 5.3504average G loss: 0.0000, average realD loss: 0.0001, average fakeD loss: 100.0000, 
[09/23 00:41:58][INFO] visual_prompt:  441: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1175, average loss: 5.3200
[09/23 00:41:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 2.50	
[09/23 00:42:12][INFO] visual_prompt:  441: Inference (test):avg data time: 6.65e-05, avg batch time: 0.1245, average loss: 5.3201
[09/23 00:42:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.40	top5: 2.55	
[09/23 00:42:12][INFO] visual_prompt:  259: Training 4 / 200 epoch, with learning rate 0.375
[09/23 00:43:28][INFO] visual_prompt:  327: Epoch 4 / 200: avg data time: 2.03e-02, avg batch time: 0.8985, average train loss: 5.3529average G loss: 0.0000, average realD loss: 0.0001, average fakeD loss: 100.0000, 
[09/23 00:43:30][INFO] visual_prompt:  441: Inference (val):avg data time: 5.92e-05, avg batch time: 0.1177, average loss: 5.2997
[09/23 00:43:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 4.50	
[09/23 00:43:44][INFO] visual_prompt:  441: Inference (test):avg data time: 8.22e-05, avg batch time: 0.1245, average loss: 5.3037
[09/23 00:43:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.86	top5: 4.64	
[09/23 00:43:45][INFO] visual_prompt:  363: Best epoch 4: best metric: 0.007
[09/23 00:43:45][INFO] visual_prompt:  259: Training 5 / 200 epoch, with learning rate 0.5
[09/23 00:45:01][INFO] visual_prompt:  327: Epoch 5 / 200: avg data time: 1.73e-02, avg batch time: 0.8957, average train loss: 5.1894average G loss: 0.0000, average realD loss: 0.0000, average fakeD loss: 100.0000, 
[09/23 00:45:03][INFO] visual_prompt:  441: Inference (val):avg data time: 7.71e-05, avg batch time: 0.1176, average loss: 4.7909
[09/23 00:45:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 2.33	top5: 9.33	
[09/23 00:45:17][INFO] visual_prompt:  441: Inference (test):avg data time: 8.96e-05, avg batch time: 0.1248, average loss: 4.8026
[09/23 00:45:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 2.35	top5: 9.72	
[09/23 00:45:17][INFO] visual_prompt:  363: Best epoch 5: best metric: 0.023
[09/23 00:45:17][INFO] visual_prompt:  259: Training 6 / 200 epoch, with learning rate 0.625
[09/23 00:46:33][INFO] visual_prompt:  327: Epoch 6 / 200: avg data time: 2.05e-02, avg batch time: 0.8989, average train loss: 3.4698average G loss: 0.0197, average realD loss: 0.0067, average fakeD loss: 97.1165, 
[09/23 00:46:36][INFO] visual_prompt:  441: Inference (val):avg data time: 7.12e-05, avg batch time: 0.1176, average loss: 2.3052
[09/23 00:46:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 48.83	top5: 79.83	
[09/23 00:46:49][INFO] visual_prompt:  441: Inference (test):avg data time: 9.54e-05, avg batch time: 0.1246, average loss: 2.2418
[09/23 00:46:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 51.29	top5: 79.58	
[09/23 00:46:49][INFO] visual_prompt:  363: Best epoch 6: best metric: 0.488
[09/23 00:46:49][INFO] visual_prompt:  259: Training 7 / 200 epoch, with learning rate 0.75
[09/23 00:48:06][INFO] visual_prompt:  327: Epoch 7 / 200: avg data time: 1.96e-02, avg batch time: 0.9000, average train loss: 5.3223average G loss: 5.1382, average realD loss: 5.5161, average fakeD loss: 57.0833, 
[09/23 00:48:08][INFO] visual_prompt:  441: Inference (val):avg data time: 6.14e-05, avg batch time: 0.1181, average loss: 5.7461
[09/23 00:48:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/23 00:48:22][INFO] visual_prompt:  441: Inference (test):avg data time: 7.62e-05, avg batch time: 0.1247, average loss: 5.7487
[09/23 00:48:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/23 00:48:22][INFO] visual_prompt:  259: Training 8 / 200 epoch, with learning rate 0.875
[09/23 00:49:39][INFO] visual_prompt:  327: Epoch 8 / 200: avg data time: 1.89e-02, avg batch time: 0.8980, average train loss: 5.6418average G loss: 0.2889, average realD loss: 1.2065, average fakeD loss: 92.1639, 
[09/23 00:49:41][INFO] visual_prompt:  441: Inference (val):avg data time: 6.34e-05, avg batch time: 0.1175, average loss: 5.5638
[09/23 00:49:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 2.50	
[09/23 00:49:55][INFO] visual_prompt:  441: Inference (test):avg data time: 8.85e-05, avg batch time: 0.1246, average loss: 5.5539
[09/23 00:49:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.72	top5: 2.59	
[09/23 00:49:55][INFO] visual_prompt:  259: Training 9 / 200 epoch, with learning rate 1.0
[09/23 00:51:11][INFO] visual_prompt:  327: Epoch 9 / 200: avg data time: 1.90e-02, avg batch time: 0.8975, average train loss: 5.6286average G loss: 0.0000, average realD loss: 0.0612, average fakeD loss: 100.0000, 
[09/23 00:51:13][INFO] visual_prompt:  441: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1176, average loss: 5.5162
[09/23 00:51:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 3.17	
[09/23 00:51:27][INFO] visual_prompt:  441: Inference (test):avg data time: 6.82e-05, avg batch time: 0.1248, average loss: 5.5151
[09/23 00:51:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.78	top5: 3.26	
[09/23 00:51:27][INFO] visual_prompt:  259: Training 10 / 200 epoch, with learning rate 1.125
[09/23 00:52:43][INFO] visual_prompt:  327: Epoch 10 / 200: avg data time: 1.90e-02, avg batch time: 0.8975, average train loss: 5.5507average G loss: 0.0000, average realD loss: 0.0192, average fakeD loss: 100.0000, 
[09/23 00:52:45][INFO] visual_prompt:  441: Inference (val):avg data time: 6.88e-05, avg batch time: 0.1174, average loss: 5.5269
[09/23 00:52:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.67	top5: 3.33	
[09/23 00:52:59][INFO] visual_prompt:  441: Inference (test):avg data time: 1.00e-04, avg batch time: 0.1247, average loss: 5.5303
[09/23 00:52:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.54	top5: 3.21	
[09/23 00:52:59][INFO] visual_prompt:  259: Training 11 / 200 epoch, with learning rate 1.25
[09/23 00:54:16][INFO] visual_prompt:  327: Epoch 11 / 200: avg data time: 2.04e-02, avg batch time: 0.8990, average train loss: 4.6845average G loss: 0.0087, average realD loss: 0.0087, average fakeD loss: 98.9960, 
[09/23 00:54:18][INFO] visual_prompt:  441: Inference (val):avg data time: 6.04e-05, avg batch time: 0.1173, average loss: 1.7663
[09/23 00:54:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 56.50	top5: 82.50	
[09/23 00:54:32][INFO] visual_prompt:  441: Inference (test):avg data time: 9.86e-05, avg batch time: 0.1247, average loss: 1.7730
[09/23 00:54:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 55.20	top5: 81.76	
[09/23 00:54:32][INFO] visual_prompt:  363: Best epoch 11: best metric: 0.565
[09/23 00:54:32][INFO] visual_prompt:  259: Training 12 / 200 epoch, with learning rate 1.2499145656202932
[09/23 00:55:48][INFO] visual_prompt:  327: Epoch 12 / 200: avg data time: 1.95e-02, avg batch time: 0.8978, average train loss: 1.1389average G loss: 0.0083, average realD loss: 0.0174, average fakeD loss: 99.4693, 
[09/23 00:55:51][INFO] visual_prompt:  441: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1174, average loss: 0.9324
[09/23 00:55:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 75.83	top5: 93.33	
[09/23 00:56:04][INFO] visual_prompt:  441: Inference (test):avg data time: 9.90e-05, avg batch time: 0.1245, average loss: 0.9539
[09/23 00:56:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 75.11	top5: 94.18	
[09/23 00:56:04][INFO] visual_prompt:  363: Best epoch 12: best metric: 0.758
[09/23 00:56:04][INFO] visual_prompt:  259: Training 13 / 200 epoch, with learning rate 1.2496582858380787
[09/23 00:57:21][INFO] visual_prompt:  327: Epoch 13 / 200: avg data time: 1.95e-02, avg batch time: 0.8981, average train loss: 0.6780average G loss: 0.0080, average realD loss: 0.0055, average fakeD loss: 99.4502, 
[09/23 00:57:23][INFO] visual_prompt:  441: Inference (val):avg data time: 7.16e-05, avg batch time: 0.1174, average loss: 0.9726
[09/23 00:57:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 73.33	top5: 94.17	
[09/23 00:57:37][INFO] visual_prompt:  441: Inference (test):avg data time: 9.19e-05, avg batch time: 0.1246, average loss: 0.9902
[09/23 00:57:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 73.85	top5: 93.80	
[09/23 00:57:37][INFO] visual_prompt:  259: Training 14 / 200 epoch, with learning rate 1.2492312307176905
[09/23 00:58:54][INFO] visual_prompt:  327: Epoch 14 / 200: avg data time: 1.90e-02, avg batch time: 0.8974, average train loss: 0.5652average G loss: 0.0155, average realD loss: 0.0126, average fakeD loss: 99.1774, 
[09/23 00:58:56][INFO] visual_prompt:  441: Inference (val):avg data time: 8.00e-05, avg batch time: 0.1177, average loss: 0.7907
[09/23 00:58:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 95.33	
[09/23 00:59:10][INFO] visual_prompt:  441: Inference (test):avg data time: 8.46e-05, avg batch time: 0.1246, average loss: 0.8346
[09/23 00:59:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.82	top5: 94.86	
[09/23 00:59:10][INFO] visual_prompt:  363: Best epoch 14: best metric: 0.788
[09/23 00:59:10][INFO] visual_prompt:  259: Training 15 / 200 epoch, with learning rate 1.2486335170117342
[09/23 01:00:26][INFO] visual_prompt:  327: Epoch 15 / 200: avg data time: 1.91e-02, avg batch time: 0.8976, average train loss: 0.4883average G loss: 0.0071, average realD loss: 0.0071, average fakeD loss: 99.4242, 
[09/23 01:00:29][INFO] visual_prompt:  441: Inference (val):avg data time: 5.29e-05, avg batch time: 0.1179, average loss: 0.7251
[09/23 01:00:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 96.33	
[09/23 01:00:42][INFO] visual_prompt:  441: Inference (test):avg data time: 8.68e-05, avg batch time: 0.1244, average loss: 0.7095
[09/23 01:00:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.01	top5: 96.88	
[09/23 01:00:43][INFO] visual_prompt:  363: Best epoch 15: best metric: 0.807
[09/23 01:00:43][INFO] visual_prompt:  259: Training 16 / 200 epoch, with learning rate 1.2478653081291686
[09/23 01:01:59][INFO] visual_prompt:  327: Epoch 16 / 200: avg data time: 2.04e-02, avg batch time: 0.8989, average train loss: 0.4014average G loss: 0.0046, average realD loss: 0.0074, average fakeD loss: 99.2890, 
[09/23 01:02:01][INFO] visual_prompt:  441: Inference (val):avg data time: 7.57e-05, avg batch time: 0.1175, average loss: 0.6480
[09/23 01:02:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 96.83	
[09/23 01:02:15][INFO] visual_prompt:  441: Inference (test):avg data time: 8.31e-05, avg batch time: 0.1247, average loss: 0.6876
[09/23 01:02:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.22	top5: 97.17	
[09/23 01:02:15][INFO] visual_prompt:  363: Best epoch 16: best metric: 0.825
[09/23 01:02:15][INFO] visual_prompt:  259: Training 17 / 200 epoch, with learning rate 1.2469268140906322
[09/23 01:03:31][INFO] visual_prompt:  327: Epoch 17 / 200: avg data time: 2.06e-02, avg batch time: 0.8993, average train loss: 0.4201average G loss: 0.0120, average realD loss: 0.0255, average fakeD loss: 98.8876, 
[09/23 01:03:34][INFO] visual_prompt:  441: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1178, average loss: 0.6633
[09/23 01:03:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 96.67	
[09/23 01:03:47][INFO] visual_prompt:  441: Inference (test):avg data time: 6.89e-05, avg batch time: 0.1248, average loss: 0.6761
[09/23 01:03:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.12	top5: 96.91	
[09/23 01:03:47][INFO] visual_prompt:  259: Training 18 / 200 epoch, with learning rate 1.2458182914710239
[09/23 01:05:03][INFO] visual_prompt:  327: Epoch 18 / 200: avg data time: 1.85e-02, avg batch time: 0.8972, average train loss: 0.3819average G loss: 0.0119, average realD loss: 0.0219, average fakeD loss: 98.5276, 
[09/23 01:05:06][INFO] visual_prompt:  441: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1178, average loss: 0.7119
[09/23 01:05:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 96.50	
[09/23 01:05:19][INFO] visual_prompt:  441: Inference (test):avg data time: 7.73e-05, avg batch time: 0.1246, average loss: 0.7120
[09/23 01:05:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.22	top5: 96.19	
[09/23 01:05:19][INFO] visual_prompt:  259: Training 19 / 200 epoch, with learning rate 1.2445400433293594
[09/23 01:06:36][INFO] visual_prompt:  327: Epoch 19 / 200: avg data time: 1.89e-02, avg batch time: 0.8979, average train loss: 0.4467average G loss: 0.0217, average realD loss: 0.0889, average fakeD loss: 96.6009, 
[09/23 01:06:38][INFO] visual_prompt:  441: Inference (val):avg data time: 6.33e-05, avg batch time: 0.1180, average loss: 0.7906
[09/23 01:06:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 95.67	
[09/23 01:06:52][INFO] visual_prompt:  441: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1243, average loss: 0.8163
[09/23 01:06:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.81	top5: 95.70	
[09/23 01:06:52][INFO] visual_prompt:  259: Training 20 / 200 epoch, with learning rate 1.2430924191259178
[09/23 01:08:09][INFO] visual_prompt:  327: Epoch 20 / 200: avg data time: 1.90e-02, avg batch time: 0.8980, average train loss: 0.5013average G loss: 0.0244, average realD loss: 0.1895, average fakeD loss: 94.9256, 
[09/23 01:08:11][INFO] visual_prompt:  441: Inference (val):avg data time: 6.65e-05, avg batch time: 0.1184, average loss: 0.8027
[09/23 01:08:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.33	top5: 95.67	
[09/23 01:08:24][INFO] visual_prompt:  441: Inference (test):avg data time: 5.15e-05, avg batch time: 0.1245, average loss: 0.7741
[09/23 01:08:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.22	top5: 96.10	
[09/23 01:08:24][INFO] visual_prompt:  259: Training 21 / 200 epoch, with learning rate 1.2414758146267015
[09/23 01:09:41][INFO] visual_prompt:  327: Epoch 21 / 200: avg data time: 1.99e-02, avg batch time: 0.8986, average train loss: 0.4257average G loss: 0.0280, average realD loss: 0.1089, average fakeD loss: 97.3435, 
[09/23 01:09:43][INFO] visual_prompt:  441: Inference (val):avg data time: 6.50e-05, avg batch time: 0.1181, average loss: 0.7895
[09/23 01:09:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.33	top5: 97.50	
[09/23 01:09:57][INFO] visual_prompt:  441: Inference (test):avg data time: 9.68e-05, avg batch time: 0.1249, average loss: 0.7492
[09/23 01:09:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.75	top5: 96.70	
[09/23 01:09:57][INFO] visual_prompt:  259: Training 22 / 200 epoch, with learning rate 1.239690671795239
[09/23 01:11:14][INFO] visual_prompt:  327: Epoch 22 / 200: avg data time: 1.97e-02, avg batch time: 0.8986, average train loss: 0.3712average G loss: 0.0186, average realD loss: 0.0467, average fakeD loss: 98.1598, 
[09/23 01:11:16][INFO] visual_prompt:  441: Inference (val):avg data time: 9.68e-05, avg batch time: 0.1184, average loss: 0.7158
[09/23 01:11:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.17	
[09/23 01:11:31][INFO] visual_prompt:  441: Inference (test):avg data time: 7.07e-05, avg batch time: 0.1243, average loss: 0.7373
[09/23 01:11:31][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.72	top5: 96.29	
[09/23 01:11:31][INFO] visual_prompt:  259: Training 23 / 200 epoch, with learning rate 1.2377374786717559
[09/23 01:12:47][INFO] visual_prompt:  327: Epoch 23 / 200: avg data time: 1.96e-02, avg batch time: 0.8985, average train loss: 0.3859average G loss: 0.0169, average realD loss: 0.1379, average fakeD loss: 96.7090, 
[09/23 01:12:50][INFO] visual_prompt:  441: Inference (val):avg data time: 7.67e-05, avg batch time: 0.1176, average loss: 0.7671
[09/23 01:12:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.00	top5: 96.33	
[09/23 01:13:04][INFO] visual_prompt:  441: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1244, average loss: 0.7662
[09/23 01:13:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.79	top5: 95.86	
[09/23 01:13:04][INFO] visual_prompt:  259: Training 24 / 200 epoch, with learning rate 1.2356167692397495
[09/23 01:14:21][INFO] visual_prompt:  327: Epoch 24 / 200: avg data time: 2.10e-02, avg batch time: 0.8999, average train loss: 0.4545average G loss: 0.0332, average realD loss: 0.2455, average fakeD loss: 94.5429, 
[09/23 01:14:23][INFO] visual_prompt:  441: Inference (val):avg data time: 6.73e-05, avg batch time: 0.1173, average loss: 0.7558
[09/23 01:14:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 96.67	
[09/23 01:14:37][INFO] visual_prompt:  441: Inference (test):avg data time: 6.50e-05, avg batch time: 0.1245, average loss: 0.7608
[09/23 01:14:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.43	top5: 96.08	
[09/23 01:14:37][INFO] visual_prompt:  259: Training 25 / 200 epoch, with learning rate 1.2333291232800037
[09/23 01:15:53][INFO] visual_prompt:  327: Epoch 25 / 200: avg data time: 2.02e-02, avg batch time: 0.8991, average train loss: 0.4129average G loss: 0.0217, average realD loss: 0.0962, average fakeD loss: 96.9438, 
[09/23 01:15:56][INFO] visual_prompt:  441: Inference (val):avg data time: 5.45e-05, avg batch time: 0.1173, average loss: 0.7043
[09/23 01:15:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 97.00	
[09/23 01:16:09][INFO] visual_prompt:  441: Inference (test):avg data time: 7.77e-05, avg batch time: 0.1246, average loss: 0.6873
[09/23 01:16:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.69	top5: 96.69	
[09/23 01:16:10][INFO] visual_prompt:  259: Training 26 / 200 epoch, with learning rate 1.2308751662120816
[09/23 01:17:26][INFO] visual_prompt:  327: Epoch 26 / 200: avg data time: 2.03e-02, avg batch time: 0.8990, average train loss: 0.3612average G loss: 0.0160, average realD loss: 0.0824, average fakeD loss: 96.9258, 
[09/23 01:17:28][INFO] visual_prompt:  441: Inference (val):avg data time: 7.78e-05, avg batch time: 0.1177, average loss: 0.6642
[09/23 01:17:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.00	
[09/23 01:17:42][INFO] visual_prompt:  441: Inference (test):avg data time: 1.19e-04, avg batch time: 0.1247, average loss: 0.6688
[09/23 01:17:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.17	top5: 96.98	
[09/23 01:17:42][INFO] visual_prompt:  259: Training 27 / 200 epoch, with learning rate 1.228255568923343
[09/23 01:18:59][INFO] visual_prompt:  327: Epoch 27 / 200: avg data time: 1.94e-02, avg batch time: 0.8985, average train loss: 0.3740average G loss: 0.0199, average realD loss: 0.1336, average fakeD loss: 96.2275, 
[09/23 01:19:01][INFO] visual_prompt:  441: Inference (val):avg data time: 6.63e-05, avg batch time: 0.1175, average loss: 0.8100
[09/23 01:19:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 95.83	
[09/23 01:19:14][INFO] visual_prompt:  441: Inference (test):avg data time: 7.36e-05, avg batch time: 0.1246, average loss: 0.8036
[09/23 01:19:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.26	top5: 95.48	
[09/23 01:19:15][INFO] visual_prompt:  259: Training 28 / 200 epoch, with learning rate 1.2254710475855302
[09/23 01:20:31][INFO] visual_prompt:  327: Epoch 28 / 200: avg data time: 1.87e-02, avg batch time: 0.8976, average train loss: 0.4394average G loss: 0.0304, average realD loss: 0.0977, average fakeD loss: 97.4299, 
[09/23 01:20:33][INFO] visual_prompt:  441: Inference (val):avg data time: 7.87e-05, avg batch time: 0.1182, average loss: 0.6316
[09/23 01:20:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 97.67	
[09/23 01:20:47][INFO] visual_prompt:  441: Inference (test):avg data time: 7.67e-05, avg batch time: 0.1245, average loss: 0.6505
[09/23 01:20:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.77	top5: 97.19	
[09/23 01:20:47][INFO] visual_prompt:  259: Training 29 / 200 epoch, with learning rate 1.2225223634589735
[09/23 01:22:04][INFO] visual_prompt:  327: Epoch 29 / 200: avg data time: 1.94e-02, avg batch time: 0.8984, average train loss: 0.3714average G loss: 0.0223, average realD loss: 0.1345, average fakeD loss: 95.3750, 
[09/23 01:22:06][INFO] visual_prompt:  441: Inference (val):avg data time: 7.77e-05, avg batch time: 0.1178, average loss: 0.7989
[09/23 01:22:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 96.67	
[09/23 01:22:20][INFO] visual_prompt:  441: Inference (test):avg data time: 7.68e-05, avg batch time: 0.1246, average loss: 0.7747
[09/23 01:22:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.20	top5: 96.25	
[09/23 01:22:20][INFO] visual_prompt:  259: Training 30 / 200 epoch, with learning rate 1.219410322684471
[09/23 01:23:37][INFO] visual_prompt:  327: Epoch 30 / 200: avg data time: 1.86e-02, avg batch time: 0.8978, average train loss: 0.4213average G loss: 0.0247, average realD loss: 0.1551, average fakeD loss: 95.8606, 
[09/23 01:23:39][INFO] visual_prompt:  441: Inference (val):avg data time: 6.92e-05, avg batch time: 0.1175, average loss: 0.7781
[09/23 01:23:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.00	top5: 95.83	
[09/23 01:23:53][INFO] visual_prompt:  441: Inference (test):avg data time: 8.50e-05, avg batch time: 0.1246, average loss: 0.7649
[09/23 01:23:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.50	top5: 95.98	
[09/23 01:23:53][INFO] visual_prompt:  259: Training 31 / 200 epoch, with learning rate 1.2161357760628966
[09/23 01:25:10][INFO] visual_prompt:  327: Epoch 31 / 200: avg data time: 2.25e-02, avg batch time: 0.9019, average train loss: 0.3453average G loss: 0.0147, average realD loss: 0.1005, average fakeD loss: 97.1779, 
[09/23 01:25:12][INFO] visual_prompt:  441: Inference (val):avg data time: 7.04e-05, avg batch time: 0.1176, average loss: 0.6481
[09/23 01:25:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.33	
[09/23 01:25:26][INFO] visual_prompt:  441: Inference (test):avg data time: 9.72e-05, avg batch time: 0.1248, average loss: 0.6469
[09/23 01:25:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.48	top5: 97.36	
[09/23 01:25:26][INFO] visual_prompt:  259: Training 32 / 200 epoch, with learning rate 1.212699618822601
[09/23 01:26:42][INFO] visual_prompt:  327: Epoch 32 / 200: avg data time: 2.03e-02, avg batch time: 0.8998, average train loss: 0.3827average G loss: 0.0188, average realD loss: 0.1867, average fakeD loss: 94.9797, 
[09/23 01:26:45][INFO] visual_prompt:  441: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1185, average loss: 0.8207
[09/23 01:26:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.50	top5: 95.83	
[09/23 01:26:59][INFO] visual_prompt:  441: Inference (test):avg data time: 8.67e-05, avg batch time: 0.1245, average loss: 0.7866
[09/23 01:26:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.41	top5: 96.13	
[09/23 01:26:59][INFO] visual_prompt:  259: Training 33 / 200 epoch, with learning rate 1.209102790374663
[09/23 01:28:15][INFO] visual_prompt:  327: Epoch 33 / 200: avg data time: 1.90e-02, avg batch time: 0.8981, average train loss: 0.3238average G loss: 0.0135, average realD loss: 0.0519, average fakeD loss: 97.8761, 
[09/23 01:28:18][INFO] visual_prompt:  441: Inference (val):avg data time: 7.03e-05, avg batch time: 0.1174, average loss: 0.6502
[09/23 01:28:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 97.00	
[09/23 01:28:32][INFO] visual_prompt:  441: Inference (test):avg data time: 8.42e-05, avg batch time: 0.1247, average loss: 0.6721
[09/23 01:28:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.15	top5: 96.81	
[09/23 01:28:32][INFO] visual_prompt:  363: Best epoch 33: best metric: 0.838
[09/23 01:28:32][INFO] visual_prompt:  259: Training 34 / 200 epoch, with learning rate 1.205346274056067
[09/23 01:29:49][INFO] visual_prompt:  327: Epoch 34 / 200: avg data time: 2.05e-02, avg batch time: 0.8996, average train loss: 0.3430average G loss: 0.0198, average realD loss: 0.0656, average fakeD loss: 97.7006, 
[09/23 01:29:51][INFO] visual_prompt:  441: Inference (val):avg data time: 7.06e-05, avg batch time: 0.1176, average loss: 0.6736
[09/23 01:29:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 96.83	
[09/23 01:30:05][INFO] visual_prompt:  441: Inference (test):avg data time: 6.29e-05, avg batch time: 0.1246, average loss: 0.6622
[09/23 01:30:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.05	top5: 96.84	
[09/23 01:30:05][INFO] visual_prompt:  259: Training 35 / 200 epoch, with learning rate 1.2014310968608655
[09/23 01:31:21][INFO] visual_prompt:  327: Epoch 35 / 200: avg data time: 1.82e-02, avg batch time: 0.8978, average train loss: 0.3414average G loss: 0.0300, average realD loss: 0.1203, average fakeD loss: 95.6254, 
[09/23 01:31:24][INFO] visual_prompt:  441: Inference (val):avg data time: 6.60e-05, avg batch time: 0.1176, average loss: 0.7400
[09/23 01:31:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 96.33	
[09/23 01:31:37][INFO] visual_prompt:  441: Inference (test):avg data time: 6.17e-05, avg batch time: 0.1247, average loss: 0.7493
[09/23 01:31:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.79	top5: 96.08	
[09/23 01:31:38][INFO] visual_prompt:  259: Training 36 / 200 epoch, with learning rate 1.1973583291594108
[09/23 01:32:54][INFO] visual_prompt:  327: Epoch 36 / 200: avg data time: 2.06e-02, avg batch time: 0.9002, average train loss: 0.3503average G loss: 0.0287, average realD loss: 0.1293, average fakeD loss: 96.4546, 
[09/23 01:32:57][INFO] visual_prompt:  441: Inference (val):avg data time: 7.20e-05, avg batch time: 0.1177, average loss: 0.7361
[09/23 01:32:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 96.67	
[09/23 01:33:11][INFO] visual_prompt:  441: Inference (test):avg data time: 8.06e-05, avg batch time: 0.1247, average loss: 0.7233
[09/23 01:33:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.45	top5: 96.70	
[09/23 01:33:11][INFO] visual_prompt:  259: Training 37 / 200 epoch, with learning rate 1.1931290844057265
[09/23 01:34:27][INFO] visual_prompt:  327: Epoch 37 / 200: avg data time: 1.92e-02, avg batch time: 0.8987, average train loss: 0.4029average G loss: 0.0250, average realD loss: 0.1900, average fakeD loss: 94.7733, 
[09/23 01:34:30][INFO] visual_prompt:  441: Inference (val):avg data time: 8.36e-05, avg batch time: 0.1176, average loss: 0.6316
[09/23 01:34:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 98.00	
[09/23 01:34:44][INFO] visual_prompt:  441: Inference (test):avg data time: 7.82e-05, avg batch time: 0.1246, average loss: 0.6429
[09/23 01:34:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.48	top5: 97.17	
[09/23 01:34:44][INFO] visual_prompt:  259: Training 38 / 200 epoch, with learning rate 1.1887445188330994
[09/23 01:36:00][INFO] visual_prompt:  327: Epoch 38 / 200: avg data time: 2.01e-02, avg batch time: 0.8997, average train loss: 0.3306average G loss: 0.0143, average realD loss: 0.0892, average fakeD loss: 97.3603, 
[09/23 01:36:03][INFO] visual_prompt:  441: Inference (val):avg data time: 7.77e-05, avg batch time: 0.1175, average loss: 0.6748
[09/23 01:36:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 96.83	
[09/23 01:36:16][INFO] visual_prompt:  441: Inference (test):avg data time: 8.45e-05, avg batch time: 0.1247, average loss: 0.6720
[09/23 01:36:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.00	top5: 96.93	
[09/23 01:36:17][INFO] visual_prompt:  259: Training 39 / 200 epoch, with learning rate 1.184205831137977
[09/23 01:37:33][INFO] visual_prompt:  327: Epoch 39 / 200: avg data time: 1.98e-02, avg batch time: 0.8992, average train loss: 0.3265average G loss: 0.0196, average realD loss: 0.1239, average fakeD loss: 96.2494, 
[09/23 01:37:35][INFO] visual_prompt:  441: Inference (val):avg data time: 6.76e-05, avg batch time: 0.1176, average loss: 0.6668
[09/23 01:37:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.00	top5: 97.17	
[09/23 01:37:49][INFO] visual_prompt:  441: Inference (test):avg data time: 8.65e-05, avg batch time: 0.1245, average loss: 0.6552
[09/23 01:37:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.45	top5: 96.77	
[09/23 01:37:49][INFO] visual_prompt:  259: Training 40 / 200 epoch, with learning rate 1.1795142621522574
[09/23 01:39:06][INFO] visual_prompt:  327: Epoch 40 / 200: avg data time: 2.04e-02, avg batch time: 0.8997, average train loss: 0.3540average G loss: 0.0252, average realD loss: 0.1703, average fakeD loss: 95.1849, 
[09/23 01:39:08][INFO] visual_prompt:  441: Inference (val):avg data time: 5.51e-05, avg batch time: 0.1175, average loss: 0.6301
[09/23 01:39:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.00	top5: 97.67	
[09/23 01:39:22][INFO] visual_prompt:  441: Inference (test):avg data time: 7.97e-05, avg batch time: 0.1245, average loss: 0.6506
[09/23 01:39:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.95	top5: 97.34	
[09/23 01:39:22][INFO] visual_prompt:  259: Training 41 / 200 epoch, with learning rate 1.1746710945040557
[09/23 01:40:39][INFO] visual_prompt:  327: Epoch 41 / 200: avg data time: 1.84e-02, avg batch time: 0.8977, average train loss: 0.3235average G loss: 0.0178, average realD loss: 0.0759, average fakeD loss: 96.9930, 
[09/23 01:40:41][INFO] visual_prompt:  441: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1176, average loss: 0.6770
[09/23 01:40:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 98.00	
[09/23 01:40:55][INFO] visual_prompt:  441: Inference (test):avg data time: 8.33e-05, avg batch time: 0.1245, average loss: 0.7138
[09/23 01:40:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.93	top5: 96.57	
[09/23 01:40:55][INFO] visual_prompt:  259: Training 42 / 200 epoch, with learning rate 1.1696776522670482
[09/23 01:42:11][INFO] visual_prompt:  327: Epoch 42 / 200: avg data time: 1.87e-02, avg batch time: 0.8982, average train loss: 0.3406average G loss: 0.0219, average realD loss: 0.1179, average fakeD loss: 96.5207, 
[09/23 01:42:14][INFO] visual_prompt:  441: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1182, average loss: 0.7976
[09/23 01:42:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 78.83	top5: 95.33	
[09/23 01:42:27][INFO] visual_prompt:  441: Inference (test):avg data time: 7.49e-05, avg batch time: 0.1246, average loss: 0.7729
[09/23 01:42:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.57	top5: 95.65	
[09/23 01:42:27][INFO] visual_prompt:  259: Training 43 / 200 epoch, with learning rate 1.1645353005984838
[09/23 01:43:44][INFO] visual_prompt:  327: Epoch 43 / 200: avg data time: 1.90e-02, avg batch time: 0.8984, average train loss: 0.3319average G loss: 0.0236, average realD loss: 0.0831, average fakeD loss: 96.8265, 
[09/23 01:43:46][INFO] visual_prompt:  441: Inference (val):avg data time: 7.98e-05, avg batch time: 0.1178, average loss: 0.8949
[09/23 01:43:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.33	top5: 95.67	
[09/23 01:44:00][INFO] visual_prompt:  441: Inference (test):avg data time: 8.93e-05, avg batch time: 0.1247, average loss: 0.8777
[09/23 01:44:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 79.46	top5: 95.82	
[09/23 01:44:00][INFO] visual_prompt:  259: Training 44 / 200 epoch, with learning rate 1.159245445365962
[09/23 01:45:17][INFO] visual_prompt:  327: Epoch 44 / 200: avg data time: 1.99e-02, avg batch time: 0.8996, average train loss: 0.3996average G loss: 0.0316, average realD loss: 0.1762, average fakeD loss: 94.3217, 
[09/23 01:45:19][INFO] visual_prompt:  441: Inference (val):avg data time: 8.22e-05, avg batch time: 0.1187, average loss: 0.6824
[09/23 01:45:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.83	top5: 97.50	
[09/23 01:45:33][INFO] visual_prompt:  441: Inference (test):avg data time: 9.19e-05, avg batch time: 0.1246, average loss: 0.6488
[09/23 01:45:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.81	top5: 96.91	
[09/23 01:45:33][INFO] visual_prompt:  259: Training 45 / 200 epoch, with learning rate 1.1538095327630846
[09/23 01:46:50][INFO] visual_prompt:  327: Epoch 45 / 200: avg data time: 1.99e-02, avg batch time: 0.8993, average train loss: 0.3543average G loss: 0.0197, average realD loss: 0.1068, average fakeD loss: 97.0095, 
[09/23 01:46:52][INFO] visual_prompt:  441: Inference (val):avg data time: 7.00e-05, avg batch time: 0.1178, average loss: 0.6158
[09/23 01:46:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.67	
[09/23 01:47:06][INFO] visual_prompt:  441: Inference (test):avg data time: 7.56e-05, avg batch time: 0.1248, average loss: 0.6259
[09/23 01:47:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.00	top5: 96.72	
[09/23 01:47:06][INFO] visual_prompt:  259: Training 46 / 200 epoch, with learning rate 1.1482290489140803
[09/23 01:48:23][INFO] visual_prompt:  327: Epoch 46 / 200: avg data time: 2.05e-02, avg batch time: 0.9002, average train loss: 0.3254average G loss: 0.0153, average realD loss: 0.1005, average fakeD loss: 96.9154, 
[09/23 01:48:25][INFO] visual_prompt:  441: Inference (val):avg data time: 5.47e-05, avg batch time: 0.1179, average loss: 0.7160
[09/23 01:48:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.83	top5: 96.67	
[09/23 01:48:39][INFO] visual_prompt:  441: Inference (test):avg data time: 8.15e-05, avg batch time: 0.1246, average loss: 0.7022
[09/23 01:48:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.52	top5: 96.63	
[09/23 01:48:39][INFO] visual_prompt:  259: Training 47 / 200 epoch, with learning rate 1.1425055194675124
[09/23 01:49:55][INFO] visual_prompt:  327: Epoch 47 / 200: avg data time: 2.00e-02, avg batch time: 0.8990, average train loss: 0.3568average G loss: 0.0210, average realD loss: 0.1322, average fakeD loss: 96.2660, 
[09/23 01:49:58][INFO] visual_prompt:  441: Inference (val):avg data time: 6.02e-05, avg batch time: 0.1178, average loss: 0.6690
[09/23 01:49:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.33	top5: 96.67	
[09/23 01:50:11][INFO] visual_prompt:  441: Inference (test):avg data time: 7.67e-05, avg batch time: 0.1245, average loss: 0.6655
[09/23 01:50:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.27	top5: 97.19	
[09/23 01:50:12][INFO] visual_prompt:  259: Training 48 / 200 epoch, with learning rate 1.136640509179183
[09/23 01:51:28][INFO] visual_prompt:  327: Epoch 48 / 200: avg data time: 1.82e-02, avg batch time: 0.8968, average train loss: 0.3522average G loss: 0.0323, average realD loss: 0.1669, average fakeD loss: 95.0114, 
[09/23 01:51:30][INFO] visual_prompt:  441: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1175, average loss: 0.7668
[09/23 01:51:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 95.83	
[09/23 01:51:44][INFO] visual_prompt:  441: Inference (test):avg data time: 7.82e-05, avg batch time: 0.1244, average loss: 0.7295
[09/23 01:51:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.41	top5: 96.67	
[09/23 01:51:44][INFO] visual_prompt:  259: Training 49 / 200 epoch, with learning rate 1.130635621484342
[09/23 01:53:01][INFO] visual_prompt:  327: Epoch 49 / 200: avg data time: 1.90e-02, avg batch time: 0.8966, average train loss: 0.3475average G loss: 0.0249, average realD loss: 0.1844, average fakeD loss: 95.5845, 
[09/23 01:53:03][INFO] visual_prompt:  441: Inference (val):avg data time: 6.26e-05, avg batch time: 0.1173, average loss: 0.6688
[09/23 01:53:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 97.67	
[09/23 01:53:17][INFO] visual_prompt:  441: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1246, average loss: 0.6638
[09/23 01:53:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.60	top5: 97.46	
[09/23 01:53:17][INFO] visual_prompt:  259: Training 50 / 200 epoch, with learning rate 1.124492498059328
[09/23 01:54:34][INFO] visual_prompt:  327: Epoch 50 / 200: avg data time: 2.03e-02, avg batch time: 0.8977, average train loss: 0.3173average G loss: 0.0189, average realD loss: 0.1267, average fakeD loss: 96.7570, 
[09/23 01:54:36][INFO] visual_prompt:  441: Inference (val):avg data time: 6.74e-05, avg batch time: 0.1172, average loss: 0.6396
[09/23 01:54:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.83	
[09/23 01:54:50][INFO] visual_prompt:  441: Inference (test):avg data time: 7.47e-05, avg batch time: 0.1245, average loss: 0.6630
[09/23 01:54:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.19	top5: 97.08	
[09/23 01:54:50][INFO] visual_prompt:  259: Training 51 / 200 epoch, with learning rate 1.118212818372746
[09/23 01:56:06][INFO] visual_prompt:  327: Epoch 51 / 200: avg data time: 1.97e-02, avg batch time: 0.8976, average train loss: 0.3292average G loss: 0.0206, average realD loss: 0.1105, average fakeD loss: 96.5750, 
[09/23 01:56:09][INFO] visual_prompt:  441: Inference (val):avg data time: 7.19e-05, avg batch time: 0.1178, average loss: 0.6673
[09/23 01:56:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.33	
[09/23 01:56:22][INFO] visual_prompt:  441: Inference (test):avg data time: 7.57e-05, avg batch time: 0.1245, average loss: 0.6665
[09/23 01:56:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.91	top5: 97.10	
[09/23 01:56:22][INFO] visual_prompt:  259: Training 52 / 200 epoch, with learning rate 1.1117982992263205
[09/23 01:57:39][INFO] visual_prompt:  327: Epoch 52 / 200: avg data time: 1.92e-02, avg batch time: 0.8974, average train loss: 0.3559average G loss: 0.0221, average realD loss: 0.1576, average fakeD loss: 95.6953, 
[09/23 01:57:41][INFO] visual_prompt:  441: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1172, average loss: 0.7199
[09/23 01:57:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.00	
[09/23 01:57:55][INFO] visual_prompt:  441: Inference (test):avg data time: 8.00e-05, avg batch time: 0.1244, average loss: 0.7364
[09/23 01:57:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.36	top5: 96.22	
[09/23 01:57:55][INFO] visual_prompt:  259: Training 53 / 200 epoch, with learning rate 1.105250694285537
[09/23 01:59:11][INFO] visual_prompt:  327: Epoch 53 / 200: avg data time: 1.93e-02, avg batch time: 0.8965, average train loss: 0.3296average G loss: 0.0148, average realD loss: 0.0635, average fakeD loss: 97.3237, 
[09/23 01:59:14][INFO] visual_prompt:  441: Inference (val):avg data time: 7.51e-05, avg batch time: 0.1181, average loss: 0.6166
[09/23 01:59:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 97.67	
[09/23 01:59:27][INFO] visual_prompt:  441: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1242, average loss: 0.6496
[09/23 01:59:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.69	top5: 96.86	
[09/23 01:59:27][INFO] visual_prompt:  259: Training 54 / 200 epoch, with learning rate 1.0985717936002093
[09/23 02:00:44][INFO] visual_prompt:  327: Epoch 54 / 200: avg data time: 1.94e-02, avg batch time: 0.8960, average train loss: 0.3244average G loss: 0.0396, average realD loss: 0.1467, average fakeD loss: 95.0392, 
[09/23 02:00:46][INFO] visual_prompt:  441: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1171, average loss: 0.7064
[09/23 02:00:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.50	top5: 96.67	
[09/23 02:01:00][INFO] visual_prompt:  441: Inference (test):avg data time: 9.98e-05, avg batch time: 0.1242, average loss: 0.7168
[09/23 02:01:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.84	top5: 96.93	
[09/23 02:01:00][INFO] visual_prompt:  259: Training 55 / 200 epoch, with learning rate 1.091763423115096
[09/23 02:02:16][INFO] visual_prompt:  327: Epoch 55 / 200: avg data time: 1.93e-02, avg batch time: 0.8953, average train loss: 0.3181average G loss: 0.0213, average realD loss: 0.1040, average fakeD loss: 96.9353, 
[09/23 02:02:19][INFO] visual_prompt:  441: Inference (val):avg data time: 6.29e-05, avg batch time: 0.1173, average loss: 0.6491
[09/23 02:02:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 97.33	
[09/23 02:02:32][INFO] visual_prompt:  441: Inference (test):avg data time: 8.92e-05, avg batch time: 0.1239, average loss: 0.6452
[09/23 02:02:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.05	top5: 96.96	
[09/23 02:02:32][INFO] visual_prompt:  259: Training 56 / 200 epoch, with learning rate 1.0848274441707073
[09/23 02:03:48][INFO] visual_prompt:  327: Epoch 56 / 200: avg data time: 1.90e-02, avg batch time: 0.8942, average train loss: 0.3409average G loss: 0.0284, average realD loss: 0.1434, average fakeD loss: 96.3769, 
[09/23 02:03:51][INFO] visual_prompt:  441: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1171, average loss: 0.6016
[09/23 02:03:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.33	
[09/23 02:04:04][INFO] visual_prompt:  441: Inference (test):avg data time: 6.76e-05, avg batch time: 0.1238, average loss: 0.5982
[09/23 02:04:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.12	top5: 97.29	
[09/23 02:04:04][INFO] visual_prompt:  259: Training 57 / 200 epoch, with learning rate 1.0777657529944307
[09/23 02:05:20][INFO] visual_prompt:  327: Epoch 57 / 200: avg data time: 1.86e-02, avg batch time: 0.8926, average train loss: 0.3339average G loss: 0.0335, average realD loss: 0.2258, average fakeD loss: 93.3759, 
[09/23 02:05:23][INFO] visual_prompt:  441: Inference (val):avg data time: 6.02e-05, avg batch time: 0.1168, average loss: 0.8152
[09/23 02:05:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 77.83	top5: 96.50	
[09/23 02:05:36][INFO] visual_prompt:  441: Inference (test):avg data time: 8.52e-05, avg batch time: 0.1239, average loss: 0.7755
[09/23 02:05:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.84	top5: 96.03	
[09/23 02:05:36][INFO] visual_prompt:  259: Training 58 / 200 epoch, with learning rate 1.0705802801821231
[09/23 02:06:52][INFO] visual_prompt:  327: Epoch 58 / 200: avg data time: 1.93e-02, avg batch time: 0.8927, average train loss: 0.3521average G loss: 0.0221, average realD loss: 0.1068, average fakeD loss: 96.9851, 
[09/23 02:06:55][INFO] visual_prompt:  441: Inference (val):avg data time: 8.38e-05, avg batch time: 0.1169, average loss: 0.6423
[09/23 02:06:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.67	top5: 97.00	
[09/23 02:07:09][INFO] visual_prompt:  441: Inference (test):avg data time: 6.86e-05, avg batch time: 0.1237, average loss: 0.6331
[09/23 02:07:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.76	top5: 97.32	
[09/23 02:07:09][INFO] visual_prompt:  259: Training 59 / 200 epoch, with learning rate 1.0632729901703053
[09/23 02:08:25][INFO] visual_prompt:  327: Epoch 59 / 200: avg data time: 1.95e-02, avg batch time: 0.8937, average train loss: 0.2805average G loss: 0.0171, average realD loss: 0.1117, average fakeD loss: 96.3225, 
[09/23 02:08:27][INFO] visual_prompt:  441: Inference (val):avg data time: 8.46e-05, avg batch time: 0.1172, average loss: 0.7181
[09/23 02:08:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.17	top5: 96.50	
[09/23 02:08:41][INFO] visual_prompt:  441: Inference (test):avg data time: 7.03e-05, avg batch time: 0.1239, average loss: 0.6863
[09/23 02:08:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.19	top5: 97.17	
[09/23 02:08:41][INFO] visual_prompt:  259: Training 60 / 200 epoch, with learning rate 1.0558458806991036
[09/23 02:09:57][INFO] visual_prompt:  327: Epoch 60 / 200: avg data time: 1.98e-02, avg batch time: 0.8944, average train loss: 0.2812average G loss: 0.0254, average realD loss: 0.0906, average fakeD loss: 96.7897, 
[09/23 02:10:00][INFO] visual_prompt:  441: Inference (val):avg data time: 6.00e-05, avg batch time: 0.1168, average loss: 0.6120
[09/23 02:10:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.17	
[09/23 02:10:14][INFO] visual_prompt:  441: Inference (test):avg data time: 9.21e-05, avg batch time: 0.1238, average loss: 0.6247
[09/23 02:10:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.69	top5: 97.20	
[09/23 02:10:14][INFO] visual_prompt:  259: Training 61 / 200 epoch, with learning rate 1.0483009822660883
[09/23 02:11:30][INFO] visual_prompt:  327: Epoch 61 / 200: avg data time: 1.98e-02, avg batch time: 0.8937, average train loss: 0.3259average G loss: 0.0249, average realD loss: 0.1925, average fakeD loss: 94.1590, 
[09/23 02:11:32][INFO] visual_prompt:  441: Inference (val):avg data time: 7.37e-05, avg batch time: 0.1171, average loss: 0.6891
[09/23 02:11:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.83	top5: 97.17	
[09/23 02:11:46][INFO] visual_prompt:  441: Inference (test):avg data time: 7.45e-05, avg batch time: 0.1239, average loss: 0.7019
[09/23 02:11:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.74	top5: 97.26	
[09/23 02:11:46][INFO] visual_prompt:  259: Training 62 / 200 epoch, with learning rate 1.0406403575711551
[09/23 02:13:02][INFO] visual_prompt:  327: Epoch 62 / 200: avg data time: 1.91e-02, avg batch time: 0.8934, average train loss: 0.3331average G loss: 0.0247, average realD loss: 0.1789, average fakeD loss: 95.1046, 
[09/23 02:13:04][INFO] visual_prompt:  441: Inference (val):avg data time: 6.21e-05, avg batch time: 0.1168, average loss: 0.6739
[09/23 02:13:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 96.83	
[09/23 02:13:18][INFO] visual_prompt:  441: Inference (test):avg data time: 8.46e-05, avg batch time: 0.1239, average loss: 0.6841
[09/23 02:13:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.05	top5: 96.76	
[09/23 02:13:18][INFO] visual_prompt:  259: Training 63 / 200 epoch, with learning rate 1.0328661009526054
[09/23 02:14:35][INFO] visual_prompt:  327: Epoch 63 / 200: avg data time: 2.06e-02, avg batch time: 0.8940, average train loss: 0.2901average G loss: 0.0098, average realD loss: 0.1005, average fakeD loss: 97.2974, 
[09/23 02:14:37][INFO] visual_prompt:  441: Inference (val):avg data time: 5.54e-05, avg batch time: 0.1169, average loss: 0.8266
[09/23 02:14:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 96.33	
[09/23 02:14:50][INFO] visual_prompt:  441: Inference (test):avg data time: 7.85e-05, avg batch time: 0.1238, average loss: 0.8464
[09/23 02:14:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 80.19	top5: 95.58	
[09/23 02:14:50][INFO] visual_prompt:  259: Training 64 / 200 epoch, with learning rate 1.024980337814573
[09/23 02:16:06][INFO] visual_prompt:  327: Epoch 64 / 200: avg data time: 1.86e-02, avg batch time: 0.8920, average train loss: 0.3098average G loss: 0.0136, average realD loss: 0.1065, average fakeD loss: 97.5853, 
[09/23 02:16:09][INFO] visual_prompt:  441: Inference (val):avg data time: 6.22e-05, avg batch time: 0.1170, average loss: 0.6602
[09/23 02:16:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.50	
[09/23 02:16:23][INFO] visual_prompt:  441: Inference (test):avg data time: 1.16e-04, avg batch time: 0.1240, average loss: 0.6790
[09/23 02:16:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.03	top5: 97.07	
[09/23 02:16:23][INFO] visual_prompt:  259: Training 65 / 200 epoch, with learning rate 1.0169852240459607
[09/23 02:17:39][INFO] visual_prompt:  327: Epoch 65 / 200: avg data time: 1.94e-02, avg batch time: 0.8931, average train loss: 0.3131average G loss: 0.0191, average realD loss: 0.2101, average fakeD loss: 94.3775, 
[09/23 02:17:41][INFO] visual_prompt:  441: Inference (val):avg data time: 5.65e-05, avg batch time: 0.1179, average loss: 0.6911
[09/23 02:17:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 97.67	
[09/23 02:17:56][INFO] visual_prompt:  441: Inference (test):avg data time: 8.29e-05, avg batch time: 0.1239, average loss: 0.6736
[09/23 02:17:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.41	top5: 96.88	
[09/23 02:17:56][INFO] visual_prompt:  259: Training 66 / 200 epoch, with learning rate 1.0088829454310424
[09/23 02:19:12][INFO] visual_prompt:  327: Epoch 66 / 200: avg data time: 2.04e-02, avg batch time: 0.8944, average train loss: 0.2746average G loss: 0.0206, average realD loss: 0.0841, average fakeD loss: 97.2437, 
[09/23 02:19:14][INFO] visual_prompt:  441: Inference (val):avg data time: 5.04e-05, avg batch time: 0.1171, average loss: 0.6023
[09/23 02:19:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 97.83	
[09/23 02:19:28][INFO] visual_prompt:  441: Inference (test):avg data time: 8.47e-05, avg batch time: 0.1237, average loss: 0.5754
[09/23 02:19:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.67	top5: 97.70	
[09/23 02:19:28][INFO] visual_prompt:  259: Training 67 / 200 epoch, with learning rate 1.0006757170518907
[09/23 02:20:44][INFO] visual_prompt:  327: Epoch 67 / 200: avg data time: 2.00e-02, avg batch time: 0.8939, average train loss: 0.3037average G loss: 0.0249, average realD loss: 0.2673, average fakeD loss: 93.0149, 
[09/23 02:20:47][INFO] visual_prompt:  441: Inference (val):avg data time: 6.22e-05, avg batch time: 0.1171, average loss: 0.6099
[09/23 02:20:47][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 97.17	
[09/23 02:21:00][INFO] visual_prompt:  441: Inference (test):avg data time: 6.44e-05, avg batch time: 0.1239, average loss: 0.6324
[09/23 02:21:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.98	top5: 97.08	
[09/23 02:21:00][INFO] visual_prompt:  363: Best epoch 67: best metric: 0.843
[09/23 02:21:00][INFO] visual_prompt:  259: Training 68 / 200 epoch, with learning rate 0.9923657826827957
[09/23 02:22:17][INFO] visual_prompt:  327: Epoch 68 / 200: avg data time: 2.00e-02, avg batch time: 0.8940, average train loss: 0.3266average G loss: 0.0213, average realD loss: 0.1185, average fakeD loss: 96.8724, 
[09/23 02:22:19][INFO] visual_prompt:  441: Inference (val):avg data time: 7.03e-05, avg batch time: 0.1168, average loss: 0.5825
[09/23 02:22:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.33	
[09/23 02:22:33][INFO] visual_prompt:  441: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1239, average loss: 0.6061
[09/23 02:22:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.33	top5: 97.36	
[09/23 02:22:33][INFO] visual_prompt:  363: Best epoch 68: best metric: 0.845
[09/23 02:22:33][INFO] visual_prompt:  259: Training 69 / 200 epoch, with learning rate 0.9839554141768397
[09/23 02:23:49][INFO] visual_prompt:  327: Epoch 69 / 200: avg data time: 2.14e-02, avg batch time: 0.8946, average train loss: 0.2632average G loss: 0.0174, average realD loss: 0.1310, average fakeD loss: 95.7533, 
[09/23 02:23:52][INFO] visual_prompt:  441: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1166, average loss: 0.5975
[09/23 02:23:52][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 98.00	
[09/23 02:24:05][INFO] visual_prompt:  441: Inference (test):avg data time: 8.47e-05, avg batch time: 0.1237, average loss: 0.6080
[09/23 02:24:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.40	top5: 97.29	
[09/23 02:24:05][INFO] visual_prompt:  259: Training 70 / 200 epoch, with learning rate 0.9754469108447955
[09/23 02:25:21][INFO] visual_prompt:  327: Epoch 70 / 200: avg data time: 1.83e-02, avg batch time: 0.8921, average train loss: 0.2887average G loss: 0.0237, average realD loss: 0.2152, average fakeD loss: 94.0313, 
[09/23 02:25:24][INFO] visual_prompt:  441: Inference (val):avg data time: 6.81e-05, avg batch time: 0.1167, average loss: 0.6504
[09/23 02:25:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 97.33	
[09/23 02:25:38][INFO] visual_prompt:  441: Inference (test):avg data time: 7.30e-05, avg batch time: 0.1239, average loss: 0.6600
[09/23 02:25:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.05	top5: 97.08	
[09/23 02:25:38][INFO] visual_prompt:  259: Training 71 / 200 epoch, with learning rate 0.966842598826517
[09/23 02:26:54][INFO] visual_prompt:  327: Epoch 71 / 200: avg data time: 2.10e-02, avg batch time: 0.8950, average train loss: 0.2847average G loss: 0.0196, average realD loss: 0.0875, average fakeD loss: 96.4042, 
[09/23 02:26:56][INFO] visual_prompt:  441: Inference (val):avg data time: 4.52e-05, avg batch time: 0.1170, average loss: 0.6435
[09/23 02:26:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 97.33	
[09/23 02:27:10][INFO] visual_prompt:  441: Inference (test):avg data time: 8.01e-05, avg batch time: 0.1239, average loss: 0.6337
[09/23 02:27:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.43	top5: 96.95	
[09/23 02:27:10][INFO] visual_prompt:  259: Training 72 / 200 epoch, with learning rate 0.9581448304549961
[09/23 02:28:26][INFO] visual_prompt:  327: Epoch 72 / 200: avg data time: 1.90e-02, avg batch time: 0.8923, average train loss: 0.3075average G loss: 0.0200, average realD loss: 0.1428, average fakeD loss: 95.8283, 
[09/23 02:28:28][INFO] visual_prompt:  441: Inference (val):avg data time: 6.51e-05, avg batch time: 0.1170, average loss: 0.6288
[09/23 02:28:28][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 98.00	
[09/23 02:28:42][INFO] visual_prompt:  441: Inference (test):avg data time: 7.16e-05, avg batch time: 0.1238, average loss: 0.6238
[09/23 02:28:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.79	top5: 97.32	
[09/23 02:28:42][INFO] visual_prompt:  259: Training 73 / 200 epoch, with learning rate 0.9493559836132595
[09/23 02:29:58][INFO] visual_prompt:  327: Epoch 73 / 200: avg data time: 1.87e-02, avg batch time: 0.8914, average train loss: 0.2863average G loss: 0.0216, average realD loss: 0.0967, average fakeD loss: 96.6074, 
[09/23 02:30:01][INFO] visual_prompt:  441: Inference (val):avg data time: 5.33e-05, avg batch time: 0.1173, average loss: 0.7268
[09/23 02:30:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 95.67	
[09/23 02:30:14][INFO] visual_prompt:  441: Inference (test):avg data time: 8.23e-05, avg batch time: 0.1237, average loss: 0.7082
[09/23 02:30:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.79	top5: 96.88	
[09/23 02:30:14][INFO] visual_prompt:  259: Training 74 / 200 epoch, with learning rate 0.9404784610842775
[09/23 02:31:30][INFO] visual_prompt:  327: Epoch 74 / 200: avg data time: 2.19e-02, avg batch time: 0.8946, average train loss: 0.2887average G loss: 0.0186, average realD loss: 0.1897, average fakeD loss: 94.9475, 
[09/23 02:31:33][INFO] visual_prompt:  441: Inference (val):avg data time: 5.81e-05, avg batch time: 0.1172, average loss: 0.7627
[09/23 02:31:33][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.00	top5: 96.83	
[09/23 02:31:47][INFO] visual_prompt:  441: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1235, average loss: 0.7286
[09/23 02:31:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 82.07	top5: 96.76	
[09/23 02:31:47][INFO] visual_prompt:  259: Training 75 / 200 epoch, with learning rate 0.9315146898940676
[09/23 02:33:03][INFO] visual_prompt:  327: Epoch 75 / 200: avg data time: 2.04e-02, avg batch time: 0.8930, average train loss: 0.2919average G loss: 0.0204, average realD loss: 0.0630, average fakeD loss: 97.9305, 
[09/23 02:33:05][INFO] visual_prompt:  441: Inference (val):avg data time: 7.13e-05, avg batch time: 0.1176, average loss: 0.5711
[09/23 02:33:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.67	
[09/23 02:33:20][INFO] visual_prompt:  441: Inference (test):avg data time: 9.55e-05, avg batch time: 0.1240, average loss: 0.5797
[09/23 02:33:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.47	top5: 97.20	
[09/23 02:33:20][INFO] visual_prompt:  363: Best epoch 75: best metric: 0.847
[09/23 02:33:20][INFO] visual_prompt:  259: Training 76 / 200 epoch, with learning rate 0.922467120648171
[09/23 02:34:36][INFO] visual_prompt:  327: Epoch 76 / 200: avg data time: 1.87e-02, avg batch time: 0.8914, average train loss: 0.2401average G loss: 0.0082, average realD loss: 0.0452, average fakeD loss: 97.8615, 
[09/23 02:34:38][INFO] visual_prompt:  441: Inference (val):avg data time: 5.34e-05, avg batch time: 0.1176, average loss: 0.5677
[09/23 02:34:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 98.33	
[09/23 02:34:52][INFO] visual_prompt:  441: Inference (test):avg data time: 6.79e-05, avg batch time: 0.1236, average loss: 0.5870
[09/23 02:34:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.86	top5: 97.26	
[09/23 02:34:52][INFO] visual_prompt:  259: Training 77 / 200 epoch, with learning rate 0.9133382268616799
[09/23 02:36:08][INFO] visual_prompt:  327: Epoch 77 / 200: avg data time: 1.99e-02, avg batch time: 0.8929, average train loss: 0.2891average G loss: 0.0250, average realD loss: 0.2791, average fakeD loss: 91.8198, 
[09/23 02:36:10][INFO] visual_prompt:  441: Inference (val):avg data time: 7.86e-05, avg batch time: 0.1165, average loss: 0.6542
[09/23 02:36:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.00	
[09/23 02:36:24][INFO] visual_prompt:  441: Inference (test):avg data time: 7.85e-05, avg batch time: 0.1236, average loss: 0.6438
[09/23 02:36:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.23	top5: 97.13	
[09/23 02:36:24][INFO] visual_prompt:  259: Training 78 / 200 epoch, with learning rate 0.9041305042830041
[09/23 02:37:40][INFO] visual_prompt:  327: Epoch 78 / 200: avg data time: 2.06e-02, avg batch time: 0.8929, average train loss: 0.2802average G loss: 0.0102, average realD loss: 0.1166, average fakeD loss: 97.0469, 
[09/23 02:37:42][INFO] visual_prompt:  441: Inference (val):avg data time: 5.88e-05, avg batch time: 0.1169, average loss: 0.5559
[09/23 02:37:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/23 02:37:56][INFO] visual_prompt:  441: Inference (test):avg data time: 8.73e-05, avg batch time: 0.1238, average loss: 0.5616
[09/23 02:37:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.00	top5: 97.69	
[09/23 02:37:56][INFO] visual_prompt:  363: Best epoch 78: best metric: 0.857
[09/23 02:37:56][INFO] visual_prompt:  259: Training 79 / 200 epoch, with learning rate 0.8948464702115579
[09/23 02:39:12][INFO] visual_prompt:  327: Epoch 79 / 200: avg data time: 1.93e-02, avg batch time: 0.8921, average train loss: 0.2501average G loss: 0.0141, average realD loss: 0.0771, average fakeD loss: 97.3143, 
[09/23 02:39:14][INFO] visual_prompt:  441: Inference (val):avg data time: 1.11e-04, avg batch time: 0.1167, average loss: 0.5655
[09/23 02:39:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.50	
[09/23 02:39:28][INFO] visual_prompt:  441: Inference (test):avg data time: 8.69e-05, avg batch time: 0.1239, average loss: 0.5649
[09/23 02:39:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.23	top5: 97.51	
[09/23 02:39:28][INFO] visual_prompt:  259: Training 80 / 200 epoch, with learning rate 0.8854886628095565
[09/23 02:40:44][INFO] visual_prompt:  327: Epoch 80 / 200: avg data time: 1.93e-02, avg batch time: 0.8919, average train loss: 0.2570average G loss: 0.0157, average realD loss: 0.0615, average fakeD loss: 97.3256, 
[09/23 02:40:46][INFO] visual_prompt:  441: Inference (val):avg data time: 6.17e-05, avg batch time: 0.1167, average loss: 0.5392
[09/23 02:40:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.67	
[09/23 02:41:00][INFO] visual_prompt:  441: Inference (test):avg data time: 8.87e-05, avg batch time: 0.1239, average loss: 0.5720
[09/23 02:41:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.95	top5: 97.69	
[09/23 02:41:00][INFO] visual_prompt:  259: Training 81 / 200 epoch, with learning rate 0.876059640408106
[09/23 02:42:16][INFO] visual_prompt:  327: Epoch 81 / 200: avg data time: 1.93e-02, avg batch time: 0.8922, average train loss: 0.3120average G loss: 0.0282, average realD loss: 0.2172, average fakeD loss: 93.4762, 
[09/23 02:42:18][INFO] visual_prompt:  441: Inference (val):avg data time: 5.97e-05, avg batch time: 0.1167, average loss: 0.6282
[09/23 02:42:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 97.17	
[09/23 02:42:32][INFO] visual_prompt:  441: Inference (test):avg data time: 8.32e-05, avg batch time: 0.1238, average loss: 0.6170
[09/23 02:42:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.17	top5: 97.31	
[09/23 02:42:32][INFO] visual_prompt:  259: Training 82 / 200 epoch, with learning rate 0.8665619808077827
[09/23 02:43:48][INFO] visual_prompt:  327: Epoch 82 / 200: avg data time: 2.01e-02, avg batch time: 0.8926, average train loss: 0.3126average G loss: 0.0182, average realD loss: 0.1860, average fakeD loss: 96.0971, 
[09/23 02:43:50][INFO] visual_prompt:  441: Inference (val):avg data time: 4.87e-05, avg batch time: 0.1170, average loss: 0.5985
[09/23 02:43:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 97.33	
[09/23 02:44:04][INFO] visual_prompt:  441: Inference (test):avg data time: 8.32e-05, avg batch time: 0.1236, average loss: 0.6100
[09/23 02:44:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.90	top5: 97.34	
[09/23 02:44:04][INFO] visual_prompt:  259: Training 83 / 200 epoch, with learning rate 0.8569982805738879
[09/23 02:45:20][INFO] visual_prompt:  327: Epoch 83 / 200: avg data time: 1.92e-02, avg batch time: 0.8914, average train loss: 0.2499average G loss: 0.0099, average realD loss: 0.0879, average fakeD loss: 96.7653, 
[09/23 02:45:22][INFO] visual_prompt:  441: Inference (val):avg data time: 8.75e-05, avg batch time: 0.1168, average loss: 0.6834
[09/23 02:45:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 96.00	
[09/23 02:45:36][INFO] visual_prompt:  441: Inference (test):avg data time: 6.98e-05, avg batch time: 0.1237, average loss: 0.6574
[09/23 02:45:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.10	top5: 97.05	
[09/23 02:45:36][INFO] visual_prompt:  259: Training 84 / 200 epoch, with learning rate 0.8473711543265728
[09/23 02:46:52][INFO] visual_prompt:  327: Epoch 84 / 200: avg data time: 2.01e-02, avg batch time: 0.8926, average train loss: 0.2456average G loss: 0.0115, average realD loss: 0.1997, average fakeD loss: 94.5191, 
[09/23 02:46:54][INFO] visual_prompt:  441: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1166, average loss: 0.5622
[09/23 02:46:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 97.83	
[09/23 02:47:08][INFO] visual_prompt:  441: Inference (test):avg data time: 9.10e-05, avg batch time: 0.1237, average loss: 0.5915
[09/23 02:47:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.52	top5: 97.41	
[09/23 02:47:08][INFO] visual_prompt:  259: Training 85 / 200 epoch, with learning rate 0.837683234026027
[09/23 02:48:24][INFO] visual_prompt:  327: Epoch 85 / 200: avg data time: 2.08e-02, avg batch time: 0.8927, average train loss: 0.2809average G loss: 0.0160, average realD loss: 0.0835, average fakeD loss: 96.4661, 
[09/23 02:48:26][INFO] visual_prompt:  441: Inference (val):avg data time: 6.28e-05, avg batch time: 0.1169, average loss: 0.6056
[09/23 02:48:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 96.83	
[09/23 02:48:40][INFO] visual_prompt:  441: Inference (test):avg data time: 7.87e-05, avg batch time: 0.1236, average loss: 0.5857
[09/23 02:48:40][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.12	top5: 97.39	
[09/23 02:48:40][INFO] visual_prompt:  259: Training 86 / 200 epoch, with learning rate 0.8279371682529273
[09/23 02:49:56][INFO] visual_prompt:  327: Epoch 86 / 200: avg data time: 2.10e-02, avg batch time: 0.8928, average train loss: 0.2631average G loss: 0.0214, average realD loss: 0.1342, average fakeD loss: 95.2864, 
[09/23 02:49:59][INFO] visual_prompt:  441: Inference (val):avg data time: 6.32e-05, avg batch time: 0.1164, average loss: 0.6410
[09/23 02:49:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 97.50	
[09/23 02:50:13][INFO] visual_prompt:  441: Inference (test):avg data time: 8.64e-05, avg batch time: 0.1234, average loss: 0.6227
[09/23 02:50:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.93	top5: 97.32	
[09/23 02:50:13][INFO] visual_prompt:  363: Best epoch 86: best metric: 0.858
[09/23 02:50:13][INFO] visual_prompt:  259: Training 87 / 200 epoch, with learning rate 0.8181356214843422
[09/23 02:51:29][INFO] visual_prompt:  327: Epoch 87 / 200: avg data time: 2.00e-02, avg batch time: 0.8924, average train loss: 0.3749average G loss: 0.0391, average realD loss: 0.3399, average fakeD loss: 91.7200, 
[09/23 02:51:31][INFO] visual_prompt:  441: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1167, average loss: 0.5794
[09/23 02:51:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.50	
[09/23 02:51:45][INFO] visual_prompt:  441: Inference (test):avg data time: 8.10e-05, avg batch time: 0.1239, average loss: 0.5620
[09/23 02:51:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.43	top5: 97.70	
[09/23 02:51:45][INFO] visual_prompt:  259: Training 88 / 200 epoch, with learning rate 0.8082812733652905
[09/23 02:53:01][INFO] visual_prompt:  327: Epoch 88 / 200: avg data time: 1.92e-02, avg batch time: 0.8913, average train loss: 0.2564average G loss: 0.0135, average realD loss: 0.0868, average fakeD loss: 97.3162, 
[09/23 02:53:03][INFO] visual_prompt:  441: Inference (val):avg data time: 7.21e-05, avg batch time: 0.1170, average loss: 0.5646
[09/23 02:53:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.33	
[09/23 02:53:17][INFO] visual_prompt:  441: Inference (test):avg data time: 8.34e-05, avg batch time: 0.1236, average loss: 0.5586
[09/23 02:53:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.74	top5: 97.79	
[09/23 02:53:17][INFO] visual_prompt:  259: Training 89 / 200 epoch, with learning rate 0.7983768179761529
[09/23 02:54:33][INFO] visual_prompt:  327: Epoch 89 / 200: avg data time: 1.88e-02, avg batch time: 0.8910, average train loss: 0.2209average G loss: 0.0095, average realD loss: 0.0729, average fakeD loss: 96.9165, 
[09/23 02:54:36][INFO] visual_prompt:  441: Inference (val):avg data time: 6.56e-05, avg batch time: 0.1169, average loss: 0.5547
[09/23 02:54:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.17	
[09/23 02:54:49][INFO] visual_prompt:  441: Inference (test):avg data time: 9.54e-05, avg batch time: 0.1235, average loss: 0.5363
[09/23 02:54:49][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.47	top5: 97.72	
[09/23 02:54:49][INFO] visual_prompt:  259: Training 90 / 200 epoch, with learning rate 0.7884249630961373
[09/23 02:56:05][INFO] visual_prompt:  327: Epoch 90 / 200: avg data time: 2.18e-02, avg batch time: 0.8945, average train loss: 0.2580average G loss: 0.0182, average realD loss: 0.1954, average fakeD loss: 94.1798, 
[09/23 02:56:08][INFO] visual_prompt:  441: Inference (val):avg data time: 9.60e-05, avg batch time: 0.1169, average loss: 0.7766
[09/23 02:56:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.67	top5: 97.17	
[09/23 02:56:21][INFO] visual_prompt:  441: Inference (test):avg data time: 1.09e-04, avg batch time: 0.1239, average loss: 0.7630
[09/23 02:56:21][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.00	top5: 96.58	
[09/23 02:56:21][INFO] visual_prompt:  259: Training 91 / 200 epoch, with learning rate 0.7784284294629995
[09/23 02:57:37][INFO] visual_prompt:  327: Epoch 91 / 200: avg data time: 1.90e-02, avg batch time: 0.8923, average train loss: 0.2703average G loss: 0.0155, average realD loss: 0.1293, average fakeD loss: 96.6411, 
[09/23 02:57:40][INFO] visual_prompt:  441: Inference (val):avg data time: 6.80e-05, avg batch time: 0.1171, average loss: 0.5533
[09/23 02:57:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 98.00	
[09/23 02:57:53][INFO] visual_prompt:  441: Inference (test):avg data time: 8.79e-05, avg batch time: 0.1239, average loss: 0.5520
[09/23 02:57:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.40	top5: 97.72	
[09/23 02:57:53][INFO] visual_prompt:  259: Training 92 / 200 epoch, with learning rate 0.7683899500292197
[09/23 02:59:09][INFO] visual_prompt:  327: Epoch 92 / 200: avg data time: 1.87e-02, avg batch time: 0.8928, average train loss: 0.2505average G loss: 0.0247, average realD loss: 0.1952, average fakeD loss: 93.6310, 
[09/23 02:59:12][INFO] visual_prompt:  441: Inference (val):avg data time: 5.65e-05, avg batch time: 0.1172, average loss: 0.6679
[09/23 02:59:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 97.67	
[09/23 02:59:26][INFO] visual_prompt:  441: Inference (test):avg data time: 8.79e-05, avg batch time: 0.1237, average loss: 0.6554
[09/23 02:59:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.05	top5: 97.31	
[09/23 02:59:26][INFO] visual_prompt:  259: Training 93 / 200 epoch, with learning rate 0.7583122692148418
[09/23 03:00:42][INFO] visual_prompt:  327: Epoch 93 / 200: avg data time: 1.92e-02, avg batch time: 0.8936, average train loss: 0.2823average G loss: 0.0204, average realD loss: 0.1694, average fakeD loss: 94.9099, 
[09/23 03:00:44][INFO] visual_prompt:  441: Inference (val):avg data time: 6.31e-05, avg batch time: 0.1169, average loss: 0.5726
[09/23 03:00:44][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 97.67	
[09/23 03:00:58][INFO] visual_prompt:  441: Inference (test):avg data time: 8.82e-05, avg batch time: 0.1238, average loss: 0.5801
[09/23 03:00:58][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.47	top5: 97.43	
[09/23 03:00:58][INFO] visual_prompt:  259: Training 94 / 200 epoch, with learning rate 0.7481981421571751
[09/23 03:02:14][INFO] visual_prompt:  327: Epoch 94 / 200: avg data time: 1.93e-02, avg batch time: 0.8940, average train loss: 0.2572average G loss: 0.0226, average realD loss: 0.2731, average fakeD loss: 92.2136, 
[09/23 03:02:16][INFO] visual_prompt:  441: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1168, average loss: 0.5272
[09/23 03:02:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.50	
[09/23 03:02:30][INFO] visual_prompt:  441: Inference (test):avg data time: 8.24e-05, avg batch time: 0.1238, average loss: 0.5583
[09/23 03:02:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.98	top5: 97.69	
[09/23 03:02:30][INFO] visual_prompt:  363: Best epoch 94: best metric: 0.860
[09/23 03:02:30][INFO] visual_prompt:  259: Training 95 / 200 epoch, with learning rate 0.7380503339575688
[09/23 03:03:46][INFO] visual_prompt:  327: Epoch 95 / 200: avg data time: 1.98e-02, avg batch time: 0.8945, average train loss: 0.2604average G loss: 0.0118, average realD loss: 0.0899, average fakeD loss: 97.2728, 
[09/23 03:03:49][INFO] visual_prompt:  441: Inference (val):avg data time: 9.85e-05, avg batch time: 0.1169, average loss: 0.5270
[09/23 03:03:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.50	
[09/23 03:04:02][INFO] visual_prompt:  441: Inference (test):avg data time: 7.37e-05, avg batch time: 0.1239, average loss: 0.5356
[09/23 03:04:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.07	top5: 97.79	
[09/23 03:04:02][INFO] visual_prompt:  259: Training 96 / 200 epoch, with learning rate 0.7278716189254587
[09/23 03:05:18][INFO] visual_prompt:  327: Epoch 96 / 200: avg data time: 1.89e-02, avg batch time: 0.8939, average train loss: 0.2151average G loss: 0.0178, average realD loss: 0.1062, average fakeD loss: 96.2387, 
[09/23 03:05:21][INFO] visual_prompt:  441: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1168, average loss: 0.7844
[09/23 03:05:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.00	
[09/23 03:05:35][INFO] visual_prompt:  441: Inference (test):avg data time: 1.01e-04, avg batch time: 0.1240, average loss: 0.7649
[09/23 03:05:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.05	top5: 97.05	
[09/23 03:05:35][INFO] visual_prompt:  259: Training 97 / 200 epoch, with learning rate 0.7176647798199012
[09/23 03:06:51][INFO] visual_prompt:  327: Epoch 97 / 200: avg data time: 1.87e-02, avg batch time: 0.8937, average train loss: 0.3176average G loss: 0.0259, average realD loss: 0.2280, average fakeD loss: 93.1576, 
[09/23 03:06:54][INFO] visual_prompt:  441: Inference (val):avg data time: 9.01e-05, avg batch time: 0.1170, average loss: 0.6588
[09/23 03:06:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.17	
[09/23 03:07:08][INFO] visual_prompt:  441: Inference (test):avg data time: 9.06e-05, avg batch time: 0.1237, average loss: 0.6445
[09/23 03:07:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.66	top5: 97.31	
[09/23 03:07:08][INFO] visual_prompt:  259: Training 98 / 200 epoch, with learning rate 0.7074326070887932
[09/23 03:08:24][INFO] visual_prompt:  327: Epoch 98 / 200: avg data time: 1.96e-02, avg batch time: 0.8940, average train loss: 0.2690average G loss: 0.0150, average realD loss: 0.1357, average fakeD loss: 95.7914, 
[09/23 03:08:27][INFO] visual_prompt:  441: Inference (val):avg data time: 7.32e-05, avg batch time: 0.1175, average loss: 0.5295
[09/23 03:08:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.17	
[09/23 03:08:41][INFO] visual_prompt:  441: Inference (test):avg data time: 7.46e-05, avg batch time: 0.1237, average loss: 0.5356
[09/23 03:08:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.18	top5: 97.64	
[09/23 03:08:41][INFO] visual_prompt:  363: Best epoch 98: best metric: 0.865
[09/23 03:08:41][INFO] visual_prompt:  259: Training 99 / 200 epoch, with learning rate 0.6971778981059915
[09/23 03:09:57][INFO] visual_prompt:  327: Epoch 99 / 200: avg data time: 2.12e-02, avg batch time: 0.8954, average train loss: 0.2470average G loss: 0.0232, average realD loss: 0.1745, average fakeD loss: 94.3545, 
[09/23 03:09:59][INFO] visual_prompt:  441: Inference (val):avg data time: 6.97e-05, avg batch time: 0.1169, average loss: 0.6629
[09/23 03:09:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.83	top5: 97.17	
[09/23 03:10:13][INFO] visual_prompt:  441: Inference (test):avg data time: 8.75e-05, avg batch time: 0.1237, average loss: 0.6358
[09/23 03:10:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.48	top5: 97.22	
[09/23 03:10:13][INFO] visual_prompt:  259: Training 100 / 200 epoch, with learning rate 0.6869034564065393
[09/23 03:11:29][INFO] visual_prompt:  327: Epoch 100 / 200: avg data time: 2.13e-02, avg batch time: 0.8943, average train loss: 0.2617average G loss: 0.0196, average realD loss: 0.1394, average fakeD loss: 95.8615, 
[09/23 03:11:32][INFO] visual_prompt:  441: Inference (val):avg data time: 5.92e-05, avg batch time: 0.1167, average loss: 0.5597
[09/23 03:11:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 97.83	
[09/23 03:11:46][INFO] visual_prompt:  441: Inference (test):avg data time: 8.04e-05, avg batch time: 0.1240, average loss: 0.5487
[09/23 03:11:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.18	top5: 97.65	
[09/23 03:11:46][INFO] visual_prompt:  259: Training 101 / 200 epoch, with learning rate 0.6766120909202078
[09/23 03:13:02][INFO] visual_prompt:  327: Epoch 101 / 200: avg data time: 2.08e-02, avg batch time: 0.8934, average train loss: 0.2101average G loss: 0.0114, average realD loss: 0.0812, average fakeD loss: 96.7862, 
[09/23 03:13:04][INFO] visual_prompt:  441: Inference (val):avg data time: 6.53e-05, avg batch time: 0.1167, average loss: 0.6232
[09/23 03:13:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 98.17	
[09/23 03:13:18][INFO] visual_prompt:  441: Inference (test):avg data time: 8.37e-05, avg batch time: 0.1238, average loss: 0.5817
[09/23 03:13:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.11	top5: 97.64	
[09/23 03:13:18][INFO] visual_prompt:  259: Training 102 / 200 epoch, with learning rate 0.6663066152035622
[09/23 03:14:34][INFO] visual_prompt:  327: Epoch 102 / 200: avg data time: 1.95e-02, avg batch time: 0.8921, average train loss: 0.2148average G loss: 0.0150, average realD loss: 0.2068, average fakeD loss: 93.1469, 
[09/23 03:14:37][INFO] visual_prompt:  441: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1168, average loss: 0.7411
[09/23 03:14:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.33	top5: 97.33	
[09/23 03:14:51][INFO] visual_prompt:  441: Inference (test):avg data time: 8.81e-05, avg batch time: 0.1239, average loss: 0.7127
[09/23 03:14:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.60	top5: 97.10	
[09/23 03:14:51][INFO] visual_prompt:  259: Training 103 / 200 epoch, with learning rate 0.6559898466707639
[09/23 03:16:07][INFO] visual_prompt:  327: Epoch 103 / 200: avg data time: 1.98e-02, avg batch time: 0.8918, average train loss: 0.2720average G loss: 0.0201, average realD loss: 0.3148, average fakeD loss: 92.3596, 
[09/23 03:16:09][INFO] visual_prompt:  441: Inference (val):avg data time: 7.34e-05, avg batch time: 0.1166, average loss: 0.6830
[09/23 03:16:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.33	
[09/23 03:16:23][INFO] visual_prompt:  441: Inference (test):avg data time: 9.47e-05, avg batch time: 0.1236, average loss: 0.6686
[09/23 03:16:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.40	top5: 97.27	
[09/23 03:16:23][INFO] visual_prompt:  259: Training 104 / 200 epoch, with learning rate 0.6456646058233175
[09/23 03:17:39][INFO] visual_prompt:  327: Epoch 104 / 200: avg data time: 1.81e-02, avg batch time: 0.8900, average train loss: 0.2342average G loss: 0.0127, average realD loss: 0.1178, average fakeD loss: 96.6001, 
[09/23 03:17:41][INFO] visual_prompt:  441: Inference (val):avg data time: 8.47e-05, avg batch time: 0.1167, average loss: 0.5174
[09/23 03:17:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.00	
[09/23 03:17:55][INFO] visual_prompt:  441: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1237, average loss: 0.5215
[09/23 03:17:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.14	top5: 97.89	
[09/23 03:17:55][INFO] visual_prompt:  363: Best epoch 104: best metric: 0.870
[09/23 03:17:55][INFO] visual_prompt:  259: Training 105 / 200 epoch, with learning rate 0.6353337154789741
[09/23 03:19:11][INFO] visual_prompt:  327: Epoch 105 / 200: avg data time: 1.98e-02, avg batch time: 0.8917, average train loss: 0.1990average G loss: 0.0128, average realD loss: 0.1063, average fakeD loss: 95.7734, 
[09/23 03:19:14][INFO] visual_prompt:  441: Inference (val):avg data time: 8.44e-05, avg batch time: 0.1169, average loss: 0.5269
[09/23 03:19:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.67	top5: 98.17	
[09/23 03:19:27][INFO] visual_prompt:  441: Inference (test):avg data time: 7.77e-05, avg batch time: 0.1236, average loss: 0.5287
[09/23 03:19:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.02	top5: 97.79	
[09/23 03:19:28][INFO] visual_prompt:  259: Training 106 / 200 epoch, with learning rate 0.625
[09/23 03:20:44][INFO] visual_prompt:  327: Epoch 106 / 200: avg data time: 2.04e-02, avg batch time: 0.8928, average train loss: 0.2343average G loss: 0.0199, average realD loss: 0.1505, average fakeD loss: 94.8021, 
[09/23 03:20:46][INFO] visual_prompt:  441: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1168, average loss: 0.5282
[09/23 03:20:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.17	
[09/23 03:21:00][INFO] visual_prompt:  441: Inference (test):avg data time: 8.35e-05, avg batch time: 0.1237, average loss: 0.5216
[09/23 03:21:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.47	top5: 97.55	
[09/23 03:21:00][INFO] visual_prompt:  363: Best epoch 106: best metric: 0.875
[09/23 03:21:00][INFO] visual_prompt:  259: Training 107 / 200 epoch, with learning rate 0.6146662845210259
[09/23 03:22:16][INFO] visual_prompt:  327: Epoch 107 / 200: avg data time: 2.16e-02, avg batch time: 0.8940, average train loss: 0.2826average G loss: 0.0313, average realD loss: 0.3027, average fakeD loss: 91.1133, 
[09/23 03:22:19][INFO] visual_prompt:  441: Inference (val):avg data time: 6.09e-05, avg batch time: 0.1176, average loss: 0.5879
[09/23 03:22:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 97.67	
[09/23 03:22:32][INFO] visual_prompt:  441: Inference (test):avg data time: 6.91e-05, avg batch time: 0.1238, average loss: 0.5752
[09/23 03:22:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.12	top5: 97.67	
[09/23 03:22:32][INFO] visual_prompt:  259: Training 108 / 200 epoch, with learning rate 0.6043353941766824
[09/23 03:23:48][INFO] visual_prompt:  327: Epoch 108 / 200: avg data time: 1.95e-02, avg batch time: 0.8922, average train loss: 0.2501average G loss: 0.0143, average realD loss: 0.1782, average fakeD loss: 94.5517, 
[09/23 03:23:50][INFO] visual_prompt:  441: Inference (val):avg data time: 7.08e-05, avg batch time: 0.1168, average loss: 0.5955
[09/23 03:23:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.83	
[09/23 03:24:03][INFO] visual_prompt:  441: Inference (test):avg data time: 7.54e-05, avg batch time: 0.1239, average loss: 0.5636
[09/23 03:24:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.43	top5: 97.70	
[09/23 03:24:04][INFO] visual_prompt:  259: Training 109 / 200 epoch, with learning rate 0.594010153329236
[09/23 03:25:19][INFO] visual_prompt:  327: Epoch 109 / 200: avg data time: 1.99e-02, avg batch time: 0.8923, average train loss: 0.2134average G loss: 0.0171, average realD loss: 0.1358, average fakeD loss: 95.3444, 
[09/23 03:25:22][INFO] visual_prompt:  441: Inference (val):avg data time: 7.80e-05, avg batch time: 0.1168, average loss: 0.5920
[09/23 03:25:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 97.83	
[09/23 03:25:35][INFO] visual_prompt:  441: Inference (test):avg data time: 6.56e-05, avg batch time: 0.1235, average loss: 0.5709
[09/23 03:25:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.37	top5: 97.48	
[09/23 03:25:35][INFO] visual_prompt:  259: Training 110 / 200 epoch, with learning rate 0.5836933847964378
[09/23 03:26:51][INFO] visual_prompt:  327: Epoch 110 / 200: avg data time: 1.80e-02, avg batch time: 0.8899, average train loss: 0.2122average G loss: 0.0133, average realD loss: 0.1215, average fakeD loss: 95.4560, 
[09/23 03:26:53][INFO] visual_prompt:  441: Inference (val):avg data time: 7.54e-05, avg batch time: 0.1166, average loss: 0.5150
[09/23 03:26:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.00	
[09/23 03:27:07][INFO] visual_prompt:  441: Inference (test):avg data time: 7.99e-05, avg batch time: 0.1235, average loss: 0.5203
[09/23 03:27:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.61	top5: 97.50	
[09/23 03:27:07][INFO] visual_prompt:  259: Training 111 / 200 epoch, with learning rate 0.5733879090797923
[09/23 03:28:23][INFO] visual_prompt:  327: Epoch 111 / 200: avg data time: 1.84e-02, avg batch time: 0.8905, average train loss: 0.2695average G loss: 0.0286, average realD loss: 0.4848, average fakeD loss: 88.4068, 
[09/23 03:28:25][INFO] visual_prompt:  441: Inference (val):avg data time: 7.04e-05, avg batch time: 0.1176, average loss: 0.5367
[09/23 03:28:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.83	
[09/23 03:28:39][INFO] visual_prompt:  441: Inference (test):avg data time: 7.79e-05, avg batch time: 0.1237, average loss: 0.5450
[09/23 03:28:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.69	top5: 97.89	
[09/23 03:28:39][INFO] visual_prompt:  259: Training 112 / 200 epoch, with learning rate 0.5630965435934608
[09/23 03:29:55][INFO] visual_prompt:  327: Epoch 112 / 200: avg data time: 2.01e-02, avg batch time: 0.8919, average train loss: 0.2152average G loss: 0.0133, average realD loss: 0.1539, average fakeD loss: 94.9537, 
[09/23 03:29:57][INFO] visual_prompt:  441: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1168, average loss: 0.5463
[09/23 03:29:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 97.67	
[09/23 03:30:11][INFO] visual_prompt:  441: Inference (test):avg data time: 8.26e-05, avg batch time: 0.1240, average loss: 0.5424
[09/23 03:30:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.45	top5: 97.88	
[09/23 03:30:11][INFO] visual_prompt:  259: Training 113 / 200 epoch, with learning rate 0.5528221018940087
[09/23 03:31:27][INFO] visual_prompt:  327: Epoch 113 / 200: avg data time: 1.81e-02, avg batch time: 0.8899, average train loss: 0.1897average G loss: 0.0091, average realD loss: 0.1761, average fakeD loss: 95.0050, 
[09/23 03:31:29][INFO] visual_prompt:  441: Inference (val):avg data time: 5.44e-05, avg batch time: 0.1177, average loss: 0.5558
[09/23 03:31:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.50	
[09/23 03:31:42][INFO] visual_prompt:  441: Inference (test):avg data time: 7.16e-05, avg batch time: 0.1237, average loss: 0.5573
[09/23 03:31:42][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.04	top5: 97.57	
[09/23 03:31:42][INFO] visual_prompt:  259: Training 114 / 200 epoch, with learning rate 0.5425673929112069
[09/23 03:32:58][INFO] visual_prompt:  327: Epoch 114 / 200: avg data time: 1.96e-02, avg batch time: 0.8919, average train loss: 0.2222average G loss: 0.0208, average realD loss: 0.3362, average fakeD loss: 90.8818, 
[09/23 03:33:00][INFO] visual_prompt:  441: Inference (val):avg data time: 6.47e-05, avg batch time: 0.1170, average loss: 0.7423
[09/23 03:33:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 97.83	
[09/23 03:33:14][INFO] visual_prompt:  441: Inference (test):avg data time: 7.31e-05, avg batch time: 0.1237, average loss: 0.7250
[09/23 03:33:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.31	top5: 97.13	
[09/23 03:33:14][INFO] visual_prompt:  259: Training 115 / 200 epoch, with learning rate 0.5323352201800987
[09/23 03:34:30][INFO] visual_prompt:  327: Epoch 115 / 200: avg data time: 1.75e-02, avg batch time: 0.8896, average train loss: 0.2539average G loss: 0.0187, average realD loss: 0.1783, average fakeD loss: 94.2544, 
[09/23 03:34:32][INFO] visual_prompt:  441: Inference (val):avg data time: 6.11e-05, avg batch time: 0.1167, average loss: 0.5249
[09/23 03:34:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.50	
[09/23 03:34:45][INFO] visual_prompt:  441: Inference (test):avg data time: 9.71e-05, avg batch time: 0.1239, average loss: 0.5249
[09/23 03:34:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.81	
[09/23 03:34:45][INFO] visual_prompt:  259: Training 116 / 200 epoch, with learning rate 0.5221283810745412
[09/23 03:36:01][INFO] visual_prompt:  327: Epoch 116 / 200: avg data time: 1.94e-02, avg batch time: 0.8921, average train loss: 0.2779average G loss: 0.0306, average realD loss: 0.4250, average fakeD loss: 89.4202, 
[09/23 03:36:03][INFO] visual_prompt:  441: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1170, average loss: 0.5644
[09/23 03:36:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 97.83	
[09/23 03:36:17][INFO] visual_prompt:  441: Inference (test):avg data time: 7.46e-05, avg batch time: 0.1237, average loss: 0.5457
[09/23 03:36:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.45	top5: 97.88	
[09/23 03:36:17][INFO] visual_prompt:  259: Training 117 / 200 epoch, with learning rate 0.5119496660424315
[09/23 03:37:33][INFO] visual_prompt:  327: Epoch 117 / 200: avg data time: 1.79e-02, avg batch time: 0.8899, average train loss: 0.1976average G loss: 0.0103, average realD loss: 0.0540, average fakeD loss: 97.7736, 
[09/23 03:37:35][INFO] visual_prompt:  441: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1167, average loss: 0.5392
[09/23 03:37:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.17	
[09/23 03:37:48][INFO] visual_prompt:  441: Inference (test):avg data time: 9.85e-05, avg batch time: 0.1239, average loss: 0.5230
[09/23 03:37:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.76	top5: 97.72	
[09/23 03:37:48][INFO] visual_prompt:  259: Training 118 / 200 epoch, with learning rate 0.5018018578428249
[09/23 03:39:04][INFO] visual_prompt:  327: Epoch 118 / 200: avg data time: 1.93e-02, avg batch time: 0.8912, average train loss: 0.1808average G loss: 0.0111, average realD loss: 0.0743, average fakeD loss: 96.9322, 
[09/23 03:39:07][INFO] visual_prompt:  441: Inference (val):avg data time: 6.17e-05, avg batch time: 0.1171, average loss: 0.5626
[09/23 03:39:07][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.33	
[09/23 03:39:20][INFO] visual_prompt:  441: Inference (test):avg data time: 8.58e-05, avg batch time: 0.1235, average loss: 0.5517
[09/23 03:39:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.76	top5: 97.70	
[09/23 03:39:20][INFO] visual_prompt:  259: Training 119 / 200 epoch, with learning rate 0.4916877307851583
[09/23 03:40:36][INFO] visual_prompt:  327: Epoch 119 / 200: avg data time: 1.77e-02, avg batch time: 0.8898, average train loss: 0.1816average G loss: 0.0099, average realD loss: 0.1168, average fakeD loss: 96.0070, 
[09/23 03:40:38][INFO] visual_prompt:  441: Inference (val):avg data time: 7.44e-05, avg batch time: 0.1173, average loss: 0.5073
[09/23 03:40:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.33	
[09/23 03:40:52][INFO] visual_prompt:  441: Inference (test):avg data time: 8.20e-05, avg batch time: 0.1236, average loss: 0.4961
[09/23 03:40:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.93	
[09/23 03:40:52][INFO] visual_prompt:  259: Training 120 / 200 epoch, with learning rate 0.48161004997078033
[09/23 03:42:08][INFO] visual_prompt:  327: Epoch 120 / 200: avg data time: 1.86e-02, avg batch time: 0.8907, average train loss: 0.2190average G loss: 0.0240, average realD loss: 0.2858, average fakeD loss: 91.2969, 
[09/23 03:42:10][INFO] visual_prompt:  441: Inference (val):avg data time: 6.88e-05, avg batch time: 0.1171, average loss: 0.5875
[09/23 03:42:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 97.50	
[09/23 03:42:24][INFO] visual_prompt:  441: Inference (test):avg data time: 7.19e-05, avg batch time: 0.1234, average loss: 0.5728
[09/23 03:42:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.04	top5: 97.88	
[09/23 03:42:24][INFO] visual_prompt:  259: Training 121 / 200 epoch, with learning rate 0.47157157053700055
[09/23 03:43:39][INFO] visual_prompt:  327: Epoch 121 / 200: avg data time: 1.85e-02, avg batch time: 0.8907, average train loss: 0.2465average G loss: 0.0183, average realD loss: 0.3669, average fakeD loss: 90.3554, 
[09/23 03:43:42][INFO] visual_prompt:  441: Inference (val):avg data time: 7.26e-05, avg batch time: 0.1167, average loss: 0.5085
[09/23 03:43:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/23 03:43:56][INFO] visual_prompt:  441: Inference (test):avg data time: 8.56e-05, avg batch time: 0.1237, average loss: 0.5171
[09/23 03:43:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.99	top5: 97.74	
[09/23 03:43:56][INFO] visual_prompt:  259: Training 122 / 200 epoch, with learning rate 0.46157503690386265
[09/23 03:45:11][INFO] visual_prompt:  327: Epoch 122 / 200: avg data time: 1.72e-02, avg batch time: 0.8894, average train loss: 0.2209average G loss: 0.0147, average realD loss: 0.3659, average fakeD loss: 90.7750, 
[09/23 03:45:14][INFO] visual_prompt:  441: Inference (val):avg data time: 6.18e-05, avg batch time: 0.1176, average loss: 0.5017
[09/23 03:45:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.17	
[09/23 03:45:28][INFO] visual_prompt:  441: Inference (test):avg data time: 8.90e-05, avg batch time: 0.1236, average loss: 0.5054
[09/23 03:45:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 98.07	
[09/23 03:45:28][INFO] visual_prompt:  259: Training 123 / 200 epoch, with learning rate 0.45162318202384727
[09/23 03:46:44][INFO] visual_prompt:  327: Epoch 123 / 200: avg data time: 2.00e-02, avg batch time: 0.8925, average train loss: 0.2073average G loss: 0.0139, average realD loss: 0.3222, average fakeD loss: 90.3473, 
[09/23 03:46:46][INFO] visual_prompt:  441: Inference (val):avg data time: 7.34e-05, avg batch time: 0.1164, average loss: 0.5241
[09/23 03:46:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.50	
[09/23 03:47:00][INFO] visual_prompt:  441: Inference (test):avg data time: 8.86e-05, avg batch time: 0.1236, average loss: 0.5197
[09/23 03:47:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.28	top5: 97.96	
[09/23 03:47:00][INFO] visual_prompt:  259: Training 124 / 200 epoch, with learning rate 0.44171872663470957
[09/23 03:48:16][INFO] visual_prompt:  327: Epoch 124 / 200: avg data time: 1.94e-02, avg batch time: 0.8913, average train loss: 0.2113average G loss: 0.0165, average realD loss: 0.4129, average fakeD loss: 89.5273, 
[09/23 03:48:18][INFO] visual_prompt:  441: Inference (val):avg data time: 7.61e-05, avg batch time: 0.1165, average loss: 0.5258
[09/23 03:48:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.33	
[09/23 03:48:32][INFO] visual_prompt:  441: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1239, average loss: 0.5321
[09/23 03:48:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.12	top5: 97.69	
[09/23 03:48:32][INFO] visual_prompt:  259: Training 125 / 200 epoch, with learning rate 0.4318643785156579
[09/23 03:49:47][INFO] visual_prompt:  327: Epoch 125 / 200: avg data time: 1.73e-02, avg batch time: 0.8895, average train loss: 0.2105average G loss: 0.0190, average realD loss: 0.3094, average fakeD loss: 90.9993, 
[09/23 03:49:50][INFO] visual_prompt:  441: Inference (val):avg data time: 6.49e-05, avg batch time: 0.1169, average loss: 0.5184
[09/23 03:49:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.33	
[09/23 03:50:03][INFO] visual_prompt:  441: Inference (test):avg data time: 7.61e-05, avg batch time: 0.1238, average loss: 0.5310
[09/23 03:50:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.56	top5: 97.95	
[09/23 03:50:03][INFO] visual_prompt:  259: Training 126 / 200 epoch, with learning rate 0.4220628317470729
[09/23 03:51:19][INFO] visual_prompt:  327: Epoch 126 / 200: avg data time: 1.87e-02, avg batch time: 0.8913, average train loss: 0.2196average G loss: 0.0177, average realD loss: 0.3084, average fakeD loss: 92.0585, 
[09/23 03:51:21][INFO] visual_prompt:  441: Inference (val):avg data time: 6.62e-05, avg batch time: 0.1167, average loss: 0.5277
[09/23 03:51:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.17	
[09/23 03:51:34][INFO] visual_prompt:  441: Inference (test):avg data time: 8.09e-05, avg batch time: 0.1239, average loss: 0.5028
[09/23 03:51:34][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.35	top5: 97.98	
[09/23 03:51:34][INFO] visual_prompt:  259: Training 127 / 200 epoch, with learning rate 0.41231676597397304
[09/23 03:52:50][INFO] visual_prompt:  327: Epoch 127 / 200: avg data time: 1.86e-02, avg batch time: 0.8913, average train loss: 0.1959average G loss: 0.0165, average realD loss: 0.3272, average fakeD loss: 90.2404, 
[09/23 03:52:53][INFO] visual_prompt:  441: Inference (val):avg data time: 6.84e-05, avg batch time: 0.1166, average loss: 0.5829
[09/23 03:52:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.67	
[09/23 03:53:06][INFO] visual_prompt:  441: Inference (test):avg data time: 7.58e-05, avg batch time: 0.1236, average loss: 0.5775
[09/23 03:53:06][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.81	top5: 97.72	
[09/23 03:53:06][INFO] visual_prompt:  259: Training 128 / 200 epoch, with learning rate 0.40262884567342716
[09/23 03:54:22][INFO] visual_prompt:  327: Epoch 128 / 200: avg data time: 1.80e-02, avg batch time: 0.8908, average train loss: 0.2364average G loss: 0.0211, average realD loss: 0.5231, average fakeD loss: 89.8613, 
[09/23 03:54:25][INFO] visual_prompt:  441: Inference (val):avg data time: 8.92e-05, avg batch time: 0.1169, average loss: 0.5637
[09/23 03:54:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 98.17	
[09/23 03:54:38][INFO] visual_prompt:  441: Inference (test):avg data time: 8.78e-05, avg batch time: 0.1237, average loss: 0.5278
[09/23 03:54:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.72	
[09/23 03:54:38][INFO] visual_prompt:  259: Training 129 / 200 epoch, with learning rate 0.39300171942611195
[09/23 03:55:54][INFO] visual_prompt:  327: Epoch 129 / 200: avg data time: 1.81e-02, avg batch time: 0.8899, average train loss: 0.2053average G loss: 0.0113, average realD loss: 0.1372, average fakeD loss: 95.6361, 
[09/23 03:55:56][INFO] visual_prompt:  441: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1166, average loss: 0.5004
[09/23 03:55:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.83	
[09/23 03:56:09][INFO] visual_prompt:  441: Inference (test):avg data time: 8.51e-05, avg batch time: 0.1238, average loss: 0.5055
[09/23 03:56:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.76	top5: 97.95	
[09/23 03:56:09][INFO] visual_prompt:  259: Training 130 / 200 epoch, with learning rate 0.38343801919221754
[09/23 03:57:25][INFO] visual_prompt:  327: Epoch 130 / 200: avg data time: 1.80e-02, avg batch time: 0.8896, average train loss: 0.1693average G loss: 0.0089, average realD loss: 0.1253, average fakeD loss: 95.2568, 
[09/23 03:57:27][INFO] visual_prompt:  441: Inference (val):avg data time: 8.51e-05, avg batch time: 0.1169, average loss: 0.5412
[09/23 03:57:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.67	
[09/23 03:57:40][INFO] visual_prompt:  441: Inference (test):avg data time: 6.96e-05, avg batch time: 0.1236, average loss: 0.5269
[09/23 03:57:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.12	top5: 97.89	
[09/23 03:57:41][INFO] visual_prompt:  259: Training 131 / 200 epoch, with learning rate 0.3739403595918942
[09/23 03:58:56][INFO] visual_prompt:  327: Epoch 131 / 200: avg data time: 1.82e-02, avg batch time: 0.8908, average train loss: 0.2364average G loss: 0.0308, average realD loss: 0.6498, average fakeD loss: 83.8715, 
[09/23 03:58:59][INFO] visual_prompt:  441: Inference (val):avg data time: 6.63e-05, avg batch time: 0.1170, average loss: 0.6458
[09/23 03:58:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.17	
[09/23 03:59:12][INFO] visual_prompt:  441: Inference (test):avg data time: 8.85e-05, avg batch time: 0.1237, average loss: 0.6407
[09/23 03:59:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.76	top5: 97.70	
[09/23 03:59:12][INFO] visual_prompt:  259: Training 132 / 200 epoch, with learning rate 0.3645113371904436
[09/23 04:00:28][INFO] visual_prompt:  327: Epoch 132 / 200: avg data time: 1.90e-02, avg batch time: 0.8916, average train loss: 0.2126average G loss: 0.0115, average realD loss: 0.4302, average fakeD loss: 91.2801, 
[09/23 04:00:31][INFO] visual_prompt:  441: Inference (val):avg data time: 7.35e-05, avg batch time: 0.1167, average loss: 0.5687
[09/23 04:00:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 98.50	
[09/23 04:00:45][INFO] visual_prompt:  441: Inference (test):avg data time: 8.22e-05, avg batch time: 0.1238, average loss: 0.5486
[09/23 04:00:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 97.81	
[09/23 04:00:45][INFO] visual_prompt:  363: Best epoch 132: best metric: 0.877
[09/23 04:00:45][INFO] visual_prompt:  259: Training 133 / 200 epoch, with learning rate 0.355153529788442
[09/23 04:02:01][INFO] visual_prompt:  327: Epoch 133 / 200: avg data time: 1.86e-02, avg batch time: 0.8909, average train loss: 0.1762average G loss: 0.0069, average realD loss: 0.1371, average fakeD loss: 96.9804, 
[09/23 04:02:03][INFO] visual_prompt:  441: Inference (val):avg data time: 6.49e-05, avg batch time: 0.1168, average loss: 0.5311
[09/23 04:02:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.33	top5: 98.17	
[09/23 04:02:16][INFO] visual_prompt:  441: Inference (test):avg data time: 7.03e-05, avg batch time: 0.1239, average loss: 0.5190
[09/23 04:02:16][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.28	top5: 97.84	
[09/23 04:02:16][INFO] visual_prompt:  259: Training 134 / 200 epoch, with learning rate 0.345869495716996
[09/23 04:03:32][INFO] visual_prompt:  327: Epoch 134 / 200: avg data time: 1.91e-02, avg batch time: 0.8910, average train loss: 0.1460average G loss: 0.0056, average realD loss: 0.1317, average fakeD loss: 96.0397, 
[09/23 04:03:34][INFO] visual_prompt:  441: Inference (val):avg data time: 7.46e-05, avg batch time: 0.1168, average loss: 0.5356
[09/23 04:03:35][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.33	
[09/23 04:03:48][INFO] visual_prompt:  441: Inference (test):avg data time: 8.87e-05, avg batch time: 0.1237, average loss: 0.5173
[09/23 04:03:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.50	top5: 97.77	
[09/23 04:03:48][INFO] visual_prompt:  259: Training 135 / 200 epoch, with learning rate 0.33666177313832024
[09/23 04:05:04][INFO] visual_prompt:  327: Epoch 135 / 200: avg data time: 1.93e-02, avg batch time: 0.8913, average train loss: 0.1648average G loss: 0.0076, average realD loss: 0.2696, average fakeD loss: 92.4383, 
[09/23 04:05:06][INFO] visual_prompt:  441: Inference (val):avg data time: 5.93e-05, avg batch time: 0.1166, average loss: 0.5143
[09/23 04:05:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 88.00	top5: 98.17	
[09/23 04:05:20][INFO] visual_prompt:  441: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1237, average loss: 0.5073
[09/23 04:05:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.78	top5: 97.74	
[09/23 04:05:20][INFO] visual_prompt:  363: Best epoch 135: best metric: 0.880
[09/23 04:05:20][INFO] visual_prompt:  259: Training 136 / 200 epoch, with learning rate 0.327532879351829
[09/23 04:06:35][INFO] visual_prompt:  327: Epoch 136 / 200: avg data time: 1.74e-02, avg batch time: 0.8897, average train loss: 0.2505average G loss: 0.0349, average realD loss: 0.7467, average fakeD loss: 82.7251, 
[09/23 04:06:38][INFO] visual_prompt:  441: Inference (val):avg data time: 6.79e-05, avg batch time: 0.1172, average loss: 0.5587
[09/23 04:06:38][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.33	
[09/23 04:06:51][INFO] visual_prompt:  441: Inference (test):avg data time: 6.63e-05, avg batch time: 0.1235, average loss: 0.5481
[09/23 04:06:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.50	top5: 97.74	
[09/23 04:06:51][INFO] visual_prompt:  259: Training 137 / 200 epoch, with learning rate 0.3184853101059326
[09/23 04:08:07][INFO] visual_prompt:  327: Epoch 137 / 200: avg data time: 1.83e-02, avg batch time: 0.8899, average train loss: 0.2188average G loss: 0.0205, average realD loss: 0.4225, average fakeD loss: 88.6567, 
[09/23 04:08:09][INFO] visual_prompt:  441: Inference (val):avg data time: 6.89e-05, avg batch time: 0.1169, average loss: 0.5401
[09/23 04:08:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.67	
[09/23 04:08:23][INFO] visual_prompt:  441: Inference (test):avg data time: 7.01e-05, avg batch time: 0.1236, average loss: 0.5311
[09/23 04:08:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.80	top5: 97.60	
[09/23 04:08:23][INFO] visual_prompt:  259: Training 138 / 200 epoch, with learning rate 0.30952153891572287
[09/23 04:09:39][INFO] visual_prompt:  327: Epoch 138 / 200: avg data time: 1.95e-02, avg batch time: 0.8916, average train loss: 0.2112average G loss: 0.0169, average realD loss: 0.4714, average fakeD loss: 89.1391, 
[09/23 04:09:41][INFO] visual_prompt:  441: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1169, average loss: 0.4939
[09/23 04:09:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 98.50	
[09/23 04:09:55][INFO] visual_prompt:  441: Inference (test):avg data time: 7.12e-05, avg batch time: 0.1236, average loss: 0.4832
[09/23 04:09:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.73	top5: 97.91	
[09/23 04:09:55][INFO] visual_prompt:  259: Training 139 / 200 epoch, with learning rate 0.3006440163867407
[09/23 04:11:11][INFO] visual_prompt:  327: Epoch 139 / 200: avg data time: 1.79e-02, avg batch time: 0.8899, average train loss: 0.1817average G loss: 0.0097, average realD loss: 0.2147, average fakeD loss: 93.5817, 
[09/23 04:11:13][INFO] visual_prompt:  441: Inference (val):avg data time: 9.32e-05, avg batch time: 0.1172, average loss: 0.6357
[09/23 04:11:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.00	
[09/23 04:11:27][INFO] visual_prompt:  441: Inference (test):avg data time: 6.93e-05, avg batch time: 0.1237, average loss: 0.6127
[09/23 04:11:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.31	top5: 97.43	
[09/23 04:11:27][INFO] visual_prompt:  259: Training 140 / 200 epoch, with learning rate 0.291855169545004
[09/23 04:12:43][INFO] visual_prompt:  327: Epoch 140 / 200: avg data time: 2.02e-02, avg batch time: 0.8930, average train loss: 0.1873average G loss: 0.0096, average realD loss: 0.3498, average fakeD loss: 90.6373, 
[09/23 04:12:45][INFO] visual_prompt:  441: Inference (val):avg data time: 6.92e-05, avg batch time: 0.1173, average loss: 0.6272
[09/23 04:12:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.83	
[09/23 04:12:59][INFO] visual_prompt:  441: Inference (test):avg data time: 7.70e-05, avg batch time: 0.1239, average loss: 0.5973
[09/23 04:12:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.47	top5: 97.64	
[09/23 04:12:59][INFO] visual_prompt:  259: Training 141 / 200 epoch, with learning rate 0.2831574011734833
[09/23 04:14:15][INFO] visual_prompt:  327: Epoch 141 / 200: avg data time: 1.81e-02, avg batch time: 0.8917, average train loss: 0.2450average G loss: 0.0274, average realD loss: 0.7779, average fakeD loss: 83.0258, 
[09/23 04:14:17][INFO] visual_prompt:  441: Inference (val):avg data time: 8.05e-05, avg batch time: 0.1167, average loss: 0.7651
[09/23 04:14:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 96.50	
[09/23 04:14:30][INFO] visual_prompt:  441: Inference (test):avg data time: 7.38e-05, avg batch time: 0.1236, average loss: 0.7192
[09/23 04:14:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.40	top5: 97.17	
[09/23 04:14:30][INFO] visual_prompt:  259: Training 142 / 200 epoch, with learning rate 0.2745530891552046
[09/23 04:15:46][INFO] visual_prompt:  327: Epoch 142 / 200: avg data time: 1.91e-02, avg batch time: 0.8923, average train loss: 0.2076average G loss: 0.0136, average realD loss: 0.3848, average fakeD loss: 88.9468, 
[09/23 04:15:49][INFO] visual_prompt:  441: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1168, average loss: 0.5244
[09/23 04:15:49][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.17	
[09/23 04:16:03][INFO] visual_prompt:  441: Inference (test):avg data time: 8.47e-05, avg batch time: 0.1235, average loss: 0.5159
[09/23 04:16:03][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.14	top5: 97.70	
[09/23 04:16:03][INFO] visual_prompt:  259: Training 143 / 200 epoch, with learning rate 0.26604458582316026
[09/23 04:17:19][INFO] visual_prompt:  327: Epoch 143 / 200: avg data time: 1.86e-02, avg batch time: 0.8919, average train loss: 0.1984average G loss: 0.0149, average realD loss: 0.3842, average fakeD loss: 89.7168, 
[09/23 04:17:21][INFO] visual_prompt:  441: Inference (val):avg data time: 7.22e-05, avg batch time: 0.1170, average loss: 0.5411
[09/23 04:17:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.50	
[09/23 04:17:35][INFO] visual_prompt:  441: Inference (test):avg data time: 6.18e-05, avg batch time: 0.1237, average loss: 0.5094
[09/23 04:17:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.61	top5: 97.70	
[09/23 04:17:35][INFO] visual_prompt:  259: Training 144 / 200 epoch, with learning rate 0.2576342173172044
[09/23 04:18:51][INFO] visual_prompt:  327: Epoch 144 / 200: avg data time: 1.92e-02, avg batch time: 0.8934, average train loss: 0.2282average G loss: 0.0285, average realD loss: 1.0145, average fakeD loss: 78.5024, 
[09/23 04:18:53][INFO] visual_prompt:  441: Inference (val):avg data time: 5.57e-05, avg batch time: 0.1171, average loss: 0.6594
[09/23 04:18:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 97.50	
[09/23 04:19:07][INFO] visual_prompt:  441: Inference (test):avg data time: 8.01e-05, avg batch time: 0.1237, average loss: 0.6242
[09/23 04:19:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.07	top5: 97.32	
[09/23 04:19:07][INFO] visual_prompt:  259: Training 145 / 200 epoch, with learning rate 0.24932428294810932
[09/23 04:20:23][INFO] visual_prompt:  327: Epoch 145 / 200: avg data time: 1.95e-02, avg batch time: 0.8934, average train loss: 0.2122average G loss: 0.0147, average realD loss: 0.4295, average fakeD loss: 89.4155, 
[09/23 04:20:25][INFO] visual_prompt:  441: Inference (val):avg data time: 5.01e-05, avg batch time: 0.1168, average loss: 0.5037
[09/23 04:20:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 98.17	
[09/23 04:20:39][INFO] visual_prompt:  441: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1238, average loss: 0.5065
[09/23 04:20:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.61	top5: 97.86	
[09/23 04:20:39][INFO] visual_prompt:  259: Training 146 / 200 epoch, with learning rate 0.2411170545689576
[09/23 04:21:55][INFO] visual_prompt:  327: Epoch 146 / 200: avg data time: 1.98e-02, avg batch time: 0.8936, average train loss: 0.1789average G loss: 0.0100, average realD loss: 0.3381, average fakeD loss: 90.2913, 
[09/23 04:21:57][INFO] visual_prompt:  441: Inference (val):avg data time: 7.88e-05, avg batch time: 0.1171, average loss: 0.5092
[09/23 04:21:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.00	
[09/23 04:22:11][INFO] visual_prompt:  441: Inference (test):avg data time: 6.83e-05, avg batch time: 0.1238, average loss: 0.5071
[09/23 04:22:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.45	top5: 97.69	
[09/23 04:22:11][INFO] visual_prompt:  259: Training 147 / 200 epoch, with learning rate 0.23301477595403935
[09/23 04:23:27][INFO] visual_prompt:  327: Epoch 147 / 200: avg data time: 1.93e-02, avg batch time: 0.8939, average train loss: 0.1786average G loss: 0.0131, average realD loss: 0.5700, average fakeD loss: 83.9081, 
[09/23 04:23:30][INFO] visual_prompt:  441: Inference (val):avg data time: 6.38e-05, avg batch time: 0.1169, average loss: 0.6721
[09/23 04:23:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 97.83	
[09/23 04:23:43][INFO] visual_prompt:  441: Inference (test):avg data time: 7.25e-05, avg batch time: 0.1241, average loss: 0.6372
[09/23 04:23:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.33	top5: 97.32	
[09/23 04:23:43][INFO] visual_prompt:  259: Training 148 / 200 epoch, with learning rate 0.2250196621854271
[09/23 04:24:59][INFO] visual_prompt:  327: Epoch 148 / 200: avg data time: 1.86e-02, avg batch time: 0.8935, average train loss: 0.2261average G loss: 0.0255, average realD loss: 1.1378, average fakeD loss: 78.3330, 
[09/23 04:25:02][INFO] visual_prompt:  441: Inference (val):avg data time: 8.72e-05, avg batch time: 0.1168, average loss: 0.5058
[09/23 04:25:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.00	
[09/23 04:25:15][INFO] visual_prompt:  441: Inference (test):avg data time: 8.10e-05, avg batch time: 0.1238, average loss: 0.4974
[09/23 04:25:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.95	top5: 98.02	
[09/23 04:25:15][INFO] visual_prompt:  259: Training 149 / 200 epoch, with learning rate 0.21713389904739455
[09/23 04:26:31][INFO] visual_prompt:  327: Epoch 149 / 200: avg data time: 1.88e-02, avg batch time: 0.8929, average train loss: 0.1518average G loss: 0.0087, average realD loss: 0.2862, average fakeD loss: 93.0278, 
[09/23 04:26:34][INFO] visual_prompt:  441: Inference (val):avg data time: 7.37e-05, avg batch time: 0.1168, average loss: 0.5122
[09/23 04:26:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.17	
[09/23 04:26:47][INFO] visual_prompt:  441: Inference (test):avg data time: 9.65e-05, avg batch time: 0.1238, average loss: 0.5056
[09/23 04:26:47][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.92	top5: 97.84	
[09/23 04:26:47][INFO] visual_prompt:  259: Training 150 / 200 epoch, with learning rate 0.20935964242884478
[09/23 04:28:04][INFO] visual_prompt:  327: Epoch 150 / 200: avg data time: 1.88e-02, avg batch time: 0.8933, average train loss: 0.1542average G loss: 0.0099, average realD loss: 0.4101, average fakeD loss: 88.3051, 
[09/23 04:28:06][INFO] visual_prompt:  441: Inference (val):avg data time: 1.11e-04, avg batch time: 0.1176, average loss: 0.5516
[09/23 04:28:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 97.67	
[09/23 04:28:19][INFO] visual_prompt:  441: Inference (test):avg data time: 7.46e-05, avg batch time: 0.1240, average loss: 0.5425
[09/23 04:28:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.44	top5: 97.84	
[09/23 04:28:19][INFO] visual_prompt:  259: Training 151 / 200 epoch, with learning rate 0.20169901773391197
[09/23 04:29:35][INFO] visual_prompt:  327: Epoch 151 / 200: avg data time: 1.87e-02, avg batch time: 0.8940, average train loss: 0.2080average G loss: 0.0232, average realD loss: 1.0331, average fakeD loss: 79.6289, 
[09/23 04:29:37][INFO] visual_prompt:  441: Inference (val):avg data time: 6.14e-05, avg batch time: 0.1171, average loss: 0.5407
[09/23 04:29:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.50	
[09/23 04:29:51][INFO] visual_prompt:  441: Inference (test):avg data time: 6.41e-05, avg batch time: 0.1240, average loss: 0.5303
[09/23 04:29:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.38	top5: 97.98	
[09/23 04:29:51][INFO] visual_prompt:  259: Training 152 / 200 epoch, with learning rate 0.19415411930089638
[09/23 04:31:07][INFO] visual_prompt:  327: Epoch 152 / 200: avg data time: 1.99e-02, avg batch time: 0.8936, average train loss: 0.2104average G loss: 0.0177, average realD loss: 0.6637, average fakeD loss: 84.0279, 
[09/23 04:31:09][INFO] visual_prompt:  441: Inference (val):avg data time: 5.78e-05, avg batch time: 0.1172, average loss: 0.5062
[09/23 04:31:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.67	
[09/23 04:31:23][INFO] visual_prompt:  441: Inference (test):avg data time: 1.47e-04, avg batch time: 0.1239, average loss: 0.4967
[09/23 04:31:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.94	top5: 97.96	
[09/23 04:31:23][INFO] visual_prompt:  259: Training 153 / 200 epoch, with learning rate 0.18672700982969465
[09/23 04:32:39][INFO] visual_prompt:  327: Epoch 153 / 200: avg data time: 1.92e-02, avg batch time: 0.8927, average train loss: 0.2077average G loss: 0.0206, average realD loss: 1.3150, average fakeD loss: 73.6019, 
[09/23 04:32:42][INFO] visual_prompt:  441: Inference (val):avg data time: 7.51e-05, avg batch time: 0.1167, average loss: 0.5178
[09/23 04:32:42][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.50	
[09/23 04:32:56][INFO] visual_prompt:  441: Inference (test):avg data time: 9.41e-05, avg batch time: 0.1235, average loss: 0.5115
[09/23 04:32:56][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.23	top5: 97.76	
[09/23 04:32:56][INFO] visual_prompt:  259: Training 154 / 200 epoch, with learning rate 0.17941971981787685
[09/23 04:34:11][INFO] visual_prompt:  327: Epoch 154 / 200: avg data time: 1.86e-02, avg batch time: 0.8911, average train loss: 0.1856average G loss: 0.0172, average realD loss: 0.7334, average fakeD loss: 84.3066, 
[09/23 04:34:14][INFO] visual_prompt:  441: Inference (val):avg data time: 7.22e-05, avg batch time: 0.1167, average loss: 0.4878
[09/23 04:34:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.67	
[09/23 04:34:27][INFO] visual_prompt:  441: Inference (test):avg data time: 7.78e-05, avg batch time: 0.1234, average loss: 0.4900
[09/23 04:34:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.85	top5: 97.96	
[09/23 04:34:27][INFO] visual_prompt:  259: Training 155 / 200 epoch, with learning rate 0.17223424700556939
[09/23 04:35:43][INFO] visual_prompt:  327: Epoch 155 / 200: avg data time: 1.85e-02, avg batch time: 0.8907, average train loss: 0.1849average G loss: 0.0195, average realD loss: 0.7959, average fakeD loss: 80.6867, 
[09/23 04:35:45][INFO] visual_prompt:  441: Inference (val):avg data time: 9.69e-05, avg batch time: 0.1164, average loss: 0.6223
[09/23 04:35:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.17	
[09/23 04:35:59][INFO] visual_prompt:  441: Inference (test):avg data time: 7.63e-05, avg batch time: 0.1236, average loss: 0.6199
[09/23 04:36:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.90	top5: 97.72	
[09/23 04:36:00][INFO] visual_prompt:  259: Training 156 / 200 epoch, with learning rate 0.16517255582929274
[09/23 04:37:15][INFO] visual_prompt:  327: Epoch 156 / 200: avg data time: 1.79e-02, avg batch time: 0.8908, average train loss: 0.2536average G loss: 0.0246, average realD loss: 1.5224, average fakeD loss: 71.0789, 
[09/23 04:37:18][INFO] visual_prompt:  441: Inference (val):avg data time: 8.76e-05, avg batch time: 0.1164, average loss: 0.5998
[09/23 04:37:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.00	
[09/23 04:37:32][INFO] visual_prompt:  441: Inference (test):avg data time: 6.89e-05, avg batch time: 0.1237, average loss: 0.5988
[09/23 04:37:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.70	
[09/23 04:37:32][INFO] visual_prompt:  259: Training 157 / 200 epoch, with learning rate 0.158236576884904
[09/23 04:38:48][INFO] visual_prompt:  327: Epoch 157 / 200: avg data time: 1.77e-02, avg batch time: 0.8896, average train loss: 0.1860average G loss: 0.0129, average realD loss: 1.0821, average fakeD loss: 80.3195, 
[09/23 04:38:50][INFO] visual_prompt:  441: Inference (val):avg data time: 6.24e-05, avg batch time: 0.1166, average loss: 0.5334
[09/23 04:38:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.83	
[09/23 04:39:04][INFO] visual_prompt:  441: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1234, average loss: 0.5197
[09/23 04:39:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.66	top5: 97.84	
[09/23 04:39:04][INFO] visual_prompt:  259: Training 158 / 200 epoch, with learning rate 0.15142820639979093
[09/23 04:40:20][INFO] visual_prompt:  327: Epoch 158 / 200: avg data time: 1.93e-02, avg batch time: 0.8917, average train loss: 0.2126average G loss: 0.0246, average realD loss: 1.6633, average fakeD loss: 68.6746, 
[09/23 04:40:22][INFO] visual_prompt:  441: Inference (val):avg data time: 9.88e-05, avg batch time: 0.1166, average loss: 0.5938
[09/23 04:40:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.17	
[09/23 04:40:35][INFO] visual_prompt:  441: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1236, average loss: 0.5799
[09/23 04:40:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.88	top5: 97.64	
[09/23 04:40:35][INFO] visual_prompt:  259: Training 159 / 200 epoch, with learning rate 0.14474930571446326
[09/23 04:41:51][INFO] visual_prompt:  327: Epoch 159 / 200: avg data time: 1.86e-02, avg batch time: 0.8905, average train loss: 0.1976average G loss: 0.0151, average realD loss: 1.2168, average fakeD loss: 77.0436, 
[09/23 04:41:54][INFO] visual_prompt:  441: Inference (val):avg data time: 6.39e-05, avg batch time: 0.1166, average loss: 0.5063
[09/23 04:41:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.17	top5: 98.33	
[09/23 04:42:07][INFO] visual_prompt:  441: Inference (test):avg data time: 8.54e-05, avg batch time: 0.1234, average loss: 0.4948
[09/23 04:42:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.87	top5: 97.93	
[09/23 04:42:07][INFO] visual_prompt:  259: Training 160 / 200 epoch, with learning rate 0.1382017007736798
[09/23 04:43:23][INFO] visual_prompt:  327: Epoch 160 / 200: avg data time: 1.75e-02, avg batch time: 0.8891, average train loss: 0.1733average G loss: 0.0160, average realD loss: 0.8855, average fakeD loss: 81.5477, 
[09/23 04:43:25][INFO] visual_prompt:  441: Inference (val):avg data time: 7.40e-05, avg batch time: 0.1170, average loss: 0.5269
[09/23 04:43:25][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 97.67	
[09/23 04:43:39][INFO] visual_prompt:  441: Inference (test):avg data time: 8.45e-05, avg batch time: 0.1235, average loss: 0.5265
[09/23 04:43:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.35	top5: 97.76	
[09/23 04:43:39][INFO] visual_prompt:  259: Training 161 / 200 epoch, with learning rate 0.13178718162725409
[09/23 04:44:55][INFO] visual_prompt:  327: Epoch 161 / 200: avg data time: 1.83e-02, avg batch time: 0.8914, average train loss: 0.2300average G loss: 0.0352, average realD loss: 2.0244, average fakeD loss: 62.4567, 
[09/23 04:44:57][INFO] visual_prompt:  441: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1165, average loss: 0.6382
[09/23 04:44:57][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 98.17	
[09/23 04:45:11][INFO] visual_prompt:  441: Inference (test):avg data time: 8.50e-05, avg batch time: 0.1237, average loss: 0.6488
[09/23 04:45:11][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.73	top5: 97.57	
[09/23 04:45:11][INFO] visual_prompt:  259: Training 162 / 200 epoch, with learning rate 0.12550750194067206
[09/23 04:46:27][INFO] visual_prompt:  327: Epoch 162 / 200: avg data time: 2.01e-02, avg batch time: 0.8928, average train loss: 0.2215average G loss: 0.0187, average realD loss: 1.4287, average fakeD loss: 76.2864, 
[09/23 04:46:30][INFO] visual_prompt:  441: Inference (val):avg data time: 7.35e-05, avg batch time: 0.1168, average loss: 0.5382
[09/23 04:46:30][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.50	
[09/23 04:46:43][INFO] visual_prompt:  441: Inference (test):avg data time: 7.26e-05, avg batch time: 0.1236, average loss: 0.5289
[09/23 04:46:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.68	top5: 97.86	
[09/23 04:46:43][INFO] visual_prompt:  259: Training 163 / 200 epoch, with learning rate 0.11936437851565791
[09/23 04:47:59][INFO] visual_prompt:  327: Epoch 163 / 200: avg data time: 1.98e-02, avg batch time: 0.8928, average train loss: 0.1610average G loss: 0.0081, average realD loss: 0.7793, average fakeD loss: 84.6999, 
[09/23 04:48:01][INFO] visual_prompt:  441: Inference (val):avg data time: 7.53e-05, avg batch time: 0.1173, average loss: 0.5071
[09/23 04:48:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 98.00	
[09/23 04:48:15][INFO] visual_prompt:  441: Inference (test):avg data time: 6.88e-05, avg batch time: 0.1239, average loss: 0.4979
[09/23 04:48:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.02	top5: 97.88	
[09/23 04:48:15][INFO] visual_prompt:  259: Training 164 / 200 epoch, with learning rate 0.11335949082081728
[09/23 04:49:31][INFO] visual_prompt:  327: Epoch 164 / 200: avg data time: 2.04e-02, avg batch time: 0.8942, average train loss: 0.1905average G loss: 0.0229, average realD loss: 1.7269, average fakeD loss: 67.5526, 
[09/23 04:49:34][INFO] visual_prompt:  441: Inference (val):avg data time: 6.32e-05, avg batch time: 0.1169, average loss: 0.7151
[09/23 04:49:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 97.67	
[09/23 04:49:47][INFO] visual_prompt:  441: Inference (test):avg data time: 1.08e-04, avg batch time: 0.1238, average loss: 0.6958
[09/23 04:49:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.59	top5: 97.36	
[09/23 04:49:48][INFO] visual_prompt:  259: Training 165 / 200 epoch, with learning rate 0.10749448053248747
[09/23 04:51:04][INFO] visual_prompt:  327: Epoch 165 / 200: avg data time: 2.13e-02, avg batch time: 0.8960, average train loss: 0.2514average G loss: 0.0305, average realD loss: 1.9932, average fakeD loss: 64.5757, 
[09/23 04:51:06][INFO] visual_prompt:  441: Inference (val):avg data time: 8.88e-05, avg batch time: 0.1169, average loss: 0.5765
[09/23 04:51:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 98.00	
[09/23 04:51:20][INFO] visual_prompt:  441: Inference (test):avg data time: 8.28e-05, avg batch time: 0.1240, average loss: 0.5469
[09/23 04:51:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.56	top5: 97.79	
[09/23 04:51:20][INFO] visual_prompt:  259: Training 166 / 200 epoch, with learning rate 0.10177095108591966
[09/23 04:52:36][INFO] visual_prompt:  327: Epoch 166 / 200: avg data time: 1.93e-02, avg batch time: 0.8943, average train loss: 0.2369average G loss: 0.0282, average realD loss: 2.1643, average fakeD loss: 60.1238, 
[09/23 04:52:39][INFO] visual_prompt:  441: Inference (val):avg data time: 6.33e-05, avg batch time: 0.1169, average loss: 0.5446
[09/23 04:52:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.17	top5: 98.17	
[09/23 04:52:52][INFO] visual_prompt:  441: Inference (test):avg data time: 6.74e-05, avg batch time: 0.1239, average loss: 0.5326
[09/23 04:52:53][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.38	top5: 98.00	
[09/23 04:52:53][INFO] visual_prompt:  259: Training 167 / 200 epoch, with learning rate 0.0961904672369153
[09/23 04:54:09][INFO] visual_prompt:  327: Epoch 167 / 200: avg data time: 1.94e-02, avg batch time: 0.8941, average train loss: 0.2062average G loss: 0.0220, average realD loss: 2.4361, average fakeD loss: 62.2835, 
[09/23 04:54:11][INFO] visual_prompt:  441: Inference (val):avg data time: 5.31e-05, avg batch time: 0.1169, average loss: 0.6136
[09/23 04:54:11][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.17	
[09/23 04:54:25][INFO] visual_prompt:  441: Inference (test):avg data time: 9.19e-05, avg batch time: 0.1237, average loss: 0.5933
[09/23 04:54:25][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.16	top5: 98.00	
[09/23 04:54:25][INFO] visual_prompt:  259: Training 168 / 200 epoch, with learning rate 0.09075455463403805
[09/23 04:55:41][INFO] visual_prompt:  327: Epoch 168 / 200: avg data time: 1.88e-02, avg batch time: 0.8943, average train loss: 0.2226average G loss: 0.0272, average realD loss: 2.8735, average fakeD loss: 59.6675, 
[09/23 04:55:43][INFO] visual_prompt:  441: Inference (val):avg data time: 8.37e-05, avg batch time: 0.1171, average loss: 0.5445
[09/23 04:55:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 97.67	
[09/23 04:55:57][INFO] visual_prompt:  441: Inference (test):avg data time: 8.54e-05, avg batch time: 0.1238, average loss: 0.5275
[09/23 04:55:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.59	top5: 98.03	
[09/23 04:55:57][INFO] visual_prompt:  259: Training 169 / 200 epoch, with learning rate 0.08546469940151631
[09/23 04:57:14][INFO] visual_prompt:  327: Epoch 169 / 200: avg data time: 2.02e-02, avg batch time: 0.8958, average train loss: 0.2259average G loss: 0.0277, average realD loss: 2.9747, average fakeD loss: 52.8920, 
[09/23 04:57:16][INFO] visual_prompt:  441: Inference (val):avg data time: 8.09e-05, avg batch time: 0.1171, average loss: 0.5641
[09/23 04:57:16][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.33	
[09/23 04:57:30][INFO] visual_prompt:  441: Inference (test):avg data time: 7.24e-05, avg batch time: 0.1237, average loss: 0.5483
[09/23 04:57:30][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.94	top5: 98.14	
[09/23 04:57:30][INFO] visual_prompt:  259: Training 170 / 200 epoch, with learning rate 0.08032234773295163
[09/23 04:58:46][INFO] visual_prompt:  327: Epoch 170 / 200: avg data time: 1.88e-02, avg batch time: 0.8946, average train loss: 0.2275average G loss: 0.0222, average realD loss: 3.1349, average fakeD loss: 55.1896, 
[09/23 04:58:48][INFO] visual_prompt:  441: Inference (val):avg data time: 6.76e-05, avg batch time: 0.1167, average loss: 0.5253
[09/23 04:58:48][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.83	
[09/23 04:59:02][INFO] visual_prompt:  441: Inference (test):avg data time: 6.54e-05, avg batch time: 0.1238, average loss: 0.5268
[09/23 04:59:02][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.78	top5: 97.84	
[09/23 04:59:02][INFO] visual_prompt:  259: Training 171 / 200 epoch, with learning rate 0.0753289054959444
[09/23 05:00:18][INFO] visual_prompt:  327: Epoch 171 / 200: avg data time: 1.93e-02, avg batch time: 0.8946, average train loss: 0.1917average G loss: 0.0194, average realD loss: 2.0919, average fakeD loss: 61.8937, 
[09/23 05:00:21][INFO] visual_prompt:  441: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1173, average loss: 0.5722
[09/23 05:00:21][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.33	
[09/23 05:00:35][INFO] visual_prompt:  441: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1236, average loss: 0.5600
[09/23 05:00:35][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.26	top5: 97.79	
[09/23 05:00:35][INFO] visual_prompt:  259: Training 172 / 200 epoch, with learning rate 0.07048573784774262
[09/23 05:01:51][INFO] visual_prompt:  327: Epoch 172 / 200: avg data time: 2.16e-02, avg batch time: 0.8978, average train loss: 0.2605average G loss: 0.0352, average realD loss: 4.9876, average fakeD loss: 38.3372, 
[09/23 05:01:54][INFO] visual_prompt:  441: Inference (val):avg data time: 6.89e-05, avg batch time: 0.1171, average loss: 0.5685
[09/23 05:01:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.50	
[09/23 05:02:07][INFO] visual_prompt:  441: Inference (test):avg data time: 8.12e-05, avg batch time: 0.1238, average loss: 0.5617
[09/23 05:02:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.78	top5: 97.86	
[09/23 05:02:08][INFO] visual_prompt:  259: Training 173 / 200 epoch, with learning rate 0.06579416886202283
[09/23 05:03:24][INFO] visual_prompt:  327: Epoch 173 / 200: avg data time: 1.87e-02, avg batch time: 0.8928, average train loss: 0.2159average G loss: 0.0198, average realD loss: 2.5569, average fakeD loss: 63.9646, 
[09/23 05:03:26][INFO] visual_prompt:  441: Inference (val):avg data time: 6.39e-05, avg batch time: 0.1166, average loss: 0.5318
[09/23 05:03:26][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 98.17	
[09/23 05:03:39][INFO] visual_prompt:  441: Inference (test):avg data time: 6.38e-05, avg batch time: 0.1237, average loss: 0.5121
[09/23 05:03:39][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.04	top5: 98.02	
[09/23 05:03:40][INFO] visual_prompt:  259: Training 174 / 200 epoch, with learning rate 0.06125548116690069
[09/23 05:04:56][INFO] visual_prompt:  327: Epoch 174 / 200: avg data time: 1.93e-02, avg batch time: 0.8931, average train loss: 0.2054average G loss: 0.0293, average realD loss: 2.5989, average fakeD loss: 57.1295, 
[09/23 05:04:58][INFO] visual_prompt:  441: Inference (val):avg data time: 8.33e-05, avg batch time: 0.1169, average loss: 0.6088
[09/23 05:04:58][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 98.33	
[09/23 05:05:12][INFO] visual_prompt:  441: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1235, average loss: 0.6034
[09/23 05:05:12][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.38	top5: 97.93	
[09/23 05:05:12][INFO] visual_prompt:  259: Training 175 / 200 epoch, with learning rate 0.05687091559427343
[09/23 05:06:28][INFO] visual_prompt:  327: Epoch 175 / 200: avg data time: 2.10e-02, avg batch time: 0.8959, average train loss: 0.3058average G loss: 0.0499, average realD loss: 6.2545, average fakeD loss: 27.6588, 
[09/23 05:06:31][INFO] visual_prompt:  441: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1164, average loss: 0.5941
[09/23 05:06:31][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.50	
[09/23 05:06:44][INFO] visual_prompt:  441: Inference (test):avg data time: 8.31e-05, avg batch time: 0.1236, average loss: 0.5766
[09/23 05:06:44][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.50	top5: 97.83	
[09/23 05:06:44][INFO] visual_prompt:  259: Training 176 / 200 epoch, with learning rate 0.05264167084058906
[09/23 05:08:01][INFO] visual_prompt:  327: Epoch 176 / 200: avg data time: 2.07e-02, avg batch time: 0.8945, average train loss: 0.2478average G loss: 0.0284, average realD loss: 3.2787, average fakeD loss: 51.2488, 
[09/23 05:08:03][INFO] visual_prompt:  441: Inference (val):avg data time: 5.49e-05, avg batch time: 0.1172, average loss: 0.5546
[09/23 05:08:03][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.50	
[09/23 05:08:17][INFO] visual_prompt:  441: Inference (test):avg data time: 8.16e-05, avg batch time: 0.1237, average loss: 0.5385
[09/23 05:08:17][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 88.13	top5: 98.07	
[09/23 05:08:17][INFO] visual_prompt:  259: Training 177 / 200 epoch, with learning rate 0.048568903139134534
[09/23 05:09:34][INFO] visual_prompt:  327: Epoch 177 / 200: avg data time: 2.09e-02, avg batch time: 0.8950, average train loss: 0.2581average G loss: 0.0380, average realD loss: 4.9554, average fakeD loss: 34.3260, 
[09/23 05:09:36][INFO] visual_prompt:  441: Inference (val):avg data time: 6.81e-05, avg batch time: 0.1165, average loss: 0.6244
[09/23 05:09:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.67	top5: 97.83	
[09/23 05:09:50][INFO] visual_prompt:  441: Inference (test):avg data time: 8.53e-05, avg batch time: 0.1235, average loss: 0.6197
[09/23 05:09:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.00	top5: 97.96	
[09/23 05:09:50][INFO] visual_prompt:  259: Training 178 / 200 epoch, with learning rate 0.044653725943933145
[09/23 05:11:06][INFO] visual_prompt:  327: Epoch 178 / 200: avg data time: 2.11e-02, avg batch time: 0.8955, average train loss: 0.2742average G loss: 0.0388, average realD loss: 5.4457, average fakeD loss: 34.2156, 
[09/23 05:11:08][INFO] visual_prompt:  441: Inference (val):avg data time: 6.36e-05, avg batch time: 0.1171, average loss: 0.5975
[09/23 05:11:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.67	
[09/23 05:11:22][INFO] visual_prompt:  441: Inference (test):avg data time: 7.31e-05, avg batch time: 0.1236, average loss: 0.5939
[09/23 05:11:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.07	top5: 97.83	
[09/23 05:11:22][INFO] visual_prompt:  259: Training 179 / 200 epoch, with learning rate 0.040897209625337036
[09/23 05:12:38][INFO] visual_prompt:  327: Epoch 179 / 200: avg data time: 1.92e-02, avg batch time: 0.8948, average train loss: 0.3110average G loss: 0.0581, average realD loss: 7.6579, average fakeD loss: 19.7210, 
[09/23 05:12:41][INFO] visual_prompt:  441: Inference (val):avg data time: 5.01e-05, avg batch time: 0.1167, average loss: 0.7013
[09/23 05:12:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.83	top5: 98.50	
[09/23 05:12:55][INFO] visual_prompt:  441: Inference (test):avg data time: 7.84e-05, avg batch time: 0.1236, average loss: 0.6768
[09/23 05:12:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.95	top5: 97.93	
[09/23 05:12:55][INFO] visual_prompt:  259: Training 180 / 200 epoch, with learning rate 0.03730038117739927
[09/23 05:14:11][INFO] visual_prompt:  327: Epoch 180 / 200: avg data time: 2.02e-02, avg batch time: 0.8958, average train loss: 0.2922average G loss: 0.0508, average realD loss: 6.1346, average fakeD loss: 28.1601, 
[09/23 05:14:13][INFO] visual_prompt:  441: Inference (val):avg data time: 7.32e-05, avg batch time: 0.1172, average loss: 0.5893
[09/23 05:14:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.50	
[09/23 05:14:27][INFO] visual_prompt:  441: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1237, average loss: 0.5879
[09/23 05:14:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 98.00	
[09/23 05:14:27][INFO] visual_prompt:  259: Training 181 / 200 epoch, with learning rate 0.03386422393710335
[09/23 05:15:44][INFO] visual_prompt:  327: Epoch 181 / 200: avg data time: 2.05e-02, avg batch time: 0.8970, average train loss: 0.3245average G loss: 0.0610, average realD loss: 8.5108, average fakeD loss: 16.0219, 
[09/23 05:15:46][INFO] visual_prompt:  441: Inference (val):avg data time: 6.94e-05, avg batch time: 0.1168, average loss: 0.6870
[09/23 05:15:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.00	top5: 97.83	
[09/23 05:16:00][INFO] visual_prompt:  441: Inference (test):avg data time: 1.00e-04, avg batch time: 0.1238, average loss: 0.6724
[09/23 05:16:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.52	top5: 97.96	
[09/23 05:16:00][INFO] visual_prompt:  259: Training 182 / 200 epoch, with learning rate 0.030589677315529043
[09/23 05:17:16][INFO] visual_prompt:  327: Epoch 182 / 200: avg data time: 2.06e-02, avg batch time: 0.8970, average train loss: 0.3608average G loss: 0.0716, average realD loss: 10.2063, average fakeD loss: 11.3269, 
[09/23 05:17:18][INFO] visual_prompt:  441: Inference (val):avg data time: 7.74e-05, avg batch time: 0.1172, average loss: 0.7330
[09/23 05:17:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 98.50	
[09/23 05:17:32][INFO] visual_prompt:  441: Inference (test):avg data time: 9.14e-05, avg batch time: 0.1240, average loss: 0.7098
[09/23 05:17:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.83	top5: 97.98	
[09/23 05:17:32][INFO] visual_prompt:  259: Training 183 / 200 epoch, with learning rate 0.027477636541026473
[09/23 05:18:49][INFO] visual_prompt:  327: Epoch 183 / 200: avg data time: 1.92e-02, avg batch time: 0.8958, average train loss: 0.3775average G loss: 0.0706, average realD loss: 9.5774, average fakeD loss: 10.7855, 
[09/23 05:18:51][INFO] visual_prompt:  441: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1169, average loss: 0.7165
[09/23 05:18:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 98.50	
[09/23 05:19:05][INFO] visual_prompt:  441: Inference (test):avg data time: 8.53e-05, avg batch time: 0.1238, average loss: 0.7118
[09/23 05:19:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.04	top5: 97.76	
[09/23 05:19:05][INFO] visual_prompt:  259: Training 184 / 200 epoch, with learning rate 0.02452895241446991
[09/23 05:20:21][INFO] visual_prompt:  327: Epoch 184 / 200: avg data time: 1.99e-02, avg batch time: 0.8969, average train loss: 0.4163average G loss: 0.0963, average realD loss: 11.6778, average fakeD loss: 7.7275, 
[09/23 05:20:24][INFO] visual_prompt:  441: Inference (val):avg data time: 6.92e-05, avg batch time: 0.1168, average loss: 0.7943
[09/23 05:20:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/23 05:20:37][INFO] visual_prompt:  441: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1235, average loss: 0.7746
[09/23 05:20:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.88	top5: 97.76	
[09/23 05:20:38][INFO] visual_prompt:  259: Training 185 / 200 epoch, with learning rate 0.021744431076657147
[09/23 05:21:54][INFO] visual_prompt:  327: Epoch 185 / 200: avg data time: 1.91e-02, avg batch time: 0.8958, average train loss: 0.4553average G loss: 0.1013, average realD loss: 11.0155, average fakeD loss: 6.6603, 
[09/23 05:21:56][INFO] visual_prompt:  441: Inference (val):avg data time: 6.61e-05, avg batch time: 0.1166, average loss: 0.7614
[09/23 05:21:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.33	
[09/23 05:22:10][INFO] visual_prompt:  441: Inference (test):avg data time: 9.87e-05, avg batch time: 0.1238, average loss: 0.7544
[09/23 05:22:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.57	top5: 97.88	
[09/23 05:22:10][INFO] visual_prompt:  259: Training 186 / 200 epoch, with learning rate 0.019124833787918516
[09/23 05:23:26][INFO] visual_prompt:  327: Epoch 186 / 200: avg data time: 1.91e-02, avg batch time: 0.8964, average train loss: 0.4999average G loss: 0.1360, average realD loss: 11.8906, average fakeD loss: 5.9990, 
[09/23 05:23:29][INFO] visual_prompt:  441: Inference (val):avg data time: 7.03e-05, avg batch time: 0.1170, average loss: 0.7477
[09/23 05:23:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.00	top5: 97.83	
[09/23 05:23:43][INFO] visual_prompt:  441: Inference (test):avg data time: 7.77e-05, avg batch time: 0.1239, average loss: 0.7309
[09/23 05:23:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.06	top5: 98.07	
[09/23 05:23:43][INFO] visual_prompt:  259: Training 187 / 200 epoch, with learning rate 0.01667087671999641
[09/23 05:24:59][INFO] visual_prompt:  327: Epoch 187 / 200: avg data time: 2.06e-02, avg batch time: 0.8978, average train loss: 0.5034average G loss: 0.1429, average realD loss: 10.0160, average fakeD loss: 5.0365, 
[09/23 05:25:02][INFO] visual_prompt:  441: Inference (val):avg data time: 5.55e-05, avg batch time: 0.1170, average loss: 0.8055
[09/23 05:25:02][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 97.50	
[09/23 05:25:15][INFO] visual_prompt:  441: Inference (test):avg data time: 7.78e-05, avg batch time: 0.1237, average loss: 0.7843
[09/23 05:25:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.23	top5: 97.72	
[09/23 05:25:15][INFO] visual_prompt:  259: Training 188 / 200 epoch, with learning rate 0.014383230760250457
[09/23 05:26:32][INFO] visual_prompt:  327: Epoch 188 / 200: avg data time: 1.90e-02, avg batch time: 0.8966, average train loss: 0.5436average G loss: 0.1445, average realD loss: 10.5876, average fakeD loss: 4.4248, 
[09/23 05:26:34][INFO] visual_prompt:  441: Inference (val):avg data time: 6.85e-05, avg batch time: 0.1168, average loss: 0.9079
[09/23 05:26:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 97.50	
[09/23 05:26:48][INFO] visual_prompt:  441: Inference (test):avg data time: 7.36e-05, avg batch time: 0.1241, average loss: 0.8885
[09/23 05:26:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.73	top5: 97.96	
[09/23 05:26:48][INFO] visual_prompt:  259: Training 189 / 200 epoch, with learning rate 0.012262521328244153
[09/23 05:28:04][INFO] visual_prompt:  327: Epoch 189 / 200: avg data time: 1.86e-02, avg batch time: 0.8959, average train loss: 0.5693average G loss: 0.1883, average realD loss: 9.8482, average fakeD loss: 3.5881, 
[09/23 05:28:06][INFO] visual_prompt:  441: Inference (val):avg data time: 6.30e-05, avg batch time: 0.1172, average loss: 0.9037
[09/23 05:28:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 98.00	
[09/23 05:28:20][INFO] visual_prompt:  441: Inference (test):avg data time: 7.97e-05, avg batch time: 0.1237, average loss: 0.8831
[09/23 05:28:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.54	top5: 97.81	
[09/23 05:28:20][INFO] visual_prompt:  259: Training 190 / 200 epoch, with learning rate 0.01030932820476102
[09/23 05:29:37][INFO] visual_prompt:  327: Epoch 190 / 200: avg data time: 2.06e-02, avg batch time: 0.8979, average train loss: 0.5655average G loss: 0.2217, average realD loss: 8.1629, average fakeD loss: 2.7303, 
[09/23 05:29:39][INFO] visual_prompt:  441: Inference (val):avg data time: 8.32e-05, avg batch time: 0.1167, average loss: 0.8247
[09/23 05:29:39][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.50	top5: 98.00	
[09/23 05:29:53][INFO] visual_prompt:  441: Inference (test):avg data time: 7.86e-05, avg batch time: 0.1235, average loss: 0.8161
[09/23 05:29:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.19	top5: 98.03	
[09/23 05:29:54][INFO] visual_prompt:  259: Training 191 / 200 epoch, with learning rate 0.008524185373298548
[09/23 05:31:10][INFO] visual_prompt:  327: Epoch 191 / 200: avg data time: 1.94e-02, avg batch time: 0.8967, average train loss: 0.5315average G loss: 0.2209, average realD loss: 6.9881, average fakeD loss: 2.5451, 
[09/23 05:31:12][INFO] visual_prompt:  441: Inference (val):avg data time: 5.61e-05, avg batch time: 0.1181, average loss: 0.7970
[09/23 05:31:12][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 87.50	top5: 98.50	
[09/23 05:31:26][INFO] visual_prompt:  441: Inference (test):avg data time: 1.00e-04, avg batch time: 0.1238, average loss: 0.7970
[09/23 05:31:26][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.23	top5: 97.96	
[09/23 05:31:26][INFO] visual_prompt:  259: Training 192 / 200 epoch, with learning rate 0.006907580874082192
[09/23 05:32:43][INFO] visual_prompt:  327: Epoch 192 / 200: avg data time: 2.03e-02, avg batch time: 0.8980, average train loss: 0.5473average G loss: 0.2372, average realD loss: 7.2890, average fakeD loss: 2.2536, 
[09/23 05:32:45][INFO] visual_prompt:  441: Inference (val):avg data time: 6.06e-05, avg batch time: 0.1169, average loss: 0.8695
[09/23 05:32:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.33	
[09/23 05:32:59][INFO] visual_prompt:  441: Inference (test):avg data time: 7.65e-05, avg batch time: 0.1237, average loss: 0.8682
[09/23 05:32:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.69	top5: 97.96	
[09/23 05:32:59][INFO] visual_prompt:  259: Training 193 / 200 epoch, with learning rate 0.005459956670640503
[09/23 05:34:16][INFO] visual_prompt:  327: Epoch 193 / 200: avg data time: 2.10e-02, avg batch time: 0.8987, average train loss: 0.5613average G loss: 0.2499, average realD loss: 6.8169, average fakeD loss: 2.0230, 
[09/23 05:34:18][INFO] visual_prompt:  441: Inference (val):avg data time: 6.71e-05, avg batch time: 0.1177, average loss: 0.8259
[09/23 05:34:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.17	
[09/23 05:34:32][INFO] visual_prompt:  441: Inference (test):avg data time: 8.57e-05, avg batch time: 0.1239, average loss: 0.8209
[09/23 05:34:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.64	top5: 97.96	
[09/23 05:34:32][INFO] visual_prompt:  259: Training 194 / 200 epoch, with learning rate 0.004181708528976161
[09/23 05:35:48][INFO] visual_prompt:  327: Epoch 194 / 200: avg data time: 2.19e-02, avg batch time: 0.8999, average train loss: 0.5179average G loss: 0.2291, average realD loss: 6.0146, average fakeD loss: 2.0163, 
[09/23 05:35:51][INFO] visual_prompt:  441: Inference (val):avg data time: 6.95e-05, avg batch time: 0.1170, average loss: 0.7909
[09/23 05:35:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.33	
[09/23 05:36:05][INFO] visual_prompt:  441: Inference (test):avg data time: 7.88e-05, avg batch time: 0.1242, average loss: 0.7902
[09/23 05:36:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.56	top5: 98.08	
[09/23 05:36:05][INFO] visual_prompt:  259: Training 195 / 200 epoch, with learning rate 0.003073185909367865
[09/23 05:37:21][INFO] visual_prompt:  327: Epoch 195 / 200: avg data time: 1.93e-02, avg batch time: 0.8976, average train loss: 0.4966average G loss: 0.2231, average realD loss: 5.6260, average fakeD loss: 1.9977, 
[09/23 05:37:23][INFO] visual_prompt:  441: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1179, average loss: 0.7839
[09/23 05:37:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.67	top5: 98.33	
[09/23 05:37:37][INFO] visual_prompt:  441: Inference (test):avg data time: 8.91e-05, avg batch time: 0.1241, average loss: 0.7818
[09/23 05:37:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.69	top5: 98.26	
[09/23 05:37:37][INFO] visual_prompt:  259: Training 196 / 200 epoch, with learning rate 0.0021346918708313456
[09/23 05:38:54][INFO] visual_prompt:  327: Epoch 196 / 200: avg data time: 1.95e-02, avg batch time: 0.8973, average train loss: 0.4910average G loss: 0.2218, average realD loss: 5.3355, average fakeD loss: 1.9922, 
[09/23 05:38:56][INFO] visual_prompt:  441: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1174, average loss: 0.7821
[09/23 05:38:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.33	top5: 98.50	
[09/23 05:39:10][INFO] visual_prompt:  441: Inference (test):avg data time: 7.24e-05, avg batch time: 0.1236, average loss: 0.7769
[09/23 05:39:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.76	top5: 98.24	
[09/23 05:39:10][INFO] visual_prompt:  259: Training 197 / 200 epoch, with learning rate 0.0013664829882659157
[09/23 05:40:26][INFO] visual_prompt:  327: Epoch 197 / 200: avg data time: 1.98e-02, avg batch time: 0.8975, average train loss: 0.4929average G loss: 0.2153, average realD loss: 5.1562, average fakeD loss: 2.0119, 
[09/23 05:40:29][INFO] visual_prompt:  441: Inference (val):avg data time: 5.69e-05, avg batch time: 0.1171, average loss: 0.7796
[09/23 05:40:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 98.67	
[09/23 05:40:42][INFO] visual_prompt:  441: Inference (test):avg data time: 8.32e-05, avg batch time: 0.1236, average loss: 0.7721
[09/23 05:40:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.69	top5: 98.26	
[09/23 05:40:43][INFO] visual_prompt:  259: Training 198 / 200 epoch, with learning rate 0.0007687692823095393
[09/23 05:41:59][INFO] visual_prompt:  327: Epoch 198 / 200: avg data time: 1.93e-02, avg batch time: 0.8961, average train loss: 0.4872average G loss: 0.2094, average realD loss: 5.2010, average fakeD loss: 2.0370, 
[09/23 05:42:01][INFO] visual_prompt:  441: Inference (val):avg data time: 7.82e-05, avg batch time: 0.1172, average loss: 0.7769
[09/23 05:42:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.67	
[09/23 05:42:15][INFO] visual_prompt:  441: Inference (test):avg data time: 9.56e-05, avg batch time: 0.1237, average loss: 0.7687
[09/23 05:42:15][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.88	top5: 98.26	
[09/23 05:42:15][INFO] visual_prompt:  259: Training 199 / 200 epoch, with learning rate 0.0003417141619212194
[09/23 05:43:31][INFO] visual_prompt:  327: Epoch 199 / 200: avg data time: 1.89e-02, avg batch time: 0.8945, average train loss: 0.4850average G loss: 0.2060, average realD loss: 5.1498, average fakeD loss: 2.0368, 
[09/23 05:43:34][INFO] visual_prompt:  441: Inference (val):avg data time: 6.00e-05, avg batch time: 0.1167, average loss: 0.7750
[09/23 05:43:34][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.67	
[09/23 05:43:47][INFO] visual_prompt:  441: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1236, average loss: 0.7663
[09/23 05:43:48][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.92	top5: 98.21	
[09/23 05:43:48][INFO] visual_prompt:  259: Training 200 / 200 epoch, with learning rate 8.54343797068724e-05
[09/23 05:45:04][INFO] visual_prompt:  327: Epoch 200 / 200: avg data time: 2.05e-02, avg batch time: 0.8957, average train loss: 0.4862average G loss: 0.2085, average realD loss: 5.0963, average fakeD loss: 2.0312, 
[09/23 05:45:06][INFO] visual_prompt:  441: Inference (val):avg data time: 6.73e-05, avg batch time: 0.1175, average loss: 0.7748
[09/23 05:45:06][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 86.17	top5: 98.67	
[09/23 05:45:20][INFO] visual_prompt:  441: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1238, average loss: 0.7661
[09/23 05:45:20][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 87.92	top5: 98.21	
