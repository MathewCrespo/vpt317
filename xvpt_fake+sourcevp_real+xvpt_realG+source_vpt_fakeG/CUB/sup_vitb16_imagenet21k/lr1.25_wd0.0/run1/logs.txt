[09/25 00:41:13][INFO] visual_prompt:   97: Rank of current process: 0. World size: 1
[09/25 00:41:13][INFO] visual_prompt:   98: Environment info:
-------------------  ---------------------------------------------------
Python               3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                GeForce RTX 3090
Pillow               9.2.0
cv2                  4.6.0
-------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/25 00:41:13][INFO] visual_prompt:  100: Command line arguments: Namespace(config_file='configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit-gan', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'MODEL.PROMPT.NUM_TOKENS', '10', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.DATAPATH', '/remote-home/share/VPT/data/CUB_200_2011', 'MODEL.MODEL_ROOT', '/remote-home/share/VPT/pretrain/', 'OUTPUT_DIR', 'xvpt_fake+sourcevp_real+xvpt_realG+source_vpt_fakeG', 'MODEL.TRANSFER_TYPE', 'prompt+gan'], train_type='prompt')
[09/25 00:41:13][INFO] visual_prompt:  105: Contents of args.config_file=configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 5
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 00:41:13][INFO] visual_prompt:  109: Training with config:
[09/25 00:41:13][INFO] visual_prompt:  110: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': '/remote-home/share/VPT/data/CUB_200_2011',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'CUB',
          'NO_TEST': False,
          'NUMBER_CLASSES': 200,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'DIST_BACKEND': 'nccl',
 'DIST_INIT_FILE': '',
 'DIST_INIT_PATH': 'env://',
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': '/remote-home/share/VPT/pretrain/',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 10,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt+gan',
           'TYPE': 'vit-gan',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'xvpt_fake+sourcevp_real+xvpt_realG+source_vpt_fakeG/CUB/sup_vitb16_imagenet21k/lr1.25_wd0.0/run1',
 'RUN_N_TIMES': 5,
 'SEED': None,
 'SOLVER': {'BASE_LR': 1.25,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0,
            'WEIGHT_DECAY_BIAS': 0}}
[09/25 00:41:13][INFO] visual_prompt:   67: Loading training data (final training data for vtab)...
[09/25 00:41:13][INFO] visual_prompt:   28: Constructing CUB dataset train...
[09/25 00:41:13][INFO] visual_prompt:   77: Number of images: 5394
[09/25 00:41:13][INFO] visual_prompt:   78: Number of classes: 200
[09/25 00:41:13][INFO] visual_prompt:   42: Number of Source Images: 1000
[09/25 00:41:13][INFO] visual_prompt:   73: Loading validation data...
[09/25 00:41:13][INFO] visual_prompt:   28: Constructing CUB dataset val...
[09/25 00:41:13][INFO] visual_prompt:   77: Number of images: 600
[09/25 00:41:13][INFO] visual_prompt:   78: Number of classes: 200
[09/25 00:41:13][INFO] visual_prompt:   76: Loading test data...
[09/25 00:41:13][INFO] visual_prompt:   28: Constructing CUB dataset test...
[09/25 00:41:13][INFO] visual_prompt:   77: Number of images: 5794
[09/25 00:41:13][INFO] visual_prompt:   78: Number of classes: 200
[09/25 00:41:13][INFO] visual_prompt:  103: Constructing models...
[09/25 00:41:19][INFO] visual_prompt:   54: Total Parameters: 171843272	 Gradient Parameters: 245960
[09/25 00:41:19][INFO] visual_prompt:   55: tuned percent:0.143
[09/25 00:41:20][INFO] visual_prompt:   41: Device used for model: 0
[09/25 00:41:20][INFO] visual_prompt:  106: Setting up Evalutator...
[09/25 00:41:20][INFO] visual_prompt:  108: Setting up Trainer...
[09/25 00:41:20][INFO] visual_prompt:   58: 	Setting up the optimizer...
[09/25 00:41:20][INFO] visual_prompt:  266: Training 1 / 100 epoch, with learning rate 0.0
[09/25 00:42:50][INFO] visual_prompt:  334: Epoch 1 / 100: avg data time: 1.89e-02, avg batch time: 1.0638, average train loss: 5.3345average G loss: 4.8880, average realD loss: 1.8002, average fakeD loss: 3.0068, 
[09/25 00:42:53][INFO] visual_prompt:  448: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1195, average loss: 5.3374
[09/25 00:42:53][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.17	top5: 1.83	
[09/25 00:43:07][INFO] visual_prompt:  448: Inference (test):avg data time: 7.49e-05, avg batch time: 0.1264, average loss: 5.3345
[09/25 00:43:07][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.38	top5: 2.24	
[09/25 00:43:07][INFO] visual_prompt:  370: Best epoch 1: best metric: 0.002
[09/25 00:43:07][INFO] visual_prompt:  266: Training 2 / 100 epoch, with learning rate 0.125
[09/25 00:44:37][INFO] visual_prompt:  334: Epoch 2 / 100: avg data time: 2.03e-02, avg batch time: 1.0663, average train loss: 5.3403average G loss: 9.8217, average realD loss: 2.9073, average fakeD loss: 6.6093, 
[09/25 00:44:40][INFO] visual_prompt:  448: Inference (val):avg data time: 5.34e-05, avg batch time: 0.1196, average loss: 5.3069
[09/25 00:44:40][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.33	top5: 2.67	
[09/25 00:44:54][INFO] visual_prompt:  448: Inference (test):avg data time: 9.49e-05, avg batch time: 0.1264, average loss: 5.3072
[09/25 00:44:54][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.64	top5: 2.85	
[09/25 00:44:54][INFO] visual_prompt:  370: Best epoch 2: best metric: 0.003
[09/25 00:44:54][INFO] visual_prompt:  266: Training 3 / 100 epoch, with learning rate 0.25
[09/25 00:46:25][INFO] visual_prompt:  334: Epoch 3 / 100: avg data time: 1.83e-02, avg batch time: 1.0632, average train loss: 5.3590average G loss: 9.8709, average realD loss: 2.1628, average fakeD loss: 7.6510, 
[09/25 00:46:27][INFO] visual_prompt:  448: Inference (val):avg data time: 5.08e-05, avg batch time: 0.1195, average loss: 5.3250
[09/25 00:46:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/25 00:46:41][INFO] visual_prompt:  448: Inference (test):avg data time: 6.39e-05, avg batch time: 0.1268, average loss: 5.3260
[09/25 00:46:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.57	
[09/25 00:46:41][INFO] visual_prompt:  370: Best epoch 3: best metric: 0.005
[09/25 00:46:41][INFO] visual_prompt:  266: Training 4 / 100 epoch, with learning rate 0.375
[09/25 00:48:11][INFO] visual_prompt:  334: Epoch 4 / 100: avg data time: 1.96e-02, avg batch time: 1.0606, average train loss: 5.3818average G loss: 9.9514, average realD loss: 0.6564, average fakeD loss: 9.2332, 
[09/25 00:48:13][INFO] visual_prompt:  448: Inference (val):avg data time: 7.12e-05, avg batch time: 0.1196, average loss: 5.3427
[09/25 00:48:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 3.00	
[09/25 00:48:27][INFO] visual_prompt:  448: Inference (test):avg data time: 7.87e-05, avg batch time: 0.1267, average loss: 5.3453
[09/25 00:48:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.52	top5: 2.69	
[09/25 00:48:27][INFO] visual_prompt:  266: Training 5 / 100 epoch, with learning rate 0.5
[09/25 00:49:57][INFO] visual_prompt:  334: Epoch 5 / 100: avg data time: 2.05e-02, avg batch time: 1.0576, average train loss: 5.3952average G loss: 9.9987, average realD loss: 0.0085, average fakeD loss: 9.9852, 
[09/25 00:50:00][INFO] visual_prompt:  448: Inference (val):avg data time: 5.70e-05, avg batch time: 0.1194, average loss: 5.3649
[09/25 00:50:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.50	top5: 2.50	
[09/25 00:50:13][INFO] visual_prompt:  448: Inference (test):avg data time: 7.24e-05, avg batch time: 0.1268, average loss: 5.3654
[09/25 00:50:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.50	top5: 2.76	
[09/25 00:50:13][INFO] visual_prompt:  266: Training 6 / 100 epoch, with learning rate 0.625
[09/25 00:51:43][INFO] visual_prompt:  334: Epoch 6 / 100: avg data time: 1.96e-02, avg batch time: 1.0564, average train loss: 5.4125average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 00:51:46][INFO] visual_prompt:  448: Inference (val):avg data time: 6.80e-05, avg batch time: 0.1191, average loss: 5.4057
[09/25 00:51:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.17	top5: 2.33	
[09/25 00:52:00][INFO] visual_prompt:  448: Inference (test):avg data time: 8.43e-05, avg batch time: 0.1263, average loss: 5.4087
[09/25 00:52:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.60	top5: 2.61	
[09/25 00:52:00][INFO] visual_prompt:  266: Training 7 / 100 epoch, with learning rate 0.75
[09/25 00:53:30][INFO] visual_prompt:  334: Epoch 7 / 100: avg data time: 1.98e-02, avg batch time: 1.0567, average train loss: 5.4313average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 00:53:32][INFO] visual_prompt:  448: Inference (val):avg data time: 8.56e-05, avg batch time: 0.1192, average loss: 5.4197
[09/25 00:53:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 0.83	top5: 2.83	
[09/25 00:53:46][INFO] visual_prompt:  448: Inference (test):avg data time: 6.51e-05, avg batch time: 0.1270, average loss: 5.4256
[09/25 00:53:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 0.57	top5: 2.62	
[09/25 00:53:46][INFO] visual_prompt:  370: Best epoch 7: best metric: 0.008
[09/25 00:53:46][INFO] visual_prompt:  266: Training 8 / 100 epoch, with learning rate 0.875
[09/25 00:55:16][INFO] visual_prompt:  334: Epoch 8 / 100: avg data time: 1.94e-02, avg batch time: 1.0565, average train loss: 5.4298average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 00:55:19][INFO] visual_prompt:  448: Inference (val):avg data time: 7.77e-05, avg batch time: 0.1196, average loss: 5.3297
[09/25 00:55:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 1.00	top5: 5.00	
[09/25 00:55:32][INFO] visual_prompt:  448: Inference (test):avg data time: 7.35e-05, avg batch time: 0.1266, average loss: 5.3289
[09/25 00:55:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 1.09	top5: 5.30	
[09/25 00:55:32][INFO] visual_prompt:  370: Best epoch 8: best metric: 0.010
[09/25 00:55:32][INFO] visual_prompt:  266: Training 9 / 100 epoch, with learning rate 1.0
[09/25 00:57:02][INFO] visual_prompt:  334: Epoch 9 / 100: avg data time: 1.93e-02, avg batch time: 1.0568, average train loss: 5.1441average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 00:57:05][INFO] visual_prompt:  448: Inference (val):avg data time: 6.58e-05, avg batch time: 0.1195, average loss: 4.5469
[09/25 00:57:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 9.50	top5: 21.33	
[09/25 00:57:19][INFO] visual_prompt:  448: Inference (test):avg data time: 8.04e-05, avg batch time: 0.1267, average loss: 4.5504
[09/25 00:57:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 8.73	top5: 20.00	
[09/25 00:57:19][INFO] visual_prompt:  370: Best epoch 9: best metric: 0.095
[09/25 00:57:19][INFO] visual_prompt:  266: Training 10 / 100 epoch, with learning rate 1.125
[09/25 00:58:49][INFO] visual_prompt:  334: Epoch 10 / 100: avg data time: 1.93e-02, avg batch time: 1.0570, average train loss: 2.3957average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 00:58:51][INFO] visual_prompt:  448: Inference (val):avg data time: 5.89e-05, avg batch time: 0.1195, average loss: 1.1062
[09/25 00:58:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 70.00	top5: 93.67	
[09/25 00:59:05][INFO] visual_prompt:  448: Inference (test):avg data time: 9.23e-05, avg batch time: 0.1266, average loss: 1.0510
[09/25 00:59:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 70.71	top5: 94.06	
[09/25 00:59:05][INFO] visual_prompt:  370: Best epoch 10: best metric: 0.700
[09/25 00:59:05][INFO] visual_prompt:  266: Training 11 / 100 epoch, with learning rate 1.25
[09/25 01:00:35][INFO] visual_prompt:  334: Epoch 11 / 100: avg data time: 1.88e-02, avg batch time: 1.0570, average train loss: 0.8245average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:00:37][INFO] visual_prompt:  448: Inference (val):avg data time: 9.32e-05, avg batch time: 0.1197, average loss: 0.7980
[09/25 01:00:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 79.67	top5: 95.83	
[09/25 01:00:51][INFO] visual_prompt:  448: Inference (test):avg data time: 7.32e-05, avg batch time: 0.1266, average loss: 0.7660
[09/25 01:00:52][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 78.93	top5: 96.81	
[09/25 01:00:52][INFO] visual_prompt:  370: Best epoch 11: best metric: 0.797
[09/25 01:00:52][INFO] visual_prompt:  266: Training 12 / 100 epoch, with learning rate 1.2496192668869348
[09/25 01:02:22][INFO] visual_prompt:  334: Epoch 12 / 100: avg data time: 2.06e-02, avg batch time: 1.0588, average train loss: 0.5054average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:02:24][INFO] visual_prompt:  448: Inference (val):avg data time: 6.43e-05, avg batch time: 0.1198, average loss: 0.6995
[09/25 01:02:24][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.17	top5: 96.67	
[09/25 01:02:38][INFO] visual_prompt:  448: Inference (test):avg data time: 1.14e-04, avg batch time: 0.1268, average loss: 0.7061
[09/25 01:02:38][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.98	top5: 96.81	
[09/25 01:02:38][INFO] visual_prompt:  370: Best epoch 12: best metric: 0.812
[09/25 01:02:38][INFO] visual_prompt:  266: Training 13 / 100 epoch, with learning rate 1.2484775314123902
[09/25 01:04:08][INFO] visual_prompt:  334: Epoch 13 / 100: avg data time: 1.87e-02, avg batch time: 1.0562, average train loss: 0.3637average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:04:10][INFO] visual_prompt:  448: Inference (val):avg data time: 8.13e-05, avg batch time: 0.1195, average loss: 0.6919
[09/25 01:04:10][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 81.50	top5: 97.00	
[09/25 01:04:24][INFO] visual_prompt:  448: Inference (test):avg data time: 7.15e-05, avg batch time: 0.1266, average loss: 0.6355
[09/25 01:04:24][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.09	top5: 97.24	
[09/25 01:04:24][INFO] visual_prompt:  370: Best epoch 13: best metric: 0.815
[09/25 01:04:24][INFO] visual_prompt:  266: Training 14 / 100 epoch, with learning rate 1.2465761846051708
[09/25 01:05:54][INFO] visual_prompt:  334: Epoch 14 / 100: avg data time: 1.98e-02, avg batch time: 1.0573, average train loss: 0.2641average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:05:56][INFO] visual_prompt:  448: Inference (val):avg data time: 7.60e-05, avg batch time: 0.1198, average loss: 0.7715
[09/25 01:05:56][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 80.67	top5: 96.83	
[09/25 01:06:10][INFO] visual_prompt:  448: Inference (test):avg data time: 8.81e-05, avg batch time: 0.1266, average loss: 0.7426
[09/25 01:06:10][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 81.24	top5: 96.96	
[09/25 01:06:10][INFO] visual_prompt:  266: Training 15 / 100 epoch, with learning rate 1.2439175429634814
[09/25 01:07:40][INFO] visual_prompt:  334: Epoch 15 / 100: avg data time: 1.87e-02, avg batch time: 1.0555, average train loss: 0.2178average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:07:43][INFO] visual_prompt:  448: Inference (val):avg data time: 5.84e-05, avg batch time: 0.1198, average loss: 0.6680
[09/25 01:07:43][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.50	top5: 97.17	
[09/25 01:07:57][INFO] visual_prompt:  448: Inference (test):avg data time: 7.49e-05, avg batch time: 0.1262, average loss: 0.6475
[09/25 01:07:57][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 83.59	top5: 96.96	
[09/25 01:07:57][INFO] visual_prompt:  370: Best epoch 15: best metric: 0.825
[09/25 01:07:57][INFO] visual_prompt:  266: Training 16 / 100 epoch, with learning rate 1.2405048456326302
[09/25 01:09:27][INFO] visual_prompt:  334: Epoch 16 / 100: avg data time: 1.95e-02, avg batch time: 1.0554, average train loss: 0.1665average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:09:29][INFO] visual_prompt:  448: Inference (val):avg data time: 6.73e-05, avg batch time: 0.1196, average loss: 0.6771
[09/25 01:09:29][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 82.17	top5: 96.83	
[09/25 01:09:43][INFO] visual_prompt:  448: Inference (test):avg data time: 7.10e-05, avg batch time: 0.1264, average loss: 0.6291
[09/25 01:09:43][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.90	top5: 97.19	
[09/25 01:09:43][INFO] visual_prompt:  266: Training 17 / 100 epoch, with learning rate 1.2363422504586286
[09/25 01:11:13][INFO] visual_prompt:  334: Epoch 17 / 100: avg data time: 1.99e-02, avg batch time: 1.0544, average train loss: 0.1375average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:11:15][INFO] visual_prompt:  448: Inference (val):avg data time: 5.43e-05, avg batch time: 0.1195, average loss: 0.6956
[09/25 01:11:15][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.17	top5: 96.50	
[09/25 01:11:29][INFO] visual_prompt:  448: Inference (test):avg data time: 9.49e-05, avg batch time: 0.1263, average loss: 0.6673
[09/25 01:11:29][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.59	top5: 96.96	
[09/25 01:11:29][INFO] visual_prompt:  370: Best epoch 17: best metric: 0.832
[09/25 01:11:29][INFO] visual_prompt:  266: Training 18 / 100 epoch, with learning rate 1.2314348289224977
[09/25 01:12:58][INFO] visual_prompt:  334: Epoch 18 / 100: avg data time: 1.73e-02, avg batch time: 1.0507, average train loss: 0.0960average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:13:01][INFO] visual_prompt:  448: Inference (val):avg data time: 6.89e-05, avg batch time: 0.1190, average loss: 0.6606
[09/25 01:13:01][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.33	top5: 96.33	
[09/25 01:13:14][INFO] visual_prompt:  448: Inference (test):avg data time: 7.61e-05, avg batch time: 0.1265, average loss: 0.6383
[09/25 01:13:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.38	top5: 96.98	
[09/25 01:13:14][INFO] visual_prompt:  370: Best epoch 18: best metric: 0.833
[09/25 01:13:14][INFO] visual_prompt:  266: Training 19 / 100 epoch, with learning rate 1.2257885599614493
[09/25 01:14:44][INFO] visual_prompt:  334: Epoch 19 / 100: avg data time: 1.95e-02, avg batch time: 1.0520, average train loss: 0.0903average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:14:46][INFO] visual_prompt:  448: Inference (val):avg data time: 5.21e-05, avg batch time: 0.1198, average loss: 0.6785
[09/25 01:14:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 96.83	
[09/25 01:15:00][INFO] visual_prompt:  448: Inference (test):avg data time: 9.55e-05, avg batch time: 0.1258, average loss: 0.6390
[09/25 01:15:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.02	top5: 96.98	
[09/25 01:15:00][INFO] visual_prompt:  370: Best epoch 19: best metric: 0.835
[09/25 01:15:00][INFO] visual_prompt:  266: Training 20 / 100 epoch, with learning rate 1.219410322684471
[09/25 01:16:30][INFO] visual_prompt:  334: Epoch 20 / 100: avg data time: 2.05e-02, avg batch time: 1.0532, average train loss: 0.0666average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:16:32][INFO] visual_prompt:  448: Inference (val):avg data time: 5.75e-05, avg batch time: 0.1187, average loss: 0.6530
[09/25 01:16:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.50	top5: 97.17	
[09/25 01:16:46][INFO] visual_prompt:  448: Inference (test):avg data time: 7.02e-05, avg batch time: 0.1264, average loss: 0.6371
[09/25 01:16:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.67	top5: 97.22	
[09/25 01:16:46][INFO] visual_prompt:  266: Training 21 / 100 epoch, with learning rate 1.2123078879911928
[09/25 01:18:16][INFO] visual_prompt:  334: Epoch 21 / 100: avg data time: 2.03e-02, avg batch time: 1.0540, average train loss: 0.0535average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:18:18][INFO] visual_prompt:  448: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1192, average loss: 0.6394
[09/25 01:18:18][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 97.00	
[09/25 01:18:32][INFO] visual_prompt:  448: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1259, average loss: 0.6255
[09/25 01:18:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.14	top5: 97.05	
[09/25 01:18:32][INFO] visual_prompt:  370: Best epoch 21: best metric: 0.838
[09/25 01:18:32][INFO] visual_prompt:  266: Training 22 / 100 epoch, with learning rate 1.2044899091042423
[09/25 01:20:02][INFO] visual_prompt:  334: Epoch 22 / 100: avg data time: 1.95e-02, avg batch time: 1.0542, average train loss: 0.0463average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:20:04][INFO] visual_prompt:  448: Inference (val):avg data time: 6.35e-05, avg batch time: 0.1192, average loss: 0.6435
[09/25 01:20:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.00	
[09/25 01:20:18][INFO] visual_prompt:  448: Inference (test):avg data time: 9.27e-05, avg batch time: 0.1263, average loss: 0.6242
[09/25 01:20:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.55	top5: 97.10	
[09/25 01:20:18][INFO] visual_prompt:  370: Best epoch 22: best metric: 0.857
[09/25 01:20:18][INFO] visual_prompt:  266: Training 23 / 100 epoch, with learning rate 1.1959659110266254
[09/25 01:21:48][INFO] visual_prompt:  334: Epoch 23 / 100: avg data time: 1.92e-02, avg batch time: 1.0541, average train loss: 0.0423average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:21:50][INFO] visual_prompt:  448: Inference (val):avg data time: 8.46e-05, avg batch time: 0.1193, average loss: 0.6306
[09/25 01:21:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 96.83	
[09/25 01:22:04][INFO] visual_prompt:  448: Inference (test):avg data time: 7.29e-05, avg batch time: 0.1267, average loss: 0.6402
[09/25 01:22:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.43	top5: 97.05	
[09/25 01:22:04][INFO] visual_prompt:  266: Training 24 / 100 epoch, with learning rate 1.1867462789369794
[09/25 01:23:34][INFO] visual_prompt:  334: Epoch 24 / 100: avg data time: 1.82e-02, avg batch time: 1.0542, average train loss: 0.0335average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:23:36][INFO] visual_prompt:  448: Inference (val):avg data time: 8.09e-05, avg batch time: 0.1207, average loss: 0.6261
[09/25 01:23:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 97.00	
[09/25 01:23:50][INFO] visual_prompt:  448: Inference (test):avg data time: 7.67e-05, avg batch time: 0.1266, average loss: 0.6575
[09/25 01:23:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 84.59	top5: 97.13	
[09/25 01:23:50][INFO] visual_prompt:  266: Training 25 / 100 epoch, with learning rate 1.1768422455368293
[09/25 01:25:20][INFO] visual_prompt:  334: Epoch 25 / 100: avg data time: 1.98e-02, avg batch time: 1.0568, average train loss: 0.0369average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:25:22][INFO] visual_prompt:  448: Inference (val):avg data time: 6.20e-05, avg batch time: 0.1203, average loss: 0.6064
[09/25 01:25:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 97.33	
[09/25 01:25:36][INFO] visual_prompt:  448: Inference (test):avg data time: 8.86e-05, avg batch time: 0.1263, average loss: 0.6239
[09/25 01:25:36][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.28	top5: 97.15	
[09/25 01:25:36][INFO] visual_prompt:  266: Training 26 / 100 epoch, with learning rate 1.1662658773652743
[09/25 01:27:06][INFO] visual_prompt:  334: Epoch 26 / 100: avg data time: 2.07e-02, avg batch time: 1.0571, average train loss: 0.0315average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:27:08][INFO] visual_prompt:  448: Inference (val):avg data time: 6.66e-05, avg batch time: 0.1198, average loss: 0.5909
[09/25 01:27:08][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 97.17	
[09/25 01:27:22][INFO] visual_prompt:  448: Inference (test):avg data time: 8.60e-05, avg batch time: 0.1265, average loss: 0.6262
[09/25 01:27:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.11	top5: 97.03	
[09/25 01:27:22][INFO] visual_prompt:  266: Training 27 / 100 epoch, with learning rate 1.155030060097766
[09/25 01:28:52][INFO] visual_prompt:  334: Epoch 27 / 100: avg data time: 1.92e-02, avg batch time: 1.0559, average train loss: 0.0283average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:28:54][INFO] visual_prompt:  448: Inference (val):avg data time: 7.54e-05, avg batch time: 0.1198, average loss: 0.6232
[09/25 01:28:54][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 83.83	top5: 97.33	
[09/25 01:29:08][INFO] visual_prompt:  448: Inference (test):avg data time: 6.71e-05, avg batch time: 0.1264, average loss: 0.6186
[09/25 01:29:08][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.69	top5: 97.26	
[09/25 01:29:08][INFO] visual_prompt:  266: Training 28 / 100 epoch, with learning rate 1.143148482846901
[09/25 01:30:38][INFO] visual_prompt:  334: Epoch 28 / 100: avg data time: 2.05e-02, avg batch time: 1.0579, average train loss: 0.0220average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:30:41][INFO] visual_prompt:  448: Inference (val):avg data time: 8.12e-05, avg batch time: 0.1192, average loss: 0.6273
[09/25 01:30:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.00	top5: 96.83	
[09/25 01:30:55][INFO] visual_prompt:  448: Inference (test):avg data time: 8.29e-05, avg batch time: 0.1264, average loss: 0.6286
[09/25 01:30:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.73	top5: 97.26	
[09/25 01:30:55][INFO] visual_prompt:  266: Training 29 / 100 epoch, with learning rate 1.130635621484342
[09/25 01:32:25][INFO] visual_prompt:  334: Epoch 29 / 100: avg data time: 2.00e-02, avg batch time: 1.0573, average train loss: 0.0249average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:32:27][INFO] visual_prompt:  448: Inference (val):avg data time: 5.21e-05, avg batch time: 0.1204, average loss: 0.6255
[09/25 01:32:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 96.67	
[09/25 01:32:41][INFO] visual_prompt:  448: Inference (test):avg data time: 6.75e-05, avg batch time: 0.1267, average loss: 0.6340
[09/25 01:32:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.45	top5: 97.15	
[09/25 01:32:41][INFO] visual_prompt:  266: Training 30 / 100 epoch, with learning rate 1.1175067210042011
[09/25 01:34:11][INFO] visual_prompt:  334: Epoch 30 / 100: avg data time: 2.00e-02, avg batch time: 1.0575, average train loss: 0.0264average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:34:13][INFO] visual_prompt:  448: Inference (val):avg data time: 6.57e-05, avg batch time: 0.1201, average loss: 0.6497
[09/25 01:34:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 97.33	
[09/25 01:34:28][INFO] visual_prompt:  448: Inference (test):avg data time: 9.75e-05, avg batch time: 0.1265, average loss: 0.6400
[09/25 01:34:28][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.71	top5: 97.13	
[09/25 01:34:28][INFO] visual_prompt:  266: Training 31 / 100 epoch, with learning rate 1.1037777769493613
[09/25 01:35:58][INFO] visual_prompt:  334: Epoch 31 / 100: avg data time: 1.89e-02, avg batch time: 1.0565, average train loss: 0.0245average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:36:00][INFO] visual_prompt:  448: Inference (val):avg data time: 6.69e-05, avg batch time: 0.1196, average loss: 0.6327
[09/25 01:36:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 97.00	
[09/25 01:36:14][INFO] visual_prompt:  448: Inference (test):avg data time: 1.77e-04, avg batch time: 0.1269, average loss: 0.6218
[09/25 01:36:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.69	top5: 97.01	
[09/25 01:36:14][INFO] visual_prompt:  266: Training 32 / 100 epoch, with learning rate 1.0894655159233715
[09/25 01:37:44][INFO] visual_prompt:  334: Epoch 32 / 100: avg data time: 1.99e-02, avg batch time: 1.0578, average train loss: 0.0180average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:37:46][INFO] visual_prompt:  448: Inference (val):avg data time: 6.46e-05, avg batch time: 0.1202, average loss: 0.6440
[09/25 01:37:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 96.50	
[09/25 01:38:00][INFO] visual_prompt:  448: Inference (test):avg data time: 8.90e-05, avg batch time: 0.1266, average loss: 0.6374
[09/25 01:38:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.61	top5: 97.03	
[09/25 01:38:00][INFO] visual_prompt:  266: Training 33 / 100 epoch, with learning rate 1.074587375211657
[09/25 01:39:30][INFO] visual_prompt:  334: Epoch 33 / 100: avg data time: 1.92e-02, avg batch time: 1.0557, average train loss: 0.0191average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:39:32][INFO] visual_prompt:  448: Inference (val):avg data time: 8.68e-05, avg batch time: 0.1191, average loss: 0.6049
[09/25 01:39:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 97.17	
[09/25 01:39:46][INFO] visual_prompt:  448: Inference (test):avg data time: 9.14e-05, avg batch time: 0.1265, average loss: 0.6213
[09/25 01:39:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.64	top5: 97.00	
[09/25 01:39:46][INFO] visual_prompt:  266: Training 34 / 100 epoch, with learning rate 1.0591614815368733
[09/25 01:41:16][INFO] visual_prompt:  334: Epoch 34 / 100: avg data time: 2.00e-02, avg batch time: 1.0553, average train loss: 0.0174average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:41:19][INFO] visual_prompt:  448: Inference (val):avg data time: 7.41e-05, avg batch time: 0.1191, average loss: 0.6447
[09/25 01:41:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 97.00	
[09/25 01:41:32][INFO] visual_prompt:  448: Inference (test):avg data time: 7.84e-05, avg batch time: 0.1263, average loss: 0.6331
[09/25 01:41:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.74	top5: 97.13	
[09/25 01:41:32][INFO] visual_prompt:  266: Training 35 / 100 epoch, with learning rate 1.0432066289742865
[09/25 01:43:02][INFO] visual_prompt:  334: Epoch 35 / 100: avg data time: 1.83e-02, avg batch time: 1.0519, average train loss: 0.0230average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:43:04][INFO] visual_prompt:  448: Inference (val):avg data time: 6.19e-05, avg batch time: 0.1190, average loss: 0.6313
[09/25 01:43:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 97.00	
[09/25 01:43:18][INFO] visual_prompt:  448: Inference (test):avg data time: 7.55e-05, avg batch time: 0.1262, average loss: 0.6300
[09/25 01:43:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.74	top5: 97.05	
[09/25 01:43:18][INFO] visual_prompt:  266: Training 36 / 100 epoch, with learning rate 1.026742256054087
[09/25 01:44:48][INFO] visual_prompt:  334: Epoch 36 / 100: avg data time: 1.87e-02, avg batch time: 1.0515, average train loss: 0.0163average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:44:50][INFO] visual_prompt:  448: Inference (val):avg data time: 6.96e-05, avg batch time: 0.1191, average loss: 0.6403
[09/25 01:44:50][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 96.83	
[09/25 01:45:04][INFO] visual_prompt:  448: Inference (test):avg data time: 7.79e-05, avg batch time: 0.1260, average loss: 0.6330
[09/25 01:45:04][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.67	top5: 96.98	
[09/25 01:45:04][INFO] visual_prompt:  266: Training 37 / 100 epoch, with learning rate 1.0097884220785365
[09/25 01:46:34][INFO] visual_prompt:  334: Epoch 37 / 100: avg data time: 2.01e-02, avg batch time: 1.0532, average train loss: 0.0130average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:46:36][INFO] visual_prompt:  448: Inference (val):avg data time: 9.68e-05, avg batch time: 0.1189, average loss: 0.6456
[09/25 01:46:36][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.17	top5: 96.83	
[09/25 01:46:50][INFO] visual_prompt:  448: Inference (test):avg data time: 9.02e-05, avg batch time: 0.1260, average loss: 0.6456
[09/25 01:46:50][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.66	top5: 96.96	
[09/25 01:46:50][INFO] visual_prompt:  266: Training 38 / 100 epoch, with learning rate 0.9923657826827957
[09/25 01:48:20][INFO] visual_prompt:  334: Epoch 38 / 100: avg data time: 2.08e-02, avg batch time: 1.0544, average train loss: 0.0151average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:48:22][INFO] visual_prompt:  448: Inference (val):avg data time: 7.25e-05, avg batch time: 0.1194, average loss: 0.6248
[09/25 01:48:22][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 96.83	
[09/25 01:48:36][INFO] visual_prompt:  448: Inference (test):avg data time: 8.85e-05, avg batch time: 0.1260, average loss: 0.6337
[09/25 01:48:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.50	top5: 97.08	
[09/25 01:48:37][INFO] visual_prompt:  266: Training 39 / 100 epoch, with learning rate 0.9744955646692167
[09/25 01:50:06][INFO] visual_prompt:  334: Epoch 39 / 100: avg data time: 1.82e-02, avg batch time: 1.0523, average train loss: 0.0152average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:50:09][INFO] visual_prompt:  448: Inference (val):avg data time: 6.03e-05, avg batch time: 0.1197, average loss: 0.6402
[09/25 01:50:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 96.83	
[09/25 01:50:22][INFO] visual_prompt:  448: Inference (test):avg data time: 8.17e-05, avg batch time: 0.1263, average loss: 0.6420
[09/25 01:50:22][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.21	top5: 97.07	
[09/25 01:50:22][INFO] visual_prompt:  266: Training 40 / 100 epoch, with learning rate 0.956199540145753
[09/25 01:51:52][INFO] visual_prompt:  334: Epoch 40 / 100: avg data time: 2.05e-02, avg batch time: 1.0555, average train loss: 0.0125average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:51:55][INFO] visual_prompt:  448: Inference (val):avg data time: 7.26e-05, avg batch time: 0.1197, average loss: 0.6087
[09/25 01:51:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 96.67	
[09/25 01:52:09][INFO] visual_prompt:  448: Inference (test):avg data time: 7.92e-05, avg batch time: 0.1264, average loss: 0.6285
[09/25 01:52:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.92	top5: 97.08	
[09/25 01:52:09][INFO] visual_prompt:  266: Training 41 / 100 epoch, with learning rate 0.9375
[09/25 01:53:38][INFO] visual_prompt:  334: Epoch 41 / 100: avg data time: 1.87e-02, avg batch time: 1.0545, average train loss: 0.0131average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:53:41][INFO] visual_prompt:  448: Inference (val):avg data time: 7.16e-05, avg batch time: 0.1197, average loss: 0.6211
[09/25 01:53:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 97.00	
[09/25 01:53:55][INFO] visual_prompt:  448: Inference (test):avg data time: 9.13e-05, avg batch time: 0.1265, average loss: 0.6270
[09/25 01:53:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.76	top5: 97.17	
[09/25 01:53:55][INFO] visual_prompt:  266: Training 42 / 100 epoch, with learning rate 0.9184197267411818
[09/25 01:55:25][INFO] visual_prompt:  334: Epoch 42 / 100: avg data time: 2.19e-02, avg batch time: 1.0579, average train loss: 0.0112average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:55:27][INFO] visual_prompt:  448: Inference (val):avg data time: 5.62e-05, avg batch time: 0.1203, average loss: 0.6175
[09/25 01:55:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 97.33	
[09/25 01:55:41][INFO] visual_prompt:  448: Inference (test):avg data time: 7.80e-05, avg batch time: 0.1266, average loss: 0.6280
[09/25 01:55:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.64	top5: 97.13	
[09/25 01:55:41][INFO] visual_prompt:  266: Training 43 / 100 epoch, with learning rate 0.8989819667431733
[09/25 01:57:11][INFO] visual_prompt:  334: Epoch 43 / 100: avg data time: 2.31e-02, avg batch time: 1.0601, average train loss: 0.0111average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:57:14][INFO] visual_prompt:  448: Inference (val):avg data time: 5.99e-05, avg batch time: 0.1196, average loss: 0.6431
[09/25 01:57:14][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 96.50	
[09/25 01:57:27][INFO] visual_prompt:  448: Inference (test):avg data time: 7.60e-05, avg batch time: 0.1266, average loss: 0.6453
[09/25 01:57:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.52	top5: 97.08	
[09/25 01:57:27][INFO] visual_prompt:  266: Training 44 / 100 epoch, with learning rate 0.8792104019223752
[09/25 01:58:57][INFO] visual_prompt:  334: Epoch 44 / 100: avg data time: 1.97e-02, avg batch time: 1.0567, average train loss: 0.0122average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 01:59:00][INFO] visual_prompt:  448: Inference (val):avg data time: 7.05e-05, avg batch time: 0.1201, average loss: 0.6326
[09/25 01:59:00][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 96.50	
[09/25 01:59:14][INFO] visual_prompt:  448: Inference (test):avg data time: 8.73e-05, avg batch time: 0.1265, average loss: 0.6309
[09/25 01:59:14][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.97	top5: 97.17	
[09/25 01:59:14][INFO] visual_prompt:  266: Training 45 / 100 epoch, with learning rate 0.8591291208849451
[09/25 02:00:44][INFO] visual_prompt:  334: Epoch 45 / 100: avg data time: 1.97e-02, avg batch time: 1.0572, average train loss: 0.0128average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:00:46][INFO] visual_prompt:  448: Inference (val):avg data time: 6.12e-05, avg batch time: 0.1198, average loss: 0.6299
[09/25 02:00:46][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 97.00	
[09/25 02:01:00][INFO] visual_prompt:  448: Inference (test):avg data time: 6.68e-05, avg batch time: 0.1268, average loss: 0.6322
[09/25 02:01:00][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.09	top5: 97.17	
[09/25 02:01:00][INFO] visual_prompt:  266: Training 46 / 100 epoch, with learning rate 0.8387625895785431
[09/25 02:02:30][INFO] visual_prompt:  334: Epoch 46 / 100: avg data time: 1.85e-02, avg batch time: 1.0564, average train loss: 0.0117average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:02:32][INFO] visual_prompt:  448: Inference (val):avg data time: 7.54e-05, avg batch time: 0.1203, average loss: 0.6255
[09/25 02:02:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 96.50	
[09/25 02:02:46][INFO] visual_prompt:  448: Inference (test):avg data time: 8.28e-05, avg batch time: 0.1269, average loss: 0.6354
[09/25 02:02:46][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.05	top5: 97.15	
[09/25 02:02:46][INFO] visual_prompt:  266: Training 47 / 100 epoch, with learning rate 0.8181356214843422
[09/25 02:04:16][INFO] visual_prompt:  334: Epoch 47 / 100: avg data time: 1.94e-02, avg batch time: 1.0572, average train loss: 0.0133average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:04:19][INFO] visual_prompt:  448: Inference (val):avg data time: 8.93e-05, avg batch time: 0.1192, average loss: 0.6134
[09/25 02:04:19][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 96.67	
[09/25 02:04:33][INFO] visual_prompt:  448: Inference (test):avg data time: 8.15e-05, avg batch time: 0.1264, average loss: 0.6324
[09/25 02:04:33][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.07	top5: 97.19	
[09/25 02:04:33][INFO] visual_prompt:  266: Training 48 / 100 epoch, with learning rate 0.7972733473856244
[09/25 02:06:03][INFO] visual_prompt:  334: Epoch 48 / 100: avg data time: 1.93e-02, avg batch time: 1.0559, average train loss: 0.0096average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:06:05][INFO] visual_prompt:  448: Inference (val):avg data time: 6.05e-05, avg batch time: 0.1208, average loss: 0.6074
[09/25 02:06:05][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 96.50	
[09/25 02:06:19][INFO] visual_prompt:  448: Inference (test):avg data time: 7.76e-05, avg batch time: 0.1265, average loss: 0.6247
[09/25 02:06:19][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.81	top5: 97.13	
[09/25 02:06:19][INFO] visual_prompt:  266: Training 49 / 100 epoch, with learning rate 0.7762011847497923
[09/25 02:07:49][INFO] visual_prompt:  334: Epoch 49 / 100: avg data time: 1.98e-02, avg batch time: 1.0557, average train loss: 0.0096average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:07:51][INFO] visual_prompt:  448: Inference (val):avg data time: 1.04e-04, avg batch time: 0.1190, average loss: 0.6117
[09/25 02:07:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 96.33	
[09/25 02:08:05][INFO] visual_prompt:  448: Inference (test):avg data time: 8.03e-05, avg batch time: 0.1267, average loss: 0.6275
[09/25 02:08:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.12	top5: 97.17	
[09/25 02:08:05][INFO] visual_prompt:  266: Training 50 / 100 epoch, with learning rate 0.7549448067610995
[09/25 02:09:35][INFO] visual_prompt:  334: Epoch 50 / 100: avg data time: 2.03e-02, avg batch time: 1.0546, average train loss: 0.0091average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:09:37][INFO] visual_prompt:  448: Inference (val):avg data time: 6.45e-05, avg batch time: 0.1189, average loss: 0.6138
[09/25 02:09:37][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 96.83	
[09/25 02:09:51][INFO] visual_prompt:  448: Inference (test):avg data time: 9.25e-05, avg batch time: 0.1260, average loss: 0.6338
[09/25 02:09:51][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.99	top5: 97.08	
[09/25 02:09:51][INFO] visual_prompt:  266: Training 51 / 100 epoch, with learning rate 0.7335301110418315
[09/25 02:11:21][INFO] visual_prompt:  334: Epoch 51 / 100: avg data time: 1.97e-02, avg batch time: 1.0527, average train loss: 0.0084average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:11:23][INFO] visual_prompt:  448: Inference (val):avg data time: 5.67e-05, avg batch time: 0.1187, average loss: 0.6197
[09/25 02:11:23][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 96.67	
[09/25 02:11:37][INFO] visual_prompt:  448: Inference (test):avg data time: 6.44e-05, avg batch time: 0.1259, average loss: 0.6308
[09/25 02:11:37][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.12	top5: 97.26	
[09/25 02:11:37][INFO] visual_prompt:  266: Training 52 / 100 epoch, with learning rate 0.7119831881000409
[09/25 02:13:07][INFO] visual_prompt:  334: Epoch 52 / 100: avg data time: 2.00e-02, avg batch time: 1.0526, average train loss: 0.0081average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:13:09][INFO] visual_prompt:  448: Inference (val):avg data time: 7.31e-05, avg batch time: 0.1198, average loss: 0.6118
[09/25 02:13:09][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.50	top5: 96.83	
[09/25 02:13:23][INFO] visual_prompt:  448: Inference (test):avg data time: 8.30e-05, avg batch time: 0.1260, average loss: 0.6305
[09/25 02:13:23][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.07	top5: 97.13	
[09/25 02:13:23][INFO] visual_prompt:  266: Training 53 / 100 epoch, with learning rate 0.6903302895422835
[09/25 02:14:53][INFO] visual_prompt:  334: Epoch 53 / 100: avg data time: 1.96e-02, avg batch time: 1.0509, average train loss: 0.0077average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:14:55][INFO] visual_prompt:  448: Inference (val):avg data time: 5.96e-05, avg batch time: 0.1189, average loss: 0.6273
[09/25 02:14:55][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.83	top5: 96.50	
[09/25 02:15:09][INFO] visual_prompt:  448: Inference (test):avg data time: 7.81e-05, avg batch time: 0.1259, average loss: 0.6318
[09/25 02:15:09][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.99	top5: 97.19	
[09/25 02:15:09][INFO] visual_prompt:  266: Training 54 / 100 epoch, with learning rate 0.6685977960900782
[09/25 02:16:39][INFO] visual_prompt:  334: Epoch 54 / 100: avg data time: 2.21e-02, avg batch time: 1.0546, average train loss: 0.0095average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:16:41][INFO] visual_prompt:  448: Inference (val):avg data time: 6.87e-05, avg batch time: 0.1193, average loss: 0.6243
[09/25 02:16:41][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.33	top5: 96.67	
[09/25 02:16:55][INFO] visual_prompt:  448: Inference (test):avg data time: 7.17e-05, avg batch time: 0.1261, average loss: 0.6305
[09/25 02:16:55][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.95	top5: 97.17	
[09/25 02:16:55][INFO] visual_prompt:  266: Training 55 / 100 epoch, with learning rate 0.6468121854390632
[09/25 02:18:25][INFO] visual_prompt:  334: Epoch 55 / 100: avg data time: 2.06e-02, avg batch time: 1.0542, average train loss: 0.0091average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:18:27][INFO] visual_prompt:  448: Inference (val):avg data time: 7.98e-05, avg batch time: 0.1191, average loss: 0.6197
[09/25 02:18:27][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 84.67	top5: 96.33	
[09/25 02:18:41][INFO] visual_prompt:  448: Inference (test):avg data time: 1.06e-04, avg batch time: 0.1264, average loss: 0.6309
[09/25 02:18:41][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.30	top5: 97.17	
[09/25 02:18:41][INFO] visual_prompt:  266: Training 56 / 100 epoch, with learning rate 0.625
[09/25 02:20:11][INFO] visual_prompt:  334: Epoch 56 / 100: avg data time: 2.06e-02, avg batch time: 1.0547, average train loss: 0.0085average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:20:13][INFO] visual_prompt:  448: Inference (val):avg data time: 5.63e-05, avg batch time: 0.1196, average loss: 0.6195
[09/25 02:20:13][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.67	top5: 96.50	
[09/25 02:20:27][INFO] visual_prompt:  448: Inference (test):avg data time: 7.65e-05, avg batch time: 0.1262, average loss: 0.6302
[09/25 02:20:27][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.09	top5: 97.10	
[09/25 02:20:27][INFO] visual_prompt:  266: Training 57 / 100 epoch, with learning rate 0.6031878145609371
[09/25 02:21:57][INFO] visual_prompt:  334: Epoch 57 / 100: avg data time: 2.21e-02, avg batch time: 1.0567, average train loss: 0.0094average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:21:59][INFO] visual_prompt:  448: Inference (val):avg data time: 6.86e-05, avg batch time: 0.1189, average loss: 0.6211
[09/25 02:21:59][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 96.67	
[09/25 02:22:13][INFO] visual_prompt:  448: Inference (test):avg data time: 8.42e-05, avg batch time: 0.1265, average loss: 0.6282
[09/25 02:22:13][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.88	top5: 97.08	
[09/25 02:22:13][INFO] visual_prompt:  266: Training 58 / 100 epoch, with learning rate 0.5814022039099217
[09/25 02:23:43][INFO] visual_prompt:  334: Epoch 58 / 100: avg data time: 1.87e-02, avg batch time: 1.0541, average train loss: 0.0091average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:23:45][INFO] visual_prompt:  448: Inference (val):avg data time: 6.48e-05, avg batch time: 0.1189, average loss: 0.6085
[09/25 02:23:45][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.83	top5: 96.67	
[09/25 02:23:59][INFO] visual_prompt:  448: Inference (test):avg data time: 8.00e-05, avg batch time: 0.1262, average loss: 0.6310
[09/25 02:23:59][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.85	top5: 97.12	
[09/25 02:23:59][INFO] visual_prompt:  370: Best epoch 58: best metric: 0.858
[09/25 02:23:59][INFO] visual_prompt:  266: Training 59 / 100 epoch, with learning rate 0.5596697104577166
[09/25 02:25:29][INFO] visual_prompt:  334: Epoch 59 / 100: avg data time: 1.91e-02, avg batch time: 1.0548, average train loss: 0.0089average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:25:32][INFO] visual_prompt:  448: Inference (val):avg data time: 6.51e-05, avg batch time: 0.1193, average loss: 0.6134
[09/25 02:25:32][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.50	top5: 96.67	
[09/25 02:25:45][INFO] visual_prompt:  448: Inference (test):avg data time: 8.62e-05, avg batch time: 0.1265, average loss: 0.6338
[09/25 02:25:45][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 85.76	top5: 97.15	
[09/25 02:25:45][INFO] visual_prompt:  266: Training 60 / 100 epoch, with learning rate 0.5380168118999593
[09/25 02:27:15][INFO] visual_prompt:  334: Epoch 60 / 100: avg data time: 1.95e-02, avg batch time: 1.0558, average train loss: 0.0079average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:27:17][INFO] visual_prompt:  448: Inference (val):avg data time: 8.06e-05, avg batch time: 0.1193, average loss: 0.6197
[09/25 02:27:17][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 96.67	
[09/25 02:27:32][INFO] visual_prompt:  448: Inference (test):avg data time: 8.27e-05, avg batch time: 0.1263, average loss: 0.6315
[09/25 02:27:32][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.11	top5: 97.12	
[09/25 02:27:32][INFO] visual_prompt:  266: Training 61 / 100 epoch, with learning rate 0.5164698889581686
[09/25 02:29:02][INFO] visual_prompt:  334: Epoch 61 / 100: avg data time: 2.02e-02, avg batch time: 1.0570, average train loss: 0.0094average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:29:04][INFO] visual_prompt:  448: Inference (val):avg data time: 5.96e-05, avg batch time: 0.1195, average loss: 0.6240
[09/25 02:29:04][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.00	top5: 96.33	
[09/25 02:29:18][INFO] visual_prompt:  448: Inference (test):avg data time: 8.96e-05, avg batch time: 0.1267, average loss: 0.6314
[09/25 02:29:18][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.02	top5: 97.10	
[09/25 02:29:18][INFO] visual_prompt:  266: Training 62 / 100 epoch, with learning rate 0.4950551932389005
[09/25 02:30:48][INFO] visual_prompt:  334: Epoch 62 / 100: avg data time: 2.12e-02, avg batch time: 1.0582, average train loss: 0.0066average G loss: 10.0000, average realD loss: 0.0000, average fakeD loss: 10.0000, 
[09/25 02:30:51][INFO] visual_prompt:  448: Inference (val):avg data time: 8.62e-05, avg batch time: 0.1194, average loss: 0.6203
[09/25 02:30:51][INFO] visual_prompt:  113: Classification results with val_CUB: top1: 85.33	top5: 96.67	
[09/25 02:31:05][INFO] visual_prompt:  448: Inference (test):avg data time: 8.34e-05, avg batch time: 0.1265, average loss: 0.6333
[09/25 02:31:05][INFO] visual_prompt:  113: Classification results with test_CUB: top1: 86.04	top5: 97.12	
[09/25 02:31:05][INFO] visual_prompt:  266: Training 63 / 100 epoch, with learning rate 0.4737988152502077
